Sensitivity auditing is an extension of sensitivity analysis for use in policy-relevant modelling studies. Its use is recommended - e.g. in the European Commission Impact assessment guidelines   - when a sensitivity analysis (SA) of a model-based study is meant to demonstrate the robustness of the evidence provided by the model, but in a context where the inference feeds into a policy or decision-making process.  In these cases, the framing of the analysis itself, its institutional context, and the motivations of its author may become highly relevant, and a pure SA - with its focus on parametric (i.e. quantified) uncertainty - may be insufficient. The emphasis on the framing may, among other things, derive from the relevance of the policy study to different constituencies that are characterized by different norms and values, and hence by a different story about `what the problem is' and foremost about `who is telling the story'. Most often the framing includes implicit assumptions, which could be political (e.g. which group needs to be protected) all the way to technical (e.g. which variable can be treated as a constant). In order to take these concerns into due consideration, sensitivity auditing extends the instruments of sensitivity analysis to provide an assessment of the entire knowledge- and model-generating process. It takes inspiration from NUSAP,  a method used to qualify the worth (quality) of quantitative information with the generation of `Pedigrees' of numbers. Likewise, sensitivity auditing has been developed to provide pedigrees of models and model-based inferences.  Sensitivity auditing is especially suitable in an adversarial context, where not only the nature of the evidence, but also the degree of certainty and uncertainty associated to the evidence, is the subject of partisan interests. These are the settings considered in Post-normal science   or in Mode 2  science. Post-normal science (PNS) is a concept developed by Silvio Funtowicz and Jerome Ravetz,    which proposes a methodology of inquiry that is appropriate when “facts are uncertain, values in dispute, stakes high and decisions urgent” (Funtowicz and Ravetz, 1992:  251–273). Mode 2 Science, coined in 1994 by Gibbons et al., refers to a mode of production of scientific knowledge that is context-driven, problem-focused and interdisciplinary. Carrozza (2015)  offers a discussion of these concepts and approaches. Sensitivity auditing is recommended by the European Commission for use in impact assessments in order to improve the quality of model-based evidence used to support policy decisions.  Sensitivity auditing is summarised by seven rules or guiding principles: The first rule looks at the instrumental use of mathematical modeling to advance one's agenda. This use is called rhetorical, or strategic, like the use of Latin to confuse or obfuscate an interlocutor. The second rule about `assumption hunting' is a reminder to look for what was assumed when the model was originally framed. Modes are full of ceteris paribus assumptions. For example, in economics, the model can predict the result of a shock to a given set of equations, assuming that all the rest - all other input variables and inputs - remain equal, but in real life "ceteris" are never "paribus", meaning that variables tend to be linked with one another, so they cannot realistically change independently of one another. Rule three is about artificially exaggerating or playing down uncertainties wherever convenient. The tobacco lobbies exaggerated the uncertainties about the health effects of smoking according to Oreskes and Conway,  while advocates of the death penalty played down the uncertainties in the negative relations between capital punishment and crime rate.  Clearly the latter wanted the policy, in this case the death penalty, and were interested in showing that the supporting evidence was robust. In the former case the lobbies did not want regulation (e.g. bans on tobacco smoking in public places) and were hence interested in amplifying the uncertainty in the smoking-health effect causality relationship. Rule four is about `confessing' uncertainties before going public with the analysis. This rule is also one of the commandments of applied econometrics according to Kennedy:  `Thou shall confess in the presence of sensitivity. Corollary: Thou shall anticipate criticism'. According to this rule, a sensitivity analysis should be performed before the results of a modeling study are published. There are many good reasons for doing this, one being that a carefully performed sensitivity analysis often uncovers plain coding mistakes or model inadequacies. The other is that, more often than not, the analysis reveals uncertainties that are larger than those anticipated by the model developers. Rule five is about presenting the results of the modeling study in a transparent fashion. Both rules originate from the practice of impact assessment, where a modeling study presented without a proper SA, or as originating from a model which is in fact a black box, may end up being rejected by stakeholders.  Both rules four and five suggest that reproducibility may be a condition for transparency and that this latter may be a condition for legitimacy.  Rule six, about doing the right sum, is not far from the `assumption-hunting' rule; it is just more general. It deals with the fact that often an analyst is set to work on an analysis arbitrarily framed to the advantage of a party. Sometime this comes via the choice of the discipline selected to do the analysis. Thus an environmental impact problem may be framed through the lenses of economics, and presented as a cost benefit or risk analysis, while the issue has little to do with costs or benefits or risks and a lot to do with profits, controls, and norms. An example is in Marris et al.  on the issue of GMOs, mostly presented in the public discourse as a food safety issue while the spectrum of concerns of GMO opponents - including lay citizens - appears broader. Rule seven is about avoiding a perfunctory sensitivity analysis. A SA where each uncertain input is moved at a time while leaving all other inputs fixed is perfunctory.  A true SA should make an honest effort at exploring all uncertainties simultaneously, leaving the model free to display its full nonlinear and possibly non-additive behaviour. A similar point is made in Sam L. Savage's book `The flaw of averages'.  In conclusion, these rules are meant to help an analyst to anticipate criticism, in particular relating to model-based inference feeding into an impact assessment. What questions and objections may be received by the modeler? Here is a possible list: Sensitivity auditing is described in the European Commission Guidelines for impact assessment  . Relevants excerpts are (pp. 392):   