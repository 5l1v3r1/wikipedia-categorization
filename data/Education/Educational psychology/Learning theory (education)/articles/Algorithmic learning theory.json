{"parse":{"title":"Algorithmic learning theory","pageid":383480,"revid":847015181,"text":{"*":"<div class=\"mw-parser-output\"><p><b>Algorithmic learning theory</b> is a mathematical framework for analyzing \n<a href=\"/wiki/Machine_learning\" title=\"Machine learning\">machine learning</a> problems and algorithms. Synonyms include <b>formal learning theory</b> and <b>algorithmic inductive inference</b>. Algorithmic learning theory is different from <a href=\"/wiki/Statistical_learning_theory\" title=\"Statistical learning theory\">statistical learning theory</a> in that it does not make use of statistical assumptions and analysis. Both algorithmic and statistical learning theory are concerned with machine learning and can thus be viewed as branches of <a href=\"/wiki/Computational_learning_theory\" title=\"Computational learning theory\">computational learning theory</a>.\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Distinguishing_characteristics\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Distinguishing characteristics</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Learning_in_the_limit\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Learning in the limit</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#Other_identification_criteria\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Other identification criteria</span></a></li>\n<li class=\"toclevel-1 tocsection-4\"><a href=\"#See_also\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-5\"><a href=\"#References\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#External_links\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"Distinguishing_characteristics\">Distinguishing characteristics</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Algorithmic_learning_theory&amp;action=edit&amp;section=1\" title=\"Edit section: Distinguishing characteristics\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Unlike statistical learning theory and most statistical theory in general, algorithmic learning theory does not assume that data are random samples, that is, that data points are independent of each other. This makes the theory suitable for domains where observations are (relatively) noise-free but not random, such as language learning <sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\">&#91;1&#93;</a></sup> and automated scientific discovery.<sup id=\"cite_ref-2\" class=\"reference\"><a href=\"#cite_note-2\">&#91;2&#93;</a></sup><sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">&#91;3&#93;</a></sup>\n</p><p>The fundamental concept of algorithmic learning theory is learning in the limit: as the number of data points increases, a learning algorithm should converge to a correct hypothesis on <i>every</i> possible data sequence consistent with the problem space. This is a non-probabilistic version of <a href=\"/wiki/Consistency_(statistics)\" title=\"Consistency (statistics)\">statistical consistency</a>, \nwhich also requires convergence to a correct model in the limit, but allows a learner to fail on data sequences with probability measure 0.\n</p><p>Algorithmic learning theory investigates the learning power of <a href=\"/wiki/Turing_machine\" title=\"Turing machine\">Turing machines</a>. Other frameworks consider a much more restricted class of  learning algorithms than Turing machines, for example learners that compute hypotheses more quickly, for instance in <a href=\"/wiki/Polynomial_time\" class=\"mw-redirect\" title=\"Polynomial time\">polynomial time</a>. An example of such a framework is <a href=\"/wiki/Probably_approximately_correct_learning\" title=\"Probably approximately correct learning\">probably approximately correct learning</a>.\n</p>\n<h2><span class=\"mw-headline\" id=\"Learning_in_the_limit\">Learning in the limit</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Algorithmic_learning_theory&amp;action=edit&amp;section=2\" title=\"Edit section: Learning in the limit\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>The concept was introduced in <a href=\"/w/index.php?title=E._Mark_Gold&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"E. Mark Gold (page does not exist)\">E. Mark Gold</a>'s seminal paper \"<a href=\"/wiki/Language_identification_in_the_limit\" title=\"Language identification in the limit\">Language identification in the limit</a>\".<sup id=\"cite_ref-4\" class=\"reference\"><a href=\"#cite_note-4\">&#91;4&#93;</a></sup> The objective of <a href=\"/wiki/Language_identification\" title=\"Language identification\">language identification</a> is for a machine running one program to be capable of developing another program by which any given sentence can be tested to determine whether it is \"grammatical\" or \"ungrammatical\". The language being learned need not be <a href=\"/wiki/English_language\" title=\"English language\">English</a> or any other <a href=\"/wiki/Natural_language\" title=\"Natural language\">natural language</a> - in fact the definition of \"grammatical\" can be absolutely anything known to the tester.\n</p><p>In Gold's learning model, the tester gives the learner an example sentence at each step, and the learner responds with a <a href=\"/wiki/Hypothesis\" title=\"Hypothesis\">hypothesis</a>, which is a suggested <a href=\"/wiki/Computer_program\" title=\"Computer program\">program</a> to determine grammatical correctness. It is required of the tester that every possible sentence (grammatical or not) appears in the list eventually, but no particular order is required. It is required of the learner that at each step the hypothesis must be correct for all the sentences so far.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"In his paper &#39;Language Identification in the Limit&#39;, Gold did not require this, see the definition of &#39;Learnability&#39; on p.449. (November 2013)\">citation needed</span></a></i>&#93;</sup>\n</p><p>A particular learner is said to be able to \"learn a language in the limit\" if there is a certain number of steps beyond which its hypothesis no longer changes.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"Gold additionally required the hypothesis to be correct, see previous &#39;citation needed&#39; remark. (November 2013)\">citation needed</span></a></i>&#93;</sup> At this point it has indeed learned the language, because every possible sentence appears somewhere in the sequence of inputs (past or future), and the hypothesis is correct for all inputs (past or future), so the hypothesis is correct for every sentence. The learner is not required to be able to tell when it has reached a correct hypothesis, all that is required is that it be true.\n</p><p>Gold showed that any language which is defined by a <a href=\"/wiki/Turing_machine\" title=\"Turing machine\">Turing machine</a> program can be learned in the limit by another <a href=\"/wiki/Turing-complete\" class=\"mw-redirect\" title=\"Turing-complete\">Turing-complete</a> machine using <a href=\"/wiki/Enumeration\" title=\"Enumeration\">enumeration</a>.<sup class=\"noprint Inline-Template\" style=\"margin-left:0.1em; white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Please_clarify\" title=\"Wikipedia:Please clarify\"><span title=\"Gold introduces a methode called &#39;identification by enumeration&#39; (p.458), but he didn&#39;t claim that each language &#39;defined by a Turing machine program can be learned&#39; by that method, or by any other. Such a result would contradict the unlearnability result stated in the next section of this article. (November 2013)\">clarification needed</span></a></i>&#93;</sup> This is done by the learner testing all possible Turing machine programs in turn until one is found which is correct so far - this forms the hypothesis for the current step. Eventually, the correct program will be reached, after which the hypothesis will never change again (but note that the learner does not know that it won't need to change).\n</p><p>Gold also showed that if the learner is given only positive examples (that is, only grammatical sentences appear in the input, not ungrammatical sentences), then the language can only be guaranteed to be learned in the limit if there are only a <a href=\"/wiki/Finite_set\" title=\"Finite set\">finite</a> number of possible sentences in the language (this is possible if, for example, sentences are known to be of limited length).<sup class=\"noprint Inline-Template\" style=\"margin-left:0.1em; white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Please_clarify\" title=\"Wikipedia:Please clarify\"><span title=\"The problem Gold investigated is not about learning a language, but about learning a language class. For example, it is trivial to learn an infinite language L from a class consisting of L only.) Gold&#39;s result meant here is probably that of his Theorem I.8 (p.470). The paragraph should be repharsed accordingly. (November 2013)\">clarification needed</span></a></i>&#93;</sup>\n</p><p>Language identification in the limit is a highly abstract model. It does not allow for limits of <a href=\"/wiki/Run_time_(program_lifecycle_phase)\" title=\"Run time (program lifecycle phase)\">runtime</a> or <a href=\"/wiki/Computer_memory\" title=\"Computer memory\">computer memory</a> which can occur in practice, and the enumeration method may fail if there are errors in the input. However the framework is very powerful, because if these strict conditions are maintained, it allows the learning of any program known to be computable. This is because a Turing machine program can be written to mimic any program in any conventional <a href=\"/wiki/Programming_language\" title=\"Programming language\">programming language</a>. See <a href=\"/wiki/Church-Turing_thesis\" class=\"mw-redirect\" title=\"Church-Turing thesis\">Church-Turing thesis</a>.\n</p>\n<h2><span class=\"mw-headline\" id=\"Other_identification_criteria\">Other identification criteria</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Algorithmic_learning_theory&amp;action=edit&amp;section=3\" title=\"Edit section: Other identification criteria\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Learning theorists have investigated other learning criteria,<sup id=\"cite_ref-5\" class=\"reference\"><a href=\"#cite_note-5\">&#91;5&#93;</a></sup> such as the following.\n</p>\n<ul><li><i>Efficiency</i>: minimizing the number of data points required before convergence to a correct hypothesis.</li>\n<li><i>Mind Changes</i>: minimizing the number of hypothesis changes that occur before convergence.<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;6&#93;</a></sup></li></ul>\n<p>Mind change bounds are closely related to <a href=\"/wiki/Winnow_algorithm#Mistake_bounds\" class=\"mw-redirect\" title=\"Winnow algorithm\">mistake bounds</a> that are studied in <a href=\"/wiki/Statistical_learning_theory\" title=\"Statistical learning theory\">statistical learning theory</a>.<sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">&#91;7&#93;</a></sup>  Kevin Kelly has suggested that minimizing mind changes is closely related to choosing maximally simple hypotheses in the sense of <a href=\"/wiki/Occam%E2%80%99s_Razor\" class=\"mw-redirect\" title=\"Occam\u2019s Razor\">Occam\u2019s Razor</a>.<sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">&#91;8&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Algorithmic_learning_theory&amp;action=edit&amp;section=4\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a href=\"/wiki/Sample_exclusion_dimension\" title=\"Sample exclusion dimension\">Sample exclusion dimension</a></li></ul>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Algorithmic_learning_theory&amp;action=edit&amp;section=5\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap\"><ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\">Jain, S. et al (1999): <i>Systems That Learn</i>, 2nd ed. Cambridge, MA: MIT Press.</span>\n</li>\n<li id=\"cite_note-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-2\">^</a></b></span> <span class=\"reference-text\">Langley, P.; Simon, H.; Bradshaw, G. &amp; Zytkow, J. (1987), <i>Scientific Discovery: Computational Explorations of the Creative Processes</i>, MIT Press, Cambridge</span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\">Schulte, O. (2009), <i>Simultaneous Discovery of Conservation Laws and Hidden Particles With Smith Matrix Decomposition</i>, in Proceedings of the Twenty-First International Joint Conference on Artificial Intelligence (IJCAI-09), pp. 1481-1487</span>\n</li>\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\"><cite id=\"CITEREFGold1967\" class=\"citation\">Gold, E. Mark (1967), <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20090125120159/http://www.isrl.uiuc.edu/~amag/langev/paper/gold67limit.html\"><i>Language Identification in the Limit</i></a>, <b>10</b>, <a href=\"/wiki/Information_and_Control\" class=\"mw-redirect\" title=\"Information and Control\">Information and Control</a>, pp.&#160;447\u2013474, archived from <a rel=\"nofollow\" class=\"external text\" href=\"http://www.isrl.uiuc.edu/~amag/langev/paper/gold67limit.html\">the original</a> on 2009-01-25</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Language+Identification+in+the+Limit&amp;rft.pages=447-474&amp;rft.pub=Information+and+Control&amp;rft.date=1967&amp;rft.aulast=Gold&amp;rft.aufirst=E.+Mark&amp;rft_id=http%3A%2F%2Fwww.isrl.uiuc.edu%2F~amag%2Flangev%2Fpaper%2Fgold67limit.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAlgorithmic+learning+theory\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span> <a rel=\"nofollow\" class=\"external text\" href=\"http://www.isrl.uiuc.edu/~amag/langev/paper/gold67limit.html\">The original paper.</a> <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20090125120159/http://www.isrl.uiuc.edu/~amag/langev/paper/gold67limit.html\">Archived</a> 2009-01-25 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>.</span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\">Jain, S. et al (1999): <i>Systems That Learn</i>, 2nd ed. Cambridge, MA: MIT Press.</span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\">Luo, W. &amp; Schulte, O. (2005), <i>Mind Change Efficient Learning</i>, in Peter Auer &amp; Ron Meir, ed., Proceedings of the Conference on Learning Theory (COLT), pp. 398-412</span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\">Jain, S. and Sharma, A. (1999), <i>On a generalized notion of mistake bounds</i>, Proceedings of the Conference on Learning Theory (COLT), pp.249-256.</span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\">Kevin T. Kelly (2007), <i>Ockham\u2019s Razor, Empirical Complexity, and Truth-finding Efficiency</i>, Theoretical Computer Science, 383: 270-289.</span>\n</li>\n</ol></div></div>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Algorithmic_learning_theory&amp;action=edit&amp;section=6\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<style data-mw-deduplicate=\"TemplateStyles:r853264625\">.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li,.mw-parser-output .refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}</style><div class=\"refbegin\" style=\"\">\n<ul><li><a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20120125223248/http://www.learningtheory.org/\">Learning Theory in Computer Science.</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://plato.stanford.edu/entries/learning-formal/\">The Stanford Encyclopaedia of Philosophy</a> provides a highly accessible introduction to key concepts in algorithmic learning theory, especially as they apply to the philosophical problems of inductive inference.</li></ul>\n</div>\n\n<!-- \nNewPP limit report\nParsed by mw1249\nCached time: 20180909122928\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.184 seconds\nReal time usage: 0.233 seconds\nPreprocessor visited node count: 815/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 15759/2097152 bytes\nTemplate argument size: 3960/2097152 bytes\nHighest expansion depth: 11/40\nExpensive parser function count: 2/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 4626/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.103/10.000 seconds\nLua memory usage: 2.18 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  208.320      1 -total\n 33.70%   70.210      2 Template:Citation_needed\n 31.67%   65.969      4 Template:Delink\n 29.59%   61.639      2 Template:Clarify\n 28.49%   59.354      1 Template:Reflist\n 27.99%   58.304      2 Template:Fix-span\n 26.44%   55.078      2 Template:Fix\n 23.72%   49.419      2 Template:Replace\n 16.68%   34.747      1 Template:Citation\n 16.46%   34.292      8 Template:Category_handler\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:383480-0!canonical and timestamp 20180909122928 and revision id 847015181\n -->\n</div>"},"langlinks":[{"lang":"fa","url":"https://fa.wikipedia.org/wiki/%D8%AF%D8%B1%DB%8C%DA%86%D9%87_%D8%B1%D8%A7%DB%8C%D8%A7%D9%86%D8%B4%DB%8C","langname":"Persian","autonym":"\u0641\u0627\u0631\u0633\u06cc","*":"\u062f\u0631\u06cc\u0686\u0647 \u0631\u0627\u06cc\u0627\u0646\u0634\u06cc"},{"lang":"pt","url":"https://pt.wikipedia.org/wiki/Teoria_da_aprendizagem_algor%C3%ADtmica","langname":"Portuguese","autonym":"portugu\u00eas","*":"Teoria da aprendizagem algor\u00edtmica"}],"categories":[{"sortkey":"","hidden":"","*":"Webarchive_template_wayback_links"},{"sortkey":"Algorithmic Learning Theory","hidden":"","*":"All_articles_with_unsourced_statements"},{"sortkey":"Algorithmic Learning Theory","hidden":"","*":"Articles_with_unsourced_statements_from_November_2013"},{"sortkey":"Algorithmic Learning Theory","hidden":"","*":"Wikipedia_articles_needing_clarification_from_November_2013"},{"sortkey":"Algorithmic Learning Theory","*":"Computational_learning_theory"},{"sortkey":"Algorithmic Learning Theory","*":"Learning_theory_(education)"},{"sortkey":"Algorithmic Learning Theory","*":"Formal_languages"}],"links":[{"ns":14,"exists":"","*":"Category:Articles with unsourced statements from November 2013"},{"ns":14,"exists":"","*":"Category:Wikipedia articles needing clarification from November 2013"},{"ns":0,"exists":"","*":"Church-Turing thesis"},{"ns":0,"exists":"","*":"Computational learning theory"},{"ns":0,"exists":"","*":"Computer memory"},{"ns":0,"exists":"","*":"Computer program"},{"ns":0,"exists":"","*":"Consistency (statistics)"},{"ns":0,"exists":"","*":"English language"},{"ns":0,"exists":"","*":"Enumeration"},{"ns":0,"exists":"","*":"Finite set"},{"ns":0,"exists":"","*":"Hypothesis"},{"ns":0,"exists":"","*":"Information and Control"},{"ns":0,"exists":"","*":"Language identification"},{"ns":0,"exists":"","*":"Language identification in the limit"},{"ns":0,"exists":"","*":"Machine learning"},{"ns":0,"exists":"","*":"Natural language"},{"ns":0,"exists":"","*":"Occam\u2019s Razor"},{"ns":0,"exists":"","*":"Polynomial time"},{"ns":0,"exists":"","*":"Probably approximately correct learning"},{"ns":0,"exists":"","*":"Programming language"},{"ns":0,"exists":"","*":"Run time (program lifecycle phase)"},{"ns":0,"exists":"","*":"Sample exclusion dimension"},{"ns":0,"exists":"","*":"Statistical learning theory"},{"ns":0,"exists":"","*":"Turing-complete"},{"ns":0,"exists":"","*":"Turing machine"},{"ns":0,"exists":"","*":"Wayback Machine"},{"ns":0,"exists":"","*":"Winnow algorithm"},{"ns":0,"*":"E. Mark Gold"},{"ns":4,"exists":"","*":"Wikipedia:Citation needed"},{"ns":4,"exists":"","*":"Wikipedia:Please clarify"}],"templates":[{"ns":10,"exists":"","*":"Template:Citation needed"},{"ns":10,"exists":"","*":"Template:Fix"},{"ns":10,"exists":"","*":"Template:Category handler"},{"ns":10,"exists":"","*":"Template:Fix/category"},{"ns":10,"exists":"","*":"Template:Delink"},{"ns":10,"exists":"","*":"Template:Clarify"},{"ns":10,"exists":"","*":"Template:Fix-span"},{"ns":10,"exists":"","*":"Template:Replace"},{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Citation"},{"ns":10,"exists":"","*":"Template:Webarchive"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:Refbegin"},{"ns":10,"exists":"","*":"Template:Refbegin/styles.css"},{"ns":10,"exists":"","*":"Template:Refend"},{"ns":828,"exists":"","*":"Module:Unsubst"},{"ns":828,"exists":"","*":"Module:Category handler"},{"ns":828,"exists":"","*":"Module:Yesno"},{"ns":828,"exists":"","*":"Module:Category handler/data"},{"ns":828,"exists":"","*":"Module:Category handler/config"},{"ns":828,"exists":"","*":"Module:Category handler/shared"},{"ns":828,"exists":"","*":"Module:Category handler/blacklist"},{"ns":828,"exists":"","*":"Module:Namespace detect/data"},{"ns":828,"exists":"","*":"Module:Namespace detect/config"},{"ns":828,"exists":"","*":"Module:Arguments"},{"ns":828,"exists":"","*":"Module:Delink"},{"ns":828,"exists":"","*":"Module:No globals"},{"ns":828,"exists":"","*":"Module:String"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"},{"ns":828,"exists":"","*":"Module:Webarchive"},{"ns":828,"exists":"","*":"Module:Webarchive/data"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"}],"images":[],"externallinks":["https://web.archive.org/web/20090125120159/http://www.isrl.uiuc.edu/~amag/langev/paper/gold67limit.html","http://www.isrl.uiuc.edu/~amag/langev/paper/gold67limit.html","https://web.archive.org/web/20120125223248/http://www.learningtheory.org/","http://plato.stanford.edu/entries/learning-formal/"],"sections":[{"toclevel":1,"level":"2","line":"Distinguishing characteristics","number":"1","index":"1","fromtitle":"Algorithmic_learning_theory","byteoffset":519,"anchor":"Distinguishing_characteristics"},{"toclevel":1,"level":"2","line":"Learning in the limit","number":"2","index":"2","fromtitle":"Algorithmic_learning_theory","byteoffset":2291,"anchor":"Learning_in_the_limit"},{"toclevel":1,"level":"2","line":"Other identification criteria","number":"3","index":"3","fromtitle":"Algorithmic_learning_theory","byteoffset":7076,"anchor":"Other_identification_criteria"},{"toclevel":1,"level":"2","line":"See also","number":"4","index":"4","fromtitle":"Algorithmic_learning_theory","byteoffset":8272,"anchor":"See_also"},{"toclevel":1,"level":"2","line":"References","number":"5","index":"5","fromtitle":"Algorithmic_learning_theory","byteoffset":8318,"anchor":"References"},{"toclevel":1,"level":"2","line":"External links","number":"6","index":"6","fromtitle":"Algorithmic_learning_theory","byteoffset":8347,"anchor":"External_links"}],"parsewarnings":[],"displaytitle":"Algorithmic learning theory","iwlinks":[],"properties":[{"name":"defaultsort","*":"Algorithmic Learning Theory"},{"name":"wikibase_item","*":"Q4724364"}]}}