{"parse":{"title":"Computerized classification test","pageid":7955447,"revid":795078339,"text":{"*":"<div class=\"mw-parser-output\"><p>A <b>computerized classification test</b> (<b>CCT</b>) refers to, as its name would suggest, a <a href=\"/wiki/Test_(student_assessment)\" class=\"mw-redirect\" title=\"Test (student assessment)\">test</a> that is administered by <a href=\"/wiki/Computer\" title=\"Computer\">computer</a> for the purpose of <a href=\"/wiki/Classification_rule\" title=\"Classification rule\">classifying</a> examinees.  The most common CCT is a mastery test where the test classifies examinees as \"Pass\" or \"Fail,\" but the term also includes tests that classify examinees into more than two categories.  While the term may generally be considered to refer to all computer-administered tests for classification, it is usually used to refer to tests that are interactively administered or of variable-length, similar to <a href=\"/wiki/Computerized_adaptive_testing\" title=\"Computerized adaptive testing\">computerized adaptive testing</a> (CAT).  Like CAT, variable-length CCTs can accomplish the goal of the test (accurate classification) with a fraction of the number of items used in a conventional fixed-form test.\n</p><p>A CCT requires several components:\n</p>\n<ol><li>An <a href=\"/wiki/Item_bank\" title=\"Item bank\">item bank</a> calibrated with a psychometric model selected by the test designer</li>\n<li>A starting point</li>\n<li>An item selection <a href=\"/wiki/Algorithm\" title=\"Algorithm\">algorithm</a></li>\n<li>A termination criterion and scoring procedure</li></ol>\n<p>The starting point is not a topic of contention; research on CCT primarily investigates the application of different methods for the other three components.  <i>Note:</i> The termination criterion and scoring procedure are separate in CAT, but the same in CCT because the test is terminated when a classification is made.  Therefore, there are five components that must be specified to design a CAT.\n</p><p>An introduction to CCT is found in Thompson (2007)<sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\">&#91;1&#93;</a></sup> and a book by Parshall, Spray, Kalohn and Davey (2006).<sup id=\"cite_ref-2\" class=\"reference\"><a href=\"#cite_note-2\">&#91;2&#93;</a></sup>  A bibliography of published CCT research is found below.\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#How_it_works\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">How it works</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Psychometric_model\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Psychometric model</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#Starting_point\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Starting point</span></a></li>\n<li class=\"toclevel-1 tocsection-4\"><a href=\"#Item_selection\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Item selection</span></a></li>\n<li class=\"toclevel-1 tocsection-5\"><a href=\"#Termination_criterion\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">Termination criterion</span></a></li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#References\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-7\"><a href=\"#Bibliography_of_CCT_research\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">Bibliography of CCT research</span></a></li>\n<li class=\"toclevel-1 tocsection-8\"><a href=\"#External_links\"><span class=\"tocnumber\">8</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"How_it_works\">How it works</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computerized_classification_test&amp;action=edit&amp;section=1\" title=\"Edit section: How it works\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>A CCT is very similar to a CAT.  Items are administered one at a time to an examinee.  After the examinee responds to the item, the <a href=\"/wiki/Computer\" title=\"Computer\">computer</a> scores it and determines if the examinee is able to be classified yet.  If they are, the test is terminated and the examinee is classified.  If not, another item is administered.  This process repeats until the examinee is classified or another ending point is satisfied (all items in the bank have been administered, or a maximum test length is reached).\n</p>\n<h2><span class=\"mw-headline\" id=\"Psychometric_model\">Psychometric model</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computerized_classification_test&amp;action=edit&amp;section=2\" title=\"Edit section: Psychometric model\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Two approaches are available for the psychometric model of a CCT: <a href=\"/wiki/Classical_test_theory\" title=\"Classical test theory\">classical test theory</a> (CTT) and <a href=\"/wiki/Item_response_theory\" title=\"Item response theory\">item response theory</a>  (IRT).  Classical test theory assumes a state model because it is applied by determining item parameters for a sample of examinees determined to be in each category.  For instance, several hundred \"masters\" and several hundred \"nonmasters\" might be sampled to determine the difficulty and discrimination for each, but doing so requires that you be able to easily identify a distinct set of people that are in each group.  IRT, on the other hand, assumes a trait model; the knowledge or ability measured by the test is a continuum.  The classification groups will need to be more or less arbitrarily defined along the continuum, such as the use of a cutscore to demarcate masters and nonmasters, but the specification of item parameters assumes a trait model.\n</p><p>There are advantages and disadvantages to each.  CTT offers greater conceptual simplicity.  More importantly, CTT requires fewer examinees in the sample for calibration of item parameters to be used eventually in the design of the CCT, making it useful for smaller testing programs.  See Frick (1992)<sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">&#91;3&#93;</a></sup> for a description of a CTT-based CCT.  Most CCTs, however, utilize IRT.  IRT offers greater specificity, but the most important reason may be that the design of a CCT (and a CAT) is expensive, and is therefore more likely done by a large testing program with extensive resources.  Such a program would likely use IRT.\n</p>\n<h2><span class=\"mw-headline\" id=\"Starting_point\">Starting point</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computerized_classification_test&amp;action=edit&amp;section=3\" title=\"Edit section: Starting point\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>A CCT must have a specified starting point to enable certain algorithms.  If the <a href=\"/wiki/Sequential_probability_ratio_test\" title=\"Sequential probability ratio test\">sequential probability ratio test</a> is used as the termination criterion, it implicitly assumes a starting ratio of 1.0 (equal probability of the examinee being a master or nonmaster).  If the termination criterion is a <a href=\"/wiki/Confidence_interval\" title=\"Confidence interval\">confidence interval</a> approach, a specified starting point on theta must be specified.  Usually, this is 0.0, the center of the <a href=\"/wiki/Probability_distribution\" title=\"Probability distribution\">distribution</a>, but it could also be randomly drawn from a certain distribution if the parameters of the examinee distribution are known.  Also, previous information regarding an individual examinee, such as their score the last time they took the test (if re-taking) may be used.\n</p>\n<h2><span class=\"mw-headline\" id=\"Item_selection\">Item selection</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computerized_classification_test&amp;action=edit&amp;section=4\" title=\"Edit section: Item selection\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>In a CCT, items are selected for administration throughout the test, unlike the traditional method of administering a fixed set of items to all examinees.  While this is usually done by individual item, it can also be done in groups of items known as <a href=\"/wiki/Testlet\" class=\"mw-redirect\" title=\"Testlet\">testlets</a> (Leucht &amp; Nungester, 1996;<sup id=\"cite_ref-4\" class=\"reference\"><a href=\"#cite_note-4\">&#91;4&#93;</a></sup> Vos &amp; Glas, 2000<sup id=\"cite_ref-5\" class=\"reference\"><a href=\"#cite_note-5\">&#91;5&#93;</a></sup>).\n</p><p>Methods of item selection fall into two categories: cutscore-based and estimate-based.  Cutscore-based methods (also known as sequential selection) maximize the <a href=\"/wiki/Information\" title=\"Information\">information</a> provided by the item at the cutscore, or cutscores if there are more than one, regardless of the ability of the examinee.  Estimate-based methods (also known as adaptive selection) maximize information at the current estimate of examinee ability, regardless of the location of the cutscore.  Both work efficiently, but the efficiency depends in part on the termination criterion employed.  Because the <a href=\"/wiki/Sequential_probability_ratio_test\" title=\"Sequential probability ratio test\">sequential probability ratio test</a> only evaluates probabilities near the cutscore, cutscore-based item selection is more appropriate.  Because the <a href=\"/wiki/Confidence_interval\" title=\"Confidence interval\">confidence interval</a> termination criterion is centered around the examinees ability estimate, estimate-based item selection is more appropriate.  This is because the test will make a classification when the confidence interval is small enough to be completely above or below the cutscore (see below).  The confidence interval will be smaller when the standard error of measurement is smaller, and the standard error of measurement will be smaller when there is more information at the theta level of the examinee.\n</p>\n<h2><span class=\"mw-headline\" id=\"Termination_criterion\">Termination criterion</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computerized_classification_test&amp;action=edit&amp;section=5\" title=\"Edit section: Termination criterion\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>There are three termination criteria commonly used for CCTs.  <a href=\"/wiki/Bayesian_decision_theory\" class=\"mw-redirect\" title=\"Bayesian decision theory\">Bayesian decision theory</a> methods offer great flexibility by presenting an infinite choice of loss/utility structures and evaluation considerations, but also introduce greater arbitrariness.  A <a href=\"/wiki/Confidence_interval\" title=\"Confidence interval\">confidence interval</a> approach calculates a confidence interval around the examinee's current theta estimate at each point in the test, and classifies the examinee when the interval falls completely within a region of theta that defines a classification.  This was originally known as adaptive mastery testing (Kingsbury &amp; Weiss, 1983), but does not necessarily require adaptive item selection, nor is it limited to the two-classification mastery testing situation.  The <a href=\"/wiki/Sequential_probability_ratio_test\" title=\"Sequential probability ratio test\">sequential probability ratio test</a> (Reckase, 1983) defines the classification problem as a <a href=\"/wiki/Hypothesis_test\" class=\"mw-redirect\" title=\"Hypothesis test\">hypothesis test</a> that the examinee's theta is equal to a specified point above the cutscore or a specified point below the cutscore.\n</p>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computerized_classification_test&amp;action=edit&amp;section=6\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap\"><ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\">Thompson, N. A. (2007). A Practitioner\u2019s Guide for Variable-length Computerized Classification Testing. Practical Assessment Research &amp; Evaluation, 12(1). <a rel=\"nofollow\" class=\"external autonumber\" href=\"http://pareonline.net/getvn.asp?v=12&amp;n=1\">[1]</a></span>\n</li>\n<li id=\"cite_note-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-2\">^</a></b></span> <span class=\"reference-text\">\nParshall, C. G., Spray, J. A., Kalohn, J. C., &amp; Davey, T. (2006).  Practical considerations in computer-based testing.  New York: Springer.</span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\">Frick, T. (1992). Computerized Adaptive Mastery Tests as Expert Systems. Journal of Educational Computing Research, 8(2), 187-213.</span>\n</li>\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\">Luecht, R. M., &amp; Nungester, R. J. (1998). Some practical examples of computer-adaptive sequential testing. Journal of Educational Measurement, 35, 229-249.</span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\">Vos, H.J. &amp; Glas, C.A.W. (2000). Testlet-based adaptive mastery testing.  In van der Linden, W.J., and Glas, C.A.W. (Eds.) Computerized Adaptive Testing: Theory and Practice.</span>\n</li>\n</ol></div></div>\n<h2><span class=\"mw-headline\" id=\"Bibliography_of_CCT_research\">Bibliography of CCT research</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computerized_classification_test&amp;action=edit&amp;section=7\" title=\"Edit section: Bibliography of CCT research\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<style data-mw-deduplicate=\"TemplateStyles:r853264625\">.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li,.mw-parser-output .refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}</style><div class=\"refbegin\" style=\"\">\n<ul><li>Armitage, P. (1950). Sequential analysis with more than two alternative hypotheses, and its relation to discriminant function analysis. <a href=\"/wiki/Journal_of_the_Royal_Statistical_Society\" title=\"Journal of the Royal Statistical Society\">Journal of the Royal Statistical Society</a>, 12, 137-144.</li>\n<li>Braun, H., Bejar, I.I., and Williamson, D.M. (2006). Rule-based methods for automated scoring: Application in a licensing context. In Williamson, D.M., Mislevy, R.J., and Bejar, I.I. (Eds.) Automated scoring of complex tasks in computer-based testing.  Mahwah, NJ: Erlbaum.</li>\n<li>Dodd, B. G., De Ayala, R. J., &amp; Koch, W. R. (1995). Computerized adaptive testing with polytomous items. Applied Psychological Measurement, 19, 5-22.</li>\n<li>Eggen, T. J. H. M. (1999). Item selection in adaptive testing with the sequential probability ratio test.  Applied Psychological Measurement, 23, 249-261.</li>\n<li>Eggen, T. J. H. M, &amp; Straetmans, G. J. J. M. (2000). Computerized adaptive testing for classifying examinees into three categories.  Educational and Psychological Measurement, 60, 713-734.</li>\n<li>Epstein, K. I., &amp; Knerr, C. S. (1977). Applications of sequential testing procedures to performance testing.  Paper presented at the 1977 Computerized Adaptive Testing Conference, Minneapolis, MN.</li>\n<li>Ferguson, R. L. (1969). The development, implementation, and evaluation of a computer-assisted branched test for a program of individually prescribed instruction.  Unpublished doctoral dissertation, University of Pittsburgh.</li>\n<li>Frick, T. W. (1989). Bayesian adaptation during computer-based tests and computer-guided exercises.  Journal of Educational Computing Research, 5, 89-114.</li>\n<li>Frick, T. W. (1990). A comparison of three decisions models for adapting the length of computer-based mastery tests.  Journal of Educational Computing Research, 6, 479-513.</li>\n<li>Frick, T. W. (1992). Computerized adaptive mastery tests as expert systems.  Journal of Educational Computing Research, 8, 187-213.</li>\n<li>Huang, C.-Y., Kalohn, J.C., Lin, C.-J., and Spray, J. (2000). Estimating Item Parameters from Classical Indices for Item Pool Development with a Computerized Classification Test. (Research Report 2000-4). Iowa City, IA: ACT, Inc.</li>\n<li>Jacobs-Cassuto, M.S. (2005). A Comparison of Adaptive Mastery Testing Using Testlets</li></ul>\n<p>With the 3-Parameter Logistic Model.  Unpublished doctoral dissertation, University of Minnesota, Minneapolis, MN.\n</p>\n<ul><li>Jiao, H., &amp; Lau, A. C. (2003). The Effects of Model Misfit in Computerized Classification Test. Paper presented at the annual meeting of the National Council of Educational Measurement, Chicago, IL, April 2003.</li>\n<li>Jiao, H., Wang, S., &amp; Lau, C. A. (2004). An Investigation of Two Combination Procedures of SPRT for Three-category Classification Decisions in Computerized Classification Test.  Paper presented at the annual meeting of the American Educational Research Association, San Antonio, April 2004.</li>\n<li>Kalohn, J. C., &amp; Spray, J. A. (1999). The effect of model misspecification on classification decisions made using a computerized test. Journal of Educational Measurement, 36, 47-59.</li>\n<li>Kingsbury, G.G., &amp; Weiss, D.J. (1979).  An adaptive testing strategy for mastery decisions.  Research report 79-05. Minneapolis: University of Minnesota, Psychometric Methods Laboratory.</li>\n<li>Kingsbury, G.G., &amp; Weiss, D.J. (1983).  A comparison of IRT-based adaptive mastery testing and a sequential mastery testing procedure.  In D. J. Weiss (Ed.), New horizons in testing: Latent trait theory and computerized adaptive testing (pp.&#160;237\u2013254). New York: Academic Press.</li>\n<li>Lau, C. A. (1996).  Robustness of a unidimensional computerized testing mastery procedure with multidimensional testing data.  Unpublished doctoral dissertation, University of Iowa, Iowa City IA.</li>\n<li>Lau, C. A., &amp; Wang, T. (1998). Comparing and combining dichotomous and polytomous items with SPRT procedure in computerized classification testing. Paper presented at the annual meeting of the American Educational Research Association, San Diego.</li>\n<li>Lau, C. A., &amp; Wang, T. (1999). Computerized classification testing under practical constraints with a polytomous model. Paper presented at the annual meeting of the American Educational Research Association, Montreal, Canada.</li>\n<li>Lau, C. A., &amp; Wang, T. (2000). A new item selection procedure for mixed item type in computerized classification testing.  Paper presented at the annual meeting of the American Educational Research Association, New Orleans, Louisiana.</li>\n<li>Lewis, C., &amp; Sheehan, K. (1990). Using Bayesian decision theory to design a computerized mastery test.  Applied Psychological Measurement, 14, 367-386.</li>\n<li>Lin, C.-J. &amp; Spray, J.A. (2000). Effects of item-selection criteria on classification testing with the sequential probability ratio test. (Research Report 2000-8). Iowa City, IA: ACT, Inc.</li>\n<li>Linn, R. L., Rock, D. A., &amp; Cleary, T. A. (1972). Sequential testing for dichotomous decisions. Educational &amp; Psychological Measurement, 32, 85-95.</li>\n<li>Luecht, R. M. (1996). Multidimensional Computerized Adaptive Testing in a Certification or Licensure Context. Applied Psychological Measurement, 20, 389-404.</li>\n<li>Reckase, M. D. (1983). A procedure for decision making using tailored testing. In D. J. Weiss (Ed.), New horizons in testing: Latent trait theory and computerized adaptive testing (pp.&#160;237\u2013254). New York: Academic Press.</li>\n<li>Rudner, L. M. (2002). An examination of decision-theory adaptive testing procedures.  Paper presented at the annual meeting of the American Educational Research Association, April 1\u20135, 2002, New Orleans, LA.</li>\n<li>Sheehan, K., &amp; Lewis, C. (1992). Computerized mastery testing with nonequivalent testlets. Applied Psychological Measurement, 16, 65-76.</li>\n<li>Spray, J. A. (1993). Multiple-category classification using a sequential probability ratio test (Research Report 93-7).  Iowa City, Iowa: ACT, Inc.</li>\n<li>Spray, J. A., Abdel-fattah, A. A., Huang, C., and Lau, C. A. (1997). Unidimensional approximations for a computerized test when the item pool and latent space are multidimensional (Research Report 97-5). Iowa City, Iowa: ACT, Inc.</li>\n<li>Spray, J. A., &amp; Reckase, M. D. (1987). The effect of item parameter estimation error on decisions made using the sequential probability ratio test (Research Report 87-17).  Iowa City, IA: ACT, Inc.</li>\n<li>Spray, J. A., &amp; Reckase, M. D. (1994). The selection of test items for decision making with a computerized adaptive test.  Paper presented at the Annual Meeting of the National Council for Measurement in Education (New Orleans, LA, April 5\u20137, 1994).</li>\n<li>Spray, J. A., &amp; Reckase, M. D. (1996). Comparison of SPRT and sequential Bayes procedures for classifying examinees into two categories using a computerized test. Journal of Educational &amp; Behavioral Statistics,21, 405-414.</li>\n<li>Thompson, N.A. (2006).  Variable-length computerized classification testing with item response theory.  CLEAR Exam Review, 17(2).</li>\n<li>Vos, H. J. (1998). Optimal sequential rules for computer-based instruction. Journal of Educational Computing Research, 19, 133-154.</li>\n<li>Vos, H. J. (1999). Applications of Bayesian decision theory to sequential mastery testing. Journal of Educational and Behavioral Statistics, 24, 271-292.</li>\n<li>Wald, A. (1947). Sequential analysis. New York: Wiley.</li>\n<li>Weiss, D. J., &amp; Kingsbury, G. G. (1984). Application of computerized adaptive testing to educational problems.  Journal of Educational Measurement, 21, 361-375.</li>\n<li>Weissman, A. (2004). Mutual information item selection in multiple-category classification CAT.  Paper presented at the Annual Meeting of the National Council for Measurement in Education, San Diego, CA.</li>\n<li>Weitzman, R. A. (1982a). Sequential testing for selection. Applied Psychological Measurement, 6, 337-351.</li>\n<li>Weitzman, R. A. (1982b). Use of sequential testing to prescreen prospective entrants into military service. In D. J. Weiss (Ed.), Proceedings of the 1982 Computerized Adaptive Testing Conference.  Minneapolis, MN: University of Minnesota, Department of Psychology, Psychometric Methods Program, 1982.</li></ul>\n</div>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computerized_classification_test&amp;action=edit&amp;section=8\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a rel=\"nofollow\" class=\"external text\" href=\"http://edres.org/mdt/\">Measurement Decision Theory</a> by Lawrence Rudner</li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20060711174833/http://www.psych.umn.edu/psylabs/catcentral/\">CAT Central</a> by David J. Weiss</li></ul>\n\n<!-- \nNewPP limit report\nParsed by mw2208\nCached time: 20180914162229\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.080 seconds\nReal time usage: 0.098 seconds\nPreprocessor visited node count: 189/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 462/2097152 bytes\nTemplate argument size: 96/2097152 bytes\nHighest expansion depth: 7/40\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 2492/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.005/10.000 seconds\nLua memory usage: 525 KB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%   55.611      1 -total\n 55.19%   30.694      1 Template:Reflist\n 40.75%   22.664      1 Template:Refbegin\n  5.41%    3.010      1 Template:Main_other\n  3.45%    1.917      1 Template:Refend\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:7955447-0!canonical and timestamp 20180914162229 and revision id 795078339\n -->\n</div>"},"langlinks":[],"categories":[{"sortkey":"Computerized Classification Test","*":"Psychometrics"},{"sortkey":"Computerized Classification Test","*":"Educational_assessment_and_evaluation"},{"sortkey":"Computerized Classification Test","*":"Computer-based_testing"},{"sortkey":"Computerized Classification Test","*":"Educational_psychology"},{"sortkey":"Computerized Classification Test","*":"School_examinations"}],"links":[{"ns":0,"exists":"","*":"Algorithm"},{"ns":0,"exists":"","*":"Bayesian decision theory"},{"ns":0,"exists":"","*":"Classical test theory"},{"ns":0,"exists":"","*":"Classification rule"},{"ns":0,"exists":"","*":"Computer"},{"ns":0,"exists":"","*":"Computerized adaptive testing"},{"ns":0,"exists":"","*":"Confidence interval"},{"ns":0,"exists":"","*":"Hypothesis test"},{"ns":0,"exists":"","*":"Information"},{"ns":0,"exists":"","*":"Item bank"},{"ns":0,"exists":"","*":"Item response theory"},{"ns":0,"exists":"","*":"Journal of the Royal Statistical Society"},{"ns":0,"exists":"","*":"Probability distribution"},{"ns":0,"exists":"","*":"Sequential probability ratio test"},{"ns":0,"exists":"","*":"Test (student assessment)"},{"ns":0,"exists":"","*":"Testlet"}],"templates":[{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:Refbegin"},{"ns":10,"exists":"","*":"Template:Refbegin/styles.css"},{"ns":10,"exists":"","*":"Template:Refend"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"}],"images":[],"externallinks":["http://pareonline.net/getvn.asp?v=12&n=1","http://edres.org/mdt/","https://web.archive.org/web/20060711174833/http://www.psych.umn.edu/psylabs/catcentral/"],"sections":[{"toclevel":1,"level":"2","line":"How it works","number":"1","index":"1","fromtitle":"Computerized_classification_test","byteoffset":1992,"anchor":"How_it_works"},{"toclevel":1,"level":"2","line":"Psychometric model","number":"2","index":"2","fromtitle":"Computerized_classification_test","byteoffset":2513,"anchor":"Psychometric_model"},{"toclevel":1,"level":"2","line":"Starting point","number":"3","index":"3","fromtitle":"Computerized_classification_test","byteoffset":4187,"anchor":"Starting_point"},{"toclevel":1,"level":"2","line":"Item selection","number":"4","index":"4","fromtitle":"Computerized_classification_test","byteoffset":4950,"anchor":"Item_selection"},{"toclevel":1,"level":"2","line":"Termination criterion","number":"5","index":"5","fromtitle":"Computerized_classification_test","byteoffset":6882,"anchor":"Termination_criterion"},{"toclevel":1,"level":"2","line":"References","number":"6","index":"6","fromtitle":"Computerized_classification_test","byteoffset":7873,"anchor":"References"},{"toclevel":1,"level":"2","line":"Bibliography of CCT research","number":"7","index":"7","fromtitle":"Computerized_classification_test","byteoffset":7904,"anchor":"Bibliography_of_CCT_research"},{"toclevel":1,"level":"2","line":"External links","number":"8","index":"8","fromtitle":"Computerized_classification_test","byteoffset":15849,"anchor":"External_links"}],"parsewarnings":[],"displaytitle":"Computerized classification test","iwlinks":[],"properties":[{"name":"defaultsort","*":"Computerized Classification Test"},{"name":"wikibase_item","*":"Q5157604"}]}}