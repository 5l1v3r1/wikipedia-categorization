{"parse":{"title":"Visual learning","pageid":2363287,"revid":858420574,"text":{"*":"<div class=\"mw-parser-output\"><table class=\"plainlinks metadata ambox ambox-content ambox-multiple_issues compact-ambox\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><div style=\"width:52px\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Ambox_important.svg/40px-Ambox_important.svg.png\" width=\"40\" height=\"40\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Ambox_important.svg/60px-Ambox_important.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Ambox_important.svg/80px-Ambox_important.svg.png 2x\" data-file-width=\"40\" data-file-height=\"40\" /></div></td><td class=\"mbox-text\"><div class=\"mbox-text-span\"><div class=\"mw-collapsible\" style=\"width:95%; margin: 0.2em 0;\"><b>This article has multiple issues.</b> Please help <b><a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Visual_learning&amp;action=edit\">improve it</a></b> or discuss these issues on the <b><a href=\"/wiki/Talk:Visual_learning\" title=\"Talk:Visual learning\">talk page</a></b>. <small><i>(<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove these template messages</a>)</i></small>\n<div class=\"mw-collapsible-content\" style=\"margin-top: 0.3em;\">\n      <table class=\"plainlinks metadata ambox ambox-style ambox-overly_detailed\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><div style=\"width:52px\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/40px-Edit-clear.svg.png\" width=\"40\" height=\"40\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/60px-Edit-clear.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/80px-Edit-clear.svg.png 2x\" data-file-width=\"48\" data-file-height=\"48\" /></div></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">This article <b>may contain an excessive amount of intricate detail that may interest only a particular audience</b>.<span class=\"hide-when-compact\"> Please help by <a href=\"/wiki/Wikipedia:Content_forking#Article_spinoffs:_.22Summary_style.22_meta-articles_and_summary_sections\" title=\"Wikipedia:Content forking\">spinning off</a> or <a href=\"/wiki/Wikipedia:Handling_trivia#Recommendations_for_handling_trivia\" title=\"Wikipedia:Handling trivia\">relocating</a> any relevant information, and removing excessive detail that may be against <a href=\"/wiki/Wikipedia:What_Wikipedia_is_not\" title=\"Wikipedia:What Wikipedia is not\">Wikipedia's inclusion policy</a>.</span>  <small><i>(November 2016)</i></small><small class=\"hide-when-compact\"><i> (<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>\n<table class=\"plainlinks metadata ambox ambox-style ambox-technical\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><div style=\"width:52px\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/40px-Edit-clear.svg.png\" width=\"40\" height=\"40\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/60px-Edit-clear.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/80px-Edit-clear.svg.png 2x\" data-file-width=\"48\" data-file-height=\"48\" /></div></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">This article <b>may be too technical for most readers to understand</b>. Please <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Visual_learning&amp;action=edit\">help improve it</a> to <a href=\"/wiki/Wikipedia:Make_technical_articles_understandable\" title=\"Wikipedia:Make technical articles understandable\">make it understandable to non-experts</a>, without removing the technical details.  <small><i>(November 2016)</i></small><small class=\"hide-when-compact\"><i> (<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>\n<table class=\"plainlinks metadata ambox ambox-content ambox-too_few_opinions\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><div style=\"width:52px\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Ambox_important.svg/40px-Ambox_important.svg.png\" width=\"40\" height=\"40\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Ambox_important.svg/60px-Ambox_important.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Ambox_important.svg/80px-Ambox_important.svg.png 2x\" data-file-width=\"40\" data-file-height=\"40\" /></div></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">The examples and perspective in this article <b>may not <a href=\"/wiki/Wikipedia:WikiProject_Countering_systemic_bias\" title=\"Wikipedia:WikiProject Countering systemic bias\">include all significant viewpoints</a></b>.<span class=\"hide-when-compact\"> Please <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Visual_learning&amp;action=edit\">improve the article</a> or <a href=\"/wiki/Talk:Visual_learning\" title=\"Talk:Visual learning\">discuss the issue</a>.</span>  <small><i>(November 2016)</i></small><small class=\"hide-when-compact\"><i> (<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>\n<table class=\"plainlinks metadata ambox ambox-content ambox-undue-weight\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><div style=\"width:52px\"><img alt=\"Unbalanced scales\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Unbalanced_scales.svg/45px-Unbalanced_scales.svg.png\" width=\"45\" height=\"40\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Unbalanced_scales.svg/68px-Unbalanced_scales.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Unbalanced_scales.svg/90px-Unbalanced_scales.svg.png 2x\" data-file-width=\"400\" data-file-height=\"354\" /></div></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">This article may <b>lend <a href=\"/wiki/Wikipedia:Neutral_point_of_view#Due_and_undue_weight\" title=\"Wikipedia:Neutral point of view\">undue weight</a> to certain ideas, incidents, or controversies</b>.<span class=\"hide-when-compact\"> Please <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Visual_learning&amp;action=edit\">help improve it</a> by rewriting it in an <b><a href=\"/wiki/Wikipedia:Neutral_point_of_view#Balance\" title=\"Wikipedia:Neutral point of view\">neutral presentation</a></b> that contextualizes different points of view.</span>  <small><i>(November 2016)</i></small><small class=\"hide-when-compact\"><i> (<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>\n    </div>\n</div><small class=\"hide-when-compact\"><i> (<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>\n<p><b>Visual learning</b> is  a style in which a learner utilizes graphs, charts, maps and diagrams. It is one of the three basic types of learning styles in the <a href=\"/wiki/Learning_styles#Neil_Fleming&#39;s_VAK/VARK_model\" title=\"Learning styles\">Fleming VAK/VARK model</a> that also includes <a href=\"/wiki/Kinesthetic_learning\" title=\"Kinesthetic learning\">kinesthetic learning</a> and <a href=\"/wiki/Auditory_learning\" title=\"Auditory learning\">auditory learning</a>.<sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\">&#91;1&#93;</a></sup>\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Techniques\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Techniques</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Areas_of_the_brain_affected\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Areas of the brain affected</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#Infancy\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Infancy</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-4\"><a href=\"#Where_it_starts\"><span class=\"tocnumber\">3.1</span> <span class=\"toctext\">Where it starts</span></a></li>\n<li class=\"toclevel-2 tocsection-5\"><a href=\"#The_four_pathways\"><span class=\"tocnumber\">3.2</span> <span class=\"toctext\">The four pathways</span></a></li>\n<li class=\"toclevel-2 tocsection-6\"><a href=\"#Supporting_studies\"><span class=\"tocnumber\">3.3</span> <span class=\"toctext\">Supporting studies</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-7\"><a href=\"#In_early_childhood\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">In early childhood</span></a></li>\n<li class=\"toclevel-1 tocsection-8\"><a href=\"#In_middle_childhood\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">In middle childhood</span></a></li>\n<li class=\"toclevel-1 tocsection-9\"><a href=\"#In_adolescence\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">In adolescence</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-10\"><a href=\"#Brain_maturation_into_young_adulthood\"><span class=\"tocnumber\">6.1</span> <span class=\"toctext\">Brain maturation into young adulthood</span></a></li>\n<li class=\"toclevel-2 tocsection-11\"><a href=\"#Gender_differences\"><span class=\"tocnumber\">6.2</span> <span class=\"toctext\">Gender differences</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-12\"><a href=\"#Lack_of_evidence\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">Lack of evidence</span></a></li>\n<li class=\"toclevel-1 tocsection-13\"><a href=\"#See_also\"><span class=\"tocnumber\">8</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-14\"><a href=\"#References\"><span class=\"tocnumber\">9</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-15\"><a href=\"#External_links\"><span class=\"tocnumber\">10</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"Techniques\">Techniques</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=1\" title=\"Edit section: Techniques\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>A review study concluded that using <a href=\"/wiki/Graphic_organizer\" title=\"Graphic organizer\">graphic organizers</a> improves student performance in the following areas:<sup id=\"cite_ref-review_2-0\" class=\"reference\"><a href=\"#cite_note-review-2\">&#91;2&#93;</a></sup>\n</p>\n<dl><dt>Retention</dt>\n<dd>Students remember information better and can better recall it when it is represented and learned both visually and verbally.<sup id=\"cite_ref-review_2-1\" class=\"reference\"><a href=\"#cite_note-review-2\">&#91;2&#93;</a></sup></dd></dl>\n<dl><dt>Reading comprehension</dt>\n<dd>The use of graphic organizers helps improving the <a href=\"/wiki/Reading_comprehension\" title=\"Reading comprehension\">reading comprehension</a> of students.<sup id=\"cite_ref-review_2-2\" class=\"reference\"><a href=\"#cite_note-review-2\">&#91;2&#93;</a></sup></dd></dl>\n<dl><dt>Student achievement</dt>\n<dd>Students with and without <a href=\"/wiki/Learning_disabilities\" class=\"mw-redirect\" title=\"Learning disabilities\">learning disabilities</a> improve achievement across content areas and grade levels.<sup id=\"cite_ref-review_2-3\" class=\"reference\"><a href=\"#cite_note-review-2\">&#91;2&#93;</a></sup></dd></dl>\n<dl><dt>Thinking and learning skills; critical thinking</dt>\n<dd>When students develop and use a graphic organizer their <a href=\"/wiki/Higher-order_thinking\" title=\"Higher-order thinking\">higher order thinking</a> and <a href=\"/wiki/Critical_thinking\" title=\"Critical thinking\">critical thinking</a> skills are enhanced.<sup id=\"cite_ref-review_2-4\" class=\"reference\"><a href=\"#cite_note-review-2\">&#91;2&#93;</a></sup></dd></dl>\n<h2><span class=\"mw-headline\" id=\"Areas_of_the_brain_affected\">Areas of the brain affected</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=2\" title=\"Edit section: Areas of the brain affected\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Various areas of the <a href=\"/wiki/Brain\" title=\"Brain\">brain</a> work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the <a href=\"/wiki/Visual_cortex\" title=\"Visual cortex\">visual cortex</a> of the brain. The visual cortex is located in the <a href=\"/wiki/Occipital_lobe\" title=\"Occipital lobe\">occipital lobe</a> of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the <a href=\"/wiki/Inferior_temporal_cortex\" class=\"mw-redirect\" title=\"Inferior temporal cortex\">inferior temporal cortex</a>, the superior <a href=\"/wiki/Parietal_cortex\" class=\"mw-redirect\" title=\"Parietal cortex\">parietal cortex</a>, and the <a href=\"/wiki/Cerebellum\" title=\"Cerebellum\">cerebellum</a>.  During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by <a href=\"/wiki/Neural_plasticity\" class=\"mw-redirect\" title=\"Neural plasticity\">neural plasticity</a>, or the brain's ability to reshape itself based on new information.<sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">&#91;3&#93;</a></sup> Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the <a href=\"/wiki/Orbitofrontal_cortex\" title=\"Orbitofrontal cortex\">orbitofrontal cortex</a> and two <a href=\"/wiki/Dorsolateral_prefrontal\" class=\"mw-redirect\" title=\"Dorsolateral prefrontal\">dorsolateral prefrontal</a> regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know.<sup id=\"cite_ref-4\" class=\"reference\"><a href=\"#cite_note-4\">&#91;4&#93;</a></sup> After recognizing and categorizing new material entered into the <a href=\"/wiki/Visual_field\" title=\"Visual field\">visual field</a>, the brain is ready to begin the <a href=\"/wiki/Encoding_(memory)\" title=\"Encoding (memory)\">encoding</a> process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the <a href=\"/wiki/Frontal_lobe\" title=\"Frontal lobe\">frontal lobe</a>, the right <a href=\"/wiki/Extrastriate_cortex\" title=\"Extrastriate cortex\">extrastriate cortex</a>, the <a href=\"/wiki/Neocortex\" title=\"Neocortex\">neocortex</a>, and again, the <a href=\"/wiki/Neostriatum\" class=\"mw-redirect\" title=\"Neostriatum\">neostriatum</a>. One area in particular, the <a href=\"/wiki/Limbic\" class=\"mw-redirect\" title=\"Limbic\">limbic</a>-diencephalic region, is essential for transforming perceptions into memories.<sup id=\"cite_ref-5\" class=\"reference\"><a href=\"#cite_note-5\">&#91;5&#93;</a></sup> With the coming together of tasks of recognition, categorization and learning; <a href=\"/wiki/Schema_(psychology)\" title=\"Schema (psychology)\">schemas</a> help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;6&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Infancy\">Infancy</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=3\" title=\"Edit section: Infancy\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Where_it_starts\">Where it starts</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=4\" title=\"Edit section: Where it starts\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Between the fetal stage and 18 months, a baby experiences rapid growth of a substance called <a href=\"/wiki/Gray_matter\" class=\"mw-redirect\" title=\"Gray matter\">gray matter</a>. Gray matter is the darker tissue of the brain and spinal cord, consisting mainly of nerve cell bodies and branching dendrites.<sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">&#91;7&#93;</a></sup> It is responsible for processing sensory information in the brain such as areas like the primary visual cortex. The primary visual cortex is located within the occipital lobe in the back of infant's brain and is responsible for processing visual information such as static or moving objects and pattern recognition.\n</p>\n<h3><span class=\"mw-headline\" id=\"The_four_pathways\">The four pathways</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=5\" title=\"Edit section: The four pathways\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Within the primary visual cortex, there are four pathways: the <a href=\"/wiki/Superior_colliculus\" title=\"Superior colliculus\">superior colliculus</a> pathway (SC pathway), the middle temporal area pathway (MT pathway), the <a href=\"/wiki/Frontal_eye_fields\" title=\"Frontal eye fields\">frontal eye fields</a> pathway (FEF pathway), and the inhibitory pathway. Each pathway is crucial to the development of visual attention in the first few months of life. The SC pathway is responsible for the generation of eye movements toward simple stimuli. It receives information from the retina and the visual cortex and can direct behavior toward an object. The MT pathway is involved in the smooth tracking of objects and travels between the SC pathway and the primary visual cortex. In conjunction with the SC pathway and the MT pathway, the FEF pathway allows the infant to control eye movements as well as visual attention. It also plays a part in sensory processing in the infant. Lastly, the inhibitory pathway regulates the activity in the superior colliculus and, later, is responsible for obligatory attention in the infant. The maturation and functionality of these pathways depends on how well the infant can make distinctions as well as focus on stimuli.\n</p>\n<h3><span class=\"mw-headline\" id=\"Supporting_studies\">Supporting studies</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=6\" title=\"Edit section: Supporting studies\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>A study by Haith, Hazan, &amp; Goodman in 1988 showed that babies, as young as 3.5 months, are able to create short-term expectations of situations they confront. Expectations in this study refer to the cognitive and perceptual ways in which an infant can forecast a future event. This was tested by showing the infant either a predictable pattern of slides or an irregular pattern of slides and tracking the infant's <a href=\"/wiki/Eye_movement\" title=\"Eye movement\">eye movements</a>.<sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">&#91;8&#93;</a></sup> \nA later study by Johnson, Posner, &amp; Rothbart in 1991 showed that by 4 months old, infants can develop expectations, but was tested through anticipatory looks and disengagement with stimuli. For example, anticipatory looks exhibit the infant is able to predict the next part of a pattern which can then be applied to the real world scenario of breast-feeding. Infants are able to predict a mother's movements and expect feeding so they can latch onto the nipple for feeding. Expectations, anticipatory looks, and disengagement all show that infants can learn visually, even if it is only short term.<sup id=\"cite_ref-9\" class=\"reference\"><a href=\"#cite_note-9\">&#91;9&#93;</a></sup> David Roberts (2016) tested multimedia learning propositions, he found that using certain images dislocates pedagogically harmful excesses of text, reducing cognitive overloading and exploiting under-used visual processing capacities <sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">&#91;10&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"In_early_childhood\">In early childhood</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=7\" title=\"Edit section: In early childhood\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>From the ages 3\u20138 visual learning improves and begins to take many different forms. At the toddler age of 3\u20135, children's bodily actions structure the visual learning environment. At this age, toddlers are using their newly developed sensory-motor skills quite often and fusing them with their improved vision to understand the world around them. This is seen by toddler's using their arms to bring objects of interest close to their sensors, such as their eyes and face, to explore the object further. The act of bringing objects close to their face affects their immediate view by placing their mental and visual attention on that object and just blocking the view of other objects that are around them and out of view. There is an emphasis placed on objects and things that are directly in front of them and thus proximal vision is the primary perspective of visual learning. This is different from how adults utilize visual learning. This difference in toddler vision and adult vision is attributable to their body sizes, and body movements such that their visual experiences are created by their body movement. An adults view is broad, due to their larger body size, with most objects in view because of the distance between them and objects. Adults tend to scan a room, and see everything rather than focusing on one object only.<sup id=\"cite_ref-11\" class=\"reference\"><a href=\"#cite_note-11\">&#91;11&#93;</a></sup>\n</p><p>The way a child integrates visual learning with motor experiences enhances their perceptual and cognitive development.<sup id=\"cite_ref-12\" class=\"reference\"><a href=\"#cite_note-12\">&#91;12&#93;</a></sup> For elementary school children, aged 4\u201311, intellect is positively related to their level of auditory-visual integrative proficiency. The most significant period for the development of auditory-visual integration occurs between ages 5\u20137. During this time, the child has mastered visual-kinesthetic integration, and the child's visual learning can be applied to formal learning focused towards books and reading, rather than physical objects, thus impacting their intellect. As reading scores increase, children are able to learn more, and their visual learning has developed to not only focus on physical objects in close proximity to them, but also to interpret words and such to acquire knowledge by reading.<sup id=\"cite_ref-13\" class=\"reference\"><a href=\"#cite_note-13\">&#91;13&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"In_middle_childhood\">In middle childhood</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=8\" title=\"Edit section: In middle childhood\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Here we categorize middle childhood as ages 9 to 14. By this stage in a child's normal development vision is sharp and learning processes are well underway. Most studies that have focused their efforts on visual learning have found that visual learning styles as opposed to traditional learning styles greatly improve the totality of a student's learning experience. First off, visual learning engages students and student engagement is one of the most important factors that motivated students to learn. Visuals increase student interest with the use of graphics animation, and video. Consequently, it has been found that student pay greater attention to lecture material when visuals are used. With increased attention to lesson material, many positive outcomes have been seen with the use of visual tactics in the classrooms of middle aged students. Students organize and process information more thoroughly when they learn visually which helps them to understand the information better. Students are more likely to remember information that is learned with a visual aid.<sup id=\"cite_ref-14\" class=\"reference\"><a href=\"#cite_note-14\">&#91;14&#93;</a></sup> When teachers used visual tactics to teach middle aged students they found that students had more positive attitudes about the material they were learning.<sup id=\"cite_ref-Farkas_15-0\" class=\"reference\"><a href=\"#cite_note-Farkas-15\">&#91;15&#93;</a></sup> Students also exemplified higher test performance, higher standard achievement scores, thinking on levels that require higher order thinking, and more engagement. One study also found that learning about emotional events, such as the Holocaust, with visual aids increase middle aged children's empathy.<sup id=\"cite_ref-Farkas_15-1\" class=\"reference\"><a href=\"#cite_note-Farkas-15\">&#91;15&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"In_adolescence\">In adolescence</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=9\" title=\"Edit section: In adolescence\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Brain_maturation_into_young_adulthood\">Brain maturation into young adulthood</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=10\" title=\"Edit section: Brain maturation into young adulthood\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Gray matter is responsible for generating <a href=\"/wiki/Nerve_impulse\" class=\"mw-redirect\" title=\"Nerve impulse\">nerve impulses</a> that process brain information, and <a href=\"/wiki/White_matter\" title=\"White matter\">white matter</a> is responsible for transmitting that brain information between lobes and out through the spinal cord. Nerve impulses are transmitted by <a href=\"/wiki/Myelin\" title=\"Myelin\">myelin</a>, a fatty material that grows around a cell. White matter has a myelin sheath (a collection of myelin) while gray matter doesn't, which efficiently allows neural impulses to move swiftly along the fiber. The myelin sheath isn't fully formed until around ages 24\u201326.<sup id=\"cite_ref-16\" class=\"reference\"><a href=\"#cite_note-16\">&#91;16&#93;</a></sup> This means that adolescents and young adults typically learn differently, and subsequently often utilize <a href=\"/wiki/Visual_aid\" class=\"mw-redirect\" title=\"Visual aid\">visual aids</a> in order to help them better comprehend difficult subjects.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (July 2016)\">citation needed</span></a></i>&#93;</sup>\n</p><p>Learning preferences can vary across a wide spectrum. Specifically within the realm of visual learning, they can vary between people who prefer being given learning instructions with text as opposed to those who prefer being given instructions with graphics. College students were tested in general factors like learning preference and <a href=\"/wiki/Spatial_ability\" title=\"Spatial ability\">spatial ability</a> (being able to be proficient in creating, holding, and manipulating spatial representations).<sup id=\"cite_ref-17\" class=\"reference\"><a href=\"#cite_note-17\">&#91;17&#93;</a></sup> The study determined that college-age individuals report efficient learning styles and learning preferences for themselves individually. These personal assessments have proved accurate, meaning that self-ratings of factors such as spatial ability and learning preference can be effective measures of how well one learns visually.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (July 2016)\">citation needed</span></a></i>&#93;</sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Gender_differences\">Gender differences</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=11\" title=\"Edit section: Gender differences\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Studies have indicated that adolescents learn best through 10 various styles; reading, manipulative activity, teacher explanation, auditory stimulation, visual demonstration, visual stimulation (electronic), visual stimulation (just pictures), games, social interaction, and personal experience.<sup id=\"cite_ref-18\" class=\"reference\"><a href=\"#cite_note-18\">&#91;18&#93;</a></sup> According to the study, young adult males demonstrate a preference for learning through activities they are able to manipulate, and young adult females show a greater preference for learning through teacher explanation or direction, and through reading. This suggests that men are more visually stimulated, interested in information that they can have physical direct control over. Women, on the other hand, learn best through reading information and having it explained in an auditory fashion.\n</p>\n<h2><span class=\"mw-headline\" id=\"Lack_of_evidence\">Lack of evidence</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=12\" title=\"Edit section: Lack of evidence\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Although learning styles have \"enormous popularity\", and both children and adults express personal preferences, there is no evidence that identifying a student's learning style produces better outcomes, and there is significant evidence that the widely touted \"meshing hypothesis\" (that a student will learn best if taught in a method deemed appropriate for that student's learning style) is invalid.<sup id=\"cite_ref-Pashler_19-0\" class=\"reference\"><a href=\"#cite_note-Pashler-19\">&#91;19&#93;</a></sup>  Well-designed studies \"flatly contradict the popular meshing hypothesis\".<sup id=\"cite_ref-Pashler_19-1\" class=\"reference\"><a href=\"#cite_note-Pashler-19\">&#91;19&#93;</a></sup>  Rather than targeting instruction to the \"right\" learning style, students appear to benefit most from mixed modality presentations, for instance using both auditory and visual techniques for all students.<sup id=\"cite_ref-Coffield_20-0\" class=\"reference\"><a href=\"#cite_note-Coffield-20\">&#91;20&#93;</a></sup>\n</p><p>However, recent research by David Roberts at Loughborough university, appearing in peer-reviewed scholarly journals [note here], shows that images used with reduced visible text generates greater subject engagement and higher levels of active learning in large group lecture settings. The visual teaching and learning method, developed from the scholarly research of Professor Richard Mayer, was evaluated over 3 years and across 9 disciplines using control and test group methods complemented by focus groups. The visual pedagogy, and the research testing it, is hosted by the UK Higher Education Academy [note here]\n</p>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=13\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div role=\"navigation\" aria-label=\"Portals\" class=\"noprint portal plainlist tright\" style=\"margin:0.5em 0 0.5em 1em;border:solid #aaa 1px\">\n<ul style=\"display:table;box-sizing:border-box;padding:0.1em;max-width:175px;background:#f9f9f9;font-size:85%;line-height:110%;font-style:italic;font-weight:bold\">\n<li style=\"display:table-row\"><span style=\"display:table-cell;padding:0.2em;vertical-align:middle;text-align:center\"><a href=\"/wiki/File:Nicolas_P._Rougier%27s_rendering_of_the_human_brain.png\" class=\"image\"><img alt=\"icon\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/73/Nicolas_P._Rougier%27s_rendering_of_the_human_brain.png/32px-Nicolas_P._Rougier%27s_rendering_of_the_human_brain.png\" width=\"32\" height=\"24\" class=\"noviewer\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/73/Nicolas_P._Rougier%27s_rendering_of_the_human_brain.png/48px-Nicolas_P._Rougier%27s_rendering_of_the_human_brain.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/73/Nicolas_P._Rougier%27s_rendering_of_the_human_brain.png/64px-Nicolas_P._Rougier%27s_rendering_of_the_human_brain.png 2x\" data-file-width=\"800\" data-file-height=\"600\" /></a></span><span style=\"display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle\"><a href=\"/wiki/Portal:Thinking\" title=\"Portal:Thinking\">Thinking portal</a></span></li></ul></div>\n<ul><li><a href=\"/wiki/Learning_styles\" title=\"Learning styles\">Learning styles</a>\n<ul><li><a href=\"/wiki/Auditory_learning\" title=\"Auditory learning\">Auditory learning</a></li>\n<li><a href=\"/wiki/Kinesthetic_learning\" title=\"Kinesthetic learning\">Kinesthetic learning</a></li></ul></li></ul>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=14\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap mw-references-columns\"><ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\">Leite, Walter L.; Svinicki, Marilla; and Shi, Yuying: Attempted Validation of the Scores of the VARK: Learning Styles Inventory With Multitrait\u2013Multimethod Confirmatory Factor Analysis Models, pg. 2. SAGE Publications, 2009.</span>\n</li>\n<li id=\"cite_note-review-2\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-review_2-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-review_2-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-review_2-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-review_2-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-review_2-4\"><sup><i><b>e</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation web\"><a rel=\"nofollow\" class=\"external text\" href=\"http://www.inspiration.com/sites/default/files/documents/Detailed-Summary.pdf\">\"Graphic Organizers: A Review of Scientifically Based Research, The Institute for the Advancement of Research in Education at AEL\"</a> <span style=\"font-size:85%;\">(PDF)</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Graphic+Organizers%3A+A+Review+of+Scientifically+Based+Research%2C+The+Institute+for+the+Advancement+of+Research+in+Education+at+AEL&amp;rft_id=http%3A%2F%2Fwww.inspiration.com%2Fsites%2Fdefault%2Ffiles%2Fdocuments%2FDetailed-Summary.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AVisual+learning\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\">Poldrack, R., Desmond, J., Glover, G., &amp; Gabrieli, J. The Neural Basis of Visual Skill Learning: An fMRI Study of Mirror Reading. Cerebral Cortex. Jan/Feb 1998.</span>\n</li>\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\">Vogel, R., Sary, G., Dupont, P., Orban, G. Human Brain Regions Involved in Visual Categorization. Elsevier Science (USA) 2002.</span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\">Squire, L. Declarative and Nondeclarative Memory: Multiple Brain Systems Supporting Learning and Memory\". 1992 Massachusetts Institute of Technology. Journal of Cognitive Neuroscience 4.3.</span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\">Lord, C. \"Schemas and Images as Memory Aids: Two Modes of Processing Social Information\". Stanford University. 1980. American Psychological Association.</span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\">Google definition. (2013, November 12). Retrieved from Google.</span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\">Haith, M. M., Hazan, C., &amp; Goodman, G. S. (1988). Expectation and Anticipation of Dynamic Visual Events by 3.5 Month Old Babies. Child Development, 59, 467-479.</span>\n</li>\n<li id=\"cite_note-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-9\">^</a></b></span> <span class=\"reference-text\">Johnson, M. H., Posner, M. I., &amp; Rothbart, M. K. (1991). Components of Visual Orienting in Early Infancy: Contingency Learning, Anticipatory Looking, and Disengaing. Journal of Cognitive Neuroscience, 335-344</span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a rel=\"nofollow\" class=\"external text\" href=\"http://www.dracs.org/\">\"David Roberts Academic Consulting\"</a>. <i>vl.catalystitsolutions.co.uk</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2017-01-04</span></span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=vl.catalystitsolutions.co.uk&amp;rft.atitle=David+Roberts+Academic+Consulting&amp;rft_id=http%3A%2F%2Fwww.dracs.org%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AVisual+learning\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-11\">^</a></b></span> <span class=\"reference-text\">Smith, L.B., Yu, C., &amp; Pereira, A. F. (2011). Not your mother's view: The dynamics of toddler visual experience. Developmental science, 14(1), 9-17.</span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\">Bertenthal, B. I., Campos, J. J., &amp; Kermoian, R. (1994). An epigenetic perspective on the development of self-produced locomotion and its consequences. Current Directions in Psychological Science, 3(5), 140-145.</span>\n</li>\n<li id=\"cite_note-13\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-13\">^</a></b></span> <span class=\"reference-text\">Birch, H. G., &amp; Belmont, L. (1965). Auditory-visual integration, intelligence and reading ability in school children. Perceptual and Motor Skills, 20(1), 295-305.</span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\">Beeland, W. \"Student Engagement, Visual Learning, and Technology: Can Interactive Whiteboards Help?\" (2001). Theses and Dissertations from Valdosta State University Graduate School.</span>\n</li>\n<li id=\"cite_note-Farkas-15\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Farkas_15-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Farkas_15-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Farkas, R. \"Effects of Traditional Versus Learning-Styles Instructional Methods on Middle School Students\" The Journal of Educational Research. Vol. 97, No. 1 (Sep. - Oct., 2003), pp. 42-51.</span>\n</li>\n<li id=\"cite_note-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-16\">^</a></b></span> <span class=\"reference-text\">Wolfe, Pat. (2001). Brain Matters: Translating the Research to Classroom Practice. ASCD: 1-207</span>\n</li>\n<li id=\"cite_note-17\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-17\">^</a></b></span> <span class=\"reference-text\">Mayer, R. E., &amp; Massa, L. J. (2003). Three Facets of Visual and Verbal Learners: Cognitive Ability, Cognitive Style, and Learning Preference. Journal of educational psychology, 95(4), 833.</span>\n</li>\n<li id=\"cite_note-18\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-18\">^</a></b></span> <span class=\"reference-text\">Eiszler, C. F. (1982). Perceptual Preferences as an Aspect of Adolescent Learning Styles.</span>\n</li>\n<li id=\"cite_note-Pashler-19\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Pashler_19-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Pashler_19-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation journal\">Harold Pashler, Mark McDaniel, Doug Rohrer and Robert Bjork (2009). <a rel=\"nofollow\" class=\"external text\" href=\"http://psi.sagepub.com/content/9/3/105.full\">\"Learning Styles: Concepts and Evidence\"</a>. <i>Psychological Science in the Public Interest</i>. <b>9</b> (3): 105\u2013119. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1111/j.1539-6053.2009.01038.x\">10.1111/j.1539-6053.2009.01038.x</a>. <a href=\"/wiki/International_Standard_Serial_Number\" title=\"International Standard Serial Number\">ISSN</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.worldcat.org/issn/1539-6053\">1539-6053</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Psychological+Science+in+the+Public+Interest&amp;rft.atitle=Learning+Styles%3A+Concepts+and+Evidence&amp;rft.volume=9&amp;rft.issue=3&amp;rft.pages=105-119&amp;rft.date=2009&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1539-6053.2009.01038.x&amp;rft.issn=1539-6053&amp;rft.au=Harold+Pashler%2C+Mark+McDaniel%2C+Doug+Rohrer+and+Robert+Bjork&amp;rft_id=http%3A%2F%2Fpsi.sagepub.com%2Fcontent%2F9%2F3%2F105.full&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AVisual+learning\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span><span class=\"citation-comment\" style=\"display:none; color:#33aa33; margin-left:0.3em\">CS1 maint: Multiple names: authors list (<a href=\"/wiki/Category:CS1_maint:_Multiple_names:_authors_list\" title=\"Category:CS1 maint: Multiple names: authors list\">link</a>) </span></span>\n</li>\n<li id=\"cite_note-Coffield-20\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Coffield_20-0\">^</a></b></span> <span class=\"reference-text\">Coffield, F., Moseley, D., Hall, E., Ecclestone, K. (2004). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.lsda.org.uk/files/PDF/1543.pdf\"><i>Learning styles and pedagogy in post-16 learning. A systematic and critical review</i></a> <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20081205043419/http://www.lsda.org.uk/files/PDF/1543.pdf\">Archived</a> 2008-12-05 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>.. London: Learning and Skills Research Centre.</span>\n</li>\n</ol></div></div>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Visual_learning&amp;action=edit&amp;section=15\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a rel=\"nofollow\" class=\"external text\" href=\"http://www.visuallearningstyles.com\">Articles and resources about the visual learning style for students and instructors</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://www.studyingstyle.com/visual-learners.html\">More tips for visual learners</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://www.variquest.com/literature.htm\">Visual learning information</a></li></ul>\n\n<!-- \nNewPP limit report\nParsed by mw1342\nCached time: 20180911144539\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.236 seconds\nReal time usage: 0.296 seconds\nPreprocessor visited node count: 1043/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 50174/2097152 bytes\nTemplate argument size: 13046/2097152 bytes\nHighest expansion depth: 11/40\nExpensive parser function count: 7/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 11578/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.084/10.000 seconds\nLua memory usage: 3.04 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  222.234      1 -total\n 56.49%  125.540      5 Template:Ambox\n 45.50%  101.108      1 Template:Multiple_issues\n 32.29%   71.765      1 Template:Reflist\n 15.75%   35.004      2 Template:Cite_web\n 12.54%   27.879      1 Template:Overly_detailed\n 11.99%   26.657      2 Template:Citation_needed\n 10.56%   23.468      2 Template:Fix\n  4.83%   10.729      2 Template:Delink\n  4.63%   10.296      1 Template:Webarchive\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:2363287-0!canonical and timestamp 20180911144539 and revision id 858420574\n -->\n</div>"},"langlinks":[{"lang":"ar","url":"https://ar.wikipedia.org/wiki/%D8%AA%D8%B9%D9%84%D9%85_%D8%A8%D8%B5%D8%B1%D9%8A","langname":"Arabic","autonym":"\u0627\u0644\u0639\u0631\u0628\u064a\u0629","*":"\u062a\u0639\u0644\u0645 \u0628\u0635\u0631\u064a"}],"categories":[{"sortkey":"","hidden":"","*":"CS1_maint:_Multiple_names:_authors_list"},{"sortkey":"","hidden":"","*":"Webarchive_template_wayback_links"},{"sortkey":"Visual Learning","hidden":"","*":"Wikipedia_articles_with_style_issues_from_November_2016"},{"sortkey":"Visual Learning","hidden":"","*":"All_articles_with_style_issues"},{"sortkey":"Visual Learning","hidden":"","*":"Wikipedia_articles_that_are_excessively_detailed_from_November_2016"},{"sortkey":"Visual Learning","hidden":"","*":"All_articles_that_are_excessively_detailed"},{"sortkey":"Visual Learning","hidden":"","*":"Wikipedia_articles_that_are_too_technical_from_November_2016"},{"sortkey":"Visual Learning","hidden":"","*":"All_articles_that_are_too_technical"},{"sortkey":"Visual Learning","hidden":"","*":"Articles_needing_expert_attention_from_November_2016"},{"sortkey":"Visual Learning","hidden":"","*":"All_articles_needing_expert_attention"},{"sortkey":"Visual Learning","hidden":"","*":"Articles_needing_more_viewpoints_from_November_2016"},{"sortkey":"Visual Learning","hidden":"","*":"Articles_needing_POV-check_from_November_2016"},{"sortkey":"Visual Learning","hidden":"","*":"Articles_with_multiple_maintenance_issues"},{"sortkey":"Visual Learning","hidden":"","*":"All_articles_with_unsourced_statements"},{"sortkey":"Visual Learning","hidden":"","*":"Articles_with_unsourced_statements_from_July_2016"},{"sortkey":"Visual Learning","*":"Learning_methods"},{"sortkey":"Visual Learning","*":"Infographics"},{"sortkey":"Visual Learning","*":"Information_technology_management"},{"sortkey":"Visual Learning","*":"Educational_psychology"},{"sortkey":"Visual Learning","*":"Neuro-linguistic_programming_concepts_and_methods"}],"links":[{"ns":14,"exists":"","*":"Category:Wikipedia articles with style issues from November 2016"},{"ns":14,"exists":"","*":"Category:Wikipedia articles that are excessively detailed from November 2016"},{"ns":14,"exists":"","*":"Category:Wikipedia articles that are too technical from November 2016"},{"ns":14,"exists":"","*":"Category:Articles needing expert attention from November 2016"},{"ns":14,"exists":"","*":"Category:Articles needing more viewpoints from November 2016"},{"ns":14,"exists":"","*":"Category:Articles needing POV-check from November 2016"},{"ns":14,"exists":"","*":"Category:Articles with unsourced statements from July 2016"},{"ns":14,"exists":"","*":"Category:CS1 maint: Multiple names: authors list"},{"ns":0,"exists":"","*":"Auditory learning"},{"ns":0,"exists":"","*":"Brain"},{"ns":0,"exists":"","*":"Cerebellum"},{"ns":0,"exists":"","*":"Critical thinking"},{"ns":0,"exists":"","*":"Digital object identifier"},{"ns":0,"exists":"","*":"Dorsolateral prefrontal"},{"ns":0,"exists":"","*":"Encoding (memory)"},{"ns":0,"exists":"","*":"Extrastriate cortex"},{"ns":0,"exists":"","*":"Eye movement"},{"ns":0,"exists":"","*":"Frontal eye fields"},{"ns":0,"exists":"","*":"Frontal lobe"},{"ns":0,"exists":"","*":"Graphic organizer"},{"ns":0,"exists":"","*":"Gray matter"},{"ns":0,"exists":"","*":"Higher-order thinking"},{"ns":0,"exists":"","*":"Inferior temporal cortex"},{"ns":0,"exists":"","*":"International Standard Serial Number"},{"ns":0,"exists":"","*":"Kinesthetic learning"},{"ns":0,"exists":"","*":"Learning disabilities"},{"ns":0,"exists":"","*":"Learning styles"},{"ns":0,"exists":"","*":"Limbic"},{"ns":0,"exists":"","*":"Myelin"},{"ns":0,"exists":"","*":"Neocortex"},{"ns":0,"exists":"","*":"Neostriatum"},{"ns":0,"exists":"","*":"Nerve impulse"},{"ns":0,"exists":"","*":"Neural plasticity"},{"ns":0,"exists":"","*":"Occipital lobe"},{"ns":0,"exists":"","*":"Orbitofrontal cortex"},{"ns":0,"exists":"","*":"Parietal cortex"},{"ns":0,"exists":"","*":"Reading comprehension"},{"ns":0,"exists":"","*":"Schema (psychology)"},{"ns":0,"exists":"","*":"Spatial ability"},{"ns":0,"exists":"","*":"Superior colliculus"},{"ns":0,"exists":"","*":"Visual aid"},{"ns":0,"exists":"","*":"Visual cortex"},{"ns":0,"exists":"","*":"Visual field"},{"ns":0,"exists":"","*":"Wayback Machine"},{"ns":0,"exists":"","*":"White matter"},{"ns":1,"exists":"","*":"Talk:Visual learning"},{"ns":4,"exists":"","*":"Wikipedia:Citation needed"},{"ns":4,"exists":"","*":"Wikipedia:Content forking"},{"ns":4,"exists":"","*":"Wikipedia:Handling trivia"},{"ns":4,"exists":"","*":"Wikipedia:Make technical articles understandable"},{"ns":4,"exists":"","*":"Wikipedia:Neutral point of view"},{"ns":4,"exists":"","*":"Wikipedia:What Wikipedia is not"},{"ns":4,"exists":"","*":"Wikipedia:WikiProject Countering systemic bias"},{"ns":12,"exists":"","*":"Help:Maintenance template removal"},{"ns":100,"exists":"","*":"Portal:Thinking"}],"templates":[{"ns":10,"exists":"","*":"Template:Multiple issues"},{"ns":10,"exists":"","*":"Template:Ambox"},{"ns":10,"exists":"","*":"Template:Overly detailed"},{"ns":10,"exists":"","*":"Template:Technical"},{"ns":10,"exists":"","*":"Template:Too few opinions"},{"ns":10,"exists":"","*":"Template:Undue weight"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:Citation needed"},{"ns":10,"exists":"","*":"Template:Fix"},{"ns":10,"exists":"","*":"Template:Category handler"},{"ns":10,"exists":"","*":"Template:Fix/category"},{"ns":10,"exists":"","*":"Template:Delink"},{"ns":10,"exists":"","*":"Template:Portal"},{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Cite web"},{"ns":10,"exists":"","*":"Template:Cite journal"},{"ns":10,"exists":"","*":"Template:Webarchive"},{"ns":828,"exists":"","*":"Module:Message box"},{"ns":828,"exists":"","*":"Module:No globals"},{"ns":828,"exists":"","*":"Module:Yesno"},{"ns":828,"exists":"","*":"Module:Arguments"},{"ns":828,"exists":"","*":"Module:Message box/configuration"},{"ns":828,"exists":"","*":"Module:Unsubst"},{"ns":828,"exists":"","*":"Module:Category handler"},{"ns":828,"exists":"","*":"Module:Category handler/data"},{"ns":828,"exists":"","*":"Module:Category handler/config"},{"ns":828,"exists":"","*":"Module:Category handler/shared"},{"ns":828,"exists":"","*":"Module:Category handler/blacklist"},{"ns":828,"exists":"","*":"Module:Namespace detect/data"},{"ns":828,"exists":"","*":"Module:Namespace detect/config"},{"ns":828,"exists":"","*":"Module:String"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"},{"ns":828,"exists":"","*":"Module:Delink"},{"ns":828,"exists":"","*":"Module:Portal"},{"ns":828,"exists":"","*":"Module:Portal/images/t"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"},{"ns":828,"exists":"","*":"Module:Webarchive"},{"ns":828,"exists":"","*":"Module:Webarchive/data"}],"images":["Ambox_important.svg","Edit-clear.svg","Unbalanced_scales.svg","Nicolas_P._Rougier's_rendering_of_the_human_brain.png"],"externallinks":["http://www.inspiration.com/sites/default/files/documents/Detailed-Summary.pdf","http://www.dracs.org/","http://psi.sagepub.com/content/9/3/105.full","//doi.org/10.1111/j.1539-6053.2009.01038.x","//www.worldcat.org/issn/1539-6053","http://www.lsda.org.uk/files/PDF/1543.pdf","https://web.archive.org/web/20081205043419/http://www.lsda.org.uk/files/PDF/1543.pdf","http://www.visuallearningstyles.com","http://www.studyingstyle.com/visual-learners.html","http://www.variquest.com/literature.htm"],"sections":[{"toclevel":1,"level":"2","line":"Techniques","number":"1","index":"1","fromtitle":"Visual_learning","byteoffset":708,"anchor":"Techniques"},{"toclevel":1,"level":"2","line":"Areas of the brain affected","number":"2","index":"2","fromtitle":"Visual_learning","byteoffset":1771,"anchor":"Areas_of_the_brain_affected"},{"toclevel":1,"level":"2","line":"Infancy","number":"3","index":"3","fromtitle":"Visual_learning","byteoffset":4595,"anchor":"Infancy"},{"toclevel":2,"level":"3","line":"Where it starts","number":"3.1","index":"4","fromtitle":"Visual_learning","byteoffset":4608,"anchor":"Where_it_starts"},{"toclevel":2,"level":"3","line":"The four pathways","number":"3.2","index":"5","fromtitle":"Visual_learning","byteoffset":5257,"anchor":"The_four_pathways"},{"toclevel":2,"level":"3","line":"Supporting studies","number":"3.3","index":"6","fromtitle":"Visual_learning","byteoffset":6414,"anchor":"Supporting_studies"},{"toclevel":1,"level":"2","line":"In early childhood","number":"4","index":"7","fromtitle":"Visual_learning","byteoffset":8277,"anchor":"In_early_childhood"},{"toclevel":1,"level":"2","line":"In middle childhood","number":"5","index":"8","fromtitle":"Visual_learning","byteoffset":11022,"anchor":"In_middle_childhood"},{"toclevel":1,"level":"2","line":"In adolescence","number":"6","index":"9","fromtitle":"Visual_learning","byteoffset":13008,"anchor":"In_adolescence"},{"toclevel":2,"level":"3","line":"Brain maturation into young adulthood","number":"6.1","index":"10","fromtitle":"Visual_learning","byteoffset":13028,"anchor":"Brain_maturation_into_young_adulthood"},{"toclevel":2,"level":"3","line":"Gender differences","number":"6.2","index":"11","fromtitle":"Visual_learning","byteoffset":14934,"anchor":"Gender_differences"},{"toclevel":1,"level":"2","line":"Lack of evidence","number":"7","index":"12","fromtitle":"Visual_learning","byteoffset":15852,"anchor":"Lack_of_evidence"},{"toclevel":1,"level":"2","line":"See also","number":"8","index":"13","fromtitle":"Visual_learning","byteoffset":17938,"anchor":"See_also"},{"toclevel":1,"level":"2","line":"References","number":"9","index":"14","fromtitle":"Visual_learning","byteoffset":18047,"anchor":"References"},{"toclevel":1,"level":"2","line":"External links","number":"10","index":"15","fromtitle":"Visual_learning","byteoffset":18075,"anchor":"External_links"}],"parsewarnings":[],"displaytitle":"Visual learning","iwlinks":[],"properties":[{"name":"defaultsort","*":"Visual Learning"},{"name":"wikibase_item","*":"Q7936605"}]}}