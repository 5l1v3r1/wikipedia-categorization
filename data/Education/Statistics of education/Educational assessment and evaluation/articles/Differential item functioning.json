{"parse":{"title":"Differential item functioning","pageid":9268401,"revid":857235822,"text":{"*":"<div class=\"mw-parser-output\"><table class=\"plainlinks metadata ambox ambox-style ambox-Cleanup\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><div style=\"width:52px\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/40px-Edit-clear.svg.png\" width=\"40\" height=\"40\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/60px-Edit-clear.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/80px-Edit-clear.svg.png 2x\" data-file-width=\"48\" data-file-height=\"48\" /></div></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">This article may <b>require <a href=\"/wiki/Wikipedia:Cleanup\" title=\"Wikipedia:Cleanup\">cleanup</a></b> to meet Wikipedia's <a href=\"/wiki/Wikipedia:Manual_of_Style\" title=\"Wikipedia:Manual of Style\">quality standards</a>. The specific problem is: <b>Mathematical formulas need to be brought inline with <a href=\"/wiki/MOS:MATH\" class=\"mw-redirect\" title=\"MOS:MATH\">MOS:MATH</a>.</b><span class=\"hide-when-compact\"> Please help <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Differential_item_functioning&amp;action=edit\">improve this article</a> if you can.</span>  <small><i>(February 2018)</i></small><small class=\"hide-when-compact\"><i> (<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>\n<p><b>Differential item functioning</b> (<b>DIF</b>) is a statistical characteristic of an item that shows the extent to which the item might be measuring different abilities for members of separate subgroups. Average item scores for subgroups having the same overall score on the test are compared to determine whether the item is measuring in essentially the same way for all subgroups. The presence of DIF requires review and judgment, and it does not necessarily indicate the presence of bias.<sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\">&#91;1&#93;</a></sup> DIF analysis  provides an indication of unexpected behavior of items on a test. An item does not display DIF if people from different groups have a different probability to give a certain response; it displays DIF if and only if people from different groups <i>with the same underlying true ability</i> have a different probability of giving a certain response. Common procedures for assessing DIF are Mantel-Haenszel, <a href=\"/wiki/Item_response_theory\" title=\"Item response theory\">item response theory</a> (IRT) based methods, and <a href=\"/wiki/Logistic_regression\" title=\"Logistic regression\">logistic regression</a>.<sup id=\"cite_ref-2\" class=\"reference\"><a href=\"#cite_note-2\">&#91;2&#93;</a></sup>\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Description\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Description</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Forms\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Forms</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#Procedures_for_detecting_DIF\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Procedures for detecting DIF</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-4\"><a href=\"#Mantel-Haenszel\"><span class=\"tocnumber\">3.1</span> <span class=\"toctext\">Mantel-Haenszel</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-5\"><a href=\"#Odds_ratio\"><span class=\"tocnumber\">3.1.1</span> <span class=\"toctext\">Odds ratio</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-2 tocsection-6\"><a href=\"#Item_response_theory\"><span class=\"tocnumber\">3.2</span> <span class=\"toctext\">Item response theory</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-7\"><a href=\"#Wald_statistic\"><span class=\"tocnumber\">3.2.1</span> <span class=\"toctext\">Wald statistic</span></a></li>\n<li class=\"toclevel-3 tocsection-8\"><a href=\"#Likelihood-ratio_test\"><span class=\"tocnumber\">3.2.2</span> <span class=\"toctext\">Likelihood-ratio test</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-2 tocsection-9\"><a href=\"#Logistic_regression\"><span class=\"tocnumber\">3.3</span> <span class=\"toctext\">Logistic regression</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-10\"><a href=\"#Considerations\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Considerations</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-11\"><a href=\"#Sample_size\"><span class=\"tocnumber\">4.1</span> <span class=\"toctext\">Sample size</span></a></li>\n<li class=\"toclevel-2 tocsection-12\"><a href=\"#Items\"><span class=\"tocnumber\">4.2</span> <span class=\"toctext\">Items</span></a></li>\n<li class=\"toclevel-2 tocsection-13\"><a href=\"#Statistics_versus_reasoning\"><span class=\"tocnumber\">4.3</span> <span class=\"toctext\">Statistics versus reasoning</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-14\"><a href=\"#Statistical_software\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">Statistical software</span></a></li>\n<li class=\"toclevel-1 tocsection-15\"><a href=\"#See_also\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-16\"><a href=\"#References\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">References</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"Description\">Description</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=1\" title=\"Edit section: Description\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>DIF refers to differences in the functioning of items across groups, oftentimes demographic, which are matched on the latent trait or more generally the attribute being measured by the items or test.<sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">&#91;3&#93;</a></sup><sup id=\"cite_ref-4\" class=\"reference\"><a href=\"#cite_note-4\">&#91;4&#93;</a></sup> It is important to note that when examining items for DIF, the groups must be matched on the measured attribute, otherwise this may result in inaccurate detection of DIF. In order to create a general understanding of DIF or measurement bias, consider the following example offered by Osterlind and Everson (2009).<sup id=\"cite_ref-5\" class=\"reference\"><a href=\"#cite_note-5\">&#91;5&#93;</a></sup> In this case, Y refers to a response to a particular test item which is determined by the latent <a href=\"/wiki/Construct_(philosophy)\" title=\"Construct (philosophy)\">construct</a> being measured. The latent construct of interest is referred to as theta (\u03b8) where Y is an indicator of \u03b8 which can be arranged in terms of the <a href=\"/wiki/Probability_distribution\" title=\"Probability distribution\">probability distribution</a> of Y on \u03b8 by the expression <big><b><i>f</i>(Y)|\u03b8</b></big>.  Therefore, response Y is conditional on the latent trait (\u03b8). Because DIF examines differences in the conditional probabilities of Y between groups, let us label the groups as the \"reference\" and \"focal\" groups. Although the designation does not matter, a typical practice in the literature is to designate the reference group as the group who is suspected to have an advantage while the focal group refers to the group anticipated to be disadvantaged by the test.<sup>[3]</sup>  Therefore, given the functional relationship <big><b><i>f</i>(Y)|\u03b8</b></big> and under the assumption that there are identical <a href=\"/wiki/Measurement_error\" class=\"mw-redirect\" title=\"Measurement error\">measurement error</a> distributions for the reference and focal groups it can be concluded that under the <a href=\"/wiki/Null_hypothesis\" title=\"Null hypothesis\">null hypothesis</a>:\n</p>\n<big><big><center><b><i>f</i> (Y = 1 | \u03b8, G = r) = <i>f</i> (Y = 1 | \u03b8, G = f)</b></center></big></big>\n<p>with G corresponding to the grouping variable, \"r\" the reference group, and \"f\" the focal group. This equation represents an instance where DIF is not present. In this case, the absence of DIF is determined by the fact that the <a href=\"/wiki/Conditional_probability\" title=\"Conditional probability\">conditional probability</a> distribution of Y is not dependent on group membership. To illustrate, consider an item with response options 0 and 1, where Y = 0 indicates an incorrect response, and Y = 1 indicates a correct response. The probability of correctly responding to an item is the same for members of either group. This indicates that there is no DIF or item bias because members of the reference and focal group with the same underlying ability or attribute have the same probability of responding correctly. Therefore, there is no bias or disadvantage for one group over the other.\n</p><p>Consider the instance where the conditional probability of Y is not the same for the reference and focal groups. In other words, members of different groups with the same trait or ability level have unequal probability distributions on Y. Once controlling for \u03b8, there is a clear dependency between group membership and performance on an item. For <a href=\"/wiki/Dichotomous\" class=\"mw-redirect\" title=\"Dichotomous\">dichotomous</a> items, this suggests that when the focal and reference groups are at the same location on \u03b8, there is a different probability of getting a correct response or endorsing an item. Therefore, the group with the higher conditional probability of correctly responding to an item is the group advantaged by the test item. This suggests that the test item is biased and functions differently for the groups, therefore exhibits DIF.\n</p><p>It is important to draw the distinction between DIF or measurement bias and ordinary group differences. Whereas group differences indicate differing score distributions on Y, DIF explicitly involves conditioning on \u03b8. For instance, consider the following equation:\n</p>\n<big><big><center><b><i>p</i> (Y = 1 | G = g) \u2260 <i>p</i>(Y = 1)</b></center></big></big>\n<p>This indicates that an examinee's score is conditional on grouping such that having information about group membership changes the probability of a correct response. Therefore, if the groups differ on \u03b8, and performance depends on \u03b8, then the above equation would suggest item bias even in the absence of DIF. For this reason, it is generally agreed upon in the measurement literature that differences on Y conditional on group membership alone is inadequate for establishing bias.<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;6&#93;</a></sup><sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">&#91;7&#93;</a></sup><sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">&#91;8&#93;</a></sup> In fact, differences on \u03b8 or ability are common between groups and establish the basis for much research. Remember to establish bias or DIF, groups must be matched on \u03b8 and then demonstrate differential probabilities on Y as a function of group membership.\n</p>\n<h2><span class=\"mw-headline\" id=\"Forms\">Forms</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=2\" title=\"Edit section: Forms\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Uniform DIF is the simplest type of DIF where the magnitude of conditional dependency is relatively invariant across the latent trait continuum (\u03b8). The item of interest consistently gives one group an advantage across all levels of ability \u03b8.<sup id=\"cite_ref-9\" class=\"reference\"><a href=\"#cite_note-9\">&#91;9&#93;</a></sup> Within an item response theory (IRT) framework this would be evidenced when both item characteristic curves (ICC) are equally discriminating yet exhibit differences in the difficulty parameters (i.e., <i>a<sub>r</sub> = a<sub>f</sub></i> and <i>b<sub>r</sub> &lt; b<sub>f</sub></i>) as depicted in Figure 1.<sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">&#91;10&#93;</a></sup> However, nonuniform DIF presents an interesting case. Rather than a consistent advantage being given to the reference group across the ability continuum, the conditional dependency moves and changes direction at different locations on the \u03b8 continuum.<sup id=\"cite_ref-11\" class=\"reference\"><a href=\"#cite_note-11\">&#91;11&#93;</a></sup> For instance, an item may give the reference group a minor advantage at the lower end of the continuum while a major advantage at the higher end. Also, unlike uniform DIF, an item can simultaneously vary in discrimination for the two groups while also varying in difficulty (i.e., <i>a<sub>r</sub> \u2260 a<sub>f</sub></i> and <i>b<sub>r</sub> &lt; b<sub>f</sub></i>). Even more complex is \"crossing\" nonuniform DIF.  As demonstrated in Figure 2, this occurs when an item gives an advantage to a reference group at one end of the \u03b8 continuum while favors the focal group at the other end. Differences in ICCs indicate that examinees from the two groups with identical ability levels have unequal probabilities of correctly responding to an item. When the curves are different but do not intersect, this is evidence of uniform DIF. However, if the ICCs cross at any point along the \u03b8 scale, there is evidence of nonuniform DIF.\n</p>\n<center>\n<p><a href=\"/wiki/File:Uniform_DIF_curve.png\" class=\"image\"><img alt=\"Uniform DIF curve.png\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/2/2d/Uniform_DIF_curve.png/550px-Uniform_DIF_curve.png\" width=\"550\" height=\"474\" srcset=\"//upload.wikimedia.org/wikipedia/en/2/2d/Uniform_DIF_curve.png 1.5x\" data-file-width=\"777\" data-file-height=\"669\" /></a>\n<a href=\"/wiki/File:Nonuni_DIF_ICC.png\" class=\"image\"><img alt=\"Nonuni DIF ICC.png\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/d/d2/Nonuni_DIF_ICC.png/530px-Nonuni_DIF_ICC.png\" width=\"530\" height=\"500\" srcset=\"//upload.wikimedia.org/wikipedia/en/d/d2/Nonuni_DIF_ICC.png 1.5x\" data-file-width=\"715\" data-file-height=\"675\" /></a>\n</p>\n</center>\n<div style=\"clear:both;\"></div>\n<h2><span class=\"mw-headline\" id=\"Procedures_for_detecting_DIF\">Procedures for detecting DIF</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=3\" title=\"Edit section: Procedures for detecting DIF\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Mantel-Haenszel\">Mantel-Haenszel</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=4\" title=\"Edit section: Mantel-Haenszel\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>A common procedure for detecting DIF is the Mantel-Haenszel (MH) approach.<sup id=\"cite_ref-12\" class=\"reference\"><a href=\"#cite_note-12\">&#91;12&#93;</a></sup> The MH procedure is a <a href=\"/wiki/Chi-squared_test\" title=\"Chi-squared test\">chi-squared</a> contingency table based approach which examines differences between the reference and focal groups on all items of the test, one by one.<sup id=\"cite_ref-13\" class=\"reference\"><a href=\"#cite_note-13\">&#91;13&#93;</a></sup> The ability continuum, defined by total test scores, is divided into <i>k</i> intervals which then serves as the basis for matching members of both groups.<sup id=\"cite_ref-14\" class=\"reference\"><a href=\"#cite_note-14\">&#91;14&#93;</a></sup> A 2 x 2 <a href=\"/wiki/Contingency_table\" title=\"Contingency table\">contingency table</a> is used at each interval of <i>k</i> comparing both groups on an individual item. The rows of the contingency table correspond to group membership (reference or focal) while the columns correspond to correct or incorrect responses. The following table presents the general form for a single item at the <i>k</i>th ability interval.\n</p>\n<center>\n<p><a href=\"/wiki/File:MHDIFTable.png\" class=\"image\"><img alt=\"MHDIFTable.png\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/8/88/MHDIFTable.png/550px-MHDIFTable.png\" width=\"550\" height=\"221\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/8/88/MHDIFTable.png/825px-MHDIFTable.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/8/88/MHDIFTable.png/1100px-MHDIFTable.png 2x\" data-file-width=\"1415\" data-file-height=\"568\" /></a>\n</p>\n</center>\n<h4><span class=\"mw-headline\" id=\"Odds_ratio\">Odds ratio</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=5\" title=\"Edit section: Odds ratio\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>The next step in the calculation of the MH statistic is to use data from the contingency table to obtain an <a href=\"/wiki/Odds_ratio\" title=\"Odds ratio\">odds ratio</a> for the two groups on the item of interest at a particular <i>k</i> interval. This is expressed in terms of <i>p</i> and <i>q</i> where <i>p</i> represents the <a href=\"/wiki/Ratio\" title=\"Ratio\">proportion</a> correct and <i>q</i> the proportion incorrect for both the reference (R) and focal (F) groups. For the MH procedure, the obtained odds ratio is represented by <big><b>\u03b1</b></big> with possible value ranging from 0 to <big>\u221e</big>. A <big><b>\u03b1</b></big> value of 1.0 indicates an absence of DIF and thus similar performance by both groups. Values greater than 1.0 suggest that the reference group outperformed or found the item less difficult than the focal group. On the other hand, if the obtained value is less than 1.0, this is an indication that the item was less difficult for the focal group.<sup>[8]</sup> Using variables from the contingency table above, the calculation is as follows:\n</p><p><b><big><big>\u03b1 = &#x200b;<span class=\"frac nowrap\"><sup>(p<sub>Rk</sub> / q<sub>Rk</sub>)</sup>&#8260;<sub>(p<sub>Fk</sub> / q<sub>Fk</sub>) </sub></span></big></big></b>\n</p><p><b><big><big> = &#x200b;<span class=\"frac nowrap\"><sup>(A<sub>k</sub> / (A<sub>k</sub> + B<sub>k</sub>)) / (B<sub>k</sub> / (A<sub>k</sub> + B<sub>k</sub>)) </sup>&#8260;<sub> (C<sub>k</sub> / (C<sub>k</sub> + D<sub>k</sub>)) / (D<sub>k</sub> / (C<sub>k</sub> + D<sub>k</sub>))</sub></span></big></big></b>\n</p><p><b><big><big>= &#x200b;<span class=\"frac nowrap\"><sup>(A<sub>k</sub> / B<sub>k</sub>)</sup>&#8260;<sub>(C<sub>k</sub> / D<sub>k</sub>)</sub></span></big></big></b>\n</p><p><b><big><big>= &#x200b;<span class=\"frac nowrap\"><sup>A<sub>k</sub>D<sub>k</sub></sup>&#8260;<sub>B<sub>k</sub>C<sub>k</sub></sub></span></big></big></b>\n</p><p>The above computation pertains to an individual item at a single ability interval. The population estimate <big><b>\u03b1</b></big> can be extended to reflect a common odds ratio across all ability intervals <i>k</i> for a specific item. The common odds ratio estimator is denoted <b>\u03b1<sub>MH</sub></b> and can be computed by the following equation:\n</p><p><b><big><big>\u03b1<sub>MH</sub> = &#x200b;<span class=\"frac nowrap\"><sup>\u2211(A<sub>k</sub>D<sub>k</sub> / N<sub>k</sub>)</sup>&#8260;<sub> \u2211(B<sub>k</sub>C<sub>k</sub> / N<sub>k</sub>)</sub></span></big></big></b><br />\nfor all values of <i>k</i> and where N<sub>k</sub> represents the total sample size at the <i>kth</i> interval.\n</p><p>The obtained <b>\u03b1<sub>MH</sub></b> is often standardized through log transformation, centering the value around 0.<sup id=\"cite_ref-15\" class=\"reference\"><a href=\"#cite_note-15\">&#91;15&#93;</a></sup> The new transformed estimator MH<sub>D-DIF</sub> is computed as follows:\n</p><p><b><big>MH<sub>D-DIF</sub> = -2.35ln(\u03b1<sub>MH</sub>)</big></b>\n</p><p>Thus an obtained value of 0 would indicate no DIF. In examining the equation, it is important to note that the minus sign changes the interpretation of values less than or greater than 0. Values less than 0 indicate a reference group advantage whereas values greater than 0 indicate an advantage for the focal group.\n</p>\n<h3><span class=\"mw-headline\" id=\"Item_response_theory\">Item response theory</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=6\" title=\"Edit section: Item response theory\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Item response theory (IRT) is another widely used method for assessing DIF. IRT allows for a critical examination of responses to particular items from a test or measure. As noted earlier, DIF examines the probability of correctly responding to or endorsing an item conditioned on the latent trait or ability. Because IRT examines the <a href=\"/wiki/Monotonic\" class=\"mw-redirect\" title=\"Monotonic\">monotonic</a> relationship between responses and the latent trait or ability, it is a fitting approach for examining DIF.<sup id=\"cite_ref-16\" class=\"reference\"><a href=\"#cite_note-16\">&#91;16&#93;</a></sup>\n</p><p>Three major advantages of using IRT in DIF detection are:<sup id=\"cite_ref-17\" class=\"reference\"><a href=\"#cite_note-17\">&#91;17&#93;</a></sup>\n</p>\n<ul><li>Compared to <a href=\"/wiki/Classical_test_theory\" title=\"Classical test theory\">classical test theory</a>, IRT <a href=\"/wiki/Parameter\" title=\"Parameter\">parameter</a> estimates are not as confounded by sample characteristics.</li>\n<li>Statistical properties of items can be expressed with greater precision which increases the interpretation accuracy of DIF between two groups.</li>\n<li>These statistical properties of items can be expressed graphically, improving interpretability and understanding of how items function differently between groups.</li></ul>\n<p>In relation to DIF, item parameter estimates are computed and graphically examined via item characteristic curves (ICCs) also referred to as trace lines or item response functions (IRF). After examination of ICCs and subsequent suspicion of DIF, statistical procedures are implemented to test differences between parameter estimates. \nICCs represent mathematical functions of the relationship between positioning on the latent trait continuum and the probability of giving a particular response.<sup id=\"cite_ref-18\" class=\"reference\"><a href=\"#cite_note-18\">&#91;18&#93;</a></sup> Figure 3 illustrates this relationship as a <a href=\"/wiki/Logistic_function\" title=\"Logistic function\">logistic function</a>. Individuals lower on the latent trait or with less ability have a lower probability of getting a correct response or endorsing an item, especially as difficulty increases. Thus, those higher on the latent trait or in ability have a greater chance of a correct response or endorsing an item. For instance, on a depression inventory, highly depressed individuals would have a greater probability of endorsing an item than individuals with lower depression. Similarly, individuals with higher math ability have a greater probability of getting a math item correct than those with lesser ability. Another critical aspect of ICCs pertains to the <a href=\"/wiki/Inflection_point\" title=\"Inflection point\">inflection point</a>.  This is the point on the curve where the probability of a particular response is .5 and also represents the maximum value for the <a href=\"/wiki/Slope\" title=\"Slope\">slope</a>.<sup id=\"cite_ref-19\" class=\"reference\"><a href=\"#cite_note-19\">&#91;19&#93;</a></sup> This inflection point indicates where the probability of a correct response or endorsing an item becomes greater than 50%, except when a <i>c</i> parameter is greater than 0 which then places the inflection point at 1 + c/2 (a description will follow below). The inflection point is determined by the difficulty of the item which corresponds to values on the ability or latent trait continuum.<sup id=\"cite_ref-20\" class=\"reference\"><a href=\"#cite_note-20\">&#91;20&#93;</a></sup> Therefore, for an easy item, this inflection point may be lower on the ability continuum while for a difficult item it may be higher on the same scale.\n</p>\n<center>\n<p><a href=\"/wiki/File:ICC_slope_ip.png\" class=\"image\"><img alt=\"ICC slope ip.png\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/a/ad/ICC_slope_ip.png/550px-ICC_slope_ip.png\" width=\"550\" height=\"467\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/a/ad/ICC_slope_ip.png/825px-ICC_slope_ip.png 1.5x, //upload.wikimedia.org/wikipedia/en/a/ad/ICC_slope_ip.png 2x\" data-file-width=\"834\" data-file-height=\"708\" /></a>\n</p>\n</center>\n<p>Before presenting statistical procedures for testing differences of item parameters, it is important to first provide a general understanding of the different parameter estimation models and their associated parameters. These include the one-, two-, and three-parameter logistic (PL) models. All these models assume a single underling latent trait or ability. All three of these models have an item difficulty parameter denoted <i>b</i>. For the 1PL and 2PL models, the <i>b</i> parameter corresponds to the inflection point on the ability scale, as mentioned above.  In the case of the 3PL model, the inflection corresponds to 1 + c/2 where <i>c</i> is a lower asymptote (discussed below).  Difficultly values, in theory, can range from -<big>\u221e</big> to +<big>\u221e</big>; however in practice they rarely exceed \u00b13. Higher values are indicative of harder test items. Items exhibiting low <i>b</i> parameters are easy test items.<sup id=\"cite_ref-21\" class=\"reference\"><a href=\"#cite_note-21\">&#91;21&#93;</a></sup> Another parameter that is estimated is a discrimination parameter designated <i>a</i> . This parameter pertains to an item's ability to discriminate among individuals. The <i>a</i> parameter is estimated in the 2PL and 3PL models. In the case of the 1PL model, this parameter is constrained to be equal between groups. In relation to ICCs, the <i>a</i> parameter is the slope of the inflection point. As mentioned earlier, the slope is maximal at the inflection point. The <i>a</i> parameter, similar to the <i>b</i> parameter, can range from -<big>\u221e</big> to +<big>\u221e</big>; however typical values are less than 2. In this case, higher value indicate greater discrimination between individuals.<sup id=\"cite_ref-22\" class=\"reference\"><a href=\"#cite_note-22\">&#91;22&#93;</a></sup> The 3PL model has an additional parameter referred to as a <i>guessing</i> or pseudochance parameter and is denoted by <i>c</i>. This corresponds to a lower <a href=\"/wiki/Asymptote\" title=\"Asymptote\">asymptote</a> which essentially allows for the possibility of an individual to get a moderate or difficult item correct even if they are low in ability. Values for <i>c</i> range between 0 and 1, however typically fall below .3.<sup id=\"cite_ref-23\" class=\"reference\"><a href=\"#cite_note-23\">&#91;23&#93;</a></sup>\n</p><p>When applying statistical procedures to assess for DIF, the <i>a</i> and <i>b</i> parameters (discrimination and difficulty) are of particular interest. However, assume a 1PL model was used, where the <i>a</i> parameters are constrained to be equal for both groups leaving only the estimation of the <i>b</i> parameters. After examining the ICCs, there is an apparent difference in <i>b</i> parameters for both groups. Using a similar method to a <a href=\"/wiki/Student%27s_t-test\" title=\"Student&#39;s t-test\">Student's t-test</a>, the next step is to determine if the difference in difficulty is statistically significant. Under the null hypothesis\n</p><p><big><big><b>H<sub>0</sub>: b<sub>r</sub> = b<sub>f</sub></b></big></big>\n</p><p>Lord (1980) provides an easily computed and <a href=\"/wiki/Normally_distributed\" class=\"mw-redirect\" title=\"Normally distributed\">normally distributed</a> test statistic.\n</p><p><big><big><b>d = (b<sub>r</sub> - b<sub>f</sub>) / SE(b<sub>r</sub> - b<sub>f</sub>)</b></big></big>\n</p><p>The <a href=\"/wiki/Standard_error\" title=\"Standard error\">standard error</a> of the difference between <i>b</i> parameters is calculated by\n</p><p><b><big><big>\u221a</big></big><big>[SE(b<sub>r</sub>)]<sup>2</sup></big> + <big><big>\u221a</big></big><big>[SE(b<sub>f</sub>)]<sup>2</sup></big></b>\n</p>\n<h4><span class=\"mw-headline\" id=\"Wald_statistic\">Wald statistic</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=7\" title=\"Edit section: Wald statistic\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>However, more common than not, a 2PL or 3PL model is more appropriate than fitting a 1PL model to the data and thus both the <i>a</i> and <i>b</i> parameters should be tested for DIF. Lord (1980) proposed another method for testing differences in both the <i>a</i> and <i>b</i> parameters, where <i>c</i> parameters are constrained to be equal across groups. This test yields a <a href=\"/wiki/Wald_statistic\" class=\"mw-redirect\" title=\"Wald statistic\">Wald statistic</a> which follows a chi-square distribution. In this case the null hypothesis being tested is\n</p><p><big><big><b>H<sub>0</sub>: a<sub>r</sub> = a<sub>f</sub></b></big> and <big><b>b<sub>r </sub> = b<sub>f</sub></b></big></big>.\n</p><p>First, a 2 x 2 <a href=\"/wiki/Covariance_matrix\" title=\"Covariance matrix\">covariance matrix</a> of the parameter estimates is calculated for each group which are represented  by <big><b>S<sub>r</sub></b></big><b> and <big>S<sub>f</sub></big></b> for the reference and focal groups. These covariance matrices are computed by inverting the obtained information matrices.\n</p><p>Next, the differences between estimated parameters are put into a 2 x 1 vector and is denoted by\n</p><p><big><big><b>V' = (a<sub>r</sub> - a<sub>f</sub>, b<sub>r</sub> - b<sub>f</sub>)</b></big></big>\n</p><p>Next, covariance matrix <big><b>S</b></big> is estimated by summing <big><b>S<sub>r</sub></b></big><b> and <big>S<sub>f</sub></big></b>.\n</p><p>Using this information, the Wald statistic is computed as follows:\n</p><p><big><big><b>\u03c7<sup>2</sup> = V'S<sup>\u22121</sup>V</b></big></big>\n</p><p>which is evaluated at 2 <a href=\"/wiki/Degrees_of_freedom\" title=\"Degrees of freedom\">degrees of freedom</a>.\n</p>\n<h4><span class=\"mw-headline\" id=\"Likelihood-ratio_test\">Likelihood-ratio test</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=8\" title=\"Edit section: Likelihood-ratio test\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>The <a href=\"/wiki/Likelihood-ratio_test\" title=\"Likelihood-ratio test\">Likelihood-ratio test</a> is another IRT based method for assessing DIF. This procedure involves comparing the ratio of two models. Under model (M<sub>c</sub>) item parameters are constrained to be equal or invariant between the reference and focal groups. Under model (M<sub>v</sub>) item parameters are free to vary.<sup id=\"cite_ref-24\" class=\"reference\"><a href=\"#cite_note-24\">&#91;24&#93;</a></sup> The likelihood function under M<sub>c</sub> is denoted (L<sub>c</sub>) while the likelihood function under M<sub>v</sub> is designated (L<sub>v</sub>). The items constrained to be equal serve as anchor items for this procedure while items suspected of DIF are allowed to freely vary. By using anchor items and allowing remaining item parameters to vary, multiple items can be simultaneously assessed for DIF.<sup id=\"cite_ref-25\" class=\"reference\"><a href=\"#cite_note-25\">&#91;25&#93;</a></sup> However, if the likelihood ratio indicates potential DIF, an item-by-item analysis would be appropriate to determine which items, if not all, contain DIF. The likelihood ratio of the two models is computed by\n</p><p><big><b>G<sup>2</sup> = 2ln[L<sub>v</sub> / L<sub>c</sub>]</b></big>\n</p><p>Alternatively, the ratio can be expressed by\n</p><p><big><b>G<sup>2</sup> = -2ln[L<sub>c</sub> / L<sub>v</sub>]</b></big>\n</p><p>where L<sub>v</sub> and L<sub>c</sub> are inverted and then multiplied by -2ln.\n</p><p>G<sup>2</sup> approximately follows a chi square distribution, especially with larger samples. Therefore, it is evaluated by the degrees of freedom that correspond to the number of constraints necessary to derive the constrained model from the freely varying model.<sup id=\"cite_ref-26\" class=\"reference\"><a href=\"#cite_note-26\">&#91;26&#93;</a></sup> For instance, if a 2PL model is used and both <i>a</i> and <i>b</i> parameters are free to vary under M<sub>v</sub> and these same two parameters are constrained in under M<sub>c</sub>, then the ratio is evaluated at 2 degrees of freedom.\n</p>\n<h3><span class=\"mw-headline\" id=\"Logistic_regression\">Logistic regression</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=9\" title=\"Edit section: Logistic regression\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p><a href=\"/wiki/Logistic_regression\" title=\"Logistic regression\">Logistic regression</a> approaches to DIF detection involve running a separate analysis for each item. The independent variables included in the analysis are group membership, an ability matching variable typically a total score, and an interaction term between the two.  The dependent variable of interest is the probability or likelihood of getting a correct response or endorsing an item. Because the outcome of interest is expressed in terms of probabilities, <a href=\"/wiki/Maximum_likelihood_estimation\" title=\"Maximum likelihood estimation\">maximum likelihood estimation</a> is the appropriate procedure.<sup id=\"cite_ref-27\" class=\"reference\"><a href=\"#cite_note-27\">&#91;27&#93;</a></sup> This set of variables can then be expressed by the following regression equation:\n</p>\n<center><big><big><b>Y = \u03b2<sub>0</sub> + \u03b2<sub>1</sub>M + \u03b2<sub>2</sub>G + \u03b2<sub>3</sub>MG</b></big></big></center>\n<p>where <big>\u03b2<sub>0</sub></big> corresponds to the intercept or the probability of a response when <big>M</big> and <big>G</big> are equal to 0 with remaining <big>\u03b2<sub>s</sub></big> corresponding to weight coefficients for each independent variable. The first independent variable, <big>M</big>, is the matching variable used to link individuals on ability, in this case a total test score, similar to that employed by the Mantel-Haenszel procedure. The group membership variable is denoted <big>G</big> and in the case of regression is represented through dummy coded variables. The final term <big>MG</big> corresponds to the interaction between the two above mentioned variables.\n</p><p>For this procedure, variables are entered hierarchically. Following the structure of the regression equation provided above, variables are entered by the following sequence: matching variable <big>M</big>, grouping variable <big>G</big>, and the interaction variable <big>MG</big>. Determination of DIF is made by evaluating the obtained chi-square statistic with 2 degrees of freedom. Additionally, parameter estimate significance is tested.\n</p><p>From the results of the logistic regression, DIF would be indicated if individuals matched on ability have significantly different probabilities of responding to an item and thus differing logistic regression curves. Conversely, if the curves for both groups are the same, then the item is unbiased and therefore DIF is not present. In terms of uniform and nonuniform DIF, if the intercepts and matching variable parameters for both groups are not equal, then there is evidence of uniform DIF. However, if there is a nonzero interaction parameter, this is an indication of nonuniform DIF.<sup id=\"cite_ref-28\" class=\"reference\"><a href=\"#cite_note-28\">&#91;28&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Considerations\">Considerations</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=10\" title=\"Edit section: Considerations\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Sample_size\">Sample size</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=11\" title=\"Edit section: Sample size\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>The first consideration pertains to issues of sample size, specifically with regard to the reference and focal groups. Prior to any analyses, information about the amount of people in each group is typically known such as the number of males/females or members of ethnic/racial groups. However, the issue more closely revolves around whether the amount of people per group is sufficient for there to be enough <a href=\"/wiki/Statistical_power\" class=\"mw-redirect\" title=\"Statistical power\">statistical power</a> to identify DIF. In some instances such as ethnicity there may be evidence of unequal group sizes such that Whites represent a far larger group sample than each individual ethnic group being represented. Therefore, in such instances, it may be appropriate to modify or adjust data so that the groups being compared for DIF are in fact equal or closer in size. Dummy coding or recoding is a common practice employed to adjust for disparities in the size of the reference and focal group. In this case, all Non-White ethnic groups can be grouped together in order to have a relatively equal sample size for the reference and focal groups. This would allow for a \"majority/minority\" comparison of item functioning. If modifications are not made and DIF procedures are carried out, there may not be enough statistical power to identify DIF even if DIF exists between groups.\n</p><p>Another issue that pertains to sample size directly relates to the statistical procedure being used to detect DIF. Aside from sample size considerations of the reference and focal groups, certain characteristics of the sample itself must be met to comply with assumptions of each statistical test utilized in DIF detection. For instance, using IRT approaches may require larger samples than required for the Mantel-Haenszel procedure. This is important, as investigation of group size may direct one toward using one procedure over another. Within the logistic regression approach, leveraged values and outliers are of particular concern and must be examined prior to DIF detection. Additionally, as with all analyses, statistical test assumptions must be met. Some procedures are more robust to minor violations while others less so. Thus, the distributional nature of sample responses should be investigated prior to implementing any DIF procedures.\n</p>\n<h3><span class=\"mw-headline\" id=\"Items\">Items</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=12\" title=\"Edit section: Items\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Determining the number of items being used for DIF detection must be considered. No standard exists as to how many items should be used for DIF detection as this changes from study-to-study. In some cases it may be appropriate to test all items for DIF, whereas in others it may not be necessary. If only certain items are suspected of DIF with adequate reasoning, then it may be more appropriate to test those items and not the entire set. However, oftentimes it is difficult to simply assume which items may be problematic. For this reason, it is often recommended to simultaneously examine all test items for DIF. This will provide information about all items, shedding light on problematic items as well as those that function similarly for both the reference and focal groups. With regard to statistical tests, some procedures such as IRT-Likelihood Ratio testing require the use of anchor items. Some items are constrained to be equal across groups while items suspected of DIF are allowed to freely vary. In this instance, only a subset would be identified as DIF items while the rest would serve as a comparison group for DIF detection. Once DIF items are identified, the anchor items can also be analyzed by then constraining the original DIF items and allowing the original anchor items to freely vary. Thus it seems that testing all items simultaneously may be a more efficient procedure. However, as noted, depending on the procedure implemented different methods for selecting DIF items are used.\n</p><p>Aside from identifying the number of items being used in DIF detection, of additional importance is determining the number of items on the entire test or measure itself. The typical recommendation as noted by Zumbo (1999) is to have a minimum of 20 items. The reasoning for a minimum of 20 items directly relates to the formation of matching criteria. As noted in earlier sections, a total test score is typically used as a method for matching individuals on ability. The total test score is divided up into normally 3-5 ability levels (k) which is then used to match individuals on ability prior to DIF analysis procedures. Using a minimum of 20 items allows for greater variance in the score distribution which results in more meaningful ability level groups. Although the psychometric properties of the instrument should have been assessed prior to being utilized, it is important that the <a href=\"/wiki/Validity_(logic)\" title=\"Validity (logic)\">validity</a> and <a href=\"/wiki/Reliability_(psychometrics)\" class=\"mw-redirect\" title=\"Reliability (psychometrics)\">reliability</a> of an instrument be adequate. Test items need to accurately tap into the construct of interest in order to derive meaningful ability level groups. Of course, one does not want to inflate reliability coefficients by simply adding redundant items. The key is to have a valid and reliable measure with sufficient items to develop meaningful matching groups. Gadermann et al. (2012),<sup id=\"cite_ref-29\" class=\"reference\"><a href=\"#cite_note-29\">&#91;29&#93;</a></sup> Revelle and Zinbarg (2009),<sup id=\"cite_ref-30\" class=\"reference\"><a href=\"#cite_note-30\">&#91;30&#93;</a></sup> and John and Soto (2007)<sup id=\"cite_ref-31\" class=\"reference\"><a href=\"#cite_note-31\">&#91;31&#93;</a></sup> offer more information on modern approaches to structural validation and more precise and appropriate methods for assessing reliability.\n</p>\n<h3><span class=\"mw-headline\" id=\"Statistics_versus_reasoning\">Statistics versus reasoning</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=13\" title=\"Edit section: Statistics versus reasoning\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>As with all <a href=\"/wiki/Psychological_research\" title=\"Psychological research\">psychological research</a> and psychometric evaluation, <a href=\"/wiki/Statistics\" title=\"Statistics\">statistics</a> play a vital role but should by no means be the sole basis for decisions and conclusions reached. Reasoned judgment is of critical importance when evaluating items for DIF. For instance, depending on the statistical procedure used for DIF detection, differing results may be yielded. Some procedures are more precise while others less so. For instance, the Mantel-Haenszel procedure requires the researcher to construct ability levels based on total test scores whereas IRT more effectively places individuals along the latent trait or ability continuum. Thus, one procedure may indicate DIF for certain items while others do not. Another issue is that sometimes DIF may be indicated but there is no clear reason why DIF exists. This is where reasoned judgment comes into play. The researcher must use common sense to derive meaning from DIF analyses. It is not enough to report that items function differently for groups, there needs to be a theoretical reason for why it occurs. Furthermore, evidence of DIF does not directly translate into unfairness in the test. It is common in DIF studies to identify some items that suggest DIF. This may be an indication of problematic items that need to be revised or omitted and not necessarily an indication of an unfair test. Therefore, DIF analysis can be considered a useful tool for item analysis but is more effective when combined with theoretical reasoning.\n</p>\n<h2><span class=\"mw-headline\" id=\"Statistical_software\">Statistical software</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=14\" title=\"Edit section: Statistical software\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Below are common statistical programs capable of performing the procedures discussed herein. By clicking on <a href=\"/wiki/List_of_statistical_packages\" title=\"List of statistical packages\">list of statistical packages</a>, you will be directed to a comprehensive list of open source, public domain, freeware, and proprietary statistical software.\n</p><p><b>Mantel-Haenszel procedure</b><br />\n</p>\n<ul><li>SPSS<br /></li>\n<li>SAS<br /></li>\n<li>Stata<br /></li>\n<li>R (e.g., 'difR'<sup id=\"cite_ref-difR_32-0\" class=\"reference\"><a href=\"#cite_note-difR-32\">&#91;32&#93;</a></sup> package)<br /></li>\n<li>Systat</li></ul>\n<p><b>IRT-based procedures</b><br />\n</p>\n<ul><li>BILOG-MG<br /></li>\n<li>MULTILOG<br /></li>\n<li>PARSCALE<br /></li>\n<li>TESTFACT<br /></li>\n<li>EQSIRT<br /></li>\n<li>R (e.g., 'difR'<sup id=\"cite_ref-difR_32-1\" class=\"reference\"><a href=\"#cite_note-difR-32\">&#91;32&#93;</a></sup> or 'mirt'<sup id=\"cite_ref-mirt_33-0\" class=\"reference\"><a href=\"#cite_note-mirt-33\">&#91;33&#93;</a></sup> package)<br /></li>\n<li>IRTPRO</li></ul>\n<p><b>Logistic regression</b><br />\n</p>\n<ul><li>SPSS<br /></li>\n<li>SAS<br /></li>\n<li>Stata<br /></li>\n<li>R (e.g., 'difR'<sup id=\"cite_ref-difR_32-2\" class=\"reference\"><a href=\"#cite_note-difR-32\">&#91;32&#93;</a></sup> package)<br /></li>\n<li>Systat</li></ul>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=15\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a href=\"/wiki/Measurement_invariance\" title=\"Measurement invariance\">Measurement invariance</a></li></ul>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Differential_item_functioning&amp;action=edit&amp;section=16\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap mw-references-columns\"><ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\">National Council on Measurement in Education <a rel=\"nofollow\" class=\"external free\" href=\"http://www.ncme.org/ncme/NCME/Resource_Center/Glossary/NCME/Resource_Center/Glossary1.aspx?hkey=4bb87415-44dc-4088-9ed9-e8515326a061#anchorD\">http://www.ncme.org/ncme/NCME/Resource_Center/Glossary/NCME/Resource_Center/Glossary1.aspx?hkey=4bb87415-44dc-4088-9ed9-e8515326a061#anchorD</a></span>\n</li>\n<li id=\"cite_note-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-2\">^</a></b></span> <span class=\"reference-text\">Zumbo, B.D. (2007). Three generations of differential item functioning (DIF) analyses: Considering where it has been, where it is now, and where it is going. <i>Language Assessment Quarterly, 4,</i> 223\u2013233.</span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\">Camilli, G. (2006). Test fairness: In R. L. (Ed.), <i>Educational measurement</i> (4th ed., pp. 220-256). Westport, CT: American Council on Education.</span>\n</li>\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\">Holland, P. W., &amp; Wainer, H. (1993). <i>Differential item functioning.</i> Hillsdale, NJ: Lawrence Erlbaum.</span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\">Osterlind, S. J. &amp; Everson, H. T. (2009). <i>Differential item functioning.</i> Thousand Oaks, CA: Sage Publishing.</span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\">Ackerman, T. (1992). A didactic explanation of item bias, item impact, and item validity from a multidimensional perspective. <i>Journal of Educational Measurement, 29,</i> 674-691.</span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\">Lord, F. M. (1980). <i>Applications of item response theory to practical testing problems.</i> Hillsdale, NJ: Lawrence Erlbaum.</span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\">Millsap, R. E., &amp; Everson, H. T. (1993). Methodological review: Statistical approaches for assessing measurement bias. <i>Applied Psychological Measurement, 17(4),</i> 297-334.</span>\n</li>\n<li id=\"cite_note-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-9\">^</a></b></span> <span class=\"reference-text\">Walker, C. (2011). What's the DIF? Why differential item functioning analyses are an important part of instrument development and validation. <i>Journal of Psychoeducational Assessment, 29,</i> 364-376</span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\"><a href=\"/wiki/Gideon_J._Mellenbergh\" title=\"Gideon J. Mellenbergh\">Mellenbergh, G. J.</a> (1982). Contingency table models for assessing item bias. <i>Journal of Educational Statistics, 7,</i> 105-118.</span>\n</li>\n<li id=\"cite_note-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-11\">^</a></b></span> <span class=\"reference-text\">Walker, C. M., Beretvas, S. N., Ackerman, T. A. (2001). An examination of conditioning variables used in computer adaptive testing for DIF. <i>Applied Measurement in Education, 14,</i> 3-16.</span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\">Mantel, N., &amp; Haenszel, W. (1959). Statistical aspects of the analysis of data from retrospective studies of disease. <i>Journal of the National Cancer Institute, 22,</i> 719-748.</span>\n</li>\n<li id=\"cite_note-13\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-13\">^</a></b></span> <span class=\"reference-text\">Marasculio, L. A., &amp; Slaughter, R. E. (1981). Statistical procedures for identifying possible sources of item bias based on 2 x 2 statistics. <i>Journal of Educational Measurement, 18,</i> 229-248.</span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\">Holland, P. W., &amp; Thayer, D. T. (1988). Differential item performance and the Mantel-Haenszel procedure. In H. Wainer &amp; H. I. Braun (Eds.), <i>Test validity</i> (pp. 129-145). Hillsdale, NJ: Erlbaum.</span>\n</li>\n<li id=\"cite_note-15\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-15\">^</a></b></span> <span class=\"reference-text\">Dorans, N. J., &amp; Holland, P. W. (1993). DIF detection and description: Mantel-Haenszel and standardization. In P. W. Holland &amp; H. Wainer (Eds.), <i>Differential item functioning</i> (pp. 35-66). Hillsdale, NJ: Erlbaum.</span>\n</li>\n<li id=\"cite_note-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-16\">^</a></b></span> <span class=\"reference-text\">Steinberg, L., &amp; Thissen, D. (2006). Using effect sizes for research reporting: Examples using item response theory to analyze differential item functioning. <i>Psychological Methods, 11(4),</i> 402-415.</span>\n</li>\n<li id=\"cite_note-17\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-17\">^</a></b></span> <span class=\"reference-text\">Camilli, G., &amp; Shepard, L. (1994). <i>Methods for identifying biased test items</i>. Thousand Oaks, CA: Sage.</span>\n</li>\n<li id=\"cite_note-18\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-18\">^</a></b></span> <span class=\"reference-text\">Reise, S. P., &amp; Ainsworth, A. T., &amp; Haviland, M. G. (2005). Item response theory: Fundamentals, applications, and promise in psychological research. <i>Current Directions in Psychological Science, 14,</i> 95-101.</span>\n</li>\n<li id=\"cite_note-19\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-19\">^</a></b></span> <span class=\"reference-text\">Edelen, M. O., Reeve, B. B. (2007). Applying item response theory (IRT) modeling to questionnaire development, evaluation, and refinement. <i>Quality of Life Research, 16,</i> 5-18.</span>\n</li>\n<li id=\"cite_note-20\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-20\">^</a></b></span> <span class=\"reference-text\">DeMars, C. (2010). <i>Item response theory.</i> New York: Oxford Press.</span>\n</li>\n<li id=\"cite_note-21\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-21\">^</a></b></span> <span class=\"reference-text\">Harris, D. (1989). Comparison of 1-, 2-, 3-parameter IRT models. <i>Educational Measurement: Issues and Practice</i>, 8, 35-41.</span>\n</li>\n<li id=\"cite_note-22\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-22\">^</a></b></span> <span class=\"reference-text\">Baker, F. B. (2001). <i>The basics of item response theory</i>.  ERIC Clearinghouse on Assessment and Evaluation.</span>\n</li>\n<li id=\"cite_note-23\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-23\">^</a></b></span> <span class=\"reference-text\">Birnbaum, A. (1968). Some latent trait models and their use in inferring an examinee\u2019s ability. Part 5 in F. M. Lord and M. R. Novick. <i>Statistical Theories of Mental Test Scores</i>. Reading, MA: Addison-Wesley</span>\n</li>\n<li id=\"cite_note-24\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-24\">^</a></b></span> <span class=\"reference-text\">Thissen, D., Steinberg, L., Gerrard, M. (1986). Beyond group differences: The concept of bias. <i>Psychological Bulletin, 99,</i> 118-128.</span>\n</li>\n<li id=\"cite_note-25\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-25\">^</a></b></span> <span class=\"reference-text\"><i>IRTPRO: User Guide</i>. (2011). Lincolnwood, IL: Scientific Software International, Inc.</span>\n</li>\n<li id=\"cite_note-26\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-26\">^</a></b></span> <span class=\"reference-text\">Thissen, D., Steinberg, L., &amp; Wainer, H. (1993). Detection of differential item functioning using the parameters of item response models. In P. W. Holland and &amp; H. Wainer (Eds.), <i>Differential item functioning</i>(pp. 67-113). Hillsdale, NJ: Lawrence Erlbaum.</span>\n</li>\n<li id=\"cite_note-27\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-27\">^</a></b></span> <span class=\"reference-text\">Bock, R. D. (1975). <i>Multivariate statistical methods</i>. New York: McGraw-Hill.</span>\n</li>\n<li id=\"cite_note-28\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-28\">^</a></b></span> <span class=\"reference-text\">Swaminathan, H., &amp; Rogers, H. J. (1990). Detecting differential item functioning using logistic regression procedures. <i>Journal of Educational Measurement, 27,</i> 361-370.</span>\n</li>\n<li id=\"cite_note-29\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-29\">^</a></b></span> <span class=\"reference-text\">Gadermann, A., M., Guhn, M., &amp; Zumbo, B. D. (2012). Estimating ordinal reliability for Likert-type and ordinal item response data: A conceptual, empirical, and practical guide. <i>Practical Assessment, Research, &amp; Evaluation, 17(3),</i> 1-13.</span>\n</li>\n<li id=\"cite_note-30\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-30\">^</a></b></span> <span class=\"reference-text\">Revelle, W., &amp; Zinbarg, R. E. (2009). Coefficients alpha, beta, omega, and the GLB: Comments on Sijtsma. <i>Psychometrika, 74(1),</i> 145-154.</span>\n</li>\n<li id=\"cite_note-31\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-31\">^</a></b></span> <span class=\"reference-text\">John, O. P., &amp; Soto, C. J. (2007). The importance of being valid: Reliability and the process of construct validation. In R. W. Robins, R. C. Fraley, &amp; R. F. Krueger (Eds.), <i>Handbook of research methods in personality psychology</i> (pp. 461-494). New York, NY: Cambridge University Press.</span>\n</li>\n<li id=\"cite_note-difR-32\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-difR_32-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-difR_32-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-difR_32-2\"><sup><i><b>c</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation journal\">Magis, David; B\u00e9land, S\u00e9bastien; Tuerlinckx, Francis; De Boeck, Paul (2010). \"A general framework and an R package for the detection of dichotomous differential item functioning\". <i>Behavior Research Methods</i>. <b>42</b> (3): 847\u2013862. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.3758/BRM.42.3.847\">10.3758/BRM.42.3.847</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Behavior+Research+Methods&amp;rft.atitle=A+general+framework+and+an+R+package+for+the+detection+of+dichotomous+differential+item+functioning&amp;rft.volume=42&amp;rft.issue=3&amp;rft.pages=847-862&amp;rft.date=2010&amp;rft_id=info%3Adoi%2F10.3758%2FBRM.42.3.847&amp;rft.aulast=Magis&amp;rft.aufirst=David&amp;rft.au=B%C3%A9land%2C+S%C3%A9bastien&amp;rft.au=Tuerlinckx%2C+Francis&amp;rft.au=De+Boeck%2C+Paul&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADifferential+item+functioning\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-mirt-33\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-mirt_33-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Chalmers, R. P. (2012). \"mirt: A Multidimensional Item Response Theory Package for the R Environment\". <i>Journal of Statistical Software</i>. <b>48</b> (6): 1\u201329.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Statistical+Software&amp;rft.atitle=mirt%3A+A+Multidimensional+Item+Response+Theory+Package+for+the+R+Environment&amp;rft.volume=48&amp;rft.issue=6&amp;rft.pages=1-29&amp;rft.date=2012&amp;rft.aulast=Chalmers&amp;rft.aufirst=R.+P.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADifferential+item+functioning\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n</ol></div></div>\n\n<!-- \nNewPP limit report\nParsed by mw2235\nCached time: 20180921141840\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.244 seconds\nReal time usage: 0.301 seconds\nPreprocessor visited node count: 918/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 14786/2097152 bytes\nTemplate argument size: 2542/2097152 bytes\nHighest expansion depth: 15/40\nExpensive parser function count: 4/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 15039/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.062/10.000 seconds\nLua memory usage: 2.21 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  223.542      1 -total\n 45.77%  102.306      1 Template:Cleanup\n 34.21%   76.474      1 Template:Reflist\n 21.91%   48.974      2 Template:Main_other\n 21.26%   47.516      2 Template:Cite_journal\n 20.97%   46.872      1 Template:Ambox\n 12.61%   28.199      1 Template:Category_handler\n  6.93%   15.492      1 Template:DMC\n  5.31%   11.867      2 Template:FULLROOTPAGENAME\n  3.59%    8.020      2 Template:Ns_has_subpages\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:9268401-0!canonical and timestamp 20180921141839 and revision id 857235822\n -->\n</div>"},"langlinks":[{"lang":"de","url":"https://de.wikipedia.org/wiki/Differential_item_functioning","langname":"German","autonym":"Deutsch","*":"Differential item functioning"}],"categories":[{"sortkey":"","hidden":"","*":"Articles_needing_cleanup_from_February_2018"},{"sortkey":"","hidden":"","*":"All_pages_needing_cleanup"},{"sortkey":"","hidden":"","*":"Cleanup_tagged_articles_with_a_reason_field_from_February_2018"},{"sortkey":"","hidden":"","*":"Wikipedia_pages_needing_cleanup_from_February_2018"},{"sortkey":"","*":"Psychometrics"},{"sortkey":"","*":"Psychological_testing"},{"sortkey":"","*":"Educational_assessment_and_evaluation"},{"sortkey":"","*":"Educational_research"}],"links":[{"ns":14,"exists":"","*":"Category:Articles needing cleanup from February 2018"},{"ns":14,"exists":"","*":"Category:Cleanup tagged articles with a reason field from February 2018"},{"ns":14,"*":"Category:Wikipedia categories needing cleanup from February 2018"},{"ns":14,"exists":"","*":"Category:Wikipedia pages needing cleanup from February 2018"},{"ns":0,"exists":"","*":"Asymptote"},{"ns":0,"exists":"","*":"Chi-squared test"},{"ns":0,"exists":"","*":"Classical test theory"},{"ns":0,"exists":"","*":"Conditional probability"},{"ns":0,"exists":"","*":"Construct (philosophy)"},{"ns":0,"exists":"","*":"Contingency table"},{"ns":0,"exists":"","*":"Covariance matrix"},{"ns":0,"exists":"","*":"Degrees of freedom"},{"ns":0,"exists":"","*":"Dichotomous"},{"ns":0,"exists":"","*":"Digital object identifier"},{"ns":0,"exists":"","*":"Gideon J. Mellenbergh"},{"ns":0,"exists":"","*":"Inflection point"},{"ns":0,"exists":"","*":"Item response theory"},{"ns":0,"exists":"","*":"Likelihood-ratio test"},{"ns":0,"exists":"","*":"List of statistical packages"},{"ns":0,"exists":"","*":"Logistic function"},{"ns":0,"exists":"","*":"Logistic regression"},{"ns":0,"exists":"","*":"MOS:MATH"},{"ns":0,"exists":"","*":"Maximum likelihood estimation"},{"ns":0,"exists":"","*":"Measurement error"},{"ns":0,"exists":"","*":"Measurement invariance"},{"ns":0,"exists":"","*":"Monotonic"},{"ns":0,"exists":"","*":"Normally distributed"},{"ns":0,"exists":"","*":"Null hypothesis"},{"ns":0,"exists":"","*":"Odds ratio"},{"ns":0,"exists":"","*":"Parameter"},{"ns":0,"exists":"","*":"Probability distribution"},{"ns":0,"exists":"","*":"Psychological research"},{"ns":0,"exists":"","*":"Ratio"},{"ns":0,"exists":"","*":"Reliability (psychometrics)"},{"ns":0,"exists":"","*":"Slope"},{"ns":0,"exists":"","*":"Standard error"},{"ns":0,"exists":"","*":"Statistical power"},{"ns":0,"exists":"","*":"Statistics"},{"ns":0,"exists":"","*":"Student's t-test"},{"ns":0,"exists":"","*":"Validity (logic)"},{"ns":0,"exists":"","*":"Wald statistic"},{"ns":4,"exists":"","*":"Wikipedia:Cleanup"},{"ns":4,"exists":"","*":"Wikipedia:Manual of Style"},{"ns":12,"exists":"","*":"Help:Maintenance template removal"}],"templates":[{"ns":10,"exists":"","*":"Template:Cleanup"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:Ambox"},{"ns":10,"exists":"","*":"Template:SUBJECTSPACE formatted"},{"ns":10,"exists":"","*":"Template:Category handler"},{"ns":10,"exists":"","*":"Template:DMC"},{"ns":10,"exists":"","*":"Template:Dated maintenance category"},{"ns":10,"exists":"","*":"Template:FULLROOTPAGENAME"},{"ns":10,"exists":"","*":"Template:Ns has subpages"},{"ns":10,"exists":"","*":"Template:DMCA"},{"ns":10,"exists":"","*":"Template:Clear"},{"ns":10,"exists":"","*":"Template:Frac"},{"ns":10,"exists":"","*":"Template:Zwsp"},{"ns":10,"exists":"","*":"Template:Zero width space"},{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Cite journal"},{"ns":828,"exists":"","*":"Module:Unsubst"},{"ns":828,"exists":"","*":"Module:Message box"},{"ns":828,"exists":"","*":"Module:No globals"},{"ns":828,"exists":"","*":"Module:Yesno"},{"ns":828,"exists":"","*":"Module:Arguments"},{"ns":828,"exists":"","*":"Module:Message box/configuration"},{"ns":828,"exists":"","*":"Module:Category handler"},{"ns":828,"exists":"","*":"Module:Category handler/data"},{"ns":828,"exists":"","*":"Module:Category handler/config"},{"ns":828,"exists":"","*":"Module:Category handler/shared"},{"ns":828,"exists":"","*":"Module:Category handler/blacklist"},{"ns":828,"exists":"","*":"Module:Namespace detect/data"},{"ns":828,"exists":"","*":"Module:Namespace detect/config"},{"ns":828,"exists":"","*":"Module:Ns has subpages"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"}],"images":["Edit-clear.svg","Uniform_DIF_curve.png","Nonuni_DIF_ICC.png","MHDIFTable.png","ICC_slope_ip.png"],"externallinks":["//doi.org/10.3758/BRM.42.3.847","http://www.ncme.org/ncme/NCME/Resource_Center/Glossary/NCME/Resource_Center/Glossary1.aspx?hkey=4bb87415-44dc-4088-9ed9-e8515326a061#anchorD"],"sections":[{"toclevel":1,"level":"2","line":"Description","number":"1","index":"1","fromtitle":"Differential_item_functioning","byteoffset":1501,"anchor":"Description"},{"toclevel":1,"level":"2","line":"Forms","number":"2","index":"2","fromtitle":"Differential_item_functioning","byteoffset":6832,"anchor":"Forms"},{"toclevel":1,"level":"2","line":"Procedures for detecting DIF","number":"3","index":"3","fromtitle":"Differential_item_functioning","byteoffset":9224,"anchor":"Procedures_for_detecting_DIF"},{"toclevel":2,"level":"3","line":"Mantel-Haenszel","number":"3.1","index":"4","fromtitle":"Differential_item_functioning","byteoffset":9258,"anchor":"Mantel-Haenszel"},{"toclevel":3,"level":"4","line":"Odds ratio","number":"3.1.1","index":"5","fromtitle":"Differential_item_functioning","byteoffset":10706,"anchor":"Odds_ratio"},{"toclevel":2,"level":"3","line":"Item response theory","number":"3.2","index":"6","fromtitle":"Differential_item_functioning","byteoffset":13657,"anchor":"Item_response_theory"},{"toclevel":3,"level":"4","line":"Wald statistic","number":"3.2.1","index":"7","fromtitle":"Differential_item_functioning","byteoffset":20915,"anchor":"Wald_statistic"},{"toclevel":3,"level":"4","line":"Likelihood-ratio test","number":"3.2.2","index":"8","fromtitle":"Differential_item_functioning","byteoffset":22345,"anchor":"Likelihood-ratio_test"},{"toclevel":2,"level":"3","line":"Logistic regression","number":"3.3","index":"9","fromtitle":"Differential_item_functioning","byteoffset":24597,"anchor":"Logistic_regression"},{"toclevel":1,"level":"2","line":"Considerations","number":"4","index":"10","fromtitle":"Differential_item_functioning","byteoffset":27342,"anchor":"Considerations"},{"toclevel":2,"level":"3","line":"Sample size","number":"4.1","index":"11","fromtitle":"Differential_item_functioning","byteoffset":27362,"anchor":"Sample_size"},{"toclevel":2,"level":"3","line":"Items","number":"4.2","index":"12","fromtitle":"Differential_item_functioning","byteoffset":29637,"anchor":"Items"},{"toclevel":2,"level":"3","line":"Statistics versus reasoning","number":"4.3","index":"13","fromtitle":"Differential_item_functioning","byteoffset":33402,"anchor":"Statistics_versus_reasoning"},{"toclevel":1,"level":"2","line":"Statistical software","number":"5","index":"14","fromtitle":"Differential_item_functioning","byteoffset":34929,"anchor":"Statistical_software"},{"toclevel":1,"level":"2","line":"See also","number":"6","index":"15","fromtitle":"Differential_item_functioning","byteoffset":35641,"anchor":"See_also"},{"toclevel":1,"level":"2","line":"References","number":"7","index":"16","fromtitle":"Differential_item_functioning","byteoffset":35687,"anchor":"References"}],"parsewarnings":[],"displaytitle":"Differential item functioning","iwlinks":[],"properties":[{"name":"wikibase_item","*":"Q1224359"}]}}