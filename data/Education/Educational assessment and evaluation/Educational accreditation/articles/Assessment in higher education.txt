Assessment is a systemic process in higher education that uses empirical data on student learning to refine programs and improve student learning.  As a continuous process, assessment establishes measurable and clear student learning outcomes for learning, provisioning a sufficient amount of learning opportunities to achieve these outcomes, implementing a systematic way of gathering, analyzing and interpreting evidence to determine how well student learning matches expectations, and using the collected information to inform improvement in student learning.  Assessment functions as part of a continuous process whereby the parts of the cycle are revised and monitored. The term “assessment” is defined broadly in that any outcome or goal in any activity or discipline can be a part of this process. Assessment in higher education can focus on the individual learner, a course, an academic program, or the institution. Assessment embedded at the course level (sometimes referred to as embedded assessment or authentic assessment) typically involves the use of assignments.  Students receive feedback on their performance on assignments and faculty gain knowledge of student learning to use for grading.  The work assessed within courses best relates to specific program-level student learning outcomes. Angelo and Cross  believe assessment in the classroom is an important part of the faculty feedback loop which can provide meaningful information about their effectiveness as teachers while also giving students a measure of their progress as learners. Program assessment is a best practice in higher education.  The process involves a framework for placing priority and attention on the process of student learning and most specifically, the program objectives, organization of curriculum, pedagogy and student development.  Like course assessment, program assessment requires defining a statement of mission/goals, establishment of program-specific student learning outcomes and the identification of where learning takes place or “learning opportunities”. The next part in program assessment involves the development of a research question or intended goal for assessment. What questions does the program seek to answer? And what direct or indirect evidence needs to be collected to identify answers? The collected data is evaluated, analyzed and interpreted resulting in the implementation of an action plan resulting in improvement in the program and student learning.  Each course a student takes occurs within the context of a program, which occurs within the context of overarching university outcomes. With the assumption that coursework should support the program and programs should support the overall mission of the university, alignment of mission (and learning outcomes) should occur. Assessment at the course level typically takes the form of tests, quizzes, and assignments. When courses are mapped to program outcomes, this permits the aggregation of data from several courses covering the same outcome which can be used for program assessment. Additional program assessment can take the form of embedded assignments, field experiences, capstone experiences, portfolios, or tests of majors. Rubrics are often used to assess student work. Essentially, a rubric is a scoring guide grid consisting of a scale of some sort (i.e., levels of performance), the dimensions or important components of an assignment, and descriptions of what constitutes each level of performance for each assignment dimension. Rubrics can be particularly effective for assessment due to how closely they are tied with the teaching and learning process - they can be used for grading, as well as giving students feedback on their performance.  Assessment is most effective when it occurs at multiple points in time along the student's path. Multiple measures over time provide a way to triangulate data and increase confidence in the results. In order to assess student learning, students must given assignment where they can demonstrate what they know and can do. A distinction is made between direct and indirect measures of learning. Direct measures, as their name implies, involve directly examining student work products to assess the achievement of learning outcomes. These work products occur in a variety of formats including objective tests, and rubric-scored projects, performances, and written work. A recent survey of provosts indicates that classroom based assessment and rubrics are most frequently used. Large scale commercial tests such as the College Learning Assessment (CLA) are used by fewer than 50% use standardized tests according to the survey. Indirect measures focus on data from which one can make inferences about learning. Indirect measures can include surveys on student and faculty perceptions about learning, focus groups, and exit interviews. National surveys such as the National Survey of Student Engagement (NSSE) have become increasing popular indirect measures, with roughly 85% of institutions using these measures according to a recent survey. In a classroom setting or in a program level assessment, it is often possible to assess the entire population of interest, referred to as a census. However, it is sometimes impractical or ineffective to assess an entire population, due to the time and effort involved as well as survey fatigue if the same group of students are being asked to take multiple surveys. Therefore, sampling strategies can be used to pick a subset of the population of interest. The goal of sampling is to select a smaller group that represents the population on key characteristics. Multiple sampling approaches are commonly used in higher education assessment, including random and stratified sampling. In a random sample, each individual is equally likely to be selected. In a stratified sample, individuals are grouped based on specific characteristics of interest and then randomly selected from each group to ensure adequate numbers of each group. Assessment data are only effective in "closing the loop" and improving programs if they are shared and communicated widely. Benchmarking is a way for an institution or program to determine how a sample measures up to others or to themselves at an earlier time. There are numerous regional organizations dedicated to discussing issues and policies related to assessment in higher education. The Association for the Assessment of Learning in Higher Education (AALHE) is one international organization. Seven other regional assessment organizations exist in the United States.    In an interview with the Chronicle for Higher Education, Marsha Watson, former director of the AALHE, stated that the “rising demands for accountability mean that assessment must evolve into its own discipline."  The National Institute for Learning Outcomes Assessment is another organization dedicated to helping institutions use assessment data to improve academic quality. They have delivered a number of research papers on assessment practices.  There is heightened political and public pressure on higher education institutions to explain what they are trying to do and provide evidence they are actually doing it.  Faculty want students to learn. In addition, faculty love their disciplines and want to share their knowledge and enthusiasm with students. Placing emphasis on what students learn and what students do helps to effectively drive improvement in the learning process, program planning and overall institutional improvement.  Assessment adds transparency to the teaching and learning process, helps to provide some evidence to the effectiveness of student learning and promotes an environment where continuous improvement is well understood and ingrained in the institutional culture. Linda Suskie, a higher education consultant, says that "Good assessments are not once-and-done affairs.   They are part of an ongoing, organized, and systematized effort to understand and improve teaching and learning. ” Some university faculty and researchers have criticized student learning outcomes assessment in higher education. Robert Shireman, a senior fellow for the Century Foundation, argued that accrediting agencies often require institutions to reduce learning to meaningless blurbs, or student learning outcomes, which “prevents rather than leads to the type of quality assurance that has student work at the center. ” Erik Gilbert, a professor of History, wrote another notable essay criticizing assessment in higher education arguing that it has little effect on educational quality and that accrediting agencies require institutions to invest time and resources in collecting evidence on student learning even though, he believes, that it does not improve academic quality.   Molly Worthen  also criticized assessment for its seeming lack of empirical evidence indicating it improves student learning.  However, Matthew Fuller  and others have developed the Surveys of Assessment Culture, aimed at examining the foundations of institutional cultures of assessment through empirical studies. 