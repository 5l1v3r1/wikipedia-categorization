Criticism of college and university rankings refers to movements which  developed among faculty and administrators in American Institutions of Higher Education as well as in Canada. The arguments of those who criticize the ranking are that it is not possible to come with a single number that characterizes university performance. Furthermore, ratings can be easily manipulated and include such subjective characteristics as the “reputation” determined by surveying university administrators such as chancellors or deans.  In addition, the methodology of many rankings (e.g., U.S. News & World Report 2015 Best Engineering Schools Rankings) emphasizes research expenditures (such as grants and contracts) as the only measure of scientific accomplishments despite the concern that measuring science by the amount of money spent rather than by the importance and impact of scientific discoveries or the depth of the ideas could encourage costly projects that are not necessary scientifically sound.  In 1995, Reed College refused to participate in U.S. News & World Report annual survey. According to Reed's Office of Admissions, "Reed College has actively questioned the methodology and usefulness of college rankings ever since the magazine's best-colleges list first appeared in 1983, despite the fact that the issue ranked Reed among the top ten national liberal arts colleges. Reed's concern intensified with disclosures in 1994 by The Wall Street Journal about institutions flagrantly manipulating data in order to move up in the rankings in U.S. News and other popular college guides. This led Reed's then-president Steven Koblik to inform the editors of U.S. News that he didn't find their project credible, and that the college would not be returning any of their surveys."   Rolling Stone, in its 16 October 1997 issue, argued that Reed's rankings were artificially decreased by U.S. News after they stopped sending data to U.S. News & World Report.   Reed has also made the same claim.  In discussing Reed's decision, President Colin Diver wrote in an article for the November 2005 issue of the Atlantic Monthly, "by far the most important consequence of sitting out the rankings game, however, is the freedom to pursue our own educational philosophy, not that of some newsmagazine."   Associated Students of Stanford University (ASSU) Vice-President Nicholas Thompson founded FUNC or "Forget U.S. News Coalition" in 1996 as a show of support for Reed College's decision not to participate in the U.S. News & World Report survey.   FUNC eventually spread to other colleges and universities and was composed of a "group of students at universities across the country who argue that ranking something as complex and variable as a college education with a single number is an oversimplification. FUNC claims that the process makes college administrations focus on numerical rankings rather than on educating students."    FUNC also involved then-Stanford President Gerhard Casper. On 23 September 1996, Casper sent a letter to James Fallows, editor of U.S. News & World Report, stating, "As the president of a university that is among the top-ranked universities, I hope I have the standing to persuade you that much about these rankings - particularly their specious formulas and spurious precision - is utterly misleading."   In January 1997, then-president of Alma College, Alan Stone, asked 480 colleges to boycott the U.S. News & World Report Rankings due to the peer assessment survey which counts for 22.5% of a college's ranking.  According to the Chronicle of Higher Education, in 1996, Alma College surveyed 158 colleges about the rankings. The result of the survey indicated that "84 per cent of the respondents admitted that they were unfamiliar with some of the institutions they had been asked to rank. Almost 44 per cent indicated that they 'tended to leave responses for unfamiliar schools blank.' " Stone stated, "this makes me wonder just how many votes are being considered for each school's academic-reputation ranking."    In February 1997, Stanford University contemplated following both Reed and Alma by not filling out the ranking survey, a move advocated by FUNC.  On 18 April 1997, Casper issued a letter critical of U.S. News & World Report college rankings titled "An alternative to the U.S. News & World Report College Survey"  Casper's letter circulated among college presidents and led to a decision by Stanford that it will "submit objective data to U.S. News, but will withhold subjective reputational votes."   Stanford also announced at this time that it would post information about the University on its website.   In 1998, Stanford posted an alternative database on its website, stating: "This page is offered in contrast to commercial guides that purport to "rank" colleges; such rankings are inherently misleading and inaccurate. Stanford believes the following information, presented without arbitrary formulas, provides a better foundation for prospective students and their families to begin comparing and contrasting schools."  .  It has since been posted annually as the "Stanford University Common Data Set."  FUNC eventually disbanded and Stanford currently participates in the survey.  St. John's College, which since 1937 has followed the Great Books Program, runs counter to the usual emphasis on rankings and selectivity. As of  2005[update], St. John's has chosen not to participate in any collegiate rankings surveys and has not sent them their requested survey information. However, the school is still included in the U.S News college ranking guide and ranks in the third tier. This may be due to school's decision not to send information to U.S. News. President Christopher B. Nelson stated that, "in principle, St. John's is opposed to rankings." He notes that In September 2006, a number of universities in Canada jointly refused to participate in the Maclean’s University Rankings survey. The president of the University of Alberta, Indira Samarasekera, commented that, "Canadian universities are listening with great interest as the call to boycott U.S. News & World Report rankings continues to increase in volume among our colleagues to the south. Many of our American colleagues say that they would like to resist the rankings, but fear it can’t be done, especially if only a few institutions act. I write to let you know that institutions can take on the rankings. About a year ago, a growing number of Canadian institutions began to raise the same alarm, ultimately resulting in 25 of our 90+ institutions — including many of our leading universities — banding together to take just such a stand against the fall rankings issue of Maclean's, our Canadian equivalent [...] It’s time to question these third-party rankings that are actually marketing driven, designed to sell particular issues of a publication with repurposing of their content into even higher sales volume special editions with year-long shelf life."   On 19 June 2007, during the annual meeting of the Annapolis Group, members discussed the letter to college presidents asking them not to participate in the "reputation survey" section of the U.S. News & World Report survey (this section comprises 25% of the ranking). As a result, "a majority of the approximately 80 presidents at the meeting said that they did not intend to participate in the U.S. News reputational rankings in the future."   However, the decision to fill out the reputational survey or not will be left up to each individual college as: "the Annapolis Group is not a legislative body and any decision about participating in the US News rankings rests with the individual institutions."   The statement also said that its members  "have agreed to participate in the development of an alternative common format that presents information about their colleges for students and their families to use in the college search process."   This database will be web based and developed in conjunction with higher education organizations including the National Association of Independent Colleges and Universities and the Council of Independent Colleges. On 22 June 2007, U.S. News & World Report editor Robert Morse issued a response in which he argued, "in terms of the peer assessment survey, we at U.S. News firmly believe the survey has significant value because it allows us to measure the "intangibles" of a college that we can't measure through statistical data. Plus, the reputation of a school can help get that all-important first job and plays a key part in which grad school someone will be able to get into. The peer survey is by nature subjective, but the technique of asking industry leaders to rate their competitors is a commonly accepted practice. The results from the peer survey also can act to level the playing field between private and public colleges."   In reference to the alternative database discussed by the Annapolis Group, Morse also argued, "It's important to point out that the Annapolis Group's stated goal of presenting college data in a common format has been tried before [...] U.S. News has been supplying this exact college information for many years already. And it appears that NAICU will be doing it with significantly less comparability and functionality. U.S. News first collects all these data (using an agreed-upon set of definitions from the Common Data Set). Then we post the data on our website in easily accessible, comparable tables. In other words, the Annapolis Group and the others in the NAICU initiative actually are following the lead of U.S. News."   