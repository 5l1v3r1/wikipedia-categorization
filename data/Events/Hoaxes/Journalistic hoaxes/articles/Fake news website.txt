 Fake news websites (also referred to as hoax news websites)   are Internet websites that deliberately publish fake news—hoaxes, propaganda, and disinformation purporting to be real news—often using social media to drive web traffic and amplify their effect.    Unlike news satire, fake news websites deliberately seek to be perceived as legitimate and taken at face value, often for financial or political gain.   Such sites have promoted political falsehoods in Germany,   Indonesia and the Philippines,  Sweden,   Myanmar,  and the United States.   Many sites originate in, or are promoted by, Russia,   Macedonia,   Romania,  and some individuals in the United States.   One pan-European newspaper, The Local, described the proliferation of fake news as a form of psychological warfare.  Some media analysts have seen it as a threat to democracy.  In 2016, the European Parliament's Committee on Foreign Affairs passed a resolution warning that the Russian government was using "pseudo-news agencies" and Internet trolls as disinformation propaganda to weaken confidence in democratic values.  In 2015, the Swedish Security Service, Sweden's national security agency, issued a report concluding Russia was using fake news to inflame "splits in society" through the proliferation of propaganda.  Sweden's Ministry of Defence tasked its Civil Contingencies Agency with combating fake news from Russia.  Fraudulent news affected politics in Indonesia and the Philippines, where there was simultaneously widespread usage of social media and limited resources to check the veracity of political claims.  German Chancellor Angela Merkel warned of the societal impact of "fake sites, bots, trolls".  Fraudulent articles spread through social media during the 2016 U.S. presidential election,   and several officials within the U.S. Intelligence Community said that Russia was engaged in spreading fake news.  Computer security company FireEye concluded that Russia used social media to spread fake news stories   as part of a cyberwarfare campaign.  Google and Facebook banned fake sites from using online advertising.   Facebook launched a partnership with fact-checking websites to flag fraudulent news and hoaxes; debunking organizations that joined the initiative included: Snopes.com, FactCheck.org, and PolitiFact.  U.S. President Barack Obama said a disregard for facts created a "dust cloud of nonsense".  Chief of the Secret Intelligence Service (MI6) Alex Younger called fake news propaganda online dangerous for democratic nations.  Some fake news websites use website spoofing, structured to make visitors believe they are visiting trusted sources like ABC News or MSNBC.  The New York Times defined "fake news" on the internet as fictitious articles deliberately fabricated to deceive readers, generally with the goal of profiting through clickbait.  PolitiFact described fake news as fabricated content designed to fool readers and subsequently made viral through the Internet to crowds that increase its dissemination.  Others have taken as constitutive the "systemic features inherent in the design of the sources and channels through which fake news proliferates", for example by playing to the audience's cognitive biases, heuristics, and partisan affiliation.  Fake news maintained a presence on the internet and in tabloid journalism in the years prior to the 2016 U.S. presidential election.  Before the election campaign involving Hillary Clinton and Donald Trump, fake news had not impacted the election process and subsequent events to such a high degree.  Subsequent to the 2016 election, the issue of fake news turned into a political weapon, with supporters of left-wing politics saying that supporters of right-wing politics spread false news, while the latter claimed that they were being "censored". [not in citation given] Due to these back-and-forth complaints, the definition of fake news as used for such polemics has become more vague.  Unethical journalistic practices existed in printed media for hundreds of years before the advent of the Internet.    Yellow journalism, reporting from a standard which is devoid of morals and professional ethics, was pervasive during the time period in history known as the Gilded Age, and unethical journalists would engage in fraud by fabricating stories, interviews, and made-up names for scholars.   During the 1890s, the spread of this unethical news sparked violence and conflicts.  Both Joseph Pulitzer and William Randolph Hearst fomented yellow journalism in order to increase profits, which helped lead to misunderstandings which became partially responsible for the outset of the Spanish–American War in 1898.  A radio broadcast from Gleiwitz by German soldier Karl Homack, pretending to be a Polish invader who had captured the station, was taken at face value by other stations, in Germany and abroad, fueling Adolf Hitler's declaration of war on Poland the next day.  According to USA Today, newspapers which have a history of commonly publishing fake news have included Globe, Weekly World News, and The National Enquirer.  Prominent among fraudulent news sites include false propaganda created by individuals in the countries of Russia,   Macedonia,   Romania,  and the United States.   Much of the fake news during the 2016 U.S. presidential election season was traced to adolescents in Macedonia,   specifically Veles. It is a town of 50,000 in the middle of the country, with high unemployment, where the average wage is $4,800.  The income from fake news was characterized by NBC News as a gold rush.  Adults supported this income, saying they were happy the youths were working.  The mayor of Veles, Slavcho Chadiev, said he was not bothered by their actions, as they were not against Macedonian law and their finances were taxable.  Chadiev said he was happy if deception from Veles influenced the results of the 2016 U.S. election in favor of Trump.  BuzzFeed News and The Guardian separately investigated and found teenagers in Veles created over 100 sites spreading fake news stories supportive of Donald Trump.    The teenagers experimented with left slanted fake stories about Bernie Sanders, but found that pro-Trump fictions were more popular.  Prior to the 2016 election the teenagers gained revenues from fake medical advice sites.  One youth named Alex stated, in an August 2016 interview with The Guardian, that this fraud would remain profitable regardless of who won the election.  Alex explained he plagiarized material for articles by copying and pasting from other websites.  This could net them thousands of dollars daily, but they averaged only a few thousand per month.  The Associated Press (AP) interviewed an 18-year-old in Veles about his tactics.  A Google Analytics analysis of his traffic showed more than 650,000 views in one week.  He plagiarized pro-Trump stories from a right-wing site called The Political Insider.  He said he did not care about politics, and published fake news to gain money and experience.  The AP used DomainTools to confirm the teenager was behind fake sites, and determined there were about 200 websites tracked to Veles focused on U.S. news, many of which mostly contained plagiarized legitimate news to create an appearance of credibility.  NBC News also interviewed an 18-year-old there.  Dmitri (a pseudonym) was one of the most profitable fake news operators in town, and said about 300 people in Veles wrote for fake sites.  Dmitri said he gained over $60,000 during the six months prior through doing this, more than both his parents' earnings.  Dmitri said his main dupes were supporters of Trump.  He said after the 2016 U.S. election he continued to earn significant amounts.  The 2020 U.S. election is their next project.  "Ending the Fed", a popular purveyor of fraudulent reports, was run by a 24-year-old named Ovidiu Drobota out of Oradea, Romania, who boasted to Inc. magazine about being more popular than mainstream media.  Established in March 2016, "Ending the Fed" was responsible for a false story in August 2016 that incorrectly stated Fox News had fired journalist Megyn Kelly—the story was briefly prominent on Facebook on its "Trending News" section.  "Ending the Fed" held four out of the 10 most popular fake articles on Facebook related to the 2016 U.S. election in the prior three months before the election itself.  The Facebook page for the website, called "End the Feed", had 350,000 "likes" in November 2016.  After being contacted by Inc. magazine, Drobota stated he was proud of the impact he had on the 2016 U.S. election in favor of his preferred candidate Donald Trump.  According to Alexa Internet, "Ending the Fed" garnered approximately 3.4 million views over a 30-day-period in November 2016.  Drobota stated the majority of incoming traffic is from Facebook.  He said his normal line of work before starting "Ending the Fed" included web development and search engine optimization.  Beginning in fall 2014, The New Yorker writer Adrian Chen performed a six-month investigation into Russian propaganda online by a group called the Internet Research Agency.  Yevgeny Prigozhin (Evgeny Prigozhin), a close associate of Vladimir Putin, was behind the operation which hired hundreds of individuals to work in Saint Petersburg.  The group was regarded as a "troll farm", a term used to refer to propaganda efforts controlling many accounts online with the aim of artificially providing a semblance of a grassroots organization.  Chen reported that Internet trolling was used by the Russian government as a tactic largely after observing the social media organization of the 2011 protests against Putin.  In 2015, the Organization for Security and Co-operation in Europe released an analysis critical of disinformation campaigns by Russia masked as news.  This was intended to interfere with Ukraine relations with Europe after the removal of former Ukraine president Viktor Yanukovych.  According to Deutsche Welle, similar tactics were used in the 2016 U.S. elections.  The European Union created a taskforce to deal with Russian disinformation.    The taskforce, East StratCom Team, had 11 people including Russian speakers.  In November 2016, the EU voted to increase the group's funding.  In November 2016, the European Parliament Committee on Foreign Affairs passed a resolution warning of the use by Russia of tools including: "pseudo-news agencies ... social media and internet trolls" as disinformation to weaken democratic values.  The resolution requested EU analysts investigate, explaining member nations needed to be wary of disinformation.  The resolution condemned Russian sources for publicizing "absolutely fake" news reports.  The tally on 23 November 2016 passed by a margin of 304 votes to 179.  The United States Department of State planned to use a unit called the Counter-Disinformation Team, formed with the intention of combating disinformation from the Russian government, and that it was disbanded in September 2015 after department heads missed the scope of propaganda before the 2016 U.S. election.   The U.S. State Department put eight months into developing the unit before scrapping it.  It would have been a reboot of the Active Measures Working Group set up by Reagan Administration.   The Counter-Disinformation Team was set up under the Bureau of International Information Programs.   Work began in 2014, with the intention to combat propaganda from Russian sources such as the RT network (formerly known as Russia Today).   U.S. Intelligence officials explained to former National Security Agency analyst and counterintelligence officer John R. Schindler that the Obama Administration decided to cancel the unit as they were afraid of antagonizing Russia.   U.S. Undersecretary of State for Public Diplomacy Richard Stengel was point person for the unit before it was canceled.   Stengel previously wrote about disinformation by RT.    Adrian Chen observed a pattern in December 2015 where pro-Russian accounts became supportive of 2016 U.S. presidential candidate Donald Trump.  Andrew Weisburd and Foreign Policy Research Institute fellow and senior fellow at the Center for Cyber and Homeland Security at George Washington University, Clint Watts,  wrote for The Daily Beast in August 2016 that Russian propaganda fabricated articles were popularized by social media.  Weisburd and Watts documented how disinformation spread from Russia Today and Sputnik News, "the two biggest Russian state-controlled media organizations publishing in English", to pro-Russian accounts on Twitter.  Citing research by Chen, Weisburd and Watts compared Russian tactics during the 2016 U.S. election to Soviet Union Cold War strategies.  They referenced the 1992 United States Information Agency report to Congress, which warned about Russian propaganda called active measures.  They concluded social media made active measures easier.  Institute of International Relations Prague senior fellow and scholar on Russian intelligence, Mark Galeotti, agreed the Kremlin operations were a form of active measures.  The most strident Internet promoters of Trump were not U.S. citizens but paid Russian propagandists. The Guardian estimated  their number to be in the "low thousands" in November 2016.  Weisburd and Watts collaborated with colleague J. M. Berger and published a follow-up to their Daily Beast article in online magazine War on the Rocks, titled: "Trolling for Trump: How Russia is Trying to Destroy Our Democracy".    They researched 7,000 pro-Trump accounts over a two-and-a-half year period.  Their research detailed trolling techniques to denigrate critics of Russian activities in Syria, and proliferate lies about Clinton's health.  Watts said the propaganda targeted the alt-right, the right wing, and fascist groups.  After each presidential debate, thousands of Twitter bots used hashtag #Trumpwon to change perceptions.  In November 2016 the Foreign Policy Research Institute[a] stated Russian propaganda exacerbated criticism of Clinton and support for Trump.   The strategy involved social media, paid Internet trolls, botnets, and websites in order to denigrate Clinton.   Computer security company FireEye concluded Russia used social media as a weapon to influence the U.S. election.  FireEye Chairman David DeWalt said the 2016 operation was a new development in cyberwarfare by Russia.  FireEye CEO Kevin Mandia stated Russian cyberwarfare changed after fall 2014, from covert to overt tactics with decreased operational security.  Bellingcat analyst Aric Toler explained fact-checking only drew further attention to the fake news problem.  U.S. Intelligence agencies debated why Putin chose summer 2016 to escalate active measures.  Prior to the election, U.S. national security officials said they were anxious about Russia tampering with U.S. news.  Director of National Intelligence James R. Clapper said after the 2011–13 Russian protests, Putin lost self-confidence, and responded with the propaganda operation.  Former CIA officer Patrick Skinner said the goal was to spread uncertainty.  House Intelligence Committee Ranking Member Adam Schiff commented on Putin's aims, and said U.S. intelligence were concerned with Russian propaganda.  Speaking about disinformation that appeared in Hungary, Slovakia, the Czech Republic, and Poland, Schiff said there was an increase of the same behavior in the U.S.  U.S. intelligence officials stated in November 2016 they believed Russia engaged in spreading fake news,  and the FBI released a statement saying they were investigating.   Two U.S. intelligence officials each told BuzzFeed News they "believe Russia helped disseminate fake and propagandized news as part of a broader effort to influence and undermine the presidential election".  The U.S. intelligence sources stated this involved "dissemination of completely fake news stories".  They told BuzzFeed the FBI investigation specifically focused on why "Russia had engaged in spreading false or misleading information".  Fake news has influenced political discourse in multiple countries, including Germany,  Indonesia and the Philippines,  Sweden,  China,   Myanmar,   and the United States.  Politicians in Austria dealt with the impact of fake news and its spread on social media after the 2016 presidential campaign in the country.  In December 2016, a court in Austria issued an injunction on Facebook Europe, mandating it block negative postings related to Eva Glawischnig-Piesczek, Austrian Green Party Chairwoman.  According to The Washington Post the postings to Facebook about her "appeared to have been spread via a fake profile" and directed derogatory epithets towards the Austrian politician.  The derogatory postings were likely created by the identical fake profile that had previously been utilized to attack Alexander van der Bellen, who won the election for President of Austria.  Brazil faced increasing influence from fake news after the 2014 re-election of President Dilma Rousseff and Rousseff's subsequent impeachment in August 2016.  In the week surrounding one of the impeachment votes, 3 out of the 5 most-shared articles on Facebook in Brazil were fake.  In 2015, reporter Tai Nalon resigned from her position at Brazilian newspaper Folha de S.Paulo in order to start the first fact-checking website in Brazil, called Aos Fatos (To The Facts).  Nalon told The Guardian there was a great deal of fake news, and hesitated to compare the problem to that experienced in the U.S.  Fake news online was brought to the attention of Canadian politicians in November 2016, as they debated helping assist local newspapers.  Member of Parliament for Vancouver Centre Hedy Fry specifically discussed fake news as an example of ways in which publishers on the Internet are less accountable than print media.  Discussion in parliament contrasted increase of fake news online with downsizing of Canadian newspapers and the impact for democracy in Canada.  Representatives from Facebook Canada attended the meeting and told members of Parliament they felt it was their duty to assist individuals gather data online.  Fake news during the 2016 U.S. election spread to China.  Articles popularized within the United States were translated into Chinese and spread within China.  The government of China used the growing problem of fake news as a rationale for increasing Internet censorship in China in November 2016.  China then published an editorial in its Communist Party newspaper The Global Times called: "Western Media's Crusade Against Facebook", and criticized "unpredictable" political problems posed by freedoms enjoyed by users of Twitter, Google, and Facebook.  China government leaders meeting in Wuzhen at the third World Internet Conference in November 2016 said fake news in the U.S. election justified adding more curbs to free and open use of the Internet.  China Deputy Minister Ren Xianliang, official at the Cyberspace Administration of China, said increasing online participation led to "harmful information" and fraud.  Kam Chow Wong, a former Hong Kong law enforcement official and criminal justice professor at Xavier University, praised attempts in the U.S. to patrol social media.  The Wall Street Journal noted China's themes of Internet censorship became more relevant at the World Internet Conference due to the outgrowth of fake news.  Officials from 11 countries held a meeting in Helsinki in November 2016, in order to plan the formation of a center to combat disinformation cyber-warfare including spread of fake news on social media.  The center is planned to be located in Helsinki and include efforts from 10 countries with participation from Sweden, Germany, Finland, and the U.S.  Prime Minister of Finland Juha Sipilä planned to deal with the center in spring 2017 with a motion before the Parliament of Finland.  Jori Arvonen, Deputy Secretary of State for EU Affairs, said cyberwarfare became an increased problem in 2016, and included hybrid cyber-warfare intrusions into Finland from Russia and Islamic State of Iraq and the Levant.  Arvonen cited examples including fake news online, disinformation, and the little green men troops during the Ukrainian crisis.  France saw an uptick in amounts of disinformation and propaganda, primarily in the midst of election cycles.  Le Monde fact-checking division "Les décodeurs" was headed by Samuel Laurent, who told The Guardian in December 2016 the upcoming French presidential election campaign in spring 2017 would face problems from fake news.  The country faced controversy regarding fake websites providing false information about abortion.  The government's lower parliamentary body moved forward with intentions to ban such fake sites.  Laurence Rossignol, women's minister for France, informed parliament though the fake sites look neutral, in actuality their intentions were specifically targeted to give women fake information.  During the 10-year period preceding 2016, France was witness to an increase in popularity of far-right alternative news sources called the fachosphere ("facho" referring to fascist); known as the extreme right on the Internet (fr).  According to sociologist Antoine Bevort, citing data from Alexa Internet rankings, the most consulted political websites in France included Égalité et Réconciliation, François Desouche (fr), and Les Moutons Enragés.   These sites increased skepticism towards mainstream media from both left and right perspectives.  German Chancellor Angela Merkel lamented the problem of fraudulent news reports in a November 2016 speech, days after announcing her campaign for a fourth term as leader of her country.  In a speech to the German parliament, Merkel was critical of such fake sites, saying they harmed political discussion.  Merkel called attention to the need of government to deal with Internet trolls, bots, and fake news websites.  She warned that such fraudulent news websites were a force increasing the power of populist extremism.  Merkel called fraudulent news a growing phenomenon that might need to be regulated in the future.  Germany's foreign intelligence agency Federal Intelligence Service Chief, Bruno Kahl (de), warned of the potential for cyberattacks by Russia in the 2017 German election.  He said the cyberattacks would take the form of the intentional spread of disinformation.  Kahl said the goal is to increase chaos in political debates.  Germany's domestic intelligence agency Federal Office for the Protection of the Constitution Chief, Hans-Georg Maassen, said sabotage by Russian intelligence was a present threat to German information security.  India had over 50 million accounts on the smartphone instant messenger Whatsapp in 2016.  On November 8, 2016, India established a 2,000-rupee currency bill on the same day as the Indian 500 and 1,000 rupee note demonetisation. Fake news went viral over Whatsapp that the note came equipped with spying technology which tracked bills 120 meters below the earth.  Finance Minister Arun Jaitley refuted the falsities, but not before they had spread to the country's mainstream news outlets.  Prabhakar Kumar of the Indian media research agency CMS, told The Guardian India was harder hit by fake news because the country lacked media policy for verification.  Law enforcement officers in India arrested individuals with charges of creating fictitious articles, predominantly if there was likelihood the articles inflamed societal conflict.  BBC Monitoring cited Pakistan Today which noted an apt example of post-truth politics, a statement by politician and broadcaster Aamir Liaquat about the Kargil War between India and Pakistan.  Liaquat defended the Pakistan Armed Forces actions in a doublethink statement akin to: "we didn't invade Kargil and we taught the Indians a lesson when we invaded Kargil".  BBC Monitoring used this example to observe fake news reporting was prominent in the Middle East.  Fraudulent news has been particularly problematic in Indonesia and the Philippines, where social media has an outsized political influence.  According to media analysts, developing countries with new access to social media and democracy felt the fake news problem to a larger extent.  In some developing countries, Facebook gives away smartphone data free of charge for Facebook and media sources, but at the same time does not provide the user with Internet access to fact-checking websites.  Between October 1 and November 30, 2016, ahead of the Italian constitutional referendum, five out of ten referendum-related stories with most social media participation were hoaxes or inaccurate.   Of the three stories with the most social media attention, two were fake.  Prime Minister of Italy Matteo Renzi met with U.S. President Obama and leaders of Europe at a meeting in Berlin, Germany in November 2016, and spoke about the fake news problem.  Renzi hosted discussions on Facebook Live in an effort to rebut falsities online.  The influence became so heavy that a senior adviser to Renzi began a defamation complaint on an anonymous Twitter user who had used the screenname "Beatrice di Maio".  The Five Star Movement (M5S), an Italian political party founded by Beppe Grillo, managed fake news sites amplifying support for Russian news, propaganda, and inflamed conspiracy theories.   The party's site TzeTze had 1.2 million Facebook fans and shared fake news and pieces supportive of Putin cited to Russia-owned sources including Sputnik News.  TzeTze plagiarized the Russian sources, and copied article titles and content from Sputnik.  TzeTze, another site critical of Renzi called La Cosa, and a blog by Grillo—were managed by the company Casaleggio Associati which was started by Five Star Movement co-founder Gianroberto Casaleggio.  Casaleggio's son Davide Casaleggio owns and manages TzeTze and La Cosa, and medical advice website La Fucina which markets anti-vaccine conspiracy theories and medical cure-all methods.  Grillo's blog, Five Star Movement fake sites use the same IP addresses, Google Analytics and Google Adsense.  Cyberwarfare against Renzi increased, and Italian newspaper La Stampa brought attention to false stories by Russia Today which wrongly asserted a pro-Renzi rally in Rome was actually an anti-Renzi rally.  In October 2016, the Five Star Movement disseminated a video from Kremlin-aligned Russia Today which falsely reported displaying thousands of individuals protesting the 4 December 2016 scheduled referendum in Italy—when in fact the video that went on to 1.5 million views showed supporters of the referendum.   President of the Italian Chamber of Deputies, Laura Boldrini, stated: "Fake news is a critical issue and we can’t ignore it. We have to act now."  Boldrini met on 30 November 2016 with vice president of public policy in Europe for Facebook Richard Allan to voice concerns about fake news.  She said Facebook needed to admit they were a media company.  Amid the 2018 local elections in Moldova a doctored video with mistranslated subtitles purported to show that the a pro-Europe party candidate for mayor of Chisinau (pop. 685,900), the capital of Moldova had proposed to lease the city of Chisinau to the UAE for 50 years.  The video was watched more than 300,000 times on Facebook and almost 250,000 times on the Russian social network site OK.ru, which is popular among Moldova's Russian-speaking population.   In 2015, fake stories using unrelated photographs and fraudulent captions were shared online in support of the Rohingya.  Fake news negatively affected individuals in Myanmar, leading to a rise in violence against Muslims in the country.   Online participation surged from one percent to 20 percent of Myanmar's total populace from 2014–2016.   Fake stories from Facebook were reprinted in paper periodicals called Facebook and The Internet.  False reporting related to practitioners of Islam in the country was directly correlated with increased attacks on people of the religion in Myanmar.   Fake news fictitiously stated believers in Islam acted out in violence at Buddhist locations.   BuzzFeed News documented a direct relationship between the fake news and violence against Muslim people.   It noted countries that were relatively newer to Internet exposure were more vulnerable to the problems of fake news and fraud.  Khawaja Muhammad Asif, the Minister of Defence of Pakistan, threatened to nuke Israel on Twitter after a false story claiming that Avigdor Lieberman, the Israeli Ministry of Defense, said "If Pakistan send ground troops into Syria on any pretext, we will destroy this country with a nuclear attack."   Polish historian Jerzy Targalski (pl) noted fake news websites had infiltrated Poland through anti-establishment and right-wing sources that copied content from Russia Today.  Targalski observed there existed about 20 specific fake news websites in Poland which spread Russian disinformation in the form of fake news.  One example cited was fake news that Ukraine announced the Polish city of Przemyśl as occupied Polish land.  The Swedish Security Service issued a report in 2015 identifying propaganda from Russia infiltrating Sweden with the objective to amplify pro-Russian propaganda and inflame societal conflicts.  The Swedish Civil Contingencies Agency (MSB), part of the Ministry of Defence of Sweden, identified fake news reports targeting Sweden in 2016 which originated from Russia.  Swedish Civil Contingencies Agency official Mikael Tofvesson stated a pattern emerged where views critical of Sweden were constantly repeated.  The MSB identified Russia Today and Sputnik News as significant fake news purveyors.  As a result of growth in this propaganda in Sweden, the MSB planned to hire six additional security officials to fight back against the campaign of fraudulent information.  In a report in December 2015 by The China Post, a fake video shared online showed people a light show purportedly made at the Shihmen Reservoir.  The Northern Region Water Resources Office confirmed there was no light show at the reservoir and the event had been fabricated.  The fraud led to an increase in tourist visits to the actual attraction.  Deutsche Welle interviewed the founder of Stopfake.org in 2014 about the website's efforts to debunk fake news in Ukraine, including media portrayal of the Ukrainian crisis.  Co-founder Margot Gontar began the site in March 2014, and it was aided by volunteers.  In 2014, Deutsche Welle awarded the fact-checker website with the People's Choice Award for Russian in its ceremony The BOBs, recognizing excellence in advocacy on the Internet.  Gontar highlighted an example debunked by the website, where a fictitious "Doctor Rozovskii" supposedly told The Guardian pro-Ukraine individuals refused to allow him to tend to injured in fighting with Russian supporters in 2014.  Stopfake.org exposed the event was fabricated—there actually was no individual named "Doctor Rozovskii", and found the Facebook photo distributed with the incident was of a different individual from Russia with a separate identity.  Former Ukraine president Viktor Yanukovych's ouster from power created instability, and in 2015 the Organization for Security and Co-operation in Europe concluded Russian disinformation campaigns used fake news to disrupt relations between Europe and Ukraine.  Russian-financed news spread disinformation after the conflict in Ukraine motivated the European Union to found the European External Action Service specialist task force to counter the propaganda.  Labour MP Michael Dugher was assigned by Deputy Leader of the Labour Party Tom Watson in November 2016 to investigate the impact of fake news spread through social media.  Watson said they would work with Twitter and Facebook to root out clear-cut circumstances of "downright lies".  Watson wrote an article for The Independent where he suggested methods to respond to fake news, including Internet-based societies which fact-check in a manner modeled after Wikipedia.  Minister for Culture, Matthew Hancock, stated the British government would investigate the impact of fake news and its pervasiveness on social media websites.  Watson stated he welcomed the investigation into fake news by the government.  On 8 December 2016, Chief of the Secret Intelligence Service (MI6) Alex Younger delivered a speech to journalists at the MI6 headquarters where he called fake news and propaganda damaging to democracy.  Younger said the mission of MI6 was to combat propaganda and fake news in order to deliver to his government a strategic advantage in the information warfare arena, and assist other nations including Europe.  He called such methods of fake news propaganda online as a "fundamental threat to our sovereignty".  Younger said all nations that hold democratic values should feel the same worry over fake news.  In November 2016, Private Eye's official website appeared on a controversial list of over 150 "fake news" websites compiled by Melissa Zimdars, a US lecturer,  despite the website only containing the Eye's investigative journalism and not its satirical content. Zimdars later removed the website from her list, after the Eye had contacted her for clarification.  Fraudulent stories during the 2016 U.S. presidential election popularized on Facebook included a viral post that Pope Francis had endorsed Donald Trump, and another that actor Denzel Washington "backs Trump in the most epic way possible".   Donald Trump's son and campaign surrogate Eric Trump, top national security adviser Michael T. Flynn, and then-campaign managers Kellyanne Conway and Corey Lewandowski shared fake news stories during the campaign.     Alternet reported that Trump himself had been the source of some of the related misinformation over the years.  After the 2016 election, Republican politicians and conservative media began to appropriate the term by using it to describe any news they see as hostile to their agenda, according to The New York Times, which cited Breitbart News, Rush Limbaugh and supporters of Donald Trump as dismissing true mainstream news reports, and any news they do not like as "fake news".  The Russian state-operated newswire RIA Novosti, known as Sputnik International, reported fake news and fabricated statements by White House Press Secretary Josh Earnest.  RIA Novosti falsely reported on 7 December 2016 that Earnest stated sanctions for Russia were on the table related to Syria.  RIA Novosti falsely quoted Earnest as saying: "There are a number of things that are to be considered, including some of the financial sanctions that the United States can administer in coordination with our allies. I would definitely not rule that out."  However, the word "sanctions" was never used by the Press Secretary.  Russia was discussed in eight instances during the press conference, but never about sanctions.  The press conference focused solely on Russian air raids in Syria towards rebels fighting President of Syria Bashar al-Assad in Aleppo.  Members of the U.S. Senate Intelligence Committee traveled to Ukraine and Poland in March 2016 and heard about Russian operations to influence internal Ukrainian matters.  Senator Angus King recalled they were informed about Russia "planting fake news stories" during elections.  On 30 November 2016 seven members of the Senate Intelligence Committee asked President Obama to publicize information on Russia's role in spreading disinformation in the U.S. election.    On 30 November 2016, legislators approved a measure within the National Defense Authorization Act to finance the U.S. State Department to act against foreign propaganda.   The initiative was developed through a bipartisan bill, the Countering Foreign Propaganda and Disinformation Act, written by U.S. Senators Republican Rob Portman and Democrat Chris Murphy.  Republican U.S. Senators stated they planned to hold hearings and investigate Russian influence on the 2016 U.S. elections.  By doing so they went against the preference of incoming Republican President-elect Donald Trump, who downplayed any potential Russian meddling in the election.  Senate Armed Services Committee Chairman John McCain, Senate Intelligence Committee Chairman Richard Burr, U.S. Senate Foreign Relations Committee Chairman Bob Corker, and Senator Lindsey Graham all planned investigations in the 115th U.S. Congress session.  U.S. President Barack Obama commented on fake news online in a speech the day before Election Day in 2016, saying social media spread lies and created a "dust cloud of nonsense".   Obama commented again on the problem after the election: "if we can't discriminate between serious arguments and propaganda, then we have problems."   On December 9, 2016, President Obama ordered U.S. Intelligence Community to conduct a complete review of the Russian propaganda operation.  In his year-end press conference on December 16, 2016, President Obama criticized a hyper-partisan atmosphere for enabling the proliferation of fake news.  In November 2016, fake news sites and Internet forums falsely implicated the restaurant Comet Ping Pong and Democratic Party figures as part of a fictitious child trafficking ring, which was dubbed "Pizzagate".  The rumor was widely debunked by sources such as the Metropolitan Police Department of the District of Columbia, fact-checking website Snopes.com, The New York Times, and Fox News.     The restaurant's owners were harassed and threatened, and increased their security.    On 4 December 2016, an individual from Salisbury, North Carolina, walked into the restaurant to "self-investigate" this conspiracy theory. He brought a semi-automatic rifle, and fired shots before being arrested; no one was injured.   The suspect told police that he planned to "self-investigate" the conspiracy theory,  and was charged with assault with a dangerous weapon, carrying a pistol without a license, unlawful discharge of a firearm, and carrying a rifle or shotgun outside the home or business.  After the incident, future National Security Advisor Michael T. Flynn and his son Michael G. Flynn were criticized by many reporters for spreading the rumors.    Two days after the shooting, Trump fired Michael G. Flynn from his transition team in connection with Flynn's Twitter posting of fake news.   Days after the attack, Hillary Clinton spoke out on the dangers of fake news in a tribute speech to retiring Senator Harry Reid at the U.S. Capitol, and called the problem an epidemic.   Fact-checking websites FactCheck.org, PolitiFact.com and Snopes.com authored guides on how to respond to fraudulent news.    FactCheck.org advised readers to check the source, author, date, and headline of publications.  They recommended their colleagues Snopes.com, The Washington Post Fact Checker,[b] and PolitiFact.com.  FactCheck.org admonished consumers to be wary of confirmation bias.  PolitiFact.com used a "Fake news" tag so readers could view all stories Polifact had debunked.  Snopes.com warned readers social media was used as a harmful tool by fraudsters.  The Washington Post's "The Fact Checker" manager Glenn Kessler wrote that all fact-checking sites saw increased visitors during the 2016 election cycle.  Unique visitors to The Fact Checker increased five-fold from the 2012 election.  Will Moy, director of London-based fact-checker Full Fact, said debunking must take place over a sustained period to be effective.  Full Fact worked with Google to help automate fact-checking.  FactCheck.org former director Brooks Jackson said media companies devoted increased focus to the importance of debunking fraud during the 2016 election.  FactCheck.org partnered with CNN's Jake Tapper in 2016 to examine the veracity candidate statements.  Angie Drobnic Holan, editor of PolitiFact.com, cautioned media companies chiefs must be supportive of debunking, as it often provokes hate mail and extreme responses from zealots.  In December 2016, PolitiFact announced fake news was its selection for "Lie of the Year".   PolitiFact explained its choice for the year: "In 2016, the prevalence of political fact abuse – promulgated by the words of two polarizing presidential candidates and their passionate supporters – gave rise to a spreading of fake news with unprecedented impunity."  PolitiFact called fake news a significant symbol of a culture accepting of post-truth politics.  In the aftermath of the 2016 U.S. election, Google and Facebook, faced scrutiny regarding the impact of fake news.  The top result on Google for election results was to a fake site.  "70 News" had fraudulently written an incorrect headline and article that Trump won the popular vote against Clinton.    Google later stated that prominence of the fake site in search results was a mistake.  By 14 November, the "70 News" result was the second link shown when searching for results of the election.  When asked shortly after the election whether fake news influenced election results, Google CEO Sundar Pichai responded: "Sure" and went on to emphasize the importance of stopping the spread of fraudulent sites.  On 14 November 2016, Google responded to the problem of fraudulent sites by banning such companies from profiting on advertising from traffic through its program AdSense.    Google previously had a policy for denying ads for dieting ripoffs and counterfeit merchandise.  Google stated upon the announcement they would work to ban advertisements from sources that lie about their purpose, content, or publisher.   The ban is not expected to apply to news satire sites like The Onion, although some satirical sites may be inadvertently blocked under the new system.   On April 25, 2017 Ben Gomes wrote a blog post announcing changes to the search algorithms that would stop the "spread of blatantly misleading, low quality, offensive or downright false information."  On July 27, 2017, the World Socialist Web Site published data that showed a significant drop after the April 25 announcement in Google referrals to left-wing and anti-war websites, including the ACLU, Alternet, and Counterpunch. . The World Socialist Web Site insists that the "fake news" charge is a cover to remove anti-establishment websites from public access, and believes the algorithm changes are infringing on the democratic right to free speech.  One day after Google took action, Facebook decided to block fake sites from advertising there.   Facebook said they would ban ads from sites with deceptive content, including fake news, and review publishers for compliance.  These steps by both Google and Facebook intended to deny ad revenue to fraudulent news sites; neither company took actions to prevent dissemination of false stories in search engine results pages or web feeds.   Facebook CEO Mark Zuckerberg called the notion that fraudulent news impacted the 2016 election a "crazy idea"   and denied that his platform influenced the election.  He stated that 99% of Facebook's content was neither fake news nor a hoax.  Zuckerberg said that Facebook is not a media company.  Zuckerberg advised users to check the fact-checking website Snopes.com whenever they encounter fake news on Facebook.   Top staff members at Facebook did not feel simply blocking ad revenue from fraudulent sites was a strong enough response, and they made an executive decision and created a secret group to deal with the issue themselves.   In response to Zuckerberg's first statement that fraudulent news did not impact the 2016 election, the secret Facebook group disputed this notion, saying fake news was rampant on their website during the election cycle.   The secret task force included dozens of Facebook employees.   Facebook faced criticism after its decision to revoke advertising revenues from fraudulent news providers, and not take further action.   After negative media coverage including assertions that fraudulent news gave the 2016 U.S. presidential election to Trump, Zuckerberg posted a second time about it on 18 November 2016.   The post was a reversal of his earlier comments on the matter where he had discounted the impact of fraudulent news.  Zuckerberg said there it was difficult to filter out fraudulent news because he desired open communication.  Measures considered and not implemented by Facebook included adding an ability for users to tag questionable material, automated checking tools, and third-party confirmation.  The 18 November post did not announce any concrete actions the company would definitively take, or when such measures would be put into usage.   National Public Radio observed the changes being considered by Facebook to identify fraud constituted progress for the company into a new media entity.  On 19 November 2016, BuzzFeed advised Facebook users they could report posts from fraudulent sites.  Users could choose the report option: "I think it shouldn't be on Facebook", followed by: "It's a false news story."  In November 2016, Facebook began assessing use of warning labels on fake news.  The rollout was at first only available to a few users in a testing phase.  A sample warning read: "This website is not a reliable news source. Reason: Classification Pending".  TechCrunch analyzed the new feature during the testing phase and surmised it may have a tendency towards false positives.  Fake news proliferation on Facebook had a negative financial impact for the company. Brian Wieser of Pivotal Research predicted that revenues could decrease by two percentage points due to the concern over fake news and loss of advertising dollars.  Shortly after Mark Zuckerberg's second statement on fake news proliferation on his website, Facebook decided to engage in assisting the government of China with a version of its software in the country to allow increased censorship by the government.  Barron's contributor William Pesek was highly critical of this move, writing by porting its fake news conundrum to China, Facebook would become a tool in that Communist Party's General Secretary Xi Jinping's efforts to increase censorship.  Society of Professional Journalists president Lynn Walsh said in November 2016 that they would reach out to Facebook to assist weeding out fake news.  Walsh said Facebook should evolve and admit it functioned as a media company.  On 17 November 2016, the Poynter International Fact-Checking Network (IFCN)[c] published an open letter on the Poynter Institute website to Mark Zuckerberg, imploring him to utilize fact-checkers to identify fraud on Facebook.   Signatories to the 2016 letter to Zuckerberg featured a global representation of fact-checking groups, including: Africa Check, FactCheck.org, PolitiFact.com, and The Washington Post Fact Checker.   In his second post on the matter on 18 November 2016, Zuckerberg responded to the fraudulent news problem by suggesting usage of fact-checkers.   He specifically identified fact-checking website Snopes.com, and pointed out that Facebook monitors links to such debunkers in reply comments to determine which original posts were fraudulent.   On 15 December 2016, Facebook announced more specifics in its efforts to combat fake news and hoaxes on its site.    The company said it would form a partnership with fact-checking groups that had joined the Poynter International Fact-Checking Network fact-checkers' code of principles, to help debunk fraud on the site.   It was the first instance Facebook had ever given third-party entities highlighted featuring in its News Feed, a significant motivator of web traffic online.  The fact-checking organizations partnered with Facebook in order to confirm whether or not links posted from one individual to another on the site were factual or fraudulent.  Facebook did not finance the fact-checkers, and acknowledged they could see increased traffic to their sites from the partnership.  Fact-checking organizations that joined Facebook's initiative included: ABC News, The Washington Post, Snopes.com, FactCheck.org, PolitiFact, and the Associated Press.  Fraudulent articles will receive a warning tag: "disputed by 3rd party fact-checkers".  The company planned to start with obvious cases of hoaxes shared specifically for fraudulent purposes to gain money for the purveyor of fake news.  Users may still share such tagged articles, and they will show up farther down in the news feed with an accompanying warning.  Facebook will employ staff researchers to determine whether website spoofing has occurred, for example "washingtonpost.co" instead of the real washingtonpost.com.  In a post on 15 December, Mark Zuckerberg acknowledged the changing nature of Facebook: "I think of Facebook as a technology company, but I recognize we have a greater responsibility than just building technology that information flows through. While we don't write the news stories you read and share, we also recognize we're more than just a distributor of news. We're a new kind of platform for public discourse -- and that means we have a new kind of responsibility to enable people to have the most meaningful conversations, and to build a space where people can be informed."  New York magazine contributor Brian Feldman responded to an article by media communications professor Melissa Zimdars, and used her list to create a Google Chrome extension that would warn users about fraudulent news sites.  He invited others to use his code and improve upon it.  Upworthy co-founder and The Filter Bubble author Eli Pariser launched an open-source model initiative on 17 November 2016 to address false news.   Pariser began a Google Document to collaborate with others online on how to lessen the phenomenon of fraudulent news.   Pariser called his initiative: "Design Solutions for Fake News".  Pariser's document included recommendations for a ratings organization analogous to the Better Business Bureau, and a database on media producers in a format like Wikipedia.   Writing for Fortune, Matthew Ingram agreed with the idea that Wikipedia could serve as a helpful model to improve Facebook's analysis of potentially fake news.  Ingram concluded Facebook could benefit from a social network form of fact-checking similar to Wikipedia's methods while incorporating debunking websites such as PolitiFact.com.  Pope Francis, the leader of the Roman Catholic Church, spoke out against fake news in an interview with the Belgian Catholic weekly Tertio (magazine) (nl) on 7 December 2016.  The Pope had prior experience being the subject of a fake news website fiction—during the 2016 U.S. election cycle, he was falsely said to support Donald Trump for president.    Pope Francis said the singular worst thing the news media could do was spreading disinformation and that amplifying fake news instead of educating society was a sin. He compared salacious reporting of scandals, whether true or not, to coprophilia and the consumption of it to coprophagy.     The Pope said that he did not intend to offend with his strong words, but emphasized that "a lot of damage can be done" when the truth is disregarded and slander is spread.   Jamie Condliffe wrote that banning ad revenue from fraudulent sites was not aggressive enough action by Facebook to deal with the problem, and did not prevent fake news from appearing in Facebook news feeds.  Dartmouth College political scientist Brendan Nyhan criticized Facebook for not doing more to combat fake news amplification.  Indiana University computer science professor Filippo Menczer commented on measures by Google and Facebook to deny fraudulent sites revenue, saying it was a good step to reduce motivation for fraudsters.  Menczer's research team engaged in developing an online tool titled: Hoaxy — to see the pervasiveness of unconfirmed assertions as well as related debunking on the Internet.  Zeynep Tufekci wrote critically about Facebook's stance on fraudulent news sites, stating that fraudulent websites in Macedonia profited handsomely off false stories about the 2016 U.S. election.  Tufecki wrote that Facebook's algorithms, and structure exacerbated the impact of echo chambers and increased fake news blight.  Merrimack College assistant professor of media studies Melissa Zimdars wrote an article "False, Misleading, Clickbait-y and Satirical 'News' Sources" in which she advised how to determine if a fraudulent source was a fake news site.  Zimdars identified strange domain names, lack of attribution, poor layout, use of all caps, and URLs ending in "lo" or "com.co" as red flags.  Zimdars recommended checking the "About Us" page, and considering whether reputable news outlets have reported the same story.  Stanford University professors Sam Wineburg and Sarah McGrew authored a 2016 study analyzing students' ability to discern fraudulent news from factual.   The study took place over a year-long period of time, and involved a sample size of over 7,800 responses from university, secondary and middle school students in 12 states within the United States.   They were surprised at the consistency with which students thought fraudulent news reports were factual.   The study found 82% of students in middle school were unable to differentiate between an advertisement denoted as sponsored content from an actual news article.  The authors concluded the solution was to educate online media consumers to themselves behave like fact-checkers — and actively question the veracity of all sources.   Scientist Emily Willingham has proposed applying the scientific method to fake news analysis.  She had previously written on the topic of differentiating science from pseudoscience, and proposed applying that logic to fake news.  She calls the recommended steps Observe, Question, Hypothesize, Analyze data, Draw conclusion, and Act on results.  Willingham suggested a hypothesis of "This is real news", and then forming a strong set of questions to attempt to disprove the hypothesis.  These tests included: check the URL, date of the article, evaluate reader bias and writer bias, double-check the evidence, and verify the sources cited.  University of Connecticut philosophy professor Michael P. Lynch said that a troubling number of individuals make determinations relying upon the most recent piece of information they've consumed.  He said the greater issue however was that fake news could make people less likely to believe news that really is true.  Lynch summed up the thought process of such individuals, as "...ignore the facts because nobody knows what’s really true anyway."  