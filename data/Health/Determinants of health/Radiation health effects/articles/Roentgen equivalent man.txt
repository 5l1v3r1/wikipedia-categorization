 The roentgen equivalent man (or rem)   is an older, CGS unit of equivalent dose, effective dose, and committed dose which are measures of the health effect of low levels of ionizing radiation on the human body.  Quantities measured in rem are designed to represent the stochastic biological risk of ionizing radiation; primarily radiation-induced cancer. These quantities are derived from absorbed dose, which in the CGS system has the unit rad which is also an older unit. There is no universally applicable conversion constant from rad to rem; the conversion depends on relative biological effectiveness (RBE). The rem has been defined since 1976 as equal to 0.01 sievert, which is the more commonly used SI unit outside the United States. A number of earlier definitions going back to 1945 were derived from the roentgen unit, which was named after Wilhelm Röntgen, a German scientist who discovered X-rays. The acronym is now a misleading historical artifact, since 1 roentgen actually deposits about 0.96 rem in soft biological tissue, when all weighting factors equal unity. Older units of rem following other definitions are up to 17% smaller than the modern rem. One rem carries with it a 0.05% chance of eventually developing cancer.  Doses greater than 100 rem received over a short time period are likely to cause acute radiation syndrome (ARS), possibly leading to death within weeks if left untreated. Note that the quantities that are measured in rem were not designed to be correlated to ARS symptoms. The absorbed dose, measured in rad, is the best indicator of ARS. :592–593 A rem is a large dose of radiation, so the millirem (mrem), which is one thousandth of a rem, is often used for the dosages commonly encountered, such as the amount of radiation received from medical x-rays and background sources. The rem and millirem are CGS units in widest use among the American public, industry, and government.  SI units are the norm outside of the United States, and they are increasingly encountered within the US in academic, scientific, and engineering environments. The conventional units for dose rate is mrem/h. Regulatory limits and chronic doses are often given in units of mrem/yr or rem/yr, where they are understood to represent the total amount of radiation allowed (or received) over the entire year. In many occupational scenarios, the hourly dose rate might fluctuate to levels thousands of times higher for a brief period of time, without infringing on the annual total exposure limits. There is no exact conversion from hours to years because of leap years, but approximate conversions are: The ICRP once adopted fixed conversion for occupational exposure, although these have not appeared in recent documents:  Therefore, for occupation exposures of that time period, The US National Institute of Standards and Technology (NIST) strongly discourages Americans from expressing doses in rem, in favor of recommending the SI unit.  The NIST recommends defining the rem in relation to the SI in every document where this unit is used.  For US industries and US firms that do not require the sole use of SI, however, the unit rem is often preferred. Ionizing radiation has deterministic and stochastic effects on human health. The deterministic effects that can lead to acute radiation syndrome only occur in the case of high doses (> ~10 rad or > 0.1 Gy) and high dose rates (> ~10 rad/h or > 0.1 Gy/h). A model of deterministic risk would require different weighting factors (not yet established) than are used in the calculation of equivalent and effective dose. To avoid confusion, deterministic effects are normally compared to absorbed dose in units of rad, not rem. Stochastic effects are those that occur randomly, such as radiation-induced cancer. The consensus of the nuclear industry, nuclear regulators, and governments, is that the incidence of cancers due to ionizing radiation can be modeled as increasing linearly with effective dose at a rate of 0.055% per rem (5.5%/Sv).  Individual studies, alternate models, and earlier versions of the industry consensus have produced other risk estimates scattered around this consensus model. There is general agreement that the risk is much higher for infants and fetuses than adults, higher for the middle-aged than for seniors, and higher for women than for men, though there is no quantitative consensus about this.    There is much less data, and much more controversy, regarding the possibility of cardiac and teratogenic effects, and the modelling of internal dose.  The International Commission on Radiological Protection (ICRP) recommends limiting artificial irradiation of the public to an average of 100 mrem (1 mSv) of effective dose per year, not including medical and occupational exposures.   For comparison, radiation levels inside the US United States Capitol are 85 mrem/yr (0.85 mSv/yr), close to the regulatory limit, because of the uranium content of the granite structure.  According to the ICRP model, someone who spent 20 years inside the capitol building would have an extra one in a thousand chance of getting cancer, over and above any other existing risk. (20 yr × 85 mrem/yr × 0.001 rem/mrem × 0.055%/rem = ~0.1%) That "existing risk" is much higher; an average person would have a one in ten chance of getting cancer during this same 20-year period, even without any exposure to artificial radiation. The concept of the rem first appeared in the literature in 1945,  and was given its first definition in 1947.  The definition was refined in 1950 as "that dose of any ionizing radiation which produces a relevant biological effect equal to that produced by one roentgen of high-voltage x-radiation."  Using data available at the time, the rem was variously evaluated as 83, 93, or 95 erg/gram.  Along with the introduction of the rad in 1953, the International Commission on Radiological Protection (ICRP) decided to "continue" the use of the rem. The US National Committee on Radiation Protection and Measurements noted in 1954 that this effectively implied an increase in the magnitude of the rem to match the rad (100 erg/gram).  The ICRP officially adopted the rem as the unit of equivalent dose in 1962 to measure the way different types of radiation distribute energy in tissue, and began recommending values of relative biological effectiveness (RBE) for various types of radiation.  In practice, the unit of rem was used to denote that an RBE factor had been applied to a number which was originally in units of rad or roentgen. In 1977 the rem was redefined by the ICRP as 0.01 sievert or 0.01 J/kg, with the intention that the sievert would come to replace the rem. The International Committee for Weights and Measures (CIPM) adopted the sievert in 1980, but never accepted the use of the rem. The US National Institute of Standards and Technology (NIST) recognizes that this unit is outside the SI, but temporarily accepts its use in the US with the SI.  The rem remains in widespread use as an industry standard in the US.  The United States Nuclear Regulatory Commission still permits the use of the units curie, rad and rem alongside SI units.  The following table shows radiation quantities in SI and non-SI units: 