{"parse":{"title":"Lip reading","pageid":315084,"revid":857610524,"text":{"*":"<div class=\"mw-parser-output\"><p><b>Lip reading</b>, also known as lipreading or <b>speechreading</b>, is a technique of understanding <a href=\"/wiki/Speech\" title=\"Speech\">speech</a> by visually interpreting the movements of the lips, face and tongue when normal sound is not available. It relies also on information provided by the context, knowledge of the language, and any residual hearing. Although ostensibly used by deaf and hard-of-hearing people, most people with normal hearing process some speech information from sight of the moving mouth.<sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\">&#91;1&#93;</a></sup>\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Process\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Process</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-2\"><a href=\"#Phonemes_and_visemes\"><span class=\"tocnumber\">1.1</span> <span class=\"toctext\">Phonemes and visemes</span></a></li>\n<li class=\"toclevel-2 tocsection-3\"><a href=\"#Co-articulation\"><span class=\"tocnumber\">1.2</span> <span class=\"toctext\">Co-articulation</span></a></li>\n<li class=\"toclevel-2 tocsection-4\"><a href=\"#How_can_it_&#39;work&#39;_with_so_few_visemes?\"><span class=\"tocnumber\">1.3</span> <span class=\"toctext\">How can it 'work' with so few visemes?</span></a></li>\n<li class=\"toclevel-2 tocsection-5\"><a href=\"#Variation_in_readability_and_skill\"><span class=\"tocnumber\">1.4</span> <span class=\"toctext\">Variation in readability and skill</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#Lipreading_and_language_learning_in_hearing_infants_and_children\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Lipreading and language learning in hearing infants and children</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-7\"><a href=\"#The_first_few_months\"><span class=\"tocnumber\">2.1</span> <span class=\"toctext\">The first few months</span></a></li>\n<li class=\"toclevel-2 tocsection-8\"><a href=\"#The_next_six_months;_a_role_in_learning_a_native_language\"><span class=\"tocnumber\">2.2</span> <span class=\"toctext\">The next six months; a role in learning a native language</span></a></li>\n<li class=\"toclevel-2 tocsection-9\"><a href=\"#Early_language_production:_one_to_two_years\"><span class=\"tocnumber\">2.3</span> <span class=\"toctext\">Early language production: one to two years</span></a></li>\n<li class=\"toclevel-2 tocsection-10\"><a href=\"#In_childhood\"><span class=\"tocnumber\">2.4</span> <span class=\"toctext\">In childhood</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-11\"><a href=\"#In_hearing_adults:_lifespan_considerations\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">In hearing adults: lifespan considerations</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-12\"><a href=\"#In_specific_(hearing)_populations\"><span class=\"tocnumber\">3.1</span> <span class=\"toctext\">In specific (hearing) populations</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-13\"><a href=\"#Deafness\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Deafness</span></a></li>\n<li class=\"toclevel-1 tocsection-14\"><a href=\"#Teaching_and_training\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">Teaching and training</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-15\"><a href=\"#Tests\"><span class=\"tocnumber\">5.1</span> <span class=\"toctext\">Tests</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-16\"><a href=\"#Lipreading_and_lip-speaking_by_machine\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">Lipreading and lip-speaking by machine</span></a></li>\n<li class=\"toclevel-1 tocsection-17\"><a href=\"#The_brain\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">The brain</span></a></li>\n<li class=\"toclevel-1 tocsection-18\"><a href=\"#References\"><span class=\"tocnumber\">8</span> <span class=\"toctext\">References</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-19\"><a href=\"#Bibliography\"><span class=\"tocnumber\">8.1</span> <span class=\"toctext\">Bibliography</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-20\"><a href=\"#External_links\"><span class=\"tocnumber\">9</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"Process\">Process</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=1\" title=\"Edit section: Process\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Although <a href=\"/wiki/Speech_perception\" title=\"Speech perception\">speech perception</a> is considered to be an auditory skill, it is intrinsically multimodal, since producing speech requires the speaker to make  movements of the lips, teeth and tongue which are often visible in face-to-face communication. Information from the lips and face supports aural comprehension <sup id=\"cite_ref-2\" class=\"reference\"><a href=\"#cite_note-2\">&#91;2&#93;</a></sup> and most fluent listeners of a language are sensitive to seen speech actions (see <a href=\"/wiki/McGurk_effect\" title=\"McGurk effect\">McGurk effect</a>).  The extent to which people make use of seen speech actions varies with the visibility of the speech action and the knowledge and skill of the perceiver.\n</p>\n<h3><span class=\"mw-headline\" id=\"Phonemes_and_visemes\">Phonemes and visemes</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=2\" title=\"Edit section: Phonemes and visemes\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>The <a href=\"/wiki/Phoneme\" title=\"Phoneme\">phoneme</a> is the smallest detectable unit of sound in a language that serves to distinguish words from one another. /pit/ and /pik/ differ by one phoneme and refer to different concepts. Spoken English has about 44 phonemes. For lip reading, the number of visually distinctive units - <a href=\"/wiki/Viseme\" title=\"Viseme\">visemes</a> - is much smaller, thus several phonemes map onto a few visemes. This is because many phonemes are produced within the mouth and throat, and cannot be seen. These include <a href=\"/wiki/Glottal_consonants\" class=\"mw-redirect\" title=\"Glottal consonants\">glottal consonants</a> and most gestures of the tongue. <a href=\"/wiki/Voiced\" class=\"mw-redirect\" title=\"Voiced\">Voiced</a> and <a href=\"/wiki/Unvoiced\" class=\"mw-redirect\" title=\"Unvoiced\">unvoiced</a> pairs look identical, such as [p] and [b], [k] and [g], [t] and [d], [f] and [v], and [s] and [z]; likewise for <a href=\"/wiki/Nasalisation\" class=\"mw-redirect\" title=\"Nasalisation\">nasalisation</a> (e.g. [m] vs. [b]). <a class=\"external text\" href=\"https://en.wiktionary.org/wiki/homophene\">Homophenes</a> are words that look similar when lip read, but which contain different phonemes. Because there are about three times as many phonemes as visemes in English, it is often claimed that only 30% of speech can be lip read. Homophenes are a crucial source of  <a href=\"/wiki/Bad_Lip_Reading\" title=\"Bad Lip Reading\">mis-lip reading</a>.\n</p>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><a href=\"/wiki/File:Sam_Loyd_lipreading_puzzle.jpg\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1d/Sam_Loyd_lipreading_puzzle.jpg/220px-Sam_Loyd_lipreading_puzzle.jpg\" width=\"220\" height=\"146\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1d/Sam_Loyd_lipreading_puzzle.jpg/330px-Sam_Loyd_lipreading_puzzle.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1d/Sam_Loyd_lipreading_puzzle.jpg/440px-Sam_Loyd_lipreading_puzzle.jpg 2x\" data-file-width=\"660\" data-file-height=\"438\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Sam_Loyd_lipreading_puzzle.jpg\" class=\"internal\" title=\"Enlarge\"></a></div>The legend to this puzzle reads \"Here is a class of a dozen boys, who, being called up to give their names were photographed by the instantaneous process just as each one was commencing to pronounce his own name. The twelve names were Oom, Alden, Eastman, Alfred, Arthur, Luke, Fletcher, Matthew, Theodore, Richard, Shirmer, and Hisswald. Now it would not seem possible to be able to give the correct name to each of the twelve boys, but if you practice the list over to each one, you will find it not a difficult task to locate the proper name for every one of the boys.\"<sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">&#91;3&#93;</a></sup></div></div></div>\n<h3><span class=\"mw-headline\" id=\"Co-articulation\"><a href=\"/wiki/Co-articulation\" class=\"mw-redirect\" title=\"Co-articulation\">Co-articulation</a></span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=3\" title=\"Edit section: Co-articulation\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Visemes can be captured as still images, but speech unfolds in time. The smooth articulation of speech sounds in sequence can mean that mouth patterns may be \u2018shaped\u2019 by an adjacent phoneme:  the \u2018th\u2019 sound in \u2018tooth\u2019 and in \u2018teeth\u2019 appears very different because of the <a href=\"/wiki/Vowel\" title=\"Vowel\">vocalic</a> context. This feature of dynamic speech-reading affects lip-reading 'beyond the viseme'.<sup id=\"cite_ref-4\" class=\"reference\"><a href=\"#cite_note-4\">&#91;4&#93;</a></sup>\n</p>\n<h3><span id=\"How_can_it_.27work.27_with_so_few_visemes.3F\"></span><span class=\"mw-headline\" id=\"How_can_it_'work'_with_so_few_visemes?\">How can it 'work' with so few visemes?</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=4\" title=\"Edit section: How can it &#039;work&#039; with so few visemes?\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>The statistical distribution of phonemes within the lexicon of a language is uneven. While there are clusters of words which are phonemically similar to each other ('lexical neighbors', such as spit/sip/sit/stick...etc.), others are unlike all other words: they are 'unique' in terms of the distribution of their phonemes ('umbrella' may be an example). Skilled users of the language bring this knowledge to bear when interpreting speech, so it is generally harder to identify a heard word with many lexical neighbors than one with few neighbors. Applying this insight to seen speech, some words in the language can be unambiguously lip-read even when they contain few visemes - simply because no other words could possibly 'fit'.<sup id=\"cite_ref-5\" class=\"reference\"><a href=\"#cite_note-5\">&#91;5&#93;</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Variation_in_readability_and_skill\">Variation in readability and skill</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=5\" title=\"Edit section: Variation in readability and skill\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Many factors affect the visibility of a speaking face, including illumination, movement of the head/camera, frame-rate of the moving image and distance from the viewer (see e.g.<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;6&#93;</a></sup>). Head movement that accompanies normal speech can also improve lip-reading, independently of oral actions.<sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">&#91;7&#93;</a></sup> However, when lip-reading <a href=\"/wiki/Connected_speech\" title=\"Connected speech\">connected speech</a>, the viewer's knowledge of the spoken language, familiarity with the speaker and style of speech, and the context of the lip-read material<sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">&#91;8&#93;</a></sup> are as important as the visibility of the speaker. While most hearing people are sensitive to seen speech, there is great variability in individual speechreading skill. Good lipreaders are often more accurate than poor lipreaders at identifying phonemes from visual speech.\n</p><p>A simple visemic measure of 'lipreadability'  has been questioned by some researchers. The 'phoneme equivalence class' measure takes into account the statistical structure of the lexicon<sup id=\"cite_ref-9\" class=\"reference\"><a href=\"#cite_note-9\">&#91;9&#93;</a></sup> and can also accommodate individual differences in lip-reading ability.<sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">&#91;10&#93;</a></sup><sup id=\"cite_ref-11\" class=\"reference\"><a href=\"#cite_note-11\">&#91;11&#93;</a></sup> In line with this, excellent lipreading is often associated with more broad-based cognitive skills including general language proficiency, <a href=\"/wiki/Executive_function\" class=\"mw-redirect\" title=\"Executive function\">executive function</a> and <a href=\"/wiki/Working_memory\" title=\"Working memory\">working memory</a>.<sup id=\"cite_ref-12\" class=\"reference\"><a href=\"#cite_note-12\">&#91;12&#93;</a></sup><sup id=\"cite_ref-13\" class=\"reference\"><a href=\"#cite_note-13\">&#91;13&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Lipreading_and_language_learning_in_hearing_infants_and_children\">Lipreading and language learning in hearing infants and children</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=6\" title=\"Edit section: Lipreading and language learning in hearing infants and children\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"The_first_few_months\">The first few months</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=7\" title=\"Edit section: The first few months\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Seeing the mouth plays a role in the very young infant's early sensitivity to speech, and prepares them to become speakers at 1 \u2013 2 years. In order to imitate, a baby must learn to shape their lips in accordance with the sounds they hear; seeing the speaker may help them to do this.<sup id=\"cite_ref-14\" class=\"reference\"><a href=\"#cite_note-14\">&#91;14&#93;</a></sup> Newborns imitate adult mouth movements such as sticking out the tongue or opening the mouth, which could be a precursor to further imitation and later language learning.<sup id=\"cite_ref-15\" class=\"reference\"><a href=\"#cite_note-15\">&#91;15&#93;</a></sup> Infants are disturbed when audiovisual speech of a familiar speaker is desynchronized <sup id=\"cite_ref-16\" class=\"reference\"><a href=\"#cite_note-16\">&#91;16&#93;</a></sup> and tend to show different looking patterns for familiar than for unfamiliar faces when matched to (recorded) voices.<sup id=\"cite_ref-17\" class=\"reference\"><a href=\"#cite_note-17\">&#91;17&#93;</a></sup>  Infants are sensitive to <a href=\"/wiki/McGurk_effect\" title=\"McGurk effect\">McGurk illusions</a> months before they have learned to speak.<sup id=\"cite_ref-18\" class=\"reference\"><a href=\"#cite_note-18\">&#91;18&#93;</a></sup><sup id=\"cite_ref-19\" class=\"reference\"><a href=\"#cite_note-19\">&#91;19&#93;</a></sup> These studies and many more point to a role for vision in the development of sensitivity to (auditory) speech in the first half-year of life.\n</p>\n<h3><span id=\"The_next_six_months.3B_a_role_in_learning_a_native_language\"></span><span class=\"mw-headline\" id=\"The_next_six_months;_a_role_in_learning_a_native_language\">The next six months; a role in learning a native language</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=8\" title=\"Edit section: The next six months; a role in learning a native language\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Until around six months of age, most hearing infants are sensitive to a wide range of speech gestures - including ones that can be seen on the mouth - which may or may not later be part of the <a href=\"/wiki/Phonology\" title=\"Phonology\">phonology</a> of their native language. But in the second six months of life, the hearing infant shows <a href=\"/wiki/Perceptual_narrowing\" title=\"Perceptual narrowing\">perceptual narrowing</a> for the phonetic structure of their own language - and may lose the early sensitivity to mouth patterns that are not useful. The speech sounds  /v/ and /b/ which are visemically distinctive in English but not in Castilian Spanish are accurately distinguished in Spanish-exposed and English-exposed babies up to the age of around 6 months. However, older Spanish-exposed infants lose the ability to 'see' this distinction, while it is retained for English-exposed infants.<sup id=\"cite_ref-20\" class=\"reference\"><a href=\"#cite_note-20\">&#91;20&#93;</a></sup> Such studies suggest that rather than hearing and vision developing in independent ways in infancy, multimodal processing is the rule, not the exception, in (language) development of the infant brain.<sup id=\"cite_ref-21\" class=\"reference\"><a href=\"#cite_note-21\">&#91;21&#93;</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Early_language_production:_one_to_two_years\">Early language production: one to two years</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=9\" title=\"Edit section: Early language production: one to two years\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Given the many studies indicating a role for vision in the development of language in the pre-lingual infant, the effects of congenital blindness on language development are surprisingly small.  18-month-olds learn new words more readily when they hear them, and do not learn them when they are shown the speech movements without hearing.<sup id=\"cite_ref-22\" class=\"reference\"><a href=\"#cite_note-22\">&#91;22&#93;</a></sup> However, children blind from birth can confuse /m/ and /n/ in their own early production of English words \u2013 a confusion rarely seen in sighted hearing children, since  /m/ and /n/ are visibly distinctive, but auditorilly confusable.<sup id=\"cite_ref-23\" class=\"reference\"><a href=\"#cite_note-23\">&#91;23&#93;</a></sup> The role of vision in children aged 1\u20132 years may be less critical to the production of their native language, since, by that age, they have attained the skills they need to identify and imitate speech sounds. However, hearing a non-native language can shift the child's attention to visual and auditory engagement by way of lipreading and listening in order to process, understand and produce speech.<sup id=\"cite_ref-24\" class=\"reference\"><a href=\"#cite_note-24\">&#91;24&#93;</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"In_childhood\">In childhood</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=10\" title=\"Edit section: In childhood\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Studies with pre-lingual infants and children use indirect, non-verbal measures to indicate sensitivity to seen speech. <i>Explicit</i> lip-reading can be reliably tested in hearing preschoolers by asking them to 'say aloud what I say silently'.<sup id=\"cite_ref-25\" class=\"reference\"><a href=\"#cite_note-25\">&#91;25&#93;</a></sup> In school-age children, lipreading of familiar closed-set words such as number words can be readily elicited.<sup id=\"cite_ref-26\" class=\"reference\"><a href=\"#cite_note-26\">&#91;26&#93;</a></sup> Individual differences in lip-reading skill, as tested by asking the child to 'speak the word that you lip-read', or by matching a lip-read utterance to a picture,<sup id=\"cite_ref-27\" class=\"reference\"><a href=\"#cite_note-27\">&#91;27&#93;</a></sup> show a relationship between lip-reading skill and age.<sup id=\"cite_ref-28\" class=\"reference\"><a href=\"#cite_note-28\">&#91;28&#93;</a></sup><sup id=\"cite_ref-29\" class=\"reference\"><a href=\"#cite_note-29\">&#91;29&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"In_hearing_adults:_lifespan_considerations\">In hearing adults: lifespan considerations</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=11\" title=\"Edit section: In hearing adults: lifespan considerations\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>While lip-reading silent speech poses a challenge for most hearing people, adding sight of the speaker to heard speech improves speech processing under many conditions. The mechanisms for this, and the precise ways in which lip-reading helps, are topics of current research.<sup id=\"cite_ref-30\" class=\"reference\"><a href=\"#cite_note-30\">&#91;30&#93;</a></sup>\nSeeing the speaker helps at all levels of speech processing from <a href=\"/wiki/Phonetics\" title=\"Phonetics\">phonetic feature</a> discrimination to interpretation of <a href=\"/wiki/Pragmatics\" title=\"Pragmatics\">pragmatic</a> utterances.<sup id=\"cite_ref-31\" class=\"reference\"><a href=\"#cite_note-31\">&#91;31&#93;</a></sup>\nThe positive effects of adding vision to heard speech are greater in noisy than quiet environments,<sup id=\"cite_ref-32\" class=\"reference\"><a href=\"#cite_note-32\">&#91;32&#93;</a></sup>\nwhere by making speech perception easier, seeing the speaker can free up cognitive resources, enabling deeper processing of speech content.\n</p><p>As <a href=\"/wiki/Hearing_loss\" title=\"Hearing loss\">hearing becomes less reliable in old-age</a> people may tend to rely more on lip-reading, and are encouraged to do so. However, greater reliance on lip-reading may not always make good the effects of age-related hearing loss. Cognitive decline in aging may be preceded by and/or associated with measurable hearing loss.<sup id=\"cite_ref-33\" class=\"reference\"><a href=\"#cite_note-33\">&#91;33&#93;</a></sup><sup id=\"cite_ref-34\" class=\"reference\"><a href=\"#cite_note-34\">&#91;34&#93;</a></sup> Thus lipreading may not always be able to fully compensate for the combined hearing and cognitive age-related decrements.\n</p>\n<h3><span id=\"In_specific_.28hearing.29_populations\"></span><span class=\"mw-headline\" id=\"In_specific_(hearing)_populations\">In specific (hearing) populations</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=12\" title=\"Edit section: In specific (hearing) populations\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>A number of studies report anomalies of lipreading in populations with distinctive developmental disorders. <a href=\"/wiki/Autism\" title=\"Autism\">Autism</a>:  People with autism may show reduced lipreading abilities and reduced reliance on vision in audiovisual speech perception.<sup id=\"cite_ref-35\" class=\"reference\"><a href=\"#cite_note-35\">&#91;35&#93;</a></sup><sup id=\"cite_ref-36\" class=\"reference\"><a href=\"#cite_note-36\">&#91;36&#93;</a></sup> This may be associated with gaze-to-the-face anomalies in these people.<sup id=\"cite_ref-37\" class=\"reference\"><a href=\"#cite_note-37\">&#91;37&#93;</a></sup> <a href=\"/wiki/Williams_syndrome\" title=\"Williams syndrome\">Williams syndrome</a>:   People with Williams syndrome show some deficits in speechreading which may be independent of their visuo-spatial difficulties.<sup id=\"cite_ref-38\" class=\"reference\"><a href=\"#cite_note-38\">&#91;38&#93;</a></sup> <a href=\"/wiki/Specific_Language_Impairment\" class=\"mw-redirect\" title=\"Specific Language Impairment\">Specific Language Impairment</a>:   Children with SLI are also reported to show reduced lipreading sensitivity,<sup id=\"cite_ref-39\" class=\"reference\"><a href=\"#cite_note-39\">&#91;39&#93;</a></sup> as are people with <a href=\"/wiki/Dyslexia\" title=\"Dyslexia\">dyslexia</a>.<sup id=\"cite_ref-40\" class=\"reference\"><a href=\"#cite_note-40\">&#91;40&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Deafness\">Deafness</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=13\" title=\"Edit section: Deafness\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>\"When you are deaf you live inside a well-corked glass bottle. You see the entrancing outside world, but it does not reach you. After learning to lip read, you are still inside the bottle, but the cork has come out and the outside world slowly but surely comes in to you.\" <sup id=\"cite_ref-Clegg1953_41-0\" class=\"reference\"><a href=\"#cite_note-Clegg1953-41\">&#91;41&#93;</a></sup> <a href=\"/wiki/Second_International_Congress_on_Education_of_the_Deaf\" title=\"Second International Congress on Education of the Deaf\">Debate has raged for hundreds of years</a> over the role of lip-reading ('<a href=\"/wiki/Oralism\" title=\"Oralism\">oralism</a>') compared with other communication methods (most recently, <a href=\"/wiki/Total_communication\" class=\"mw-redirect\" title=\"Total communication\">total communication</a>) in the education of deaf people. The extent to which one or other approach is beneficial depends on a range of factors, including level of hearing loss of the deaf person, age of hearing loss, parental involvement and parental language(s). Then there is a question concerning the aims of the deaf person and her community and carers. Is the aim of education to enhance communication generally, to develop <a href=\"/wiki/Sign_language\" title=\"Sign language\">sign language</a> as a first language, or to develop skills in the spoken language of the hearing community? Researchers now focus on which aspects of language and communication may be best delivered by what means and in which contexts, given the hearing status of the child and her family, and their educational plans.<sup id=\"cite_ref-42\" class=\"reference\"><a href=\"#cite_note-42\">&#91;42&#93;</a></sup> <a href=\"/wiki/Bimodal_bilingualism\" title=\"Bimodal bilingualism\">Bimodal bilingualism</a> (proficiency in both speech and sign language) is one dominant current approach in language education for the deaf child.<sup id=\"cite_ref-43\" class=\"reference\"><a href=\"#cite_note-43\">&#91;43&#93;</a></sup>\n</p><p>Deaf people  are often better lip-readers than people with normal hearing.<sup id=\"cite_ref-44\" class=\"reference\"><a href=\"#cite_note-44\">&#91;44&#93;</a></sup> Some deaf people practice as professional lipreaders, for instance in <a href=\"/wiki/Forensic_lipreading\" class=\"mw-redirect\" title=\"Forensic lipreading\">forensic lipreading</a>. In deaf people who have a <a href=\"/wiki/Cochlear_implant\" title=\"Cochlear implant\">cochlear implant</a>, pre-implant lip-reading skill can predict post-implant (auditory or audiovisual) speech processing.<sup id=\"cite_ref-45\" class=\"reference\"><a href=\"#cite_note-45\">&#91;45&#93;</a></sup> For many deaf people, access to spoken communication can be helped when a spoken message is relayed via a trained, <i><a rel=\"nofollow\" class=\"external text\" href=\"http://lipspeaking.co.uk/\">professional lip-speaker</a></i>.<sup id=\"cite_ref-46\" class=\"reference\"><a href=\"#cite_note-46\">&#91;46&#93;</a></sup><sup id=\"cite_ref-47\" class=\"reference\"><a href=\"#cite_note-47\">&#91;47&#93;</a></sup>\n</p><p>In connection with lipreading and literacy development, children born deaf typically show <a href=\"/wiki/Reading_disability\" title=\"Reading disability\">delayed development of literacy</a> skills<sup id=\"cite_ref-48\" class=\"reference\"><a href=\"#cite_note-48\">&#91;48&#93;</a></sup> which can reflect difficulties in acquiring elements of the spoken language.<sup id=\"cite_ref-49\" class=\"reference\"><a href=\"#cite_note-49\">&#91;49&#93;</a></sup> In particular, reliable <a href=\"/wiki/Phonics\" title=\"Phonics\">phoneme-grapheme mapping</a> may be more difficult for deaf children, who need to be skilled speech-readers in order to master this necessary step in literacy acquisition.  Lip-reading skill is associated with literacy abilities in deaf adults and children<sup id=\"cite_ref-50\" class=\"reference\"><a href=\"#cite_note-50\">&#91;50&#93;</a></sup><sup id=\"cite_ref-51\" class=\"reference\"><a href=\"#cite_note-51\">&#91;51&#93;</a></sup> and training in lipreading may help to develop literacy skills.<sup id=\"cite_ref-52\" class=\"reference\"><a href=\"#cite_note-52\">&#91;52&#93;</a></sup>\n</p><p><a href=\"/wiki/Cued_Speech\" class=\"mw-redirect\" title=\"Cued Speech\">Cued Speech</a> uses lipreading with accompanying hand shapes that disambiguate the visemic (consonant) lipshape. Cued speech is said to be easier for hearing parents to learn than a sign language, and studies, primarily from Belgium, show that a deaf child exposed to cued speech in infancy can make more efficient progress in learning a spoken language than from lipreading alone\n.<sup id=\"cite_ref-53\" class=\"reference\"><a href=\"#cite_note-53\">&#91;53&#93;</a></sup> The use of cued speech in cochlear implantation for deafness is likely to be positive.<sup id=\"cite_ref-54\" class=\"reference\"><a href=\"#cite_note-54\">&#91;54&#93;</a></sup> A similar approach, involving the use of handshapes accompanying seen speech, is  <a rel=\"nofollow\" class=\"external text\" href=\"http://seethesound.org/visual_phonics.html\">Visual Phonics</a>, which is used by some educators to support the learning of  written and spoken language.\n</p>\n<h2><span class=\"mw-headline\" id=\"Teaching_and_training\">Teaching and training</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=14\" title=\"Edit section: Teaching and training\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>The aim of teaching and training in lipreading is to develop awareness of the nature of lipreading, and to practice ways of improving the ability to perceive speech 'by eye'.<sup id=\"cite_ref-55\" class=\"reference\"><a href=\"#cite_note-55\">&#91;55&#93;</a></sup> Lipreading classes, often called <i>lipreading and managing hearing loss classes</i>, are mainly aimed at adults who have hearing loss. The highest proportion of adults with hearing loss have an <a href=\"/wiki/Presbycusis\" title=\"Presbycusis\">age related</a>, or <a href=\"/wiki/Occupational_hearing_loss\" title=\"Occupational hearing loss\">noise related loss</a>, and with both these the high frequency sounds are lost first. Since many of the consonants in speech are high frequency sounds, speech becomes distorted. Hearing aids help, but may not cure this. Lipreading classes have been shown to be of benefit in  UK studies  commissioned by the charity, <a href=\"/wiki/Action_on_Hearing_Loss\" title=\"Action on Hearing Loss\">Action on Hearing Loss</a><sup id=\"cite_ref-56\" class=\"reference\"><a href=\"#cite_note-56\">&#91;56&#93;</a></sup> in 2012.\n</p><p>Trainers recognise that lipreading is an inexact art. Students are taught to watch the lips, tongue and jaw movements, to follow the stress and rhythm of language, to use their residual hearing, with or without hearing aids, to watch expression and body language, and use their ability to put two and two together. They are taught the <a rel=\"nofollow\" class=\"external text\" href=\"http://limpingchicken.com/2016/04/05/molly-berry-what-lipreading-classes-can-offer-deaf-people/\">lipreaders alphabet</a>, groups of sounds that look alike on the lips (visemes) like p, b, m, or f, v. The aim is to get the gist, so as to have the confidence to join in conversation, and avoid damaging social isolation that often accompanies hearing loss. Lipreading classes are recommended for anyone who struggles to hear in noise, and help to adjust to hearing loss.\n<a rel=\"nofollow\" class=\"external text\" href=\"http://atlalipreading.org.uk\">ATLA </a>(the association for teaching lipreading to adults) is the professional association in the UK  for qualified lipreading tutors.\n</p>\n<h3><span class=\"mw-headline\" id=\"Tests\">Tests</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=15\" title=\"Edit section: Tests\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Most tests of lipreading were devised to measure individual differences in performing specific speech processing tasks, and to detect changes in performance following training.  Lipreading tests have been used with relatively small groups in experimental settings,  or as clinical indicators with individual patients and clients. That is, lipreading tests to date have limited validity as markers of lipreading skill in the general population.\n</p>\n<h2><span class=\"mw-headline\" id=\"Lipreading_and_lip-speaking_by_machine\">Lipreading and lip-speaking by machine</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=16\" title=\"Edit section: Lipreading and lip-speaking by machine\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p><a href=\"/wiki/Automated_Lip_Reading\" title=\"Automated Lip Reading\">Automated lip-reading</a> has been a topic of interest in computational engineering, as well as in <a href=\"/wiki/2001:_A_Space_Odyssey\" title=\"2001: A Space Odyssey\">science fiction movies</a>. The computational engineer <a href=\"/wiki/Steve_Omohundro\" title=\"Steve Omohundro\">Steve Omohundro</a>, among others, pioneered its development. In <a href=\"/wiki/Facial_animation\" class=\"mw-redirect\" title=\"Facial animation\">facial animation</a>, the aim is to generate realistic facial actions, especially mouth movements, that simulate human speech actions. Computer algorithms to deform or manipulate images of faces can be driven by heard or written language. Systems may be based on detailed models derived from facial movements (<a href=\"/wiki/Motion_capture\" title=\"Motion capture\">motion capture</a>); on anatomical modelling of actions of the jaw, mouth and tongue; or on mapping of known viseme- phoneme properties.<sup id=\"cite_ref-57\" class=\"reference\"><a href=\"#cite_note-57\">&#91;57&#93;</a></sup><sup id=\"cite_ref-58\" class=\"reference\"><a href=\"#cite_note-58\">&#91;58&#93;</a></sup> Facial animation has been used in speechreading training (demonstrating how different sounds 'look').<sup id=\"cite_ref-59\" class=\"reference\"><a href=\"#cite_note-59\">&#91;59&#93;</a></sup> These systems are a subset of <a href=\"/wiki/Speech_synthesis\" title=\"Speech synthesis\">speech synthesis</a> modelling which aim to deliver reliable 'text-to-(seen)-speech' outputs.  A complementary aim\u2014the  reverse of making faces move in speech\u2014is to develop computer algorithms  that can deliver realistic interpretations of speech (i.e. a written transcript or audio record)  from natural video data of a face in action: this is facial speech recognition. These models too can be sourced from a variety of data.<sup id=\"cite_ref-60\" class=\"reference\"><a href=\"#cite_note-60\">&#91;60&#93;</a></sup> Automatic visual speech recognition from video has been quite successful in distinguishing different languages (from a corpus of spoken language data).<sup id=\"cite_ref-61\" class=\"reference\"><a href=\"#cite_note-61\">&#91;61&#93;</a></sup> Demonstration models, using machine-learning algorithms, have had some success in lipreading speech elements, such as specific words, from video<sup id=\"cite_ref-62\" class=\"reference\"><a href=\"#cite_note-62\">&#91;62&#93;</a></sup>  and for identifying hard-to-lipread phonemes from visemically similar seen mouth actions.<sup id=\"cite_ref-63\" class=\"reference\"><a href=\"#cite_note-63\">&#91;63&#93;</a></sup> Machine-based speechreading is now making successful use of <a rel=\"nofollow\" class=\"external text\" href=\"https://www.technologyreview.com/s/602949/ai-has-beaten-humans-at-lip-reading/\">neural-net based algorithms</a> which use large databases of speakers and speech material (following the successful model for auditory <a href=\"/wiki/Automatic_speech_recognition\" class=\"mw-redirect\" title=\"Automatic speech recognition\">automatic speech recognition</a>).<sup id=\"cite_ref-64\" class=\"reference\"><a href=\"#cite_note-64\">&#91;64&#93;</a></sup>\n</p><p>Uses for machine lipreading could include automated lipreading of video-only records, automated lipreading of speakers with damaged vocal tracts, and speech processing in face-to-face video (i.e. from videophone data). Automated lipreading may help in processing noisy or unfamiliar speech.<sup id=\"cite_ref-65\" class=\"reference\"><a href=\"#cite_note-65\">&#91;65&#93;</a></sup> Automated lipreading may  contribute to <a href=\"/wiki/Biometric\" class=\"mw-redirect\" title=\"Biometric\">biometric</a> person identification, replacing password-based identification.<sup id=\"cite_ref-66\" class=\"reference\"><a href=\"#cite_note-66\">&#91;66&#93;</a></sup><sup id=\"cite_ref-67\" class=\"reference\"><a href=\"#cite_note-67\">&#91;67&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"The_brain\">The brain</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=17\" title=\"Edit section: The brain\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Following the discovery that <a href=\"/wiki/Auditory_cortex\" title=\"Auditory cortex\">auditory brain regions</a>, including <a href=\"/wiki/Heschl%27s_gyrus\" class=\"mw-redirect\" title=\"Heschl&#39;s gyrus\">Heschl's gyrus</a>, were activated by seen speech,<sup id=\"cite_ref-68\" class=\"reference\"><a href=\"#cite_note-68\">&#91;68&#93;</a></sup> the neural circuitry for speechreading was shown to include supra-modal processing regions, especially <a href=\"/wiki/Superior_temporal_sulcus\" title=\"Superior temporal sulcus\">superior temporal sulcus</a> (all parts) as well as posterior inferior occipital-temporal regions including regions specialised for the processing of <a href=\"/wiki/Fusiform_face_area\" title=\"Fusiform face area\">faces</a> and <a href=\"/wiki/Visual_area_MT\" class=\"mw-redirect\" title=\"Visual area MT\">biological motion</a>.<sup id=\"cite_ref-69\" class=\"reference\"><a href=\"#cite_note-69\">&#91;69&#93;</a></sup> In some but not all studies, activation of Broca's area is reported for speechreading,<sup id=\"cite_ref-70\" class=\"reference\"><a href=\"#cite_note-70\">&#91;70&#93;</a></sup><sup id=\"cite_ref-71\" class=\"reference\"><a href=\"#cite_note-71\">&#91;71&#93;</a></sup> suggesting that articulatory mechanisms can be activated in speechreading.<sup id=\"cite_ref-72\" class=\"reference\"><a href=\"#cite_note-72\">&#91;72&#93;</a></sup> Studies of the time course of audiovisual speech processing showed that sight of speech can prime auditory processing regions in advance of the acoustic signal.<sup id=\"cite_ref-73\" class=\"reference\"><a href=\"#cite_note-73\">&#91;73&#93;</a></sup><sup id=\"cite_ref-74\" class=\"reference\"><a href=\"#cite_note-74\">&#91;74&#93;</a></sup> Better lipreading  skill is associated with greater activation in (left) superior temporal sulcus and adjacent inferior temporal (visual) regions in hearing people.<sup id=\"cite_ref-75\" class=\"reference\"><a href=\"#cite_note-75\">&#91;75&#93;</a></sup><sup id=\"cite_ref-76\" class=\"reference\"><a href=\"#cite_note-76\">&#91;76&#93;</a></sup> In deaf people, the circuitry devoted to speechreading appears to be very similar to that in hearing people, with similar associations of (left) superior temporal activation and lipreading skill.<sup id=\"cite_ref-77\" class=\"reference\"><a href=\"#cite_note-77\">&#91;77&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=18\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist columns references-column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;\">\n<ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Woodhouse, L; Hickson, L; Dodd, B (2009). \"Review of visual speech perception by hearing and hearing-impaired people: clinical implications\". <i>International Journal of Language and Communication Disorders</i>. <b>44</b> (3): 253\u201370. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1080/13682820802090281\">10.1080/13682820802090281</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/18821117\">18821117</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Journal+of+Language+and+Communication+Disorders&amp;rft.atitle=Review+of+visual+speech+perception+by+hearing+and+hearing-impaired+people%3A+clinical+implications&amp;rft.volume=44&amp;rft.issue=3&amp;rft.pages=253-70&amp;rft.date=2009&amp;rft_id=info%3Adoi%2F10.1080%2F13682820802090281&amp;rft_id=info%3Apmid%2F18821117&amp;rft.aulast=Woodhouse&amp;rft.aufirst=L&amp;rft.au=Hickson%2C+L&amp;rft.au=Dodd%2C+B&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-2\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Erber, NP (1969). \"Interaction of audition and vision in the recognition of oral speech stimuli\". <i>J Speech Hear Res</i>. <b>12</b>: 423\u20135. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1044/jshr.1202.423\">10.1044/jshr.1202.423</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/5808871\">5808871</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Speech+Hear+Res&amp;rft.atitle=Interaction+of+audition+and+vision+in+the+recognition+of+oral+speech+stimuli&amp;rft.volume=12&amp;rft.pages=423-5&amp;rft.date=1969&amp;rft_id=info%3Adoi%2F10.1044%2Fjshr.1202.423&amp;rft_id=info%3Apmid%2F5808871&amp;rft.aulast=Erber&amp;rft.aufirst=NP&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\"><a href=\"/wiki/Sam_Loyd\" title=\"Sam Loyd\">Sam Loyd's</a> Cyclopedia of Puzzles, 1914</span>\n</li>\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Benguerel, AP; Pichora-Fuller, MK (1982). \"Coarticulation effects in lipreading\". <i>J Speech Hear Res</i>. <b>25</b>: 600\u20137. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1044/jshr.2504.600\">10.1044/jshr.2504.600</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/7162162\">7162162</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Speech+Hear+Res&amp;rft.atitle=Coarticulation+effects+in+lipreading&amp;rft.volume=25&amp;rft.pages=600-7&amp;rft.date=1982&amp;rft_id=info%3Adoi%2F10.1044%2Fjshr.2504.600&amp;rft_id=info%3Apmid%2F7162162&amp;rft.aulast=Benguerel&amp;rft.aufirst=AP&amp;rft.au=Pichora-Fuller%2C+MK&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Auer, ET (2010). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3715375\">\"Investigating speechreading and deafness\"</a>. <i>Journal of the American Academy of Audiology</i>. <b>21</b> (3): 163\u20138. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.3766/jaaa.21.3.4\">10.3766/jaaa.21.3.4</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3715375\">3715375</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/20211120\">20211120</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Academy+of+Audiology&amp;rft.atitle=Investigating+speechreading+and+deafness&amp;rft.volume=21&amp;rft.issue=3&amp;rft.pages=163-8&amp;rft.date=2010&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3715375&amp;rft_id=info%3Apmid%2F20211120&amp;rft_id=info%3Adoi%2F10.3766%2Fjaaa.21.3.4&amp;rft.aulast=Auer&amp;rft.aufirst=ET&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3715375&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Jordan, TR; Thomas, SM (2011). \"When half a face is as good as a whole: effects of simple substantial occlusion on visual and audiovisual speech perception\". <i>Atten Percept Psychophys</i>. <b>73</b> (7): 2270\u201385. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.3758/s13414-011-0152-4\">10.3758/s13414-011-0152-4</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/21842332\">21842332</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Atten+Percept+Psychophys&amp;rft.atitle=When+half+a+face+is+as+good+as+a+whole%3A+effects+of+simple+substantial+occlusion+on+visual+and+audiovisual+speech+perception&amp;rft.volume=73&amp;rft.issue=7&amp;rft.pages=2270-85&amp;rft.date=2011&amp;rft_id=info%3Adoi%2F10.3758%2Fs13414-011-0152-4&amp;rft_id=info%3Apmid%2F21842332&amp;rft.aulast=Jordan&amp;rft.aufirst=TR&amp;rft.au=Thomas%2C+SM&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Thomas, SM; Jordan, TR (2004). \"Contributions of oral and extraoral facial movement to visual and audiovisual speech perception\". <i>J Exp Psychol Hum Percept Perform</i>. <b>30</b> (5): 873\u201388. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1037/0096-1523.30.5.873\">10.1037/0096-1523.30.5.873</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/15462626\">15462626</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Exp+Psychol+Hum+Percept+Perform&amp;rft.atitle=Contributions+of+oral+and+extraoral+facial+movement+to+visual+and+audiovisual+speech+perception&amp;rft.volume=30&amp;rft.issue=5&amp;rft.pages=873-88&amp;rft.date=2004&amp;rft_id=info%3Adoi%2F10.1037%2F0096-1523.30.5.873&amp;rft_id=info%3Apmid%2F15462626&amp;rft.aulast=Thomas&amp;rft.aufirst=SM&amp;rft.au=Jordan%2C+TR&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Spehar, B; Goebel, S; Tye-Murray, N (2015). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4610295\">\"Effects of Context Type on Lipreading and Listening Performance and Implications for Sentence Processing\"</a>. <i>J Speech Lang Hear Res</i>. <b>58</b> (3): 1093\u2013102. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1044/2015_JSLHR-H-14-0360\">10.1044/2015_JSLHR-H-14-0360</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4610295\">4610295</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/25863923\">25863923</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Speech+Lang+Hear+Res&amp;rft.atitle=Effects+of+Context+Type+on+Lipreading+and+Listening+Performance+and+Implications+for+Sentence+Processing&amp;rft.volume=58&amp;rft.issue=3&amp;rft.pages=1093-102&amp;rft.date=2015&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4610295&amp;rft_id=info%3Apmid%2F25863923&amp;rft_id=info%3Adoi%2F10.1044%2F2015_JSLHR-H-14-0360&amp;rft.aulast=Spehar&amp;rft.aufirst=B&amp;rft.au=Goebel%2C+S&amp;rft.au=Tye-Murray%2C+N&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4610295&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-9\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Files, BT; Tjan, BS; Jiang, J; Bernstein, LE (2015). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4499841\">\"Visual speech discrimination and identification of natural and synthetic consonant stimuli\"</a>. <i>Front Psychol</i>. <b>6</b>: 878. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.3389/fpsyg.2015.00878\">10.3389/fpsyg.2015.00878</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4499841\">4499841</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/26217249\">26217249</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Front+Psychol&amp;rft.atitle=Visual+speech+discrimination+and+identification+of+natural+and+synthetic+consonant+stimuli&amp;rft.volume=6&amp;rft.pages=878&amp;rft.date=2015&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4499841&amp;rft_id=info%3Apmid%2F26217249&amp;rft_id=info%3Adoi%2F10.3389%2Ffpsyg.2015.00878&amp;rft.aulast=Files&amp;rft.aufirst=BT&amp;rft.au=Tjan%2C+BS&amp;rft.au=Jiang%2C+J&amp;rft.au=Bernstein%2C+LE&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4499841&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Auer, ET; Bernstein, LE (1997). \"Speechreading and the structure of the lexicon: computationally modeling the effects of reduced phonetic distinctiveness on lexical uniqueness\". <i>J Acoust Soc Am</i>. <b>102</b>: 3704\u201310. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1121/1.420402\">10.1121/1.420402</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/9407662\">9407662</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Acoust+Soc+Am&amp;rft.atitle=Speechreading+and+the+structure+of+the+lexicon%3A+computationally+modeling+the+effects+of+reduced+phonetic+distinctiveness+on+lexical+uniqueness&amp;rft.volume=102&amp;rft.pages=3704-10&amp;rft.date=1997&amp;rft_id=info%3Adoi%2F10.1121%2F1.420402&amp;rft_id=info%3Apmid%2F9407662&amp;rft.aulast=Auer&amp;rft.aufirst=ET&amp;rft.au=Bernstein%2C+LE&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-11\">^</a></b></span> <span class=\"reference-text\">Feld J1, Sommers M 2011 There Goes the Neighborhood: Lipreading and the Structure of the Mental Lexicon. <i>Speech Commun.</i>  Feb;53(2):220-228</span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Tye-Murray, N; Hale, S; Spehar, B; Myerson, J; Sommers, MS (2014). \"Lipreading in school-age children: the roles of age, hearing status, and cognitive ability\". <i>J Speech Lang Hear Res</i>. <b>57</b> (2): 556\u201365. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1044/2013_JSLHR-H-12-0273\">10.1044/2013_JSLHR-H-12-0273</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/24129010\">24129010</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Speech+Lang+Hear+Res&amp;rft.atitle=Lipreading+in+school-age+children%3A+the+roles+of+age%2C+hearing+status%2C+and+cognitive+ability&amp;rft.volume=57&amp;rft.issue=2&amp;rft.pages=556-65&amp;rft.date=2014&amp;rft_id=info%3Adoi%2F10.1044%2F2013_JSLHR-H-12-0273&amp;rft_id=info%3Apmid%2F24129010&amp;rft.aulast=Tye-Murray&amp;rft.aufirst=N&amp;rft.au=Hale%2C+S&amp;rft.au=Spehar%2C+B&amp;rft.au=Myerson%2C+J&amp;rft.au=Sommers%2C+MS&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-13\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-13\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Feld, JE; Sommers, MS (2009). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3119632\">\"Lipreading, processing speed, and working memory in younger and older adults\"</a>. <i>J Speech Lang Hear Res</i>. <b>52</b> (6): 1555\u201365. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1044/1092-4388%282009/08-0137%29\">10.1044/1092-4388(2009/08-0137)</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3119632\">3119632</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/19717657\">19717657</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Speech+Lang+Hear+Res&amp;rft.atitle=Lipreading%2C+processing+speed%2C+and+working+memory+in+younger+and+older+adults&amp;rft.volume=52&amp;rft.issue=6&amp;rft.pages=1555-65&amp;rft.date=2009&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3119632&amp;rft_id=info%3Apmid%2F19717657&amp;rft_id=info%3Adoi%2F10.1044%2F1092-4388%282009%2F08-0137%29&amp;rft.aulast=Feld&amp;rft.aufirst=JE&amp;rft.au=Sommers%2C+MS&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3119632&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://www.huffingtonpost.com/2012/01/16/babies-learning-to-talk_n_1209219.html\">http://www.huffingtonpost.com/2012/01/16/babies-learning-to-talk_n_1209219.html</a></span>\n</li>\n<li id=\"cite_note-15\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-15\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Meltzoff, AN; Moore, MK (1977). \"Imitation of facial and manual gestures by human neonates\". <i>Science</i>. <b>198</b>: 74\u20138. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1126/science.897687\">10.1126/science.897687</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/897687\">897687</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Science&amp;rft.atitle=Imitation+of+facial+and+manual+gestures+by+human+neonates&amp;rft.volume=198&amp;rft.pages=74-8&amp;rft.date=1977&amp;rft_id=info%3Adoi%2F10.1126%2Fscience.897687&amp;rft_id=info%3Apmid%2F897687&amp;rft.aulast=Meltzoff&amp;rft.aufirst=AN&amp;rft.au=Moore%2C+MK&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-16\">^</a></b></span> <span class=\"reference-text\">Dodd B.1976 Lip reading in infants: attention to speech presented in- and out-of-synchrony. <i>Cognitive Psychology</i> Oct;11(4):478-84</span>\n</li>\n<li id=\"cite_note-17\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-17\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Spelke, E (1976). \"Infants intermodal perception of events\". <i>Cognitive Psychology</i>. <b>8</b> (4): 553\u2013560. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/0010-0285%2876%2990018-9\">10.1016/0010-0285(76)90018-9</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Cognitive+Psychology&amp;rft.atitle=Infants+intermodal+perception+of+events&amp;rft.volume=8&amp;rft.issue=4&amp;rft.pages=553-560&amp;rft.date=1976&amp;rft_id=info%3Adoi%2F10.1016%2F0010-0285%2876%2990018-9&amp;rft.aulast=Spelke&amp;rft.aufirst=E&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-18\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-18\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Burnham, D; Dodd, B (2004). \"Auditory-visual speech integration by prelinguistic infants: perception of an emergent consonant in the McGurk effect\". <i>Developmental Psychobiology</i>. <b>45</b> (4): 204\u201320. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1002/dev.20032\">10.1002/dev.20032</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/15549685\">15549685</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Developmental+Psychobiology&amp;rft.atitle=Auditory-visual+speech+integration+by+prelinguistic+infants%3A+perception+of+an+emergent+consonant+in+the+McGurk+effect&amp;rft.volume=45&amp;rft.issue=4&amp;rft.pages=204-20&amp;rft.date=2004&amp;rft_id=info%3Adoi%2F10.1002%2Fdev.20032&amp;rft_id=info%3Apmid%2F15549685&amp;rft.aulast=Burnham&amp;rft.aufirst=D&amp;rft.au=Dodd%2C+B&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-19\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-19\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Rosenblum, LD; Schmuckler, MA; Johnson, JA (1997). \"The McGurk effect in infants\". <i>Percept Psychophys</i>. <b>59</b>: 347\u201357. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/9136265\">9136265</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Percept+Psychophys&amp;rft.atitle=The+McGurk+effect+in+infants&amp;rft.volume=59&amp;rft.pages=347-57&amp;rft.date=1997&amp;rft_id=info%3Apmid%2F9136265&amp;rft.aulast=Rosenblum&amp;rft.aufirst=LD&amp;rft.au=Schmuckler%2C+MA&amp;rft.au=Johnson%2C+JA&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-20\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-20\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Pons, F;  et al. (2009). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2705579\">\"Narrowing of intersensory speech perception in infancy\"</a>. <i>Proceedings of the National Academy of Sciences</i>. <b>106</b> (26): 10598\u2013602. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1073/pnas.0904134106\">10.1073/pnas.0904134106</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2705579\">2705579</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/19541648\">19541648</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+National+Academy+of+Sciences&amp;rft.atitle=Narrowing+of+intersensory+speech+perception+in+infancy&amp;rft.volume=106&amp;rft.issue=26&amp;rft.pages=10598-602&amp;rft.date=2009&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2705579&amp;rft_id=info%3Apmid%2F19541648&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.0904134106&amp;rft.aulast=Pons&amp;rft.aufirst=F&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2705579&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span><span class=\"citation-comment\" style=\"display:none; color:#33aa33; margin-left:0.3em\">CS1 maint: Explicit use of et al. (<a href=\"/wiki/Category:CS1_maint:_Explicit_use_of_et_al.\" title=\"Category:CS1 maint: Explicit use of et al.\">link</a>) </span></span>\n</li>\n<li id=\"cite_note-21\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-21\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Lewkowicz, DJ; Ghazanfar, AA (2009). \"The emergence of multisensory systems through perceptual narrowing\". <i>Trends in Cognitive Sciences</i>. <b>13</b> (11): 470\u20138. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/j.tics.2009.08.004\">10.1016/j.tics.2009.08.004</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/19748305\">19748305</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Trends+in+Cognitive+Sciences&amp;rft.atitle=The+emergence+of+multisensory+systems+through+perceptual+narrowing&amp;rft.volume=13&amp;rft.issue=11&amp;rft.pages=470-8&amp;rft.date=2009&amp;rft_id=info%3Adoi%2F10.1016%2Fj.tics.2009.08.004&amp;rft_id=info%3Apmid%2F19748305&amp;rft.aulast=Lewkowicz&amp;rft.aufirst=DJ&amp;rft.au=Ghazanfar%2C+AA&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-22\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-22\">^</a></b></span> <span class=\"reference-text\">Havy, M., Foroud, A., Fais, L., &amp; Werker, J.F. (in press; online January 26, 2017). The role of auditory and visual speech in word-learning at 18 months and in adulthood. Child Development.  (Pre-print version)</span>\n</li>\n<li id=\"cite_note-23\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-23\">^</a></b></span> <span class=\"reference-text\">Mills, A.E. 1987 The development of phonology in the blind child. In B.Dodd &amp; R.Campbell(Eds) Hearing by Eye: the psychology of lipreading, Hove UK, Lawrence Erlbaum Associates</span>\n</li>\n<li id=\"cite_note-24\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-24\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Lewkowicz, DJ; Hansen-Tift, AM (Jan 2012). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3277111\">\"Infants deploy selective attention to the mouth of a talking face when learning speech\"</a>. <i>Proceedings of the National Academy of Sciences</i>. <b>109</b> (5): 1431\u20136. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1073/pnas.1114783109\">10.1073/pnas.1114783109</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3277111\">3277111</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/22307596\">22307596</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+National+Academy+of+Sciences&amp;rft.atitle=Infants+deploy+selective+attention+to+the+mouth+of+a+talking+face+when+learning+speech&amp;rft.volume=109&amp;rft.issue=5&amp;rft.pages=1431-6&amp;rft.date=2012-01&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3277111&amp;rft_id=info%3Apmid%2F22307596&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.1114783109&amp;rft.aulast=Lewkowicz&amp;rft.aufirst=DJ&amp;rft.au=Hansen-Tift%2C+AM&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3277111&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-25\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-25\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Davies R1, Kidd E; Lander, K (2009). \"Investigating the psycholinguistic correlates of speechreading in preschool age children\". <i>International Journal of Language and Communication Disorders</i>. <b>44</b> (2): 164\u201374. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1080/13682820801997189\">10.1080/13682820801997189</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Journal+of+Language+and+Communication+Disorders&amp;rft.atitle=Investigating+the+psycholinguistic+correlates+of+speechreading+in+preschool+age+children&amp;rft.volume=44&amp;rft.issue=2&amp;rft.pages=164-74&amp;rft.date=2009&amp;rft_id=info%3Adoi%2F10.1080%2F13682820801997189&amp;rft.aulast=Davies+R1&amp;rft.aufirst=Kidd+E&amp;rft.au=Lander%2C+K&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-26\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-26\">^</a></b></span> <span class=\"reference-text\">Dodd B. 1987 The acquisition of lipreading skills by normally hearing children. In B.Dodd &amp; R.Campbell (Eds) Hearing by Eye, Erlbaum NJ pp163-176</span>\n</li>\n<li id=\"cite_note-27\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-27\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Jerger, S;  et al. (2009). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2612128\">\"Developmental shifts in children's sensitivity to visual speech: a new multimodal picture-word task\"</a>. <i>J Exp Child Psychol</i>. <b>102</b> (1): 40\u201359. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/j.jecp.2008.08.002\">10.1016/j.jecp.2008.08.002</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2612128\">2612128</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/18829049\">18829049</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Exp+Child+Psychol&amp;rft.atitle=Developmental+shifts+in+children%27s+sensitivity+to+visual+speech%3A+a+new+multimodal+picture-word+task&amp;rft.volume=102&amp;rft.issue=1&amp;rft.pages=40-59&amp;rft.date=2009&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2612128&amp;rft_id=info%3Apmid%2F18829049&amp;rft_id=info%3Adoi%2F10.1016%2Fj.jecp.2008.08.002&amp;rft.aulast=Jerger&amp;rft.aufirst=S&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2612128&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span><span class=\"citation-comment\" style=\"display:none; color:#33aa33; margin-left:0.3em\">CS1 maint: Explicit use of et al. (<a href=\"/wiki/Category:CS1_maint:_Explicit_use_of_et_al.\" title=\"Category:CS1 maint: Explicit use of et al.\">link</a>) </span></span>\n</li>\n<li id=\"cite_note-28\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-28\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Kyle, FE; Campbell, R; Mohammed, T; Coleman, M; MacSweeney, M (2013). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4920223\">\"Speechreading development in deaf and hearing children: introducing the test of child speechreading\"</a>. <i>Journal of Speech, Language and Hearing Research</i>. <b>56</b> (2): 416\u201326. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1044/1092-4388%282012/12-0039%29\">10.1044/1092-4388(2012/12-0039)</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4920223\">4920223</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/23275416\">23275416</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Speech%2C+Language+and+Hearing+Research&amp;rft.atitle=Speechreading+development+in+deaf+and+hearing+children%3A+introducing+the+test+of+child+speechreading&amp;rft.volume=56&amp;rft.issue=2&amp;rft.pages=416-26&amp;rft.date=2013&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4920223&amp;rft_id=info%3Apmid%2F23275416&amp;rft_id=info%3Adoi%2F10.1044%2F1092-4388%282012%2F12-0039%29&amp;rft.aulast=Kyle&amp;rft.aufirst=FE&amp;rft.au=Campbell%2C+R&amp;rft.au=Mohammed%2C+T&amp;rft.au=Coleman%2C+M&amp;rft.au=MacSweeney%2C+M&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4920223&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-29\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-29\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Tye-Murray, N; Hale, S; Spehar, B; Myerson, J; Sommers, MS (2014). \"Lipreading in school-age children: the roles of age, hearing status, and cognitive ability\". <i>J Speech Lang Hear Res</i>. <b>57</b> (2): 556\u201365. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1044/2013_JSLHR-H-12-0273\">10.1044/2013_JSLHR-H-12-0273</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/24129010\">24129010</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Speech+Lang+Hear+Res&amp;rft.atitle=Lipreading+in+school-age+children%3A+the+roles+of+age%2C+hearing+status%2C+and+cognitive+ability&amp;rft.volume=57&amp;rft.issue=2&amp;rft.pages=556-65&amp;rft.date=2014&amp;rft_id=info%3Adoi%2F10.1044%2F2013_JSLHR-H-12-0273&amp;rft_id=info%3Apmid%2F24129010&amp;rft.aulast=Tye-Murray&amp;rft.aufirst=N&amp;rft.au=Hale%2C+S&amp;rft.au=Spehar%2C+B&amp;rft.au=Myerson%2C+J&amp;rft.au=Sommers%2C+MS&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-30\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-30\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Peelle, JE; Sommers, MS (2015). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4475441\">\"Prediction and constraint in audiovisual speech perception\"</a>. <i>Cortex</i>. <b>68</b>: 169\u201381. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/j.cortex.2015.03.006\">10.1016/j.cortex.2015.03.006</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4475441\">4475441</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/25890390\">25890390</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Cortex&amp;rft.atitle=Prediction+and+constraint+in+audiovisual+speech+perception&amp;rft.volume=68&amp;rft.pages=169-81&amp;rft.date=2015&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4475441&amp;rft_id=info%3Apmid%2F25890390&amp;rft_id=info%3Adoi%2F10.1016%2Fj.cortex.2015.03.006&amp;rft.aulast=Peelle&amp;rft.aufirst=JE&amp;rft.au=Sommers%2C+MS&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4475441&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-31\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-31\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Campbell, R (2008). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2606792\">\"The processing of audio-visual speech: empirical and neural bases\"</a>. <i>Philosophical Transactions of the Royal Society B</i>. <b>363</b> (1493): 1001\u20131010. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1098/rstb.2007.2155\">10.1098/rstb.2007.2155</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2606792\">2606792</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/17827105\">17827105</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+B&amp;rft.atitle=The+processing+of+audio-visual+speech%3A+empirical+and+neural+bases&amp;rft.volume=363&amp;rft.issue=1493&amp;rft.pages=1001-1010&amp;rft.date=2008&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2606792&amp;rft_id=info%3Apmid%2F17827105&amp;rft_id=info%3Adoi%2F10.1098%2Frstb.2007.2155&amp;rft.aulast=Campbell&amp;rft.aufirst=R&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2606792&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-32\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-32\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Sumby, WH; Pollack, I (1954). \"Visual contribution to speech intelligibility in noise\". <i>Journal of the Acoustical Society of America</i>. <b>26</b>: 212\u2013215. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1121/1.1907309\">10.1121/1.1907309</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Acoustical+Society+of+America&amp;rft.atitle=Visual+contribution+to+speech+intelligibility+in+noise&amp;rft.volume=26&amp;rft.pages=212-215&amp;rft.date=1954&amp;rft_id=info%3Adoi%2F10.1121%2F1.1907309&amp;rft.aulast=Sumby&amp;rft.aufirst=WH&amp;rft.au=Pollack%2C+I&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-33\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-33\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Taljaard, Schmulian;  et al. (2015). \"The relationship between hearing impairment and cognitive function: A meta-analysis in adults\". <i>Clin Otolaryngol</i>. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1111/coa.12607\">10.1111/coa.12607</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Clin+Otolaryngol&amp;rft.atitle=The+relationship+between+hearing+impairment+and+cognitive+function%3A+A+meta-analysis+in+adults&amp;rft.date=2015&amp;rft_id=info%3Adoi%2F10.1111%2Fcoa.12607&amp;rft.aulast=Taljaard&amp;rft.aufirst=Schmulian&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span><span class=\"citation-comment\" style=\"display:none; color:#33aa33; margin-left:0.3em\">CS1 maint: Explicit use of et al. (<a href=\"/wiki/Category:CS1_maint:_Explicit_use_of_et_al.\" title=\"Category:CS1 maint: Explicit use of et al.\">link</a>) </span></span>\n</li>\n<li id=\"cite_note-34\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-34\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Hung, SC;  et al. (2015). \"Hearing Loss is Associated With Risk of Alzheimer's Disease: A Case-Control Study in Older People\". <i>J Epidemiol</i>. <b>25</b> (8): 517\u201321. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.2188/jea.JE20140147\">10.2188/jea.JE20140147</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Epidemiol&amp;rft.atitle=Hearing+Loss+is+Associated+With+Risk+of+Alzheimer%27s+Disease%3A+A+Case-Control+Study+in+Older+People&amp;rft.volume=25&amp;rft.issue=8&amp;rft.pages=517-21&amp;rft.date=2015&amp;rft_id=info%3Adoi%2F10.2188%2Fjea.JE20140147&amp;rft.aulast=Hung&amp;rft.aufirst=SC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span><span class=\"citation-comment\" style=\"display:none; color:#33aa33; margin-left:0.3em\">CS1 maint: Explicit use of et al. (<a href=\"/wiki/Category:CS1_maint:_Explicit_use_of_et_al.\" title=\"Category:CS1 maint: Explicit use of et al.\">link</a>) </span></span>\n</li>\n<li id=\"cite_note-35\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-35\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Smith, EG; Bennetto, L.J (2007). \"Audiovisual speech integration and lipreading in autism\". <i>Child Psychol Psychiatry</i>. <b>48</b> (8): 813\u201321. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1111/j.1469-7610.2007.01766.x\">10.1111/j.1469-7610.2007.01766.x</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/17683453\">17683453</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Child+Psychol+Psychiatry&amp;rft.atitle=Audiovisual+speech+integration+and+lipreading+in+autism&amp;rft.volume=48&amp;rft.issue=8&amp;rft.pages=813-21&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1469-7610.2007.01766.x&amp;rft_id=info%3Apmid%2F17683453&amp;rft.aulast=Smith&amp;rft.aufirst=EG&amp;rft.au=Bennetto%2C+L.J&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-36\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-36\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Irwin, JR; Tornatore, LA; Brancazio, L; Whalen, DH (2011). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3169706\">\"Can children with autism spectrum disorders \"hear\" a speaking face?\"</a>. <i>Child Dev</i>. <b>82</b> (5): 1397\u2013403. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1111/j.1467-8624.2011.01619.x\">10.1111/j.1467-8624.2011.01619.x</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3169706\">3169706</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/21790542\">21790542</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Child+Dev&amp;rft.atitle=Can+children+with+autism+spectrum+disorders+%22hear%22+a+speaking+face%3F&amp;rft.volume=82&amp;rft.issue=5&amp;rft.pages=1397-403&amp;rft.date=2011&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3169706&amp;rft_id=info%3Apmid%2F21790542&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1467-8624.2011.01619.x&amp;rft.aulast=Irwin&amp;rft.aufirst=JR&amp;rft.au=Tornatore%2C+LA&amp;rft.au=Brancazio%2C+L&amp;rft.au=Whalen%2C+DH&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3169706&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-37\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-37\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Irwin, JR; Brancazio, L (2014). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4021198\">\"Seeing to hear? Patterns of gaze to speaking faces in children with autism spectrum disorders\"</a>. <i>Front Psychol</i>. <b>5</b>: 397. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.3389/fpsyg.2014.00397\">10.3389/fpsyg.2014.00397</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4021198\">4021198</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/24847297\">24847297</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Front+Psychol&amp;rft.atitle=Seeing+to+hear%3F+Patterns+of+gaze+to+speaking+faces+in+children+with+autism+spectrum+disorders&amp;rft.volume=5&amp;rft.pages=397&amp;rft.date=2014&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4021198&amp;rft_id=info%3Apmid%2F24847297&amp;rft_id=info%3Adoi%2F10.3389%2Ffpsyg.2014.00397&amp;rft.aulast=Irwin&amp;rft.aufirst=JR&amp;rft.au=Brancazio%2C+L&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4021198&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-38\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-38\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">B\u00f6hning, M; Campbell, R; Karmiloff-Smith, A (2002). \"Audiovisual speech perception in Williams syndrome\". <i>Neuropsychologia</i>. <b>40</b> (8): 1396\u2013406. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/s0028-3932%2801%2900208-1\">10.1016/s0028-3932(01)00208-1</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/11931944\">11931944</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neuropsychologia&amp;rft.atitle=Audiovisual+speech+perception+in+Williams+syndrome&amp;rft.volume=40&amp;rft.issue=8&amp;rft.pages=1396-406&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1016%2Fs0028-3932%2801%2900208-1&amp;rft_id=info%3Apmid%2F11931944&amp;rft.aulast=B%C3%B6hning&amp;rft.aufirst=M&amp;rft.au=Campbell%2C+R&amp;rft.au=Karmiloff-Smith%2C+A&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-39\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-39\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Leybaert, J; Macchi, L; Huyse, A; Champoux, F; Bayard, C; Colin, C; Berthommier, F (2014). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4033223\">\"Atypical audio-visual speech perception and McGurk effects in children with specific language impairment\"</a>. <i>Front Psychol</i>. <b>5</b>: 422. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.3389/fpsyg.2014.00422\">10.3389/fpsyg.2014.00422</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4033223\">4033223</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/24904454\">24904454</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Front+Psychol&amp;rft.atitle=Atypical+audio-visual+speech+perception+and+McGurk+effects+in+children+with+specific+language+impairment&amp;rft.volume=5&amp;rft.pages=422&amp;rft.date=2014&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4033223&amp;rft_id=info%3Apmid%2F24904454&amp;rft_id=info%3Adoi%2F10.3389%2Ffpsyg.2014.00422&amp;rft.aulast=Leybaert&amp;rft.aufirst=J&amp;rft.au=Macchi%2C+L&amp;rft.au=Huyse%2C+A&amp;rft.au=Champoux%2C+F&amp;rft.au=Bayard%2C+C&amp;rft.au=Colin%2C+C&amp;rft.au=Berthommier%2C+F&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4033223&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-40\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-40\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Mohammed T1, Campbell R; Macsweeney, M; Barry, F; Coleman, M (2006). \"Speechreading and its association with reading among deaf, hearing and dyslexic individuals\". <i>Clinical Linguistics and Phonetics</i>. <b>20</b> (7\u20138): 621\u201330. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1080/02699200500266745\">10.1080/02699200500266745</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Clinical+Linguistics+and+Phonetics&amp;rft.atitle=Speechreading+and+its+association+with+reading+among+deaf%2C+hearing+and+dyslexic+individuals&amp;rft.volume=20&amp;rft.issue=7%E2%80%938&amp;rft.pages=621-30&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1080%2F02699200500266745&amp;rft.aulast=Mohammed+T1&amp;rft.aufirst=Campbell+R&amp;rft.au=Macsweeney%2C+M&amp;rft.au=Barry%2C+F&amp;rft.au=Coleman%2C+M&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-Clegg1953-41\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Clegg1953_41-0\">^</a></b></span> <span class=\"reference-text\"><cite id=\"CITEREFClegg1953\" class=\"citation\">Clegg, Dorothy (1953), <i>The Listening Eye: A Simple Introduction to the Art of Lip-reading</i>, Methuen &amp; Company</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Listening+Eye%3A+A+Simple+Introduction+to+the+Art+of+Lip-reading&amp;rft.pub=Methuen+%26+Company&amp;rft.date=1953&amp;rft.aulast=Clegg&amp;rft.aufirst=Dorothy&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-42\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-42\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://www.handsandvoices.org/articles/research/v9-2_marschark.htm\">http://www.handsandvoices.org/articles/research/v9-2_marschark.htm</a></span>\n</li>\n<li id=\"cite_note-43\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-43\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Swanwick, R (2016). \"Deaf Children's bimodal bilingualism and education\". <i>Language Teaching</i>. <b>49</b> (01): 1\u201334. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1017/S0261444815000348\">10.1017/S0261444815000348</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Language+Teaching&amp;rft.atitle=Deaf+Children%27s+bimodal+bilingualism+and+education&amp;rft.volume=49&amp;rft.issue=01&amp;rft.pages=1-34&amp;rft.date=2016&amp;rft_id=info%3Adoi%2F10.1017%2FS0261444815000348&amp;rft.aulast=Swanwick&amp;rft.aufirst=R&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-44\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-44\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Bernstein, LE; Demorest, ME; Tucker, PE (2000). \"Speech perception without hearing\". <i>Perception &amp; Psychophysics</i>. <b>62</b> (2): 233\u201352. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.3758/bf03205546\">10.3758/bf03205546</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Perception+%26+Psychophysics&amp;rft.atitle=Speech+perception+without+hearing&amp;rft.volume=62&amp;rft.issue=2&amp;rft.pages=233-52&amp;rft.date=2000&amp;rft_id=info%3Adoi%2F10.3758%2Fbf03205546&amp;rft.aulast=Bernstein&amp;rft.aufirst=LE&amp;rft.au=Demorest%2C+ME&amp;rft.au=Tucker%2C+PE&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-45\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-45\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Bergeson TR1, Pisoni DB; Davis, RA (2005). \"Development of audiovisual comprehension skills in prelingually deaf children with cochlear implants\". <i>Ear &amp; Hearing</i>. <b>26</b> (2): 149\u201364. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1097/00003446-200504000-00004\">10.1097/00003446-200504000-00004</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Ear+%26+Hearing&amp;rft.atitle=Development+of+audiovisual+comprehension+skills+in+prelingually+deaf+children+with+cochlear+implants&amp;rft.volume=26&amp;rft.issue=2&amp;rft.pages=149-64&amp;rft.date=2005&amp;rft_id=info%3Adoi%2F10.1097%2F00003446-200504000-00004&amp;rft.aulast=Bergeson+TR1&amp;rft.aufirst=Pisoni+DB&amp;rft.au=Davis%2C+RA&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-46\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-46\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://www.nidirect.gov.uk/communication-support-for-deaf-people\">http://www.nidirect.gov.uk/communication-support-for-deaf-people</a></span>\n</li>\n<li id=\"cite_note-47\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-47\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://www.lipspeaker.co.uk\">http://www.lipspeaker.co.uk</a></span>\n</li>\n<li id=\"cite_note-48\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-48\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://www.nuffieldfoundation.org/reading-and-dyslexia-deaf-children\">http://www.nuffieldfoundation.org/reading-and-dyslexia-deaf-children</a></span>\n</li>\n<li id=\"cite_note-49\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-49\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">\"What really matters in the early literacy development of deaf children\". <i>J Deaf Stud Deaf Educ</i>. <b>12</b> (4): 411\u201331. 2007. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1093/deafed/enm020\">10.1093/deafed/enm020</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Deaf+Stud+Deaf+Educ&amp;rft.atitle=What+really+matters+in+the+early+literacy+development+of+deaf+children&amp;rft.volume=12&amp;rft.issue=4&amp;rft.pages=411-31&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1093%2Fdeafed%2Fenm020&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-50\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-50\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">\"Speechreading and its association with reading among deaf, hearing and dyslexic individuals\". <i>Clinical Linguistics &amp; Phonetics</i>. <b>20</b>: 621\u2013630. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1080/02699200500266745\">10.1080/02699200500266745</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Clinical+Linguistics+%26+Phonetics&amp;rft.atitle=Speechreading+and+its+association+with+reading+among+deaf%2C+hearing+and+dyslexic+individuals&amp;rft.volume=20&amp;rft.pages=621-630&amp;rft_id=info%3Adoi%2F10.1080%2F02699200500266745&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-51\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-51\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Kyle, F. E.; Harris, M. (2010). \"Predictors of reading development in deaf children: a 3-year longitudinal study\". <i>J Exp Child Psychol</i>. <b>107</b>: 229\u2013243. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/j.jecp.2010.04.011\">10.1016/j.jecp.2010.04.011</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Exp+Child+Psychol&amp;rft.atitle=Predictors+of+reading+development+in+deaf+children%3A+a+3-year+longitudinal+study&amp;rft.volume=107&amp;rft.pages=229-243&amp;rft.date=2010&amp;rft_id=info%3Adoi%2F10.1016%2Fj.jecp.2010.04.011&amp;rft.aulast=Kyle&amp;rft.aufirst=F.+E.&amp;rft.au=Harris%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-52\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-52\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://jslhr.pubs.asha.org/article.aspx?articleid=1795779\">http://jslhr.pubs.asha.org/article.aspx?articleid=1795779</a></span>\n</li>\n<li id=\"cite_note-53\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-53\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Nicholls, GH; Ling, D (1982). \"Cued Speech and the reception of spoken language\". <i>J Speech Hear Res</i>. <b>25</b> (2): 262\u20139. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1044/jshr.2502.262\">10.1044/jshr.2502.262</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Speech+Hear+Res&amp;rft.atitle=Cued+Speech+and+the+reception+of+spoken+language&amp;rft.volume=25&amp;rft.issue=2&amp;rft.pages=262-9&amp;rft.date=1982&amp;rft_id=info%3Adoi%2F10.1044%2Fjshr.2502.262&amp;rft.aulast=Nicholls&amp;rft.aufirst=GH&amp;rft.au=Ling%2C+D&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-54\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-54\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Leybaert, J; LaSasso, CJ (2010). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4111351\">\"Cued speech for enhancing speech perception and first language development of children with cochlear implants\"</a>. <i>Trends in Amplification</i>. <b>14</b> (2): 96\u2013112. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1177/1084713810375567\">10.1177/1084713810375567</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4111351\">4111351</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Trends+in+Amplification&amp;rft.atitle=Cued+speech+for+enhancing+speech+perception+and+first+language+development+of+children+with+cochlear+implants&amp;rft.volume=14&amp;rft.issue=2&amp;rft.pages=96-112&amp;rft.date=2010&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4111351&amp;rft_id=info%3Adoi%2F10.1177%2F1084713810375567&amp;rft.aulast=Leybaert&amp;rft.aufirst=J&amp;rft.au=LaSasso%2C+CJ&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4111351&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-55\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-55\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"https://www.lipreading.org/lipreading-\">https://www.lipreading.org/lipreading-</a></span>\n</li>\n<li id=\"cite_note-56\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-56\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"https://www.actiononhearingloss.org.uk/notjustlipservice.aspx\">https://www.actiononhearingloss.org.uk/notjustlipservice.aspx</a></span>\n</li>\n<li id=\"cite_note-57\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-57\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://www-bcf.usc.edu/~rwalker/Walker/Publications_files/1996_CohenWalker%26Massaro_VisualSpeech.pdf\">http://www-bcf.usc.edu/~rwalker/Walker/Publications_files/1996_CohenWalker%26Massaro_VisualSpeech.pdf</a></span>\n</li>\n<li id=\"cite_note-58\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-58\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A318099&amp;dswid=2041\">http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A318099&amp;dswid=2041</a></span>\n</li>\n<li id=\"cite_note-59\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-59\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\"><a rel=\"nofollow\" class=\"external text\" href=\"https://link.springer.com/article/10.1023/B:JADD.0000006002.82367.4f#/page-1\">\"Development and Evaluation of a Computer-Animated Tutor for Vocabulary and Language Learning in Children with Autism\"</a>. <i>Journal of Autism and Developmental Disorders</i>. <b>33</b>: 653\u2013672. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1023/B%3AJADD.0000006002.82367.4f\">10.1023/B:JADD.0000006002.82367.4f</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Autism+and+Developmental+Disorders&amp;rft.atitle=Development+and+Evaluation+of+a+Computer-Animated+Tutor+for+Vocabulary+and+Language+Learning+in+Children+with+Autism&amp;rft.volume=33&amp;rft.pages=653-672&amp;rft_id=info%3Adoi%2F10.1023%2FB%3AJADD.0000006002.82367.4f&amp;rft_id=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1023%2FB%3AJADD.0000006002.82367.4f%23%2Fpage-1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-60\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-60\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"https://www.uea.ac.uk/computing/visual-speech-synthesis\">https://www.uea.ac.uk/computing/visual-speech-synthesis</a></span>\n</li>\n<li id=\"cite_note-61\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-61\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://www.cnet.com/news/lip-reading-computer-can-distinguish-languages/\">http://www.cnet.com/news/lip-reading-computer-can-distinguish-languages/</a></span>\n</li>\n<li id=\"cite_note-62\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-62\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"https://www.youtube.com/watch?v=Tu2vInqqHX8\">https://www.youtube.com/watch?v=Tu2vInqqHX8</a></span>\n</li>\n<li id=\"cite_note-63\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-63\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"https://www.theguardian.com/business/2016/apr/24/the-innovators-can-computers-be-taught-to-lip-read-artificial-intelligence\">https://www.theguardian.com/business/2016/apr/24/the-innovators-can-computers-be-taught-to-lip-read-artificial-intelligence</a></span>\n</li>\n<li id=\"cite_note-64\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-64\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"https://www.newscientist.com/article/2113299-googles-deepmind-ai-can-lip-read-tv-shows-better-than-a-pro/\">https://www.newscientist.com/article/2113299-googles-deepmind-ai-can-lip-read-tv-shows-better-than-a-pro/</a></span>\n</li>\n<li id=\"cite_note-65\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-65\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"https://www.researchgate.net/profile/David_Bodoff/publication/234819242_An_improved_automatic_lipreading_system_to_enhance_speech_recognition/links/5628b96008ae04c2aeaeb404.pdf\">https://www.researchgate.net/profile/David_Bodoff/publication/234819242_An_improved_automatic_lipreading_system_to_enhance_speech_recognition/links/5628b96008ae04c2aeaeb404.pdf</a></span>\n</li>\n<li id=\"cite_note-66\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-66\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://www.asel.udel.edu/icslp/cdrom/vol1/954/a954.pdf\">http://www.asel.udel.edu/icslp/cdrom/vol1/954/a954.pdf</a></span>\n</li>\n<li id=\"cite_note-67\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-67\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://www.planetbiometrics.com-article-details-i-2250\">http://www.planetbiometrics.com-article-details-i-2250</a></span>\n</li>\n<li id=\"cite_note-68\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-68\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Calvert, GA; Bullmore, ET; Brammer, MJ;  et al. (1997). \"Activation  of auditory cortex during silent lipreading\". <i>Science</i>. <b>276</b> (5312): 593\u20136. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1126/science.276.5312.593\">10.1126/science.276.5312.593</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/9110978\">9110978</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Science&amp;rft.atitle=Activation++of+auditory+cortex+during+silent+lipreading&amp;rft.volume=276&amp;rft.issue=5312&amp;rft.pages=593-6&amp;rft.date=1997&amp;rft_id=info%3Adoi%2F10.1126%2Fscience.276.5312.593&amp;rft_id=info%3Apmid%2F9110978&amp;rft.aulast=Calvert&amp;rft.aufirst=GA&amp;rft.au=Bullmore%2C+ET&amp;rft.au=Brammer%2C+MJ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span><span class=\"citation-comment\" style=\"display:none; color:#33aa33; margin-left:0.3em\">CS1 maint: Explicit use of et al. (<a href=\"/wiki/Category:CS1_maint:_Explicit_use_of_et_al.\" title=\"Category:CS1 maint: Explicit use of et al.\">link</a>) </span></span>\n</li>\n<li id=\"cite_note-69\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-69\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Bernstein, LE; Liebenthal, E (2014). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4248808\">\"Neural pathways for visual speech perception\"</a>. <i>Front Neurosci</i>. <b>8</b>: 386. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.3389/fnins.2014.00386\">10.3389/fnins.2014.00386</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4248808\">4248808</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/25520611\">25520611</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Front+Neurosci&amp;rft.atitle=Neural+pathways+for+visual+speech+perception&amp;rft.volume=8&amp;rft.pages=386&amp;rft.date=2014&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4248808&amp;rft_id=info%3Apmid%2F25520611&amp;rft_id=info%3Adoi%2F10.3389%2Ffnins.2014.00386&amp;rft.aulast=Bernstein&amp;rft.aufirst=LE&amp;rft.au=Liebenthal%2C+E&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4248808&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-70\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-70\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Skipper, JI; van Wassenhove, V; Nusbaum, HC; Small, SL (2007). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2896890\">\"Hearing Lips and Seeing Voices: How Cortical Areas Supporting Speech Production Mediate Audiovisual Speech Perception\"</a>. <i>Cerebral Cortex</i>. <b>17</b> (10): 2387\u20132399. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1093/cercor/bhl147\">10.1093/cercor/bhl147</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2896890\">2896890</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/17218482\">17218482</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Cerebral+Cortex&amp;rft.atitle=Hearing+Lips+and+Seeing+Voices%3A+How+Cortical+Areas+Supporting+Speech+Production+Mediate+Audiovisual+Speech+Perception&amp;rft.volume=17&amp;rft.issue=10&amp;rft.pages=2387-2399&amp;rft.date=2007&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2896890&amp;rft_id=info%3Apmid%2F17218482&amp;rft_id=info%3Adoi%2F10.1093%2Fcercor%2Fbhl147&amp;rft.aulast=Skipper&amp;rft.aufirst=JI&amp;rft.au=van+Wassenhove%2C+V&amp;rft.au=Nusbaum%2C+HC&amp;rft.au=Small%2C+SL&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2896890&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-71\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-71\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Campbell, R; MacSweeney, M; Surguladze, S; Calvert, G; McGuire, P; Suckling, J; Brammer, MJ; David, AS (2001). \"Cortical substrates for the perception of face actions: an fMRI study of the specificity of activation for seen speech and for meaningless lower-face acts (gurning)\". <i>Brain Res Cogn Brain Res</i>. <b>12</b>: 233\u201343. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/s0926-6410%2801%2900054-4\">10.1016/s0926-6410(01)00054-4</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/11587893\">11587893</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Brain+Res+Cogn+Brain+Res&amp;rft.atitle=Cortical+substrates+for+the+perception+of+face+actions%3A+an+fMRI+study+of+the+specificity+of+activation+for+seen+speech+and+for+meaningless+lower-face+acts+%28gurning%29&amp;rft.volume=12&amp;rft.pages=233-43&amp;rft.date=2001&amp;rft_id=info%3Adoi%2F10.1016%2Fs0926-6410%2801%2900054-4&amp;rft_id=info%3Apmid%2F11587893&amp;rft.aulast=Campbell&amp;rft.aufirst=R&amp;rft.au=MacSweeney%2C+M&amp;rft.au=Surguladze%2C+S&amp;rft.au=Calvert%2C+G&amp;rft.au=McGuire%2C+P&amp;rft.au=Suckling%2C+J&amp;rft.au=Brammer%2C+MJ&amp;rft.au=David%2C+AS&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-72\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-72\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Swaminathan, S.; MacSweeney, M.; Boyles, R.; Waters, D.; Watkins, K. E.; M\u00f6tt\u00f6nen, R. (2013). <a rel=\"nofollow\" class=\"external text\" href=\"http://doi.org/10.1016/j.bandl.2013.03.002\">\"Motor excitability during visual perception of known and unknown spoken languages\"</a>. <i>Brain and Language</i>. <b>126</b> (1): 1\u20137. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/j.bandl.2013.03.002\">10.1016/j.bandl.2013.03.002</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Brain+and+Language&amp;rft.atitle=Motor+excitability+during+visual+perception+of+known+and+unknown+spoken+languages&amp;rft.volume=126&amp;rft.issue=1&amp;rft.pages=1-7&amp;rft.date=2013&amp;rft_id=info%3Adoi%2F10.1016%2Fj.bandl.2013.03.002&amp;rft.aulast=Swaminathan&amp;rft.aufirst=S.&amp;rft.au=MacSweeney%2C+M.&amp;rft.au=Boyles%2C+R.&amp;rft.au=Waters%2C+D.&amp;rft.au=Watkins%2C+K.+E.&amp;rft.au=M%C3%B6tt%C3%B6nen%2C+R.&amp;rft_id=http%3A%2F%2Fdoi.org%2F10.1016%2Fj.bandl.2013.03.002&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-73\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-73\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Sams, M;  et al. \"Aulenko <i>et al.</i> 1991 Seeing Speech: visual information from lip movements modifies activity in the human auditory cortex\". <i>Neuroscience Letters</i>. <b>127</b>: 141\u2013145. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/0304-3940%2891%2990914-f\">10.1016/0304-3940(91)90914-f</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neuroscience+Letters&amp;rft.atitle=Aulenko+et+al.+1991+Seeing+Speech%3A+visual+information+from+lip+movements+modifies+activity+in+the+human+auditory+cortex&amp;rft.volume=127&amp;rft.pages=141-145&amp;rft_id=info%3Adoi%2F10.1016%2F0304-3940%2891%2990914-f&amp;rft.aulast=Sams&amp;rft.aufirst=M&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span><span class=\"citation-comment\" style=\"display:none; color:#33aa33; margin-left:0.3em\">CS1 maint: Explicit use of et al. (<a href=\"/wiki/Category:CS1_maint:_Explicit_use_of_et_al.\" title=\"Category:CS1 maint: Explicit use of et al.\">link</a>) </span></span>\n</li>\n<li id=\"cite_note-74\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-74\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Van Wassenhove, V; Grant, KW; Poeppel, D (Jan 2005). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC545853\">\"Visual speech speeds up the neural processing of auditory speech\"</a>. <i>Proceedings of the National Academy of Sciences</i>. <b>102</b> (4): 1181\u20136. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1073/pnas.0408949102\">10.1073/pnas.0408949102</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC545853\">545853</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+National+Academy+of+Sciences&amp;rft.atitle=Visual+speech+speeds+up+the+neural+processing+of+auditory+speech&amp;rft.volume=102&amp;rft.issue=4&amp;rft.pages=1181-6&amp;rft.date=2005-01&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC545853&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.0408949102&amp;rft.aulast=Van+Wassenhove&amp;rft.aufirst=V&amp;rft.au=Grant%2C+KW&amp;rft.au=Poeppel%2C+D&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC545853&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-75\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-75\">^</a></b></span> <span class=\"reference-text\">Hall DA1, Fussell C, Summerfield AQ. 2005\nReading fluent speech from talking faces: typical brain networks and individual differences.J. Cogn Neurosci. 17(6):939-53.</span>\n</li>\n<li id=\"cite_note-76\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-76\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Bernstein, LE; Jiang, J; Pantazis, D; Lu, ZL; Joshi, A (2011). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3120928\">\"Visual phonetic processing localized using speech and nonspeech face gestures in video and point-light displays\"</a>. <i>Hum Brain Mapp</i>. <b>32</b> (10): 1660\u201376. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1002/hbm.21139\">10.1002/hbm.21139</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3120928\">3120928</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/20853377\">20853377</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Hum+Brain+Mapp&amp;rft.atitle=Visual+phonetic+processing+localized+using+speech+and+nonspeech+face+gestures+in+video+and+point-light+displays&amp;rft.volume=32&amp;rft.issue=10&amp;rft.pages=1660-76&amp;rft.date=2011&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3120928&amp;rft_id=info%3Apmid%2F20853377&amp;rft_id=info%3Adoi%2F10.1002%2Fhbm.21139&amp;rft.aulast=Bernstein&amp;rft.aufirst=LE&amp;rft.au=Jiang%2C+J&amp;rft.au=Pantazis%2C+D&amp;rft.au=Lu%2C+ZL&amp;rft.au=Joshi%2C+A&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3120928&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-77\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-77\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Capek, CM; Macsweeney, M; Woll, B; Waters, D; McGuire, PK; David, AS; Brammer, MJ; Campbell, R (2008). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2394569\">\"Cortical circuits for silent speechreading in deaf and hearing people\"</a>. <i>Neuropsychologia</i>. <b>46</b> (5): 1233\u201341. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/j.neuropsychologia.2007.11.026\">10.1016/j.neuropsychologia.2007.11.026</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2394569\">2394569</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/18249420\">18249420</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neuropsychologia&amp;rft.atitle=Cortical+circuits+for+silent+speechreading+in+deaf+and+hearing+people&amp;rft.volume=46&amp;rft.issue=5&amp;rft.pages=1233-41&amp;rft.date=2008&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2394569&amp;rft_id=info%3Apmid%2F18249420&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neuropsychologia.2007.11.026&amp;rft.aulast=Capek&amp;rft.aufirst=CM&amp;rft.au=Macsweeney%2C+M&amp;rft.au=Woll%2C+B&amp;rft.au=Waters%2C+D&amp;rft.au=McGuire%2C+PK&amp;rft.au=David%2C+AS&amp;rft.au=Brammer%2C+MJ&amp;rft.au=Campbell%2C+R&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2394569&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALip+reading\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n</ol></div>\n<h3><span class=\"mw-headline\" id=\"Bibliography\">Bibliography</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=19\" title=\"Edit section: Bibliography\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<ul><li>D.Stork and M.Henneke (Eds) (1996) Speechreading by Humans and machines: Models Systems and Applications. Nato ASI series F Computer and Systems sciences Vol 150. Springer, Berlin Germany</li>\n<li>E.Bailly, P.Perrier and E.Vatikiotis-Bateson (Eds)(2012) Audiovisual Speech processing, Cambridge University press, Cambridge UK</li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"https://books.google.com/books/about/Hearing_by_Eye.html?id=styYQgAACAAJ&amp;redir_esc=y\">Hearing By Eye (1987)</a>, B.Dodd and R.Campbell (Eds), Erlbaum Asstes, Hillsdale NJ, USA;  <a rel=\"nofollow\" class=\"external text\" href=\"https://books.google.com/books/about/Hearing_by_Eye_II.html?id=SOAQe97Fo04C&amp;redir_esc=y\">Hearing by Eye II</a>, (1997) R.Campbell, B.Dodd and D.Burnham (Eds), Psychology Press, Hove UK</li>\n<li>D. W. Massaro (1987, reprinted 2014) <a rel=\"nofollow\" class=\"external text\" href=\"https://www.questia.com/library/78558929/speech-perception-by-ear-and-eye-a-paradigm-for-psychological\">Speech  perception by ear and by eye</a>, Lawrence Erlbaum Associates, Hillsdale NJ</li></ul>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Lip_reading&amp;action=edit&amp;section=20\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li>Laura Ringham (2012) Why it\u2019s time to recognise the value of lipreading and managing hearing loss support (Action on Hearing Loss, full report)  <a rel=\"nofollow\" class=\"external autonumber\" href=\"https://www.actiononhearingloss.org.uk/~/media/Documents/Policy%20research%20and%20influencing/Research/Not%20just%20lip%20service/Not%20just%20lip%20service_Full%20report_FINAL_A0639_9.ashx\">[1]</a></li>\n<li>Scottish Sensory Centre 2005: workshop on lipreading <a rel=\"nofollow\" class=\"external autonumber\" href=\"http://www.ssc.education.ed.ac.uk/courses/deaf/ddec05f.html\">[2]</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://www.actiononhearingloss.org.uk/~/media/Documents/Scotland/Lipreading%20Classes%20in%20Scotland%20%20the%20way%20forward.ashx\">Lipreading Classes in Scotland: the way forward. 2015 Report</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://avisa.loria.fr\">AVISA; International Speech Communication Association special interest group focussed on lip-reading and audiovisual speech</a></li>\n<li>Speechreading for information gathering: a survey of scientific sources <a rel=\"nofollow\" class=\"external autonumber\" href=\"https://www.ucl.ac.uk/dcal/projects/tabs/images/speechreading\">[3]</a></li></ul>\n<div role=\"navigation\" class=\"navbox\" aria-labelledby=\"Deaf_education\" style=\"padding:3px\"><table class=\"nowraplinks collapsible uncollapsed navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\"><div class=\"plainlinks hlist navbar mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Deaf_education\" title=\"Template:Deaf education\"><abbr title=\"View this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Deaf_education\" title=\"Template talk:Deaf education\"><abbr title=\"Discuss this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Template:Deaf_education&amp;action=edit\"><abbr title=\"Edit this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">e</abbr></a></li></ul></div><div id=\"Deaf_education\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Deaf_education\" title=\"Deaf education\">Deaf education</a></div></th></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;padding:0.35em 1.0em; line-height:1.1em;\">Communication</th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Cued_speech\" title=\"Cued speech\">Cued speech</a></li>\n<li><a href=\"/wiki/Fingerspelling\" title=\"Fingerspelling\">Fingerspelling</a></li>\n<li><a class=\"mw-selflink selflink\">Lip reading</a></li>\n<li><a href=\"/wiki/Manually_coded_English\" title=\"Manually coded English\">Manually coded English</a></li>\n<li><a href=\"/wiki/Oralism\" title=\"Oralism\">Oralism</a></li>\n<li><a href=\"/wiki/Sign_language\" title=\"Sign language\">Sign language</a></li>\n<li><a href=\"/wiki/Simultaneous_communication\" title=\"Simultaneous communication\">Simultaneous communication</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;padding:0.35em 1.0em; line-height:1.1em;\">Educators</th><td class=\"navbox-list navbox-even hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Jean_Massieu\" title=\"Jean Massieu\">Jean Massieu</a> (b. 1772)</li>\n<li><a href=\"/wiki/Laurent_Clerc\" title=\"Laurent Clerc\">Laurent Clerc</a> (b. 1785)</li>\n<li><a href=\"/wiki/Edward_Miner_Gallaudet\" title=\"Edward Miner Gallaudet\">Edward Miner Gallaudet</a> (b. 1837)</li>\n<li><a href=\"/wiki/Sophia_Alcorn\" title=\"Sophia Alcorn\">Sophia Alcorn</a> (b. 1883)</li>\n<li><a href=\"/wiki/Andrew_Foster_(educator)\" title=\"Andrew Foster (educator)\">Andrew Foster</a> (b. 1925)</li>\n<li><a href=\"/wiki/Clayton_Valli\" title=\"Clayton Valli\">Clayton Valli</a> (b. 1951)</li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;padding:0.35em 1.0em; line-height:1.1em;\">Religious<br /> organizations</th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Christian_Mission_for_the_Deaf\" title=\"Christian Mission for the Deaf\">Christian Mission for the Deaf</a> (Africa)</li></ul>\n</div></td></tr></tbody></table></div>\n<div role=\"navigation\" class=\"navbox\" aria-labelledby=\"Schools_for_the_deaf\" style=\"padding:3px\"><table class=\"nowraplinks collapsible autocollapse navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\"><div class=\"plainlinks hlist navbar mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Schools_for_the_deaf\" title=\"Template:Schools for the deaf\"><abbr title=\"View this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Schools_for_the_deaf\" title=\"Template talk:Schools for the deaf\"><abbr title=\"Discuss this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Template:Schools_for_the_deaf&amp;action=edit\"><abbr title=\"Edit this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">e</abbr></a></li></ul></div><div id=\"Schools_for_the_deaf\" style=\"font-size:114%;margin:0 4em\">Schools for the deaf</div></th></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;padding:0.35em 1.0em; line-height:1.1em;\">Primary<br /> Schools</th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Alexander_Graham_Bell_School_(Chicago,_Illinois)\" title=\"Alexander Graham Bell School (Chicago, Illinois)\">Alexander Graham Bell School (Chicago, Illinois)</a></li>\n<li><a href=\"/wiki/Clarke_Schools_for_Hearing_and_Speech\" title=\"Clarke Schools for Hearing and Speech\">Clarke Schools for Hearing and Speech</a></li>\n<li><a href=\"/wiki/Detroit_Day_School_for_the_Deaf\" title=\"Detroit Day School for the Deaf\">Detroit Day School for the Deaf</a> (closed)</li>\n<li><a href=\"/wiki/Moog_Center_for_Deaf_Education\" title=\"Moog Center for Deaf Education\">Moog Center for Deaf Education</a></li>\n<li><a href=\"/wiki/West_Tennessee_School_for_the_Deaf\" title=\"West Tennessee School for the Deaf\">West Tennessee School for the Deaf</a></li>\n<li><a href=\"/wiki/Wyoming_School_for_the_Deaf\" title=\"Wyoming School for the Deaf\">Wyoming School for the Deaf</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;padding:0.35em 1.0em; line-height:1.1em;\">Secondary <br /> Schools</th><td class=\"navbox-list navbox-even hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Alabama_Institute_for_the_Deaf_and_Blind\" title=\"Alabama Institute for the Deaf and Blind\">Alabama Institute for the Deaf and Blind</a></li>\n<li><a href=\"/wiki/Alaska_State_School_for_the_Deaf_and_Hard_of_Hearing\" title=\"Alaska State School for the Deaf and Hard of Hearing\">Alaska State School for the Deaf and Hard of Hearing</a></li>\n<li><a href=\"/wiki/American_School_for_the_Deaf\" title=\"American School for the Deaf\">American School for the Deaf</a></li>\n<li><a href=\"/wiki/Arkansas_School_for_the_Deaf\" title=\"Arkansas School for the Deaf\">Arkansas School for the Deaf</a></li>\n<li><a href=\"/wiki/Atlanta_Area_School_for_the_Deaf\" title=\"Atlanta Area School for the Deaf\">Atlanta Area School for the Deaf</a></li>\n<li><a href=\"/wiki/Austine_School\" title=\"Austine School\">Austine School</a></li>\n<li><a href=\"/wiki/Barbara_Jordan_High_School\" title=\"Barbara Jordan High School\">Barbara Jordan High School</a></li>\n<li><a href=\"/wiki/Beverly_School_for_the_Deaf\" title=\"Beverly School for the Deaf\">Beverly School for the Deaf</a></li>\n<li><a href=\"/wiki/California_School_for_the_Deaf,_Fremont\" title=\"California School for the Deaf, Fremont\">California School for the Deaf, Fremont</a></li>\n<li><a href=\"/wiki/California_School_for_the_Deaf,_Riverside\" title=\"California School for the Deaf, Riverside\">California School for the Deaf, Riverside</a></li>\n<li><a href=\"/wiki/Colorado_School_for_the_Deaf_and_Blind\" title=\"Colorado School for the Deaf and Blind\">Colorado School for the Deaf and Blind</a></li>\n<li><a href=\"/wiki/Delaware_School_for_the_Deaf\" title=\"Delaware School for the Deaf\">Delaware School for the Deaf</a></li>\n<li><a href=\"/w/index.php?title=Eastern_North_Carolina_School_for_the_Deaf&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"Eastern North Carolina School for the Deaf (page does not exist)\">Eastern North Carolina School for the Deaf</a></li>\n<li><a href=\"/wiki/Florida_School_for_the_Deaf_and_Blind\" title=\"Florida School for the Deaf and Blind\">Florida School for the Deaf and Blind</a></li>\n<li><a href=\"/wiki/Georgia_School_for_the_Deaf\" title=\"Georgia School for the Deaf\">Georgia School for the Deaf</a></li>\n<li><a href=\"/wiki/Horace_Mann_School_for_the_Deaf_and_Hard_of_Hearing\" title=\"Horace Mann School for the Deaf and Hard of Hearing\">Horace Mann School for the Deaf and Hard of Hearing</a></li>\n<li><a href=\"/wiki/Illinois_School_for_the_Deaf\" title=\"Illinois School for the Deaf\">Illinois School for the Deaf</a></li>\n<li><a href=\"/wiki/Indiana_School_for_the_Deaf\" title=\"Indiana School for the Deaf\">Indiana School for the Deaf</a></li>\n<li><a href=\"/wiki/Iowa_School_for_the_Deaf\" title=\"Iowa School for the Deaf\">Iowa School for the Deaf</a></li>\n<li><a href=\"/wiki/Kansas_State_School_For_the_Deaf\" class=\"mw-redirect\" title=\"Kansas State School For the Deaf\">Kansas State School For the Deaf</a></li>\n<li><a href=\"/wiki/Kentucky_School_for_the_Deaf\" title=\"Kentucky School for the Deaf\">Kentucky School for the Deaf</a></li>\n<li><a href=\"/wiki/The_Learning_Center_for_the_Deaf\" title=\"The Learning Center for the Deaf\">The Learning Center for the Deaf</a></li>\n<li><a href=\"/wiki/Lexington_School_and_Center_for_the_Deaf\" title=\"Lexington School and Center for the Deaf\">Lexington School and Center for the Deaf</a></li>\n<li><a href=\"/wiki/Louisiana_School_for_the_Deaf\" title=\"Louisiana School for the Deaf\">Louisiana School for the Deaf</a></li>\n<li><a href=\"/wiki/Marlton_School\" title=\"Marlton School\">Marlton School</a></li>\n<li><a href=\"/wiki/Maryland_School_for_the_Deaf\" title=\"Maryland School for the Deaf\">Maryland School for the Deaf</a></li>\n<li><a href=\"/wiki/Minnesota_State_Academy_for_the_Deaf\" title=\"Minnesota State Academy for the Deaf\">Minnesota State Academy for the Deaf</a></li>\n<li><a href=\"/wiki/Mississippi_School_for_the_Deaf\" title=\"Mississippi School for the Deaf\">Mississippi School for the Deaf</a></li>\n<li><a href=\"/wiki/Model_Secondary_School_for_the_Deaf\" title=\"Model Secondary School for the Deaf\">Model Secondary School for the Deaf</a></li>\n<li><a href=\"/wiki/Nebraska_School_for_the_Deaf\" title=\"Nebraska School for the Deaf\">Nebraska School for the Deaf</a></li>\n<li><a href=\"/wiki/New_Mexico_School_for_the_Deaf\" title=\"New Mexico School for the Deaf\">New Mexico School for the Deaf</a></li>\n<li><a href=\"/wiki/New_York_School_for_the_Deaf\" title=\"New York School for the Deaf\">New York School for the Deaf</a></li>\n<li><a href=\"/wiki/New_York_State_School_for_the_Deaf\" title=\"New York State School for the Deaf\">New York State School for the Deaf</a></li>\n<li><a href=\"/wiki/North_Carolina_School_for_the_Deaf\" title=\"North Carolina School for the Deaf\">North Carolina School for the Deaf</a></li>\n<li><a href=\"/wiki/North_Dakota_School_for_the_Deaf\" title=\"North Dakota School for the Deaf\">North Dakota School for the Deaf</a></li>\n<li><a href=\"/wiki/Ohio_School_for_the_Deaf\" title=\"Ohio School for the Deaf\">Ohio School for the Deaf</a></li>\n<li><a href=\"/wiki/Oklahoma_School_for_the_Deaf\" title=\"Oklahoma School for the Deaf\">Oklahoma School for the Deaf</a></li>\n<li><a href=\"/wiki/Oregon_School_for_the_Deaf\" title=\"Oregon School for the Deaf\">Oregon School for the Deaf</a></li>\n<li><a href=\"/wiki/Pennsylvania_School_for_the_Deaf\" title=\"Pennsylvania School for the Deaf\">Pennsylvania School for the Deaf</a></li>\n<li><a href=\"/wiki/Rochester_School_for_the_Deaf\" title=\"Rochester School for the Deaf\">Rochester School for the Deaf</a></li>\n<li><a href=\"/wiki/T._H._Rogers_School\" title=\"T. H. Rogers School\">T. H. Rogers School</a></li>\n<li><a href=\"/wiki/St._Rita_School_for_the_Deaf\" title=\"St. Rita School for the Deaf\">St. Rita School for the Deaf</a></li>\n<li><a href=\"/wiki/Scranton_School_for_Deaf_and_Hard-of-Hearing_Children\" title=\"Scranton School for Deaf and Hard-of-Hearing Children\">Scranton School for Deaf and Hard-of-Hearing Children</a></li>\n<li><a href=\"/wiki/Scranton_State_School_for_the_Deaf\" title=\"Scranton State School for the Deaf\">Scranton State School for the Deaf</a></li>\n<li><a href=\"/wiki/South_Carolina_School_for_the_Deaf_and_Blind\" title=\"South Carolina School for the Deaf and Blind\">South Carolina School for the Deaf and Blind</a></li>\n<li><a href=\"/wiki/South_Dakota_School_for_the_Deaf\" title=\"South Dakota School for the Deaf\">South Dakota School for the Deaf</a></li>\n<li><a href=\"/wiki/Tennessee_School_for_the_Deaf\" title=\"Tennessee School for the Deaf\">Tennessee School for the Deaf</a></li>\n<li><a href=\"/wiki/Texas_School_for_the_Deaf\" title=\"Texas School for the Deaf\">Texas School for the Deaf</a></li>\n<li><a href=\"/wiki/Virginia_School_for_the_Deaf_and_the_Blind\" title=\"Virginia School for the Deaf and the Blind\">Virginia School for the Deaf and the Blind</a></li>\n<li><a href=\"/wiki/West_Virginia_Schools_for_the_Deaf_and_Blind\" title=\"West Virginia Schools for the Deaf and Blind\">West Virginia Schools for the Deaf and Blind</a></li>\n<li><a href=\"/wiki/Western_Pennsylvania_School_for_the_Deaf\" title=\"Western Pennsylvania School for the Deaf\">Western Pennsylvania School for the Deaf</a></li>\n<li><a href=\"/wiki/Jerry_L._White_Center_High_School\" title=\"Jerry L. White Center High School\">Jerry L. White Center High School</a></li>\n<li><a href=\"/wiki/Willie_Ross_School_for_the_Deaf\" title=\"Willie Ross School for the Deaf\">Willie Ross School for the Deaf</a></li>\n<li><a href=\"/wiki/Wisconsin_School_for_the_Deaf\" title=\"Wisconsin School for the Deaf\">Wisconsin School for the Deaf</a></li>\n<li><a href=\"/wiki/Naxal_School_for_the_Deaf\" title=\"Naxal School for the Deaf\">Naxal School for the Deaf</a> (Nepal)</li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;padding:0.35em 1.0em; line-height:1.1em;\">Tertiary<br /> Schools</th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Gallaudet_University\" title=\"Gallaudet University\">Gallaudet University</a></li>\n<li><a href=\"/wiki/National_Technical_Institute_for_the_Deaf\" title=\"National Technical Institute for the Deaf\">National Technical Institute for the Deaf</a> (est.1965)</li>\n<li><a href=\"/wiki/Centre_for_Deaf_Studies,_Bristol\" title=\"Centre for Deaf Studies, Bristol\">Centre for Deaf Studies, Bristol</a>(closed)</li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;padding:0.35em 1.0em; line-height:1.1em;\">Ungraded<br /> Schools</th><td class=\"navbox-list navbox-even hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Central_Institute_for_the_Deaf\" title=\"Central Institute for the Deaf\">Central Institute for the Deaf</a></li>\n<li><a href=\"/wiki/Project_Insight\" title=\"Project Insight\">Project Insight</a></li>\n<li><a href=\"/wiki/Summit_Speech_School\" title=\"Summit Speech School\">Summit Speech School</a></li>\n<li><a href=\"/wiki/Wright-Humason_School_for_the_Deaf\" title=\"Wright-Humason School for the Deaf\">Wright-Humason School for the Deaf</a></li>\n<li><a href=\"/wiki/Evangelical_School_for_the_Deaf\" title=\"Evangelical School for the Deaf\">Evangelical School for the Deaf</a> (Puerto Rico)</li></ul>\n</div></td></tr></tbody></table></div>\n\n<!-- \nNewPP limit report\nParsed by mw1233\nCached time: 20180901210135\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.724 seconds\nReal time usage: 0.768 seconds\nPreprocessor visited node count: 3003/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 139861/2097152 bytes\nTemplate argument size: 103/2097152 bytes\nHighest expansion depth: 7/40\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 91526/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.375/10.000 seconds\nLua memory usage: 3.21 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  559.529      1 -total\n 95.43%  533.950      1 Template:Reflist\n 73.33%  410.287     51 Template:Cite_journal\n  4.55%   25.460      1 Template:Deaf_education\n  3.46%   19.366      2 Template:Navbox\n  2.66%   14.867      1 Template:Citation\n  1.55%    8.677      1 Template:Schools_for_the_deaf\n  0.46%    2.563      1 Template:Main_other\n  0.29%    1.648      1 Template:Column-width\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:315084-0!canonical and timestamp 20180901210135 and revision id 857610524\n -->\n</div>"},"langlinks":[{"lang":"ar","url":"https://ar.wikipedia.org/wiki/%D9%82%D8%B1%D8%A7%D8%A1%D8%A9_%D8%A7%D9%84%D8%B4%D9%81%D8%A7%D9%87","langname":"Arabic","autonym":"\u0627\u0644\u0639\u0631\u0628\u064a\u0629","*":"\u0642\u0631\u0627\u0621\u0629 \u0627\u0644\u0634\u0641\u0627\u0647"},{"lang":"da","url":"https://da.wikipedia.org/wiki/Mundafl%C3%A6sning","langname":"Danish","autonym":"dansk","*":"Mundafl\u00e6sning"},{"lang":"de","url":"https://de.wikipedia.org/wiki/Lippenlesen","langname":"German","autonym":"Deutsch","*":"Lippenlesen"},{"lang":"es","url":"https://es.wikipedia.org/wiki/Lectura_de_labios","langname":"Spanish","autonym":"espa\u00f1ol","*":"Lectura de labios"},{"lang":"eu","url":"https://eu.wikipedia.org/wiki/Ezpain_irakurketa","langname":"Basque","autonym":"euskara","*":"Ezpain irakurketa"},{"lang":"fa","url":"https://fa.wikipedia.org/wiki/%D9%84%D8%A8%E2%80%8C%D8%AE%D9%88%D8%A7%D9%86%DB%8C","langname":"Persian","autonym":"\u0641\u0627\u0631\u0633\u06cc","*":"\u0644\u0628\u200c\u062e\u0648\u0627\u0646\u06cc"},{"lang":"fr","url":"https://fr.wikipedia.org/wiki/Lecture_labiale","langname":"French","autonym":"fran\u00e7ais","*":"Lecture labiale"},{"lang":"he","url":"https://he.wikipedia.org/wiki/%D7%A7%D7%A8%D7%99%D7%90%D7%AA_%D7%A9%D7%A4%D7%AA%D7%99%D7%99%D7%9D","langname":"Hebrew","autonym":"\u05e2\u05d1\u05e8\u05d9\u05ea","*":"\u05e7\u05e8\u05d9\u05d0\u05ea \u05e9\u05e4\u05ea\u05d9\u05d9\u05dd"},{"lang":"hu","url":"https://hu.wikipedia.org/wiki/Sz%C3%A1jr%C3%B3l_olvas%C3%A1s","langname":"Hungarian","autonym":"magyar","*":"Sz\u00e1jr\u00f3l olvas\u00e1s"},{"lang":"nl","url":"https://nl.wikipedia.org/wiki/Spraakafzien","langname":"Dutch","autonym":"Nederlands","*":"Spraakafzien"},{"lang":"ja","url":"https://ja.wikipedia.org/wiki/%E8%AA%AD%E5%94%87%E8%A1%93","langname":"Japanese","autonym":"\u65e5\u672c\u8a9e","*":"\u8aad\u5507\u8853"},{"lang":"nn","url":"https://nn.wikipedia.org/wiki/Munnavlesing","langname":"Norwegian Nynorsk","autonym":"norsk nynorsk","*":"Munnavlesing"},{"lang":"pt","url":"https://pt.wikipedia.org/wiki/Leitura_labial","langname":"Portuguese","autonym":"portugu\u00eas","*":"Leitura labial"},{"lang":"ru","url":"https://ru.wikipedia.org/wiki/%D0%A7%D1%82%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BF%D0%BE_%D0%B3%D1%83%D0%B1%D0%B0%D0%BC","langname":"Russian","autonym":"\u0440\u0443\u0441\u0441\u043a\u0438\u0439","*":"\u0427\u0442\u0435\u043d\u0438\u0435 \u043f\u043e \u0433\u0443\u0431\u0430\u043c"},{"lang":"fi","url":"https://fi.wikipedia.org/wiki/Huuliltaluku","langname":"Finnish","autonym":"suomi","*":"Huuliltaluku"},{"lang":"uk","url":"https://uk.wikipedia.org/wiki/%D0%A7%D0%B8%D1%82%D0%B0%D0%BD%D0%BD%D1%8F_%D0%B7_%D0%B3%D1%83%D0%B1","langname":"Ukrainian","autonym":"\u0443\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430","*":"\u0427\u0438\u0442\u0430\u043d\u043d\u044f \u0437 \u0433\u0443\u0431"},{"lang":"zh","url":"https://zh.wikipedia.org/wiki/%E8%AF%BB%E5%94%87%E6%B3%95","langname":"Chinese","autonym":"\u4e2d\u6587","*":"\u8bfb\u5507\u6cd5"}],"categories":[{"sortkey":"","hidden":"","*":"CS1_maint:_Explicit_use_of_et_al."},{"sortkey":"","*":"Deaf_culture"},{"sortkey":"","*":"Human_communication"},{"sortkey":"","*":"Perception"},{"sortkey":"","*":"Audiology"},{"sortkey":"","*":"Education_for_the_deaf"}],"links":[{"ns":10,"exists":"","*":"Template:Deaf education"},{"ns":10,"exists":"","*":"Template:Schools for the deaf"},{"ns":0,"exists":"","*":"2001: A Space Odyssey"},{"ns":0,"exists":"","*":"Action on Hearing Loss"},{"ns":0,"exists":"","*":"Alabama Institute for the Deaf and Blind"},{"ns":0,"exists":"","*":"Alaska State School for the Deaf and Hard of Hearing"},{"ns":0,"exists":"","*":"Alexander Graham Bell School (Chicago, Illinois)"},{"ns":0,"exists":"","*":"American School for the Deaf"},{"ns":0,"exists":"","*":"Andrew Foster (educator)"},{"ns":0,"exists":"","*":"Arkansas School for the Deaf"},{"ns":0,"exists":"","*":"Atlanta Area School for the Deaf"},{"ns":0,"exists":"","*":"Auditory cortex"},{"ns":0,"exists":"","*":"Austine School"},{"ns":0,"exists":"","*":"Autism"},{"ns":0,"exists":"","*":"Automated Lip Reading"},{"ns":0,"exists":"","*":"Automatic speech recognition"},{"ns":0,"exists":"","*":"Bad Lip Reading"},{"ns":0,"exists":"","*":"Barbara Jordan High School"},{"ns":0,"exists":"","*":"Beverly School for the Deaf"},{"ns":0,"exists":"","*":"Bimodal bilingualism"},{"ns":0,"exists":"","*":"Biometric"},{"ns":0,"exists":"","*":"California School for the Deaf, Fremont"},{"ns":0,"exists":"","*":"California School for the Deaf, Riverside"},{"ns":0,"exists":"","*":"Central Institute for the Deaf"},{"ns":0,"exists":"","*":"Centre for Deaf Studies, Bristol"},{"ns":0,"exists":"","*":"Christian Mission for the Deaf"},{"ns":0,"exists":"","*":"Clarke Schools for Hearing and Speech"},{"ns":0,"exists":"","*":"Clayton Valli"},{"ns":0,"exists":"","*":"Co-articulation"},{"ns":0,"exists":"","*":"Cochlear implant"},{"ns":0,"exists":"","*":"Colorado School for the Deaf and Blind"},{"ns":0,"exists":"","*":"Connected speech"},{"ns":0,"exists":"","*":"Cued Speech"},{"ns":0,"exists":"","*":"Cued speech"},{"ns":0,"exists":"","*":"Deaf education"},{"ns":0,"exists":"","*":"Delaware School for the Deaf"},{"ns":0,"exists":"","*":"Detroit Day School for the Deaf"},{"ns":0,"exists":"","*":"Digital object identifier"},{"ns":0,"exists":"","*":"Dyslexia"},{"ns":0,"exists":"","*":"Edward Miner Gallaudet"},{"ns":0,"exists":"","*":"Evangelical School for the Deaf"},{"ns":0,"exists":"","*":"Executive function"},{"ns":0,"exists":"","*":"Facial animation"},{"ns":0,"exists":"","*":"Fingerspelling"},{"ns":0,"exists":"","*":"Florida School for the Deaf and Blind"},{"ns":0,"exists":"","*":"Forensic lipreading"},{"ns":0,"exists":"","*":"Fusiform face area"},{"ns":0,"exists":"","*":"Gallaudet University"},{"ns":0,"exists":"","*":"Georgia School for the Deaf"},{"ns":0,"exists":"","*":"Glottal consonants"},{"ns":0,"exists":"","*":"Hearing loss"},{"ns":0,"exists":"","*":"Heschl's gyrus"},{"ns":0,"exists":"","*":"Horace Mann School for the Deaf and Hard of Hearing"},{"ns":0,"exists":"","*":"Illinois School for the Deaf"},{"ns":0,"exists":"","*":"Indiana School for the Deaf"},{"ns":0,"exists":"","*":"Iowa School for the Deaf"},{"ns":0,"exists":"","*":"Jean Massieu"},{"ns":0,"exists":"","*":"Jerry L. White Center High School"},{"ns":0,"exists":"","*":"Kansas State School For the Deaf"},{"ns":0,"exists":"","*":"Kentucky School for the Deaf"},{"ns":0,"exists":"","*":"Laurent Clerc"},{"ns":0,"exists":"","*":"Lexington School and Center for the Deaf"},{"ns":0,"exists":"","*":"Louisiana School for the Deaf"},{"ns":0,"exists":"","*":"Manually coded English"},{"ns":0,"exists":"","*":"Marlton School"},{"ns":0,"exists":"","*":"Maryland School for the Deaf"},{"ns":0,"exists":"","*":"McGurk effect"},{"ns":0,"exists":"","*":"Minnesota State Academy for the Deaf"},{"ns":0,"exists":"","*":"Mississippi School for the Deaf"},{"ns":0,"exists":"","*":"Model Secondary School for the Deaf"},{"ns":0,"exists":"","*":"Moog Center for Deaf Education"},{"ns":0,"exists":"","*":"Motion capture"},{"ns":0,"exists":"","*":"Nasalisation"},{"ns":0,"exists":"","*":"National Technical Institute for the Deaf"},{"ns":0,"exists":"","*":"Naxal School for the Deaf"},{"ns":0,"exists":"","*":"Nebraska School for the Deaf"},{"ns":0,"exists":"","*":"New Mexico School for the Deaf"},{"ns":0,"exists":"","*":"New York School for the Deaf"},{"ns":0,"exists":"","*":"New York State School for the Deaf"},{"ns":0,"exists":"","*":"North Carolina School for the Deaf"},{"ns":0,"exists":"","*":"North Dakota School for the Deaf"},{"ns":0,"exists":"","*":"Occupational hearing loss"},{"ns":0,"exists":"","*":"Ohio School for the Deaf"},{"ns":0,"exists":"","*":"Oklahoma School for the Deaf"},{"ns":0,"exists":"","*":"Oralism"},{"ns":0,"exists":"","*":"Oregon School for the Deaf"},{"ns":0,"exists":"","*":"Pennsylvania School for the Deaf"},{"ns":0,"exists":"","*":"Perceptual narrowing"},{"ns":0,"exists":"","*":"Phoneme"},{"ns":0,"exists":"","*":"Phonetics"},{"ns":0,"exists":"","*":"Phonics"},{"ns":0,"exists":"","*":"Phonology"},{"ns":0,"exists":"","*":"Pragmatics"},{"ns":0,"exists":"","*":"Presbycusis"},{"ns":0,"exists":"","*":"Project Insight"},{"ns":0,"exists":"","*":"PubMed Central"},{"ns":0,"exists":"","*":"PubMed Identifier"},{"ns":0,"exists":"","*":"Reading disability"},{"ns":0,"exists":"","*":"Rochester School for the Deaf"},{"ns":0,"exists":"","*":"Sam Loyd"},{"ns":0,"exists":"","*":"Scranton School for Deaf and Hard-of-Hearing Children"},{"ns":0,"exists":"","*":"Scranton State School for the Deaf"},{"ns":0,"exists":"","*":"Second International Congress on Education of the Deaf"},{"ns":0,"exists":"","*":"Sign language"},{"ns":0,"exists":"","*":"Simultaneous communication"},{"ns":0,"exists":"","*":"Sophia Alcorn"},{"ns":0,"exists":"","*":"South Carolina School for the Deaf and Blind"},{"ns":0,"exists":"","*":"South Dakota School for the Deaf"},{"ns":0,"exists":"","*":"Specific Language Impairment"},{"ns":0,"exists":"","*":"Speech"},{"ns":0,"exists":"","*":"Speech perception"},{"ns":0,"exists":"","*":"Speech synthesis"},{"ns":0,"exists":"","*":"St. Rita School for the Deaf"},{"ns":0,"exists":"","*":"Steve Omohundro"},{"ns":0,"exists":"","*":"Summit Speech School"},{"ns":0,"exists":"","*":"Superior temporal sulcus"},{"ns":0,"exists":"","*":"T. H. Rogers School"},{"ns":0,"exists":"","*":"Tennessee School for the Deaf"},{"ns":0,"exists":"","*":"Texas School for the Deaf"},{"ns":0,"exists":"","*":"The Learning Center for the Deaf"},{"ns":0,"exists":"","*":"Total communication"},{"ns":0,"exists":"","*":"Unvoiced"},{"ns":0,"exists":"","*":"Virginia School for the Deaf and the Blind"},{"ns":0,"exists":"","*":"Viseme"},{"ns":0,"exists":"","*":"Visual area MT"},{"ns":0,"exists":"","*":"Voiced"},{"ns":0,"exists":"","*":"Vowel"},{"ns":0,"exists":"","*":"West Tennessee School for the Deaf"},{"ns":0,"exists":"","*":"West Virginia Schools for the Deaf and Blind"},{"ns":0,"exists":"","*":"Western Pennsylvania School for the Deaf"},{"ns":0,"exists":"","*":"Williams syndrome"},{"ns":0,"exists":"","*":"Willie Ross School for the Deaf"},{"ns":0,"exists":"","*":"Wisconsin School for the Deaf"},{"ns":0,"exists":"","*":"Working memory"},{"ns":0,"exists":"","*":"Wright-Humason School for the Deaf"},{"ns":0,"exists":"","*":"Wyoming School for the Deaf"},{"ns":0,"*":"Eastern North Carolina School for the Deaf"},{"ns":11,"exists":"","*":"Template talk:Deaf education"},{"ns":11,"exists":"","*":"Template talk:Schools for the deaf"},{"ns":14,"exists":"","*":"Category:CS1 maint: Explicit use of et al."}],"templates":[{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Column-width"},{"ns":10,"exists":"","*":"Template:Cite journal"},{"ns":10,"exists":"","*":"Template:Citation"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:Deaf education"},{"ns":10,"exists":"","*":"Template:Navbox"},{"ns":10,"exists":"","*":"Template:Schools for the deaf"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"},{"ns":828,"exists":"","*":"Module:Navbox"},{"ns":828,"exists":"","*":"Module:Navbar"},{"ns":828,"exists":"","*":"Module:Arguments"}],"images":["Lock-green.svg","Sam_Loyd_lipreading_puzzle.jpg"],"externallinks":["//doi.org/10.1080/13682820802090281","//www.ncbi.nlm.nih.gov/pubmed/18821117","//doi.org/10.1044/jshr.1202.423","//www.ncbi.nlm.nih.gov/pubmed/5808871","//doi.org/10.1044/jshr.2504.600","//www.ncbi.nlm.nih.gov/pubmed/7162162","//www.ncbi.nlm.nih.gov/pmc/articles/PMC3715375","//doi.org/10.3766/jaaa.21.3.4","//www.ncbi.nlm.nih.gov/pubmed/20211120","//doi.org/10.3758/s13414-011-0152-4","//www.ncbi.nlm.nih.gov/pubmed/21842332","//doi.org/10.1037/0096-1523.30.5.873","//www.ncbi.nlm.nih.gov/pubmed/15462626","//www.ncbi.nlm.nih.gov/pmc/articles/PMC4610295","//doi.org/10.1044/2015_JSLHR-H-14-0360","//www.ncbi.nlm.nih.gov/pubmed/25863923","//www.ncbi.nlm.nih.gov/pmc/articles/PMC4499841","//doi.org/10.3389/fpsyg.2015.00878","//www.ncbi.nlm.nih.gov/pubmed/26217249","//doi.org/10.1121/1.420402","//www.ncbi.nlm.nih.gov/pubmed/9407662","//doi.org/10.1044/2013_JSLHR-H-12-0273","//www.ncbi.nlm.nih.gov/pubmed/24129010","//www.ncbi.nlm.nih.gov/pmc/articles/PMC3119632","//doi.org/10.1044/1092-4388(2009/08-0137)","//www.ncbi.nlm.nih.gov/pubmed/19717657","//doi.org/10.1126/science.897687","//www.ncbi.nlm.nih.gov/pubmed/897687","//doi.org/10.1016/0010-0285(76)90018-9","//doi.org/10.1002/dev.20032","//www.ncbi.nlm.nih.gov/pubmed/15549685","//www.ncbi.nlm.nih.gov/pubmed/9136265","//www.ncbi.nlm.nih.gov/pmc/articles/PMC2705579","//doi.org/10.1073/pnas.0904134106","//www.ncbi.nlm.nih.gov/pubmed/19541648","//doi.org/10.1016/j.tics.2009.08.004","//www.ncbi.nlm.nih.gov/pubmed/19748305","//www.ncbi.nlm.nih.gov/pmc/articles/PMC3277111","//doi.org/10.1073/pnas.1114783109","//www.ncbi.nlm.nih.gov/pubmed/22307596","//doi.org/10.1080/13682820801997189","//www.ncbi.nlm.nih.gov/pmc/articles/PMC2612128","//doi.org/10.1016/j.jecp.2008.08.002","//www.ncbi.nlm.nih.gov/pubmed/18829049","//www.ncbi.nlm.nih.gov/pmc/articles/PMC4920223","//doi.org/10.1044/1092-4388(2012/12-0039)","//www.ncbi.nlm.nih.gov/pubmed/23275416","//www.ncbi.nlm.nih.gov/pmc/articles/PMC4475441","//doi.org/10.1016/j.cortex.2015.03.006","//www.ncbi.nlm.nih.gov/pubmed/25890390","//www.ncbi.nlm.nih.gov/pmc/articles/PMC2606792","//doi.org/10.1098/rstb.2007.2155","//www.ncbi.nlm.nih.gov/pubmed/17827105","//doi.org/10.1121/1.1907309","//doi.org/10.1111/coa.12607","//doi.org/10.2188/jea.JE20140147","//doi.org/10.1111/j.1469-7610.2007.01766.x","//www.ncbi.nlm.nih.gov/pubmed/17683453","//www.ncbi.nlm.nih.gov/pmc/articles/PMC3169706","//doi.org/10.1111/j.1467-8624.2011.01619.x","//www.ncbi.nlm.nih.gov/pubmed/21790542","//www.ncbi.nlm.nih.gov/pmc/articles/PMC4021198","//doi.org/10.3389/fpsyg.2014.00397","//www.ncbi.nlm.nih.gov/pubmed/24847297","//doi.org/10.1016/s0028-3932(01)00208-1","//www.ncbi.nlm.nih.gov/pubmed/11931944","//www.ncbi.nlm.nih.gov/pmc/articles/PMC4033223","//doi.org/10.3389/fpsyg.2014.00422","//www.ncbi.nlm.nih.gov/pubmed/24904454","//doi.org/10.1080/02699200500266745","//doi.org/10.1017/S0261444815000348","//doi.org/10.3758/bf03205546","//doi.org/10.1097/00003446-200504000-00004","//doi.org/10.1093/deafed/enm020","//doi.org/10.1016/j.jecp.2010.04.011","//doi.org/10.1044/jshr.2502.262","//www.ncbi.nlm.nih.gov/pmc/articles/PMC4111351","//doi.org/10.1177/1084713810375567","https://link.springer.com/article/10.1023/B:JADD.0000006002.82367.4f#/page-1","//doi.org/10.1023/B:JADD.0000006002.82367.4f","//doi.org/10.1126/science.276.5312.593","//www.ncbi.nlm.nih.gov/pubmed/9110978","//www.ncbi.nlm.nih.gov/pmc/articles/PMC4248808","//doi.org/10.3389/fnins.2014.00386","//www.ncbi.nlm.nih.gov/pubmed/25520611","//www.ncbi.nlm.nih.gov/pmc/articles/PMC2896890","//doi.org/10.1093/cercor/bhl147","//www.ncbi.nlm.nih.gov/pubmed/17218482","//doi.org/10.1016/s0926-6410(01)00054-4","//www.ncbi.nlm.nih.gov/pubmed/11587893","http://doi.org/10.1016/j.bandl.2013.03.002","//doi.org/10.1016/j.bandl.2013.03.002","//doi.org/10.1016/0304-3940(91)90914-f","//www.ncbi.nlm.nih.gov/pmc/articles/PMC545853","//doi.org/10.1073/pnas.0408949102","//www.ncbi.nlm.nih.gov/pmc/articles/PMC3120928","//doi.org/10.1002/hbm.21139","//www.ncbi.nlm.nih.gov/pubmed/20853377","//www.ncbi.nlm.nih.gov/pmc/articles/PMC2394569","//doi.org/10.1016/j.neuropsychologia.2007.11.026","//www.ncbi.nlm.nih.gov/pubmed/18249420","http://www.huffingtonpost.com/2012/01/16/babies-learning-to-talk_n_1209219.html","http://www.handsandvoices.org/articles/research/v9-2_marschark.htm","http://www.nidirect.gov.uk/communication-support-for-deaf-people","http://www.lipspeaker.co.uk","http://www.nuffieldfoundation.org/reading-and-dyslexia-deaf-children","http://jslhr.pubs.asha.org/article.aspx?articleid=1795779","https://www.lipreading.org/lipreading-","https://www.actiononhearingloss.org.uk/notjustlipservice.aspx","http://www-bcf.usc.edu/~rwalker/Walker/Publications_files/1996_CohenWalker&Massaro_VisualSpeech.pdf","http://www.diva-portal.org/smash/record.jsf?pid=diva2:318099&dswid=2041","https://www.uea.ac.uk/computing/visual-speech-synthesis","http://www.cnet.com/news/lip-reading-computer-can-distinguish-languages/","https://www.youtube.com/watch?v=Tu2vInqqHX8","https://www.theguardian.com/business/2016/apr/24/the-innovators-can-computers-be-taught-to-lip-read-artificial-intelligence","https://www.newscientist.com/article/2113299-googles-deepmind-ai-can-lip-read-tv-shows-better-than-a-pro/","https://www.researchgate.net/profile/David_Bodoff/publication/234819242_An_improved_automatic_lipreading_system_to_enhance_speech_recognition/links/5628b96008ae04c2aeaeb404.pdf","http://www.asel.udel.edu/icslp/cdrom/vol1/954/a954.pdf","http://www.planetbiometrics.com-article-details-i-2250","https://en.wiktionary.org/wiki/homophene","http://lipspeaking.co.uk/","http://seethesound.org/visual_phonics.html","http://limpingchicken.com/2016/04/05/molly-berry-what-lipreading-classes-can-offer-deaf-people/","http://atlalipreading.org.uk","https://www.technologyreview.com/s/602949/ai-has-beaten-humans-at-lip-reading/","https://books.google.com/books/about/Hearing_by_Eye.html?id=styYQgAACAAJ&redir_esc=y","https://books.google.com/books/about/Hearing_by_Eye_II.html?id=SOAQe97Fo04C&redir_esc=y","https://www.questia.com/library/78558929/speech-perception-by-ear-and-eye-a-paradigm-for-psychological","https://www.actiononhearingloss.org.uk/~/media/Documents/Policy%20research%20and%20influencing/Research/Not%20just%20lip%20service/Not%20just%20lip%20service_Full%20report_FINAL_A0639_9.ashx","http://www.ssc.education.ed.ac.uk/courses/deaf/ddec05f.html","http://www.actiononhearingloss.org.uk/~/media/Documents/Scotland/Lipreading%20Classes%20in%20Scotland%20%20the%20way%20forward.ashx","http://avisa.loria.fr","https://www.ucl.ac.uk/dcal/projects/tabs/images/speechreading"],"sections":[{"toclevel":1,"level":"2","line":"Process","number":"1","index":"1","fromtitle":"Lip_reading","byteoffset":898,"anchor":"Process"},{"toclevel":2,"level":"3","line":"Phonemes and visemes","number":"1.1","index":"2","fromtitle":"Lip_reading","byteoffset":1738,"anchor":"Phonemes_and_visemes"},{"toclevel":2,"level":"3","line":"Co-articulation","number":"1.2","index":"3","fromtitle":"Lip_reading","byteoffset":3504,"anchor":"Co-articulation"},{"toclevel":2,"level":"3","line":"How can it 'work' with so few visemes?","number":"1.3","index":"4","fromtitle":"Lip_reading","byteoffset":4165,"anchor":"How_can_it_'work'_with_so_few_visemes?"},{"toclevel":2,"level":"3","line":"Variation in readability and skill","number":"1.4","index":"5","fromtitle":"Lip_reading","byteoffset":5232,"anchor":"Variation_in_readability_and_skill"},{"toclevel":1,"level":"2","line":"Lipreading and language learning in hearing infants and children","number":"2","index":"6","fromtitle":"Lip_reading","byteoffset":9300,"anchor":"Lipreading_and_language_learning_in_hearing_infants_and_children"},{"toclevel":2,"level":"3","line":"The first few months","number":"2.1","index":"7","fromtitle":"Lip_reading","byteoffset":9370,"anchor":"The_first_few_months"},{"toclevel":2,"level":"3","line":"The next six months; a role in learning a native language","number":"2.2","index":"8","fromtitle":"Lip_reading","byteoffset":11646,"anchor":"The_next_six_months;_a_role_in_learning_a_native_language"},{"toclevel":2,"level":"3","line":"Early language production: one to two years","number":"2.3","index":"9","fromtitle":"Lip_reading","byteoffset":13385,"anchor":"Early_language_production:_one_to_two_years"},{"toclevel":2,"level":"3","line":"In childhood","number":"2.4","index":"10","fromtitle":"Lip_reading","byteoffset":15206,"anchor":"In_childhood"},{"toclevel":1,"level":"2","line":"In hearing adults: lifespan considerations","number":"3","index":"11","fromtitle":"Lip_reading","byteoffset":17619,"anchor":"In_hearing_adults:_lifespan_considerations"},{"toclevel":2,"level":"3","line":"In specific (hearing) populations","number":"3.1","index":"12","fromtitle":"Lip_reading","byteoffset":20365,"anchor":"In_specific_(hearing)_populations"},{"toclevel":1,"level":"2","line":"Deafness","number":"4","index":"13","fromtitle":"Lip_reading","byteoffset":23323,"anchor":"Deafness"},{"toclevel":1,"level":"2","line":"Teaching and training","number":"5","index":"14","fromtitle":"Lip_reading","byteoffset":29312,"anchor":"Teaching_and_training"},{"toclevel":2,"level":"3","line":"Tests","number":"5.1","index":"15","fromtitle":"Lip_reading","byteoffset":31205,"anchor":"Tests"},{"toclevel":1,"level":"2","line":"Lipreading and lip-speaking by machine","number":"6","index":"16","fromtitle":"Lip_reading","byteoffset":31665,"anchor":"Lipreading_and_lip-speaking_by_machine"},{"toclevel":1,"level":"2","line":"The brain","number":"7","index":"17","fromtitle":"Lip_reading","byteoffset":35412,"anchor":"The_brain"},{"toclevel":1,"level":"2","line":"References","number":"8","index":"18","fromtitle":"Lip_reading","byteoffset":40630,"anchor":"References"},{"toclevel":2,"level":"3","line":"Bibliography","number":"8.1","index":"19","fromtitle":"Lip_reading","byteoffset":40674,"anchor":"Bibliography"},{"toclevel":1,"level":"2","line":"External links","number":"9","index":"20","fromtitle":"Lip_reading","byteoffset":41600,"anchor":"External_links"}],"parsewarnings":[],"displaytitle":"Lip reading","iwlinks":[],"properties":[{"name":"wikibase_item","*":"Q1069953"}]}}