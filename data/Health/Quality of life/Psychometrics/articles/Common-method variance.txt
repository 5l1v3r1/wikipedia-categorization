In applied statistics, (e.g., applied to the social sciences and psychometrics), common-method variance  (CMV) is the spurious "variance that is attributable to the measurement method rather than to the constructs the measures are assumed to represent"  or equivalently as "systematic error variance shared among variables measured with and introduced as a function of the same method and/or source".  For example, an electronic survey method might influence results for those who might be unfamiliar with an electronic survey interface differently than for those who might be familiar. If measures are affected by CMV or common-method bias, the intercorrelations among them can be inflated or deflated depending upon several factors.  Although it is sometimes assumed that CMV affects all variables, evidence suggests that whether or not the correlation between two variables is affected by CMV is a function of both the method and the particular constructs being measured.  Several ex ante remedies exist that help to avoid or minimize possible common method variance. Important remedies have been compiled and discussed by Chang et al. (2010), Lindell & Whitney (2001) and Podsakoff et al. (2003).    Using simulated data sets, Richardson et al. (2009) investigate three ex post techniques to test for common method variance: the correlational marker technique, the confirmatory factor analysis (CFA) marker technique, and the unmeasured latent method construct (ULMC) technique. Only the CFA marker technique turns out to provide some value, whereas the commonly used Harman test does not turn out to provide such value.  A comprehensive example of this technique has been demonstrated by Williams et al. (2010).  Kock (2015) discusses a full collinearity test that is successful in the identification of common method bias with a model that nevertheless passes standard convergent and discriminant validity assessment criteria based on a CFA.    