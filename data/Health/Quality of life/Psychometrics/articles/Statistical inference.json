{"parse":{"title":"Statistical inference","pageid":27577,"revid":846448830,"text":{"*":"<div class=\"mw-parser-output\"><div role=\"note\" class=\"hatnote navigation-not-searchable\">Not to be confused with <a href=\"/wiki/Statistical_interference\" title=\"Statistical interference\">Statistical interference</a>.</div>\n<p><b>Statistical inference</b> is the process of using <a href=\"/wiki/Data_analysis\" title=\"Data analysis\">data analysis</a> to deduce properties of an underlying <a href=\"/wiki/Probability_distribution\" title=\"Probability distribution\">probability distribution</a>.<sup id=\"cite_ref-Oxford_1-0\" class=\"reference\"><a href=\"#cite_note-Oxford-1\">&#91;1&#93;</a></sup> Inferential statistical analysis infers properties of a <a href=\"/wiki/Statistical_population\" title=\"Statistical population\">population</a>, for example by testing hypotheses and deriving estimates.  It is assumed that the observed data set is <a href=\"/wiki/Sampling_(statistics)\" title=\"Sampling (statistics)\">sampled</a> from a larger population.\n</p><p>Inferential statistics can be contrasted with <a href=\"/wiki/Descriptive_statistics\" title=\"Descriptive statistics\">descriptive statistics</a>. Descriptive statistics is solely concerned with properties of the observed data, and it does not rest on the assumption that the data come from a larger population.\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Introduction\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Introduction</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Models_and_assumptions\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Models and assumptions</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-3\"><a href=\"#Degree_of_models/assumptions\"><span class=\"tocnumber\">2.1</span> <span class=\"toctext\">Degree of models/assumptions</span></a></li>\n<li class=\"toclevel-2 tocsection-4\"><a href=\"#Importance_of_valid_models/assumptions\"><span class=\"tocnumber\">2.2</span> <span class=\"toctext\">Importance of valid models/assumptions</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-5\"><a href=\"#Approximate_distributions\"><span class=\"tocnumber\">2.2.1</span> <span class=\"toctext\">Approximate distributions</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-2 tocsection-6\"><a href=\"#Randomization-based_models\"><span class=\"tocnumber\">2.3</span> <span class=\"toctext\">Randomization-based models</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-7\"><a href=\"#Model-based_analysis_of_randomized_experiments\"><span class=\"tocnumber\">2.3.1</span> <span class=\"toctext\">Model-based analysis of randomized experiments</span></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-8\"><a href=\"#Paradigms_for_inference\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Paradigms for inference</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-9\"><a href=\"#Frequentist_inference\"><span class=\"tocnumber\">3.1</span> <span class=\"toctext\">Frequentist inference</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-10\"><a href=\"#Examples_of_frequentist_inference\"><span class=\"tocnumber\">3.1.1</span> <span class=\"toctext\">Examples of frequentist inference</span></a></li>\n<li class=\"toclevel-3 tocsection-11\"><a href=\"#Frequentist_inference,_objectivity,_and_decision_theory\"><span class=\"tocnumber\">3.1.2</span> <span class=\"toctext\">Frequentist inference, objectivity, and decision theory</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-2 tocsection-12\"><a href=\"#Bayesian_inference\"><span class=\"tocnumber\">3.2</span> <span class=\"toctext\">Bayesian inference</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-13\"><a href=\"#Examples_of_Bayesian_inference\"><span class=\"tocnumber\">3.2.1</span> <span class=\"toctext\">Examples of Bayesian inference</span></a></li>\n<li class=\"toclevel-3 tocsection-14\"><a href=\"#Bayesian_inference,_subjectivity_and_decision_theory\"><span class=\"tocnumber\">3.2.2</span> <span class=\"toctext\">Bayesian inference, subjectivity and decision theory</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-2 tocsection-15\"><a href=\"#AIC-based_inference\"><span class=\"tocnumber\">3.3</span> <span class=\"toctext\">AIC-based inference</span></a></li>\n<li class=\"toclevel-2 tocsection-16\"><a href=\"#Other_paradigms_for_inference\"><span class=\"tocnumber\">3.4</span> <span class=\"toctext\">Other paradigms for inference</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-17\"><a href=\"#Minimum_description_length\"><span class=\"tocnumber\">3.4.1</span> <span class=\"toctext\">Minimum description length</span></a></li>\n<li class=\"toclevel-3 tocsection-18\"><a href=\"#Fiducial_inference\"><span class=\"tocnumber\">3.4.2</span> <span class=\"toctext\">Fiducial inference</span></a></li>\n<li class=\"toclevel-3 tocsection-19\"><a href=\"#Structural_inference\"><span class=\"tocnumber\">3.4.3</span> <span class=\"toctext\">Structural inference</span></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-20\"><a href=\"#Inference_topics\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Inference topics</span></a></li>\n<li class=\"toclevel-1 tocsection-21\"><a href=\"#See_also\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-22\"><a href=\"#Notes\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">Notes</span></a></li>\n<li class=\"toclevel-1 tocsection-23\"><a href=\"#Citations\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">Citations</span></a></li>\n<li class=\"toclevel-1 tocsection-24\"><a href=\"#References\"><span class=\"tocnumber\">8</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-25\"><a href=\"#Further_reading\"><span class=\"tocnumber\">9</span> <span class=\"toctext\">Further reading</span></a></li>\n<li class=\"toclevel-1 tocsection-26\"><a href=\"#External_links\"><span class=\"tocnumber\">10</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"Introduction\">Introduction</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=1\" title=\"Edit section: Introduction\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Statistical inference makes propositions about a population, using data drawn from the population with some form of <a href=\"/wiki/Sampling_(statistics)\" title=\"Sampling (statistics)\">sampling</a>. Given a hypothesis about a population, for which we wish to draw inferences, statistical inference consists of (first) <a href=\"/wiki/Model_selection\" title=\"Model selection\">selecting</a> a <a href=\"/wiki/Statistical_model\" title=\"Statistical model\">statistical model</a> of the process that generates the data and (second) deducing propositions from the model.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (December 2016)\">citation needed</span></a></i>&#93;</sup>\n</p><p>Konishi &amp; Kitagawa state, \"The majority of the problems in statistical inference can be considered to be problems related to statistical modeling\".<sup id=\"cite_ref-2\" class=\"reference\"><a href=\"#cite_note-2\">&#91;2&#93;</a></sup>  Relatedly, <a href=\"/wiki/David_Cox_(statistician)\" title=\"David Cox (statistician)\">Sir David Cox</a> has said, \"How [the] translation from subject-matter problem to statistical model is done is often the most critical part of an analysis\".<sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">&#91;3&#93;</a></sup>\n</p><p>The <a href=\"/wiki/Logical_consequence\" title=\"Logical consequence\">conclusion</a> of a statistical inference is a statistical <a href=\"/wiki/Proposition\" title=\"Proposition\">proposition</a>.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (February 2012)\">citation needed</span></a></i>&#93;</sup> Some common forms of statistical proposition are the following:\n</p>\n<ul><li>a <a href=\"/wiki/Point_estimate\" class=\"mw-redirect\" title=\"Point estimate\">point estimate</a>, i.e. a particular value that best approximates some parameter of interest;</li>\n<li>an <a href=\"/wiki/Interval_estimate\" class=\"mw-redirect\" title=\"Interval estimate\">interval estimate</a>, e.g. a <a href=\"/wiki/Confidence_interval\" title=\"Confidence interval\">confidence interval</a> (or set estimate), i.e. an interval constructed using a dataset drawn from a population so that, under repeated sampling of such datasets, such intervals would contain the true parameter value with the <a href=\"/wiki/Frequency_probability\" class=\"mw-redirect\" title=\"Frequency probability\">probability</a> at the stated <a href=\"/wiki/Confidence_level\" class=\"mw-redirect\" title=\"Confidence level\">confidence level</a>;</li>\n<li>a <a href=\"/wiki/Credible_intervals\" class=\"mw-redirect\" title=\"Credible intervals\">credible interval</a>, i.e. a set of values containing, for example, 95% of posterior belief;</li>\n<li>rejection of a <a href=\"/wiki/Statistical_hypothesis_testing\" title=\"Statistical hypothesis testing\">hypothesis</a>;<sup id=\"cite_ref-4\" class=\"reference\"><a href=\"#cite_note-4\">&#91;a&#93;</a></sup></li>\n<li><a href=\"/wiki/Cluster_analysis\" title=\"Cluster analysis\">clustering</a> or <a href=\"/wiki/Statistical_classification\" title=\"Statistical classification\">classification</a> of data points into groups.</li></ul>\n<h2><span class=\"mw-headline\" id=\"Models_and_assumptions\">Models and assumptions</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=2\" title=\"Edit section: Models and assumptions\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">Main articles: <a href=\"/wiki/Statistical_model\" title=\"Statistical model\">Statistical model</a> and <a href=\"/wiki/Statistical_assumptions\" class=\"mw-redirect\" title=\"Statistical assumptions\">Statistical assumptions</a></div>\n<p>Any statistical inference requires some assumptions. A <b>statistical model</b> is a set of assumptions concerning the generation of the observed data and similar data. Descriptions of statistical models usually emphasize the role of population quantities of interest, about which we wish to draw inference.<sup id=\"cite_ref-Cox2006_5-0\" class=\"reference\"><a href=\"#cite_note-Cox2006-5\">&#91;4&#93;</a></sup> Descriptive statistics are typically used as a preliminary step before more formal inferences are drawn.<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;5&#93;</a></sup>\n</p>\n<h3><span id=\"Degree_of_models.2Fassumptions\"></span><span class=\"mw-headline\" id=\"Degree_of_models/assumptions\">Degree of models/assumptions</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=3\" title=\"Edit section: Degree of models/assumptions\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Statisticians distinguish between three levels of modeling assumptions;\n</p>\n<ul><li><b><a href=\"/wiki/Parametric_model\" title=\"Parametric model\">Fully parametric</a></b>: The probability distributions describing the data-generation process are assumed to be fully described by a family of probability distributions involving only a finite number of unknown parameters.<sup id=\"cite_ref-Cox2006_5-1\" class=\"reference\"><a href=\"#cite_note-Cox2006-5\">&#91;4&#93;</a></sup> For example, one may assume that the distribution of population values is truly Normal, with unknown mean and variance, and that datasets are generated by <a href=\"/wiki/Simple_random_sample\" title=\"Simple random sample\">'simple' random sampling</a>. The family of <a href=\"/wiki/Generalized_linear_model#Model_components\" title=\"Generalized linear model\">generalized linear models</a> is a widely used and flexible class of parametric models.</li>\n<li><b><a href=\"/wiki/Nonparametric_statistics#Non-parametric_models\" title=\"Nonparametric statistics\">Non-parametric</a></b>: The assumptions made about the process generating the data are much less than in parametric statistics and may be minimal.<sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">&#91;6&#93;</a></sup> For example, every continuous probability distribution has a median, which may be estimated using the sample median or the <a href=\"/wiki/Hodges%E2%80%93Lehmann_estimator\" title=\"Hodges\u2013Lehmann estimator\">Hodges\u2013Lehmann\u2013Sen estimator</a>, which has good properties when the data arise from simple random sampling.</li>\n<li><b><a href=\"/wiki/Semiparametric_model\" title=\"Semiparametric model\">Semi-parametric</a></b>: This term typically implies assumptions 'in between' fully and non-parametric approaches. For example, one may assume that a population distribution has a finite mean. Furthermore, one may assume that the mean response level in the population depends in a truly linear manner on some covariate (a parametric assumption) but not make any parametric assumption describing the variance around that mean (i.e. about the presence or possible form of any <a href=\"/wiki/Heteroscedasticity\" title=\"Heteroscedasticity\">heteroscedasticity</a>). More generally, semi-parametric models can often be separated into 'structural' and 'random variation' components. One component is treated parametrically and the other non-parametrically. The well-known <a href=\"/wiki/Cox_model\" class=\"mw-redirect\" title=\"Cox model\">Cox model</a> is a set of semi-parametric assumptions.</li></ul>\n<h3><span id=\"Importance_of_valid_models.2Fassumptions\"></span><span class=\"mw-headline\" id=\"Importance_of_valid_models/assumptions\">Importance of valid models/assumptions</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=4\" title=\"Edit section: Importance of valid models/assumptions\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Whatever level of assumption is made, correctly calibrated inference in general requires these assumptions to be correct; i.e. that the data-generating mechanisms really have been correctly specified.\n</p><p>Incorrect assumptions of <a href=\"/wiki/Simple_random_sample\" title=\"Simple random sample\">'simple' random sampling</a> can invalidate statistical inference.<sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">&#91;7&#93;</a></sup> More complex semi- and fully parametric assumptions are also cause for concern. For example, incorrectly assuming the Cox model can in some cases lead to faulty conclusions.<sup id=\"cite_ref-9\" class=\"reference\"><a href=\"#cite_note-9\">&#91;8&#93;</a></sup> Incorrect assumptions of Normality in the population also invalidates some forms of regression-based inference.<sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">&#91;9&#93;</a></sup> The use of <b>any</b> parametric model is viewed skeptically by most experts in sampling human populations:  \"most sampling statisticians, when they deal with confidence intervals at all, limit themselves to statements about [estimators] based on very large samples, where the central limit theorem ensures that these [estimators] will have distributions that are nearly normal.\"<sup id=\"cite_ref-Brewer_11-0\" class=\"reference\"><a href=\"#cite_note-Brewer-11\">&#91;10&#93;</a></sup> In particular, a normal distribution \"would be a totally unrealistic and catastrophically unwise assumption to make if we were dealing with any kind of economic population.\"<sup id=\"cite_ref-Brewer_11-1\" class=\"reference\"><a href=\"#cite_note-Brewer-11\">&#91;10&#93;</a></sup> Here, the central limit theorem states that the distribution of the sample mean \"for very large samples\" is approximately normally distributed, if the distribution is not heavy tailed.\n</p>\n<h4><span class=\"mw-headline\" id=\"Approximate_distributions\">Approximate distributions</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=5\" title=\"Edit section: Approximate distributions\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">Main articles: <a href=\"/wiki/Statistical_distance\" title=\"Statistical distance\">Statistical distance</a>, <a href=\"/wiki/Asymptotic_theory_(statistics)\" title=\"Asymptotic theory (statistics)\">Asymptotic theory (statistics)</a>, and <a href=\"/wiki/Approximation_theory\" title=\"Approximation theory\">Approximation theory</a></div>\n<p>Given the difficulty in specifying exact distributions of sample statistics, many methods have been developed for approximating these.\n</p><p>With finite samples, <a href=\"/wiki/Approximation_theory\" title=\"Approximation theory\">approximation results</a> measure how close a limiting distribution approaches the statistic's <a href=\"/wiki/Sample_distribution\" class=\"mw-redirect\" title=\"Sample distribution\">sample distribution</a>: For example, with 10,000 independent samples the <a href=\"/wiki/Normal_distribution\" title=\"Normal distribution\">normal distribution</a> approximates (to two digits of accuracy) the distribution of the <a href=\"/wiki/Sample_mean\" class=\"mw-redirect\" title=\"Sample mean\">sample mean</a> for many population distributions, by the <a href=\"/wiki/Berry%E2%80%93Esseen_theorem\" title=\"Berry\u2013Esseen theorem\">Berry\u2013Esseen theorem</a>.<sup id=\"cite_ref-JHJ_12-0\" class=\"reference\"><a href=\"#cite_note-JHJ-12\">&#91;11&#93;</a></sup>\nYet for many practical purposes, the normal approximation provides a good approximation to the sample-mean's distribution when there are 10 (or more) independent samples, according to simulation studies and statisticians' experience.<sup id=\"cite_ref-JHJ_12-1\" class=\"reference\"><a href=\"#cite_note-JHJ-12\">&#91;11&#93;</a></sup> Following Kolmogorov's work in the 1950s, advanced statistics uses <a href=\"/wiki/Approximation_theory\" title=\"Approximation theory\">approximation theory</a> and <a href=\"/wiki/Functional_analysis\" title=\"Functional analysis\">functional analysis</a> to quantify the error of approximation. In this approach, the <a href=\"/wiki/Metric_geometry\" class=\"mw-redirect\" title=\"Metric geometry\">metric geometry</a> of <a href=\"/wiki/Probability_distribution\" title=\"Probability distribution\">probability distributions</a> is studied; this approach quantifies approximation error with, for example, the <a href=\"/wiki/Kullback%E2%80%93Leibler_divergence\" title=\"Kullback\u2013Leibler divergence\">Kullback\u2013Leibler divergence</a>, <a href=\"/wiki/Bregman_divergence\" title=\"Bregman divergence\">Bregman divergence</a>, and the <a href=\"/wiki/Hellinger_distance\" title=\"Hellinger distance\">Hellinger distance</a>.<sup id=\"cite_ref-13\" class=\"reference\"><a href=\"#cite_note-13\">&#91;12&#93;</a></sup><sup id=\"cite_ref-14\" class=\"reference\"><a href=\"#cite_note-14\">&#91;13&#93;</a></sup><sup id=\"cite_ref-15\" class=\"reference\"><a href=\"#cite_note-15\">&#91;14&#93;</a></sup>\n</p><p>With indefinitely large samples, <a href=\"/wiki/Asymptotic_theory_(statistics)\" title=\"Asymptotic theory (statistics)\">limiting results</a> like the <a href=\"/wiki/Central_limit_theorem\" title=\"Central limit theorem\">central limit theorem</a> describe the sample statistic's limiting distribution, if one exists. Limiting results are not statements about finite samples, and indeed are irrelevant to finite samples.<sup id=\"cite_ref-16\" class=\"reference\"><a href=\"#cite_note-16\">&#91;15&#93;</a></sup><sup id=\"cite_ref-17\" class=\"reference\"><a href=\"#cite_note-17\">&#91;16&#93;</a></sup><sup id=\"cite_ref-18\" class=\"reference\"><a href=\"#cite_note-18\">&#91;17&#93;</a></sup> However, the asymptotic theory of limiting distributions is often invoked for work with finite samples. For example, limiting results are often invoked to justify the <a href=\"/wiki/Generalized_method_of_moments\" title=\"Generalized method of moments\">generalized method of moments</a> and the use of <a href=\"/wiki/Generalized_estimating_equation\" title=\"Generalized estimating equation\">generalized estimating equations</a>, which are popular in <a href=\"/wiki/Econometrics\" title=\"Econometrics\">econometrics</a> and <a href=\"/wiki/Biostatistics\" title=\"Biostatistics\">biostatistics</a>. The magnitude of the difference between the limiting distribution and the true distribution (formally, the 'error' of the approximation) can be assessed using simulation.<sup id=\"cite_ref-19\" class=\"reference\"><a href=\"#cite_note-19\">&#91;18&#93;</a></sup> The heuristic application of limiting results to finite samples is common practice in many applications, especially with low-dimensional <a href=\"/wiki/Statistical_model\" title=\"Statistical model\">models</a> with <a href=\"/wiki/Logarithmically_concave_function\" title=\"Logarithmically concave function\">log-concave</a> <a href=\"/wiki/Likelihood_function\" title=\"Likelihood function\">likelihoods</a> (such as with one-parameter <a href=\"/wiki/Exponential_families\" class=\"mw-redirect\" title=\"Exponential families\">exponential families</a>).\n</p>\n<h3><span class=\"mw-headline\" id=\"Randomization-based_models\">Randomization-based models</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=6\" title=\"Edit section: Randomization-based models\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">Main article: <a href=\"/wiki/Randomization\" title=\"Randomization\">Randomization</a></div>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">See also: <a href=\"/wiki/Random_sample\" class=\"mw-redirect\" title=\"Random sample\">Random sample</a> and <a href=\"/wiki/Random_assignment\" title=\"Random assignment\">Random assignment</a></div>\n<p>For a given dataset that was produced by a randomization design, the randomization distribution of a statistic (under the null-hypothesis) is defined by evaluating the test statistic for all of the plans that could have been generated by the randomization design. In frequentist inference, randomization allows inferences to be based on the randomization distribution rather than a subjective model, and this is important especially in survey sampling and design of experiments.<sup id=\"cite_ref-20\" class=\"reference\"><a href=\"#cite_note-20\">&#91;19&#93;</a></sup><sup id=\"cite_ref-Hinkelmann_and_Kempthorne_21-0\" class=\"reference\"><a href=\"#cite_note-Hinkelmann_and_Kempthorne-21\">&#91;20&#93;</a></sup> Statistical inference from randomized studies is also more straightforward than many other situations.<sup id=\"cite_ref-22\" class=\"reference\"><a href=\"#cite_note-22\">&#91;21&#93;</a></sup><sup id=\"cite_ref-23\" class=\"reference\"><a href=\"#cite_note-23\">&#91;22&#93;</a></sup><sup id=\"cite_ref-24\" class=\"reference\"><a href=\"#cite_note-24\">&#91;23&#93;</a></sup> In <a href=\"/wiki/Bayesian_inference\" title=\"Bayesian inference\">Bayesian inference</a>, randomization is also of importance: in <a href=\"/wiki/Survey_sampling\" title=\"Survey sampling\">survey sampling</a>, use of <a href=\"/wiki/Sampling_without_replacement\" class=\"mw-redirect\" title=\"Sampling without replacement\">sampling without replacement</a> ensures the <a href=\"/wiki/Exchangeability\" class=\"mw-redirect\" title=\"Exchangeability\">exchangeability</a> of the sample with the population; in randomized experiments, randomization warrants a <a href=\"/wiki/Missing_at_random\" class=\"mw-redirect\" title=\"Missing at random\">missing at random</a> assumption for <a href=\"/wiki/Covariate\" class=\"mw-redirect\" title=\"Covariate\">covariate</a> information.<sup id=\"cite_ref-25\" class=\"reference\"><a href=\"#cite_note-25\">&#91;24&#93;</a></sup>\n</p><p>Objective randomization allows properly inductive procedures.<sup id=\"cite_ref-26\" class=\"reference\"><a href=\"#cite_note-26\">&#91;25&#93;</a></sup><sup id=\"cite_ref-27\" class=\"reference\"><a href=\"#cite_note-27\">&#91;26&#93;</a></sup><sup id=\"cite_ref-28\" class=\"reference\"><a href=\"#cite_note-28\">&#91;27&#93;</a></sup><sup id=\"cite_ref-29\" class=\"reference\"><a href=\"#cite_note-29\">&#91;28&#93;</a></sup>\nMany statisticians prefer randomization-based analysis of data that was generated by well-defined randomization procedures.<sup id=\"cite_ref-30\" class=\"reference\"><a href=\"#cite_note-30\">&#91;29&#93;</a></sup> (However, it is true that in fields of science with developed theoretical knowledge and experimental control, randomized experiments may increase the costs of experimentation without improving the quality of inferences.<sup id=\"cite_ref-31\" class=\"reference\"><a href=\"#cite_note-31\">&#91;30&#93;</a></sup><sup id=\"cite_ref-32\" class=\"reference\"><a href=\"#cite_note-32\">&#91;31&#93;</a></sup>)\nSimilarly, results from <a href=\"/wiki/Randomized_experiment\" title=\"Randomized experiment\">randomized experiments</a> are recommended by leading statistical authorities as allowing inferences with greater reliability than do observational studies of the same phenomena.<sup id=\"cite_ref-33\" class=\"reference\"><a href=\"#cite_note-33\">&#91;32&#93;</a></sup>\nHowever, a good observational study may be better than a bad randomized experiment.\n</p><p>The statistical analysis of a randomized experiment may be based on the randomization scheme stated in the experimental protocol and does not need a subjective model.<sup id=\"cite_ref-34\" class=\"reference\"><a href=\"#cite_note-34\">&#91;33&#93;</a></sup><sup id=\"cite_ref-35\" class=\"reference\"><a href=\"#cite_note-35\">&#91;34&#93;</a></sup>\n</p><p>However, at any time, some hypotheses cannot be tested using objective statistical models, which accurately describe randomized experiments or random samples. In some cases, such randomized studies are uneconomical or unethical.\n</p>\n<h4><span class=\"mw-headline\" id=\"Model-based_analysis_of_randomized_experiments\">Model-based analysis of randomized experiments</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=7\" title=\"Edit section: Model-based analysis of randomized experiments\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>It is standard practice to refer to a statistical model, often a linear model, when analyzing data from randomized experiments. However, the randomization scheme guides the choice of a statistical model. It is not possible to choose an appropriate model without knowing the randomization scheme.<sup id=\"cite_ref-Hinkelmann_and_Kempthorne_21-1\" class=\"reference\"><a href=\"#cite_note-Hinkelmann_and_Kempthorne-21\">&#91;20&#93;</a></sup> Seriously misleading results can be obtained analyzing data from randomized experiments while ignoring the experimental protocol; common mistakes include forgetting the blocking used in an experiment and confusing repeated measurements on the same experimental unit with independent replicates of the treatment applied to different experimental units.<sup id=\"cite_ref-36\" class=\"reference\"><a href=\"#cite_note-36\">&#91;35&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Paradigms_for_inference\">Paradigms for inference</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=8\" title=\"Edit section: Paradigms for inference\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Different schools of statistical inference have become established. These schools&#8212;or \"paradigms\"&#8212;are not mutually exclusive, and methods that work well under one paradigm often have attractive interpretations under other paradigms.\n</p><p>Bandyopadhyay &amp; Forster<sup id=\"cite_ref-37\" class=\"reference\"><a href=\"#cite_note-37\">&#91;36&#93;</a></sup>  describe four paradigms: \"(i) classical statistics or error statistics, (ii) Bayesian statistics, (iii) likelihood-based statistics, and (iv) the Akaikean-Information Criterion-based statistics\".  The classical (or <a href=\"/wiki/Frequentist_inference\" title=\"Frequentist inference\">frequentist</a>) paradigm, the <a href=\"/wiki/Bayesian_inference\" title=\"Bayesian inference\">Bayesian</a> paradigm, and the <a href=\"/wiki/Akaike_information_criterion\" title=\"Akaike information criterion\">AIC</a>-based paradigm are summarized below.  The likelihood-based paradigm is essentially a sub-paradigm of the AIC-based paradigm.\n</p>\n<h3><span class=\"mw-headline\" id=\"Frequentist_inference\">Frequentist inference</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=9\" title=\"Edit section: Frequentist inference\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">See also: <a href=\"/wiki/Frequentist_inference\" title=\"Frequentist inference\">Frequentist inference</a></div>\n<p>This paradigm calibrates the plausibility of propositions by considering (notional) repeated sampling of a population distribution to produce datasets similar to the one at hand. By considering the dataset's characteristics under repeated sampling, the frequentist properties of a statistical proposition can be quantified\u2014although in practice this quantification may be challenging.\n</p>\n<h4><span class=\"mw-headline\" id=\"Examples_of_frequentist_inference\">Examples of frequentist inference</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=10\" title=\"Edit section: Examples of frequentist inference\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<ul><li><a href=\"/wiki/P-value\" title=\"P-value\"><i>p</i>-value</a></li>\n<li><a href=\"/wiki/Confidence_interval\" title=\"Confidence interval\">Confidence interval</a></li></ul>\n<h4><span id=\"Frequentist_inference.2C_objectivity.2C_and_decision_theory\"></span><span class=\"mw-headline\" id=\"Frequentist_inference,_objectivity,_and_decision_theory\">Frequentist inference, objectivity, and decision theory</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=11\" title=\"Edit section: Frequentist inference, objectivity, and decision theory\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>One interpretation of <a href=\"/wiki/Frequentist_inference\" title=\"Frequentist inference\">frequentist inference</a> (or classical inference) is that it is applicable only in terms of <a href=\"/wiki/Frequency_probability\" class=\"mw-redirect\" title=\"Frequency probability\">frequency probability</a>; that is, in terms of repeated sampling from a population. However, the approach of Neyman<sup id=\"cite_ref-38\" class=\"reference\"><a href=\"#cite_note-38\">&#91;37&#93;</a></sup> develops these procedures in terms of pre-experiment probabilities. That is, before undertaking an experiment, one decides on a rule for coming to a conclusion such that the probability of being correct is controlled in a suitable way: such a probability need not have a frequentist or repeated sampling interpretation. In contrast, Bayesian inference works in terms of conditional probabilities (i.e. probabilities conditional on the observed data), compared to the marginal (but conditioned on unknown parameters) probabilities used in the frequentist approach.\n</p><p>The frequentist procedures of significance testing and confidence intervals can be constructed without regard to <a href=\"/wiki/Utility_function\" class=\"mw-redirect\" title=\"Utility function\">utility functions</a>. However, some elements of frequentist statistics, such as <a href=\"/wiki/Statistical_decision_theory\" class=\"mw-redirect\" title=\"Statistical decision theory\">statistical decision theory</a>, do incorporate <a href=\"/wiki/Utility_function\" class=\"mw-redirect\" title=\"Utility function\">utility functions</a>.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (April 2012)\">citation needed</span></a></i>&#93;</sup> In particular, frequentist developments of optimal inference (such as <a href=\"/wiki/Minimum-variance_unbiased_estimator\" title=\"Minimum-variance unbiased estimator\">minimum-variance unbiased estimators</a>, or <a href=\"/wiki/Uniformly_most_powerful_test\" title=\"Uniformly most powerful test\">uniformly most powerful testing</a>) make use of <a href=\"/wiki/Loss_function\" title=\"Loss function\">loss functions</a>, which play the role of (negative) utility functions. Loss functions need not be explicitly stated for statistical theorists to prove that a statistical procedure has an optimality property.<sup id=\"cite_ref-39\" class=\"reference\"><a href=\"#cite_note-39\">&#91;38&#93;</a></sup> However, loss-functions are often useful for stating optimality properties: for example, median-unbiased estimators are optimal under <a href=\"/wiki/Absolute_value\" title=\"Absolute value\">absolute value</a> loss functions, in that they minimize expected loss, and <a href=\"/wiki/Least_squares\" title=\"Least squares\">least squares</a> estimators are optimal under squared error loss functions, in that they minimize expected loss.\n</p><p>While statisticians using frequentist inference must choose for themselves the parameters of interest, and the <a href=\"/wiki/Estimators\" class=\"mw-redirect\" title=\"Estimators\">estimators</a>/<a href=\"/wiki/Test_statistic#Common_test_statistics\" title=\"Test statistic\">test statistic</a> to be used, the absence of obviously explicit utilities and prior distributions has helped frequentist procedures to become widely viewed as 'objective'.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (April 2012)\">citation needed</span></a></i>&#93;</sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Bayesian_inference\">Bayesian inference</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=12\" title=\"Edit section: Bayesian inference\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">See also: <a href=\"/wiki/Bayesian_Inference\" class=\"mw-redirect\" title=\"Bayesian Inference\">Bayesian Inference</a></div>\n<p>The Bayesian calculus describes degrees of belief using the 'language' of probability; beliefs are positive, integrate to one, and obey probability axioms. Bayesian inference uses the available posterior beliefs as the basis for making statistical propositions. There are <a href=\"/wiki/Bayesian_probability#Justification_of_Bayesian_probabilities\" title=\"Bayesian probability\">several different justifications</a> for using the Bayesian approach.\n</p>\n<h4><span class=\"mw-headline\" id=\"Examples_of_Bayesian_inference\">Examples of Bayesian inference</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=13\" title=\"Edit section: Examples of Bayesian inference\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<ul><li><a href=\"/wiki/Credible_interval\" title=\"Credible interval\">Credible interval</a> for <a href=\"/wiki/Interval_estimation\" title=\"Interval estimation\">interval estimation</a></li>\n<li><a href=\"/wiki/Bayes_factor\" title=\"Bayes factor\">Bayes factors</a> for model comparison</li></ul>\n<h4><span id=\"Bayesian_inference.2C_subjectivity_and_decision_theory\"></span><span class=\"mw-headline\" id=\"Bayesian_inference,_subjectivity_and_decision_theory\">Bayesian inference, subjectivity and decision theory</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=14\" title=\"Edit section: Bayesian inference, subjectivity and decision theory\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Many informal Bayesian inferences are based on \"intuitively reasonable\" summaries of the posterior. For example, the posterior mean, median and mode, highest posterior density intervals, and Bayes Factors can all be motivated in this way. While a user's <a href=\"/wiki/Utility_function\" class=\"mw-redirect\" title=\"Utility function\">utility function</a> need not be stated for this sort of inference, these summaries do all depend (to some extent) on stated prior beliefs, and are generally viewed as subjective conclusions. (Methods of prior construction which do not require external input have been <a href=\"/wiki/Bayesian_probability#Personal_probabilities_and_objective_methods_for_constructing_priors\" title=\"Bayesian probability\">proposed</a> but not yet fully developed.)\n</p><p>Formally, Bayesian inference is calibrated with reference to an explicitly stated utility, or loss function; the 'Bayes rule' is the one which maximizes expected utility, averaged over the posterior uncertainty. Formal Bayesian inference therefore automatically provides <a href=\"/wiki/Optimal_decision\" title=\"Optimal decision\">optimal decisions</a> in a <a href=\"/wiki/Decision_theory\" title=\"Decision theory\">decision theoretic</a> sense. Given assumptions, data and utility, Bayesian inference can be made for essentially any problem, although not every statistical inference need have a Bayesian interpretation. Analyses which are not formally Bayesian can be (logically) <a href=\"/wiki/Coherence_(statistics)\" title=\"Coherence (statistics)\">incoherent</a>; a feature of Bayesian procedures which use proper priors (i.e. those integrable to one) is that they are guaranteed to be <a href=\"/wiki/Coherence_(statistics)\" title=\"Coherence (statistics)\">coherent</a>. Some advocates of <a href=\"/wiki/Bayesian_inference\" title=\"Bayesian inference\">Bayesian inference</a> assert that inference <i>must</i> take place in this decision-theoretic framework, and that <a href=\"/wiki/Bayesian_inference\" title=\"Bayesian inference\">Bayesian inference</a> should not conclude with the evaluation and summarization of posterior beliefs.\n</p>\n<h3><span class=\"mw-headline\" id=\"AIC-based_inference\">AIC-based inference</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=15\" title=\"Edit section: AIC-based inference\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">Main article: <a href=\"/wiki/Akaike_information_criterion\" title=\"Akaike information criterion\">Akaike information criterion</a></div>\n<table class=\"plainlinks metadata ambox mbox-small-left ambox-content\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><a href=\"/wiki/File:Wiki_letter_w_cropped.svg\" class=\"image\"><img alt=\"[icon]\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/20px-Wiki_letter_w_cropped.svg.png\" width=\"20\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/30px-Wiki_letter_w_cropped.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png 2x\" data-file-width=\"44\" data-file-height=\"31\" /></a></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">This section <b>needs expansion</b>. <small>You can help by <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=\">adding to it</a>.</small>  <small><i>(November 2017)</i></small></div></td></tr></tbody></table>\n<p>The <i><a href=\"/wiki/Akaike_information_criterion\" title=\"Akaike information criterion\">Akaike information criterion</a></i> (AIC) is an <a href=\"/wiki/Estimator\" title=\"Estimator\">estimator</a> of the relative quality of <a href=\"/wiki/Statistical_model\" title=\"Statistical model\">statistical models</a> for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. Thus, AIC provides a means for <a href=\"/wiki/Model_selection\" title=\"Model selection\">model selection</a>.\n</p><p>AIC is founded on <a href=\"/wiki/Information_theory\" title=\"Information theory\">information theory</a>: it offers an estimate of the relative information lost when a given model is used to represent the process that generated the data. (In doing so, it deals with the trade-off between the <a href=\"/wiki/Goodness_of_fit\" title=\"Goodness of fit\">goodness of fit</a> of the model and the simplicity of the model.)\n</p>\n<h3><span class=\"mw-headline\" id=\"Other_paradigms_for_inference\">Other paradigms for inference</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=16\" title=\"Edit section: Other paradigms for inference\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<h4><span class=\"mw-headline\" id=\"Minimum_description_length\">Minimum description length</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=17\" title=\"Edit section: Minimum description length\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">Main article: <a href=\"/wiki/Minimum_description_length\" title=\"Minimum description length\">Minimum description length</a></div>\n<p>The minimum description length (MDL) principle has been developed from ideas in <a href=\"/wiki/Information_theory\" title=\"Information theory\">information theory</a><sup id=\"cite_ref-Soofi_2000_1349\u20131353_40-0\" class=\"reference\"><a href=\"#cite_note-Soofi_2000_1349\u20131353-40\">&#91;39&#93;</a></sup> and the theory of <a href=\"/wiki/Kolmogorov_complexity\" title=\"Kolmogorov complexity\">Kolmogorov complexity</a>.<sup id=\"cite_ref-HY_41-0\" class=\"reference\"><a href=\"#cite_note-HY-41\">&#91;40&#93;</a></sup>  The (MDL) principle selects statistical models that maximally compress the data; inference proceeds without assuming counterfactual or non-falsifiable \"data-generating mechanisms\" or <a href=\"/wiki/Probability_models\" class=\"mw-redirect\" title=\"Probability models\">probability models</a> for the data, as might be done in frequentist or Bayesian approaches.\n</p><p>However, if a \"data generating mechanism\" does exist in reality, then according to <a href=\"/wiki/Claude_Shannon\" title=\"Claude Shannon\">Shannon</a>'s <a href=\"/wiki/Source_coding_theorem\" class=\"mw-redirect\" title=\"Source coding theorem\">source coding theorem</a> it provides the MDL description of the data, on average and asymptotically.<sup id=\"cite_ref-HY747_42-0\" class=\"reference\"><a href=\"#cite_note-HY747-42\">&#91;41&#93;</a></sup> In minimizing description length (or descriptive complexity), MDL estimation is similar to <a href=\"/wiki/Maximum_likelihood_estimation\" title=\"Maximum likelihood estimation\">maximum likelihood estimation</a> and <a href=\"/wiki/Maximum_a_posteriori_estimation\" title=\"Maximum a posteriori estimation\">maximum a posteriori estimation</a> (using <a href=\"/wiki/Maximum_entropy_probability_distribution\" title=\"Maximum entropy probability distribution\">maximum-entropy</a> <a href=\"/wiki/Bayesian_probability\" title=\"Bayesian probability\">Bayesian priors</a>). However, MDL avoids assuming that the underlying probability model is known; the MDL principle can also be applied without assumptions that e.g. the data arose from independent sampling.<sup id=\"cite_ref-HY747_42-1\" class=\"reference\"><a href=\"#cite_note-HY747-42\">&#91;41&#93;</a></sup><sup id=\"cite_ref-JR_43-0\" class=\"reference\"><a href=\"#cite_note-JR-43\">&#91;42&#93;</a></sup>\n</p><p>The MDL principle has been applied in communication-<a href=\"/wiki/Coding_theory\" title=\"Coding theory\">coding theory</a> in <a href=\"/wiki/Information_theory\" title=\"Information theory\">information theory</a>, in <a href=\"/wiki/Linear_regression\" title=\"Linear regression\">linear regression</a>,<sup id=\"cite_ref-JR_43-1\" class=\"reference\"><a href=\"#cite_note-JR-43\">&#91;42&#93;</a></sup> and in <a href=\"/wiki/Data_mining\" title=\"Data mining\">data mining</a>.<sup id=\"cite_ref-HY_41-1\" class=\"reference\"><a href=\"#cite_note-HY-41\">&#91;40&#93;</a></sup>\n</p><p>The evaluation of MDL-based inferential procedures often uses techniques or criteria from <a href=\"/wiki/Computational_complexity_theory\" title=\"Computational complexity theory\">computational complexity theory</a>.<sup id=\"cite_ref-44\" class=\"reference\"><a href=\"#cite_note-44\">&#91;43&#93;</a></sup>\n</p>\n<h4><span class=\"mw-headline\" id=\"Fiducial_inference\">Fiducial inference</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=18\" title=\"Edit section: Fiducial inference\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">Main article: <a href=\"/wiki/Fiducial_inference\" title=\"Fiducial inference\">Fiducial inference</a></div>\n<p><a href=\"/wiki/Fiducial_inference\" title=\"Fiducial inference\">Fiducial inference</a> was an approach to statistical inference based on <a href=\"/wiki/Fiducial_probability\" class=\"mw-redirect\" title=\"Fiducial probability\">fiducial probability</a>, also known as a \"fiducial distribution\". In subsequent work, this approach has been called ill-defined, extremely limited in applicability,  and even fallacious.<sup id=\"cite_ref-45\" class=\"reference\"><a href=\"#cite_note-45\">&#91;44&#93;</a></sup><sup id=\"cite_ref-46\" class=\"reference\"><a href=\"#cite_note-46\">&#91;45&#93;</a></sup> However this argument is the same as that which shows<sup id=\"cite_ref-47\" class=\"reference\"><a href=\"#cite_note-47\">&#91;46&#93;</a></sup>  that a so-called <a href=\"/wiki/Confidence_distribution\" title=\"Confidence distribution\">confidence distribution</a> is not a valid <a href=\"/wiki/Probability_distribution\" title=\"Probability distribution\">probability distribution</a> and, since this has not invalidated the application of <a href=\"/wiki/Confidence_interval\" title=\"Confidence interval\">confidence intervals</a>, it does not necessarily invalidate conclusions drawn from fiducial arguments. An attempt was made to reinterpret the early work of Fisher's <a href=\"/wiki/Fiducial_probability\" class=\"mw-redirect\" title=\"Fiducial probability\">fiducial argument</a> as a special case of an inference theory using <a href=\"/wiki/Upper_and_lower_probabilities\" title=\"Upper and lower probabilities\">Upper and lower probabilities</a>.<sup id=\"cite_ref-FOOTNOTEHampel2003_48-0\" class=\"reference\"><a href=\"#cite_note-FOOTNOTEHampel2003-48\">&#91;47&#93;</a></sup>\n</p>\n<h4><span class=\"mw-headline\" id=\"Structural_inference\">Structural inference</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=19\" title=\"Edit section: Structural inference\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Developing ideas of Fisher and of Pitman from 1938 to 1939,<sup id=\"cite_ref-49\" class=\"reference\"><a href=\"#cite_note-49\">&#91;48&#93;</a></sup> <a href=\"/wiki/George_A._Barnard\" class=\"mw-redirect\" title=\"George A. Barnard\">George A. Barnard</a> developed \"structural inference\" or \"pivotal inference\",<sup id=\"cite_ref-50\" class=\"reference\"><a href=\"#cite_note-50\">&#91;49&#93;</a></sup> an approach using <a href=\"/wiki/Haar_measure\" title=\"Haar measure\">invariant probabilities</a> on <a href=\"/wiki/Group_family\" title=\"Group family\">group families</a>. Barnard reformulated the arguments behind fiducial inference on a restricted class of models on which \"fiducial\" procedures would be well-defined and useful.\n</p>\n<h2><span class=\"mw-headline\" id=\"Inference_topics\">Inference topics</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=20\" title=\"Edit section: Inference topics\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>The topics below are usually included in the area of <b>statistical inference</b>.\n</p>\n<ol><li><a href=\"/wiki/Statistical_assumptions\" class=\"mw-redirect\" title=\"Statistical assumptions\">Statistical assumptions</a></li>\n<li><a href=\"/wiki/Statistical_decision_theory\" class=\"mw-redirect\" title=\"Statistical decision theory\">Statistical decision theory</a></li>\n<li><a href=\"/wiki/Estimation_theory\" title=\"Estimation theory\">Estimation theory</a></li>\n<li><a href=\"/wiki/Statistical_hypothesis_testing\" title=\"Statistical hypothesis testing\">Statistical hypothesis testing</a></li>\n<li><a href=\"/w/index.php?title=Revising_opinions_in_statistics&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"Revising opinions in statistics (page does not exist)\">Revising opinions in statistics</a></li>\n<li><a href=\"/wiki/Design_of_experiments\" title=\"Design of experiments\">Design of experiments</a>, the <a href=\"/wiki/Analysis_of_variance\" title=\"Analysis of variance\">analysis of variance</a>, and <a href=\"/wiki/Regression_analysis\" title=\"Regression analysis\">regression</a></li>\n<li><a href=\"/wiki/Survey_sampling\" title=\"Survey sampling\">Survey sampling</a></li>\n<li><a href=\"/wiki/Summarizing_statistical_data\" class=\"mw-redirect\" title=\"Summarizing statistical data\">Summarizing statistical data</a></li></ol>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=21\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a href=\"/wiki/Algorithmic_inference\" title=\"Algorithmic inference\">Algorithmic inference</a></li>\n<li><a href=\"/wiki/Induction_(philosophy)\" class=\"mw-redirect\" title=\"Induction (philosophy)\">Induction (philosophy)</a></li>\n<li><a href=\"/wiki/Informal_inferential_reasoning\" title=\"Informal inferential reasoning\">Informal inferential reasoning</a></li>\n<li><a href=\"/wiki/Population_proportion\" title=\"Population proportion\">Population proportion</a></li>\n<li><a href=\"/wiki/Philosophy_of_statistics\" title=\"Philosophy of statistics\">Philosophy of statistics</a></li>\n<li><a href=\"/wiki/Predictive_inference\" title=\"Predictive inference\">Predictive inference</a></li>\n<li><a href=\"/wiki/Information_field_theory\" title=\"Information field theory\">Information field theory</a></li></ul>\n<h2><span class=\"mw-headline\" id=\"Notes\">Notes</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=22\" title=\"Edit section: Notes\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: lower-alpha;\">\n<div class=\"mw-references-wrap\"><ol class=\"references\">\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\">According to Peirce, acceptance means that inquiry on this question ceases for the time being. In science, all scientific theories are revisable.</span>\n</li>\n</ol></div></div>\n<h2><span class=\"mw-headline\" id=\"Citations\">Citations</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=23\" title=\"Edit section: Citations\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap mw-references-columns\"><ol class=\"references\">\n<li id=\"cite_note-Oxford-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Oxford_1-0\">^</a></b></span> <span class=\"reference-text\">Upton, G., Cook, I. (2008) <i>Oxford Dictionary of Statistics</i>, OUP. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-0-19-954145-4\" title=\"Special:BookSources/978-0-19-954145-4\">978-0-19-954145-4</a></span>\n</li>\n<li id=\"cite_note-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-2\">^</a></b></span> <span class=\"reference-text\">Konishi &amp; Kitagawa (2008), p. 75.</span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\">Cox (2006), p. 197.</span>\n</li>\n<li id=\"cite_note-Cox2006-5\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Cox2006_5-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Cox2006_5-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Cox (2006) page 2</span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation book\">Evans, Michael;  et al. (2004). <a rel=\"nofollow\" class=\"external text\" href=\"https://books.google.com/books?id=hkWK8kFzXWIC&amp;printsec=frontcover#v=onepage&amp;q=%22descriptive%20statistics%22&amp;f=false\"><i>Probability and Statistics: The Science of Uncertainty</i></a>. Freeman and Company. p.&#160;267. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/9780716747420\" title=\"Special:BookSources/9780716747420\">9780716747420</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Probability+and+Statistics%3A+The+Science+of+Uncertainty&amp;rft.pages=267&amp;rft.pub=Freeman+and+Company&amp;rft.date=2004&amp;rft.isbn=9780716747420&amp;rft.aulast=Evans&amp;rft.aufirst=Michael&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DhkWK8kFzXWIC%26printsec%3Dfrontcover%23v%3Donepage%26q%3D%2522descriptive%2520statistics%2522%26f%3Dfalse&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\">van der Vaart, A.W. (1998) <i>Asymptotic Statistics</i>  Cambridge University Press. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-521-78450-6\" title=\"Special:BookSources/0-521-78450-6\">0-521-78450-6</a> (page 341)</span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\">Kruskal 1988</span>\n</li>\n<li id=\"cite_note-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-9\">^</a></b></span> <span class=\"reference-text\">\n<a href=\"/wiki/David_A._Freedman\" title=\"David A. Freedman\">Freedman, D.A.</a> (2008) \"Survival analysis: An Epidemiological hazard?\". <i>The American Statistician</i> (2008) 62: 110-119. (Reprinted as Chapter 11 (pages 169\u2013192) of Freedman (2010)).</span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\">Berk, R. (2003) <i>Regression Analysis: A Constructive Critique (Advanced Quantitative Techniques in the Social Sciences) (v. 11)</i> Sage Publications. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-7619-2904-5\" title=\"Special:BookSources/0-7619-2904-5\">0-7619-2904-5</a></span>\n</li>\n<li id=\"cite_note-Brewer-11\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Brewer_11-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Brewer_11-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation book\">Brewer, Ken (2002). <i>Combined Survey Sampling Inference: Weighing of Basu's Elephants</i>. Hodder Arnold. p.&#160;6. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-0340692295\" title=\"Special:BookSources/978-0340692295\">978-0340692295</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Combined+Survey+Sampling+Inference%3A+Weighing+of+Basu%27s+Elephants&amp;rft.pages=6&amp;rft.pub=Hodder+Arnold&amp;rft.date=2002&amp;rft.isbn=978-0340692295&amp;rft.aulast=Brewer&amp;rft.aufirst=Ken&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-JHJ-12\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-JHJ_12-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-JHJ_12-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">\nJ\u00f6rgen Hoffman-J\u00f6rgensen's <i>Probability With a View Towards Statistics</i>, Volume I. Page 399<sup class=\"noprint Inline-Template\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citing_sources#What_information_to_include\" title=\"Wikipedia:Citing sources\"><span title=\"A complete citation is needed (November 2012)\">full citation needed</span></a></i>&#93;</sup></span>\n</li>\n<li id=\"cite_note-13\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-13\">^</a></b></span> <span class=\"reference-text\">Le Cam (1986)<sup class=\"noprint Inline-Template\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citing_sources\" title=\"Wikipedia:Citing sources\"><span title=\"This citation requires a reference to the specific page or range of pages in which the material appears. (June 2011)\">page&#160;needed</span></a></i>&#93;</sup></span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\">Erik Torgerson (1991) <i>Comparison of Statistical Experiments</i>, volume 36 of Encyclopedia of Mathematics. Cambridge University Press.<sup class=\"noprint Inline-Template\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citing_sources#What_information_to_include\" title=\"Wikipedia:Citing sources\"><span title=\"A complete citation is needed (November 2012)\">full citation needed</span></a></i>&#93;</sup></span>\n</li>\n<li id=\"cite_note-15\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-15\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation book\">Liese, Friedrich &amp; Miescke, Klaus-J. (2008). <i>Statistical Decision Theory: Estimation, Testing, and Selection</i>. Springer. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-387-73193-8\" title=\"Special:BookSources/0-387-73193-8\">0-387-73193-8</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Statistical+Decision+Theory%3A+Estimation%2C+Testing%2C+and+Selection&amp;rft.pub=Springer&amp;rft.date=2008&amp;rft.isbn=0-387-73193-8&amp;rft.au=Liese%2C+Friedrich&amp;rft.au=Miescke%2C+Klaus-J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-16\">^</a></b></span> <span class=\"reference-text\">Kolmogorov (1963, p.369): \"The frequency concept,  based on the notion of limiting frequency as the number of trials increases to infinity, does not contribute anything to substantiate the applicability of the results of probability theory to real practical problems where we have always to deal with a finite number of trials\".</span>\n</li>\n<li id=\"cite_note-17\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-17\">^</a></b></span> <span class=\"reference-text\">\"Indeed, limit theorems 'as&#160;<span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"  alttext=\"{\\displaystyle n}\">\n  <semantics>\n    <mrow class=\"MJX-TeXAtom-ORD\">\n      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n        <mi>n</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding=\"application/x-tex\">{\\displaystyle n}</annotation>\n  </semantics>\n</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -0.338ex; width:1.395ex; height:1.676ex;\" alt=\"n\"/></span> tends to infinity' are logically devoid of content about what happens at any particular&#160;<span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"  alttext=\"{\\displaystyle n}\">\n  <semantics>\n    <mrow class=\"MJX-TeXAtom-ORD\">\n      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n        <mi>n</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding=\"application/x-tex\">{\\displaystyle n}</annotation>\n  </semantics>\n</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -0.338ex; width:1.395ex; height:1.676ex;\" alt=\"n\"/></span>. All they can do is suggest certain approaches whose performance must then be checked on the case at hand.\" &#8212; Le Cam (1986) (page xiv)</span>\n</li>\n<li id=\"cite_note-18\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-18\">^</a></b></span> <span class=\"reference-text\">Pfanzagl (1994): \"The crucial drawback of asymptotic theory: What we expect from asymptotic theory are results which hold approximately . . . . What asymptotic theory has to offer are limit theorems.\"(page ix) \"What counts for applications are approximations, not limits.\" (page 188)</span>\n</li>\n<li id=\"cite_note-19\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-19\">^</a></b></span> <span class=\"reference-text\">Pfanzagl (1994)&#160;: \"By taking a limit theorem as being approximately true for large sample sizes, we commit an error the size of which is unknown. [. . .] Realistic information about the remaining errors may be obtained by simulations.\" (page ix)</span>\n</li>\n<li id=\"cite_note-20\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-20\">^</a></b></span> <span class=\"reference-text\"><a href=\"/wiki/Jerzy_Neyman\" title=\"Jerzy Neyman\">Neyman, J.</a>(1934) \"On the two different aspects of the representative method: The method of stratified sampling and the method of purposive selection\", <i><a href=\"/wiki/Journal_of_the_Royal_Statistical_Society\" title=\"Journal of the Royal Statistical Society\">Journal of the Royal Statistical Society</a></i>, 97 (4), 557&#8211;625 <a href=\"/wiki/JSTOR\" title=\"JSTOR\">JSTOR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"https://www.jstor.org/stable/2342192\">2342192</a></span>\n</li>\n<li id=\"cite_note-Hinkelmann_and_Kempthorne-21\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Hinkelmann_and_Kempthorne_21-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Hinkelmann_and_Kempthorne_21-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Hinkelmann and Kempthorne(2008)<sup class=\"noprint Inline-Template\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citing_sources\" title=\"Wikipedia:Citing sources\"><span title=\"This citation requires a reference to the specific page or range of pages in which the material appears. (June 2011)\">page&#160;needed</span></a></i>&#93;</sup></span>\n</li>\n<li id=\"cite_note-22\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-22\">^</a></b></span> <span class=\"reference-text\">ASA Guidelines for a first course in statistics for non-statisticians. (available at the ASA website)</span>\n</li>\n<li id=\"cite_note-23\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-23\">^</a></b></span> <span class=\"reference-text\"><a href=\"/wiki/David_A._Freedman\" title=\"David A. Freedman\">David A. Freedman</a> et alia's <i>Statistics</i>.</span>\n</li>\n<li id=\"cite_note-24\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-24\">^</a></b></span> <span class=\"reference-text\">Moore et al. (2015).</span>\n</li>\n<li id=\"cite_note-25\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-25\">^</a></b></span> <span class=\"reference-text\"><a href=\"/wiki/Andrew_Gelman\" title=\"Andrew Gelman\">Gelman A.</a> et al. (2013). <i>Bayesian Data Analysis</i> (<a href=\"/wiki/Chapman_%26_Hall\" title=\"Chapman &amp; Hall\">Chapman &amp; Hall</a>).</span>\n</li>\n<li id=\"cite_note-26\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-26\">^</a></b></span> <span class=\"reference-text\">Peirce (1877-1878)</span>\n</li>\n<li id=\"cite_note-27\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-27\">^</a></b></span> <span class=\"reference-text\">Peirce (1883)</span>\n</li>\n<li id=\"cite_note-28\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-28\">^</a></b></span> <span class=\"reference-text\">\n<a href=\"/wiki/David_A._Freedman\" title=\"David A. Freedman\">David Freedman</a> et alia <i>Statistics</i> and <a href=\"/wiki/David_A._Freedman\" title=\"David A. Freedman\">David A. Freedman</a> <i>Statistical Models</i>.</span>\n</li>\n<li id=\"cite_note-29\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-29\">^</a></b></span> <span class=\"reference-text\">\n<a href=\"/wiki/C._R._Rao\" title=\"C. R. Rao\">Rao, C.R.</a> (1997) <i>Statistics and Truth: Putting Chance to Work</i>, World Scientific. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/981-02-3111-3\" title=\"Special:BookSources/981-02-3111-3\">981-02-3111-3</a></span>\n</li>\n<li id=\"cite_note-30\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-30\">^</a></b></span> <span class=\"reference-text\">Peirce; Freedman; Moore et al. (2015).<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (March 2010)\">citation needed</span></a></i>&#93;</sup></span>\n</li>\n<li id=\"cite_note-31\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-31\">^</a></b></span> <span class=\"reference-text\">Box, G.E.P. and Friends (2006) <i>Improving Almost Anything: Ideas and Essays, Revised Edition</i>, Wiley. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-0-471-72755-2\" title=\"Special:BookSources/978-0-471-72755-2\">978-0-471-72755-2</a></span>\n</li>\n<li id=\"cite_note-32\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-32\">^</a></b></span> <span class=\"reference-text\">\nCox (2006), page 196</span>\n</li>\n<li id=\"cite_note-33\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-33\">^</a></b></span> <span class=\"reference-text\">ASA Guidelines for a first course in statistics for non-statisticians. (available at the ASA website)\n<ul><li>David A. Freedman et alia's <i>Statistics</i>.</li>\n<li>Moore et al. (2015).</li></ul>\n</span></li>\n<li id=\"cite_note-34\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-34\">^</a></b></span> <span class=\"reference-text\">Neyman, Jerzy. 1923 [1990]. \"On the Application of Probability Theory to AgriculturalExperiments. Essay on Principles. Section 9.\" <i>Statistical Science</i> 5 (4): 465\u2013472. Trans. <a href=\"/wiki/Dorota_Dabrowska\" title=\"Dorota Dabrowska\">Dorota M. Dabrowska</a> and Terence P. Speed.</span>\n</li>\n<li id=\"cite_note-35\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-35\">^</a></b></span> <span class=\"reference-text\">Hinkelmann &amp; Kempthorne (2008)<sup class=\"noprint Inline-Template\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citing_sources\" title=\"Wikipedia:Citing sources\"><span title=\"This citation requires a reference to the specific page or range of pages in which the material appears. (June 2011)\">page&#160;needed</span></a></i>&#93;</sup></span>\n</li>\n<li id=\"cite_note-36\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-36\">^</a></b></span> <span class=\"reference-text\">Hinkelmann and Kempthorne (2008) Chapter 6.</span>\n</li>\n<li id=\"cite_note-37\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-37\">^</a></b></span> <span class=\"reference-text\">Bandyopadhyay &amp; Forster (2011). The quote is taken from the book's Introduction (p.3).  See also \"Section&#160;III: Four Paradigms of Statistics\".</span>\n</li>\n<li id=\"cite_note-38\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-38\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\"><a href=\"/wiki/Jerzy_Neyman\" title=\"Jerzy Neyman\">Neyman, J.</a> (1937). \"Outline of a Theory of Statistical Estimation Based on the Classical Theory of Probability\". <i>Philosophical Transactions of the Royal Society of London A</i>. <b>236</b> (767): 333\u2013380. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1098/rsta.1937.0005\">10.1098/rsta.1937.0005</a>. <a href=\"/wiki/JSTOR\" title=\"JSTOR\">JSTOR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.jstor.org/stable/91337\">91337</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+of+London+A&amp;rft.atitle=Outline+of+a+Theory+of+Statistical+Estimation+Based+on+the+Classical+Theory+of+Probability&amp;rft.volume=236&amp;rft.issue=767&amp;rft.pages=333-380&amp;rft.date=1937&amp;rft_id=info%3Adoi%2F10.1098%2Frsta.1937.0005&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F91337&amp;rft.aulast=Neyman&amp;rft.aufirst=J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-39\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-39\">^</a></b></span> <span class=\"reference-text\">Preface to Pfanzagl.</span>\n</li>\n<li id=\"cite_note-Soofi_2000_1349\u20131353-40\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Soofi_2000_1349\u20131353_40-0\">^</a></b></span> <span class=\"reference-text\">Soofi (2000)</span>\n</li>\n<li id=\"cite_note-HY-41\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-HY_41-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-HY_41-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Hansen &amp; Yu (2001)</span>\n</li>\n<li id=\"cite_note-HY747-42\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-HY747_42-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-HY747_42-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Hansen and Yu (2001), page 747.</span>\n</li>\n<li id=\"cite_note-JR-43\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-JR_43-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-JR_43-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Rissanen (1989), page 84</span>\n</li>\n<li id=\"cite_note-44\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-44\">^</a></b></span> <span class=\"reference-text\">Joseph F. Traub, G. W. Wasilkowski, and H. Wozniakowski. (1988)<sup class=\"noprint Inline-Template\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citing_sources\" title=\"Wikipedia:Citing sources\"><span title=\"This citation requires a reference to the specific page or range of pages in which the material appears. (June 2011)\">page&#160;needed</span></a></i>&#93;</sup></span>\n</li>\n<li id=\"cite_note-45\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-45\">^</a></b></span> <span class=\"reference-text\">Neyman (1956)</span>\n</li>\n<li id=\"cite_note-46\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-46\">^</a></b></span> <span class=\"reference-text\">Zabell (1992)</span>\n</li>\n<li id=\"cite_note-47\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-47\">^</a></b></span> <span class=\"reference-text\">Cox (2006) page 66</span>\n</li>\n<li id=\"cite_note-FOOTNOTEHampel2003-48\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-FOOTNOTEHampel2003_48-0\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFHampel2003\">Hampel 2003</a>.</span>\n</li>\n<li id=\"cite_note-49\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-49\">^</a></b></span> <span class=\"reference-text\">Davison, page 12.<sup class=\"noprint Inline-Template\" style=\"white-space:nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Citing_sources#What_information_to_include\" title=\"Wikipedia:Citing sources\"><span title=\"A complete citation is needed (November 2012)\">full citation needed</span></a></i>&#93;</sup></span>\n</li>\n<li id=\"cite_note-50\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-50\">^</a></b></span> <span class=\"reference-text\">Barnard, G.A. (1995) \"Pivotal Models and the Fiducial Argument\", International Statistical Review, 63 (3), 309\u2013323. <a href=\"/wiki/JSTOR\" title=\"JSTOR\">JSTOR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"https://www.jstor.org/stable/1403482\">1403482</a></span>\n</li>\n</ol></div></div>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=24\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><cite id=\"CITEREFBandyopadhyayForster2011\" class=\"citation\">Bandyopadhyay, P. S.; Forster, M. R., eds. (2011), <i>Philosophy of Statistics</i>, <a href=\"/wiki/Elsevier\" title=\"Elsevier\">Elsevier</a></cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Philosophy+of+Statistics&amp;rft.pub=Elsevier&amp;rft.date=2011&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span>.</li>\n<li><cite class=\"citation book\">Bickel, Peter J.; Doksum, Kjell A. (2001). <i>Mathematical statistics: Basic and selected topics</i>. <b>1</b> (Second (updated printing 2007) ed.). <a href=\"/wiki/Prentice_Hall\" title=\"Prentice Hall\">Prentice Hall</a>. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-13-850363-X\" title=\"Special:BookSources/0-13-850363-X\">0-13-850363-X</a>. <a href=\"/wiki/Mathematical_Reviews\" title=\"Mathematical Reviews\">MR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ams.org/mathscinet-getitem?mr=0443141\">0443141</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mathematical+statistics%3A+Basic+and+selected+topics&amp;rft.edition=Second+%28updated+printing+2007%29&amp;rft.pub=Prentice+Hall&amp;rft.date=2001&amp;rft.isbn=0-13-850363-X&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D443141&amp;rft.aulast=Bickel&amp;rft.aufirst=Peter+J.&amp;rft.au=Doksum%2C+Kjell+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><a href=\"/wiki/David_R._Cox\" class=\"mw-redirect\" title=\"David R. Cox\">Cox, D. R.</a> (2006). <i>Principles of Statistical Inference</i>, <a href=\"/wiki/Cambridge_University_Press\" title=\"Cambridge University Press\">Cambridge University Press</a>. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-521-68567-2\" title=\"Special:BookSources/0-521-68567-2\">0-521-68567-2</a>.</li>\n<li><a href=\"/wiki/Ronald_A._Fisher\" class=\"mw-redirect\" title=\"Ronald A. Fisher\">Fisher, R. A.</a> (1955), \"Statistical methods and scientific induction\", <i><a href=\"/wiki/Journal_of_the_Royal_Statistical_Society\" title=\"Journal of the Royal Statistical Society\">Journal of the Royal Statistical Society</a>, Series B</i>, 17, 69\u201478. (criticism of statistical theories of <a href=\"/wiki/Jerzy_Neyman\" title=\"Jerzy Neyman\">Jerzy Neyman</a> and <a href=\"/wiki/Abraham_Wald\" title=\"Abraham Wald\">Abraham Wald</a>)</li>\n<li><cite class=\"citation book\"><a href=\"/wiki/David_A._Freedman\" title=\"David A. Freedman\">Freedman, D. A.</a> (2009). <i>Statistical Models: Theory and practice</i> (revised ed.). <a href=\"/wiki/Cambridge_University_Press\" title=\"Cambridge University Press\">Cambridge University Press</a>. pp.&#160;xiv+442 pp. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-0-521-74385-3\" title=\"Special:BookSources/978-0-521-74385-3\">978-0-521-74385-3</a>. <a href=\"/wiki/Mathematical_Reviews\" title=\"Mathematical Reviews\">MR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ams.org/mathscinet-getitem?mr=2489600\">2489600</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Statistical+Models%3A+Theory+and+practice&amp;rft.pages=xiv%2B442+pp.&amp;rft.edition=revised&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2009&amp;rft.isbn=978-0-521-74385-3&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D2489600&amp;rft.aulast=Freedman&amp;rft.aufirst=D.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><a href=\"/wiki/David_A._Freedman\" title=\"David A. Freedman\">Freedman, D. A.</a> (2010). <i>Statistical Models and Causal Inferences: A Dialogue with the Social Sciences</i> (Edited by David Collier, Jasjeet S. Sekhon, and Philip B. Stark), <a href=\"/wiki/Cambridge_University_Press\" title=\"Cambridge University Press\">Cambridge University Press</a>.</li>\n<li><cite id=\"CITEREFHampel2003\" class=\"citation journal\">Hampel, Frank (Feb 2003). <a rel=\"nofollow\" class=\"external text\" href=\"http://e-collection.library.ethz.ch/eserv/eth:26403/eth-26403-01.pdf\">\"The proper fiducial argument\"</a> <span style=\"font-size:85%;\">(PDF)</span> (Research Report No. 114)<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">29 March</span> 2016</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=The+proper+fiducial+argument&amp;rft.issue=Research+Report+No.+114&amp;rft.date=2003-02&amp;rft.aulast=Hampel&amp;rft.aufirst=Frank&amp;rft_id=http%3A%2F%2Fe-collection.library.ethz.ch%2Feserv%2Feth%3A26403%2Feth-26403-01.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation journal\">Hansen, Mark H.; <a href=\"/wiki/Bin_Yu\" title=\"Bin Yu\">Yu, Bin</a> (June 2001). <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20041116080440/http://www.stat.berkeley.edu/webmastr/users/binyu/ps/mdl.ps\">\"Model Selection and the Principle of Minimum Description Length: Review paper\"</a>. <i><a href=\"/wiki/Journal_of_the_American_Statistical_Association\" title=\"Journal of the American Statistical Association\">Journal of the American Statistical Association</a></i>. <b>96</b> (454): 746\u2013774. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1198/016214501753168398\">10.1198/016214501753168398</a>. <a href=\"/wiki/JSTOR\" title=\"JSTOR\">JSTOR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.jstor.org/stable/2670311\">2670311</a>. <a href=\"/wiki/Mathematical_Reviews\" title=\"Mathematical Reviews\">MR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ams.org/mathscinet-getitem?mr=1939352\">1939352</a>. Archived from <a rel=\"nofollow\" class=\"external text\" href=\"http://www.stat.berkeley.edu/webmastr/users/binyu/ps/mdl.ps\">the original</a> on 2004-11-16.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Model+Selection+and+the+Principle+of+Minimum+Description+Length%3A+Review+paper&amp;rft.volume=96&amp;rft.issue=454&amp;rft.pages=746-774&amp;rft.date=2001-06&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D1939352&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2670311&amp;rft_id=info%3Adoi%2F10.1198%2F016214501753168398&amp;rft.aulast=Hansen&amp;rft.aufirst=Mark+H.&amp;rft.au=Yu%2C+Bin&amp;rft_id=http%3A%2F%2Fwww.stat.berkeley.edu%2Fwebmastr%2Fusers%2Fbinyu%2Fps%2Fmdl.ps&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation book\">Hinkelmann, Klaus; <a href=\"/wiki/Oscar_Kempthorne\" title=\"Oscar Kempthorne\">Kempthorne, Oscar</a> (2008). <a rel=\"nofollow\" class=\"external text\" href=\"https://books.google.com/?id=T3wWj2kVYZgC&amp;printsec=frontcover\"><i>Introduction to Experimental Design</i></a> (Second ed.). Wiley. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-0-471-72756-9\" title=\"Special:BookSources/978-0-471-72756-9\">978-0-471-72756-9</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction+to+Experimental+Design&amp;rft.edition=Second&amp;rft.pub=Wiley&amp;rft.date=2008&amp;rft.isbn=978-0-471-72756-9&amp;rft.aulast=Hinkelmann&amp;rft.aufirst=Klaus&amp;rft.au=Kempthorne%2C+Oscar&amp;rft_id=https%3A%2F%2Fbooks.google.com%2F%3Fid%3DT3wWj2kVYZgC%26printsec%3Dfrontcover&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation journal\"><a href=\"/wiki/Andrei_N._Kolmogorov\" class=\"mw-redirect\" title=\"Andrei N. Kolmogorov\">Kolmogorov, Andrei N.</a> (1963). \"On tables of random numbers\". <i><a href=\"/wiki/Sankhya_(journal)\" title=\"Sankhya (journal)\">Sankhy\u0101</a> Ser. A</i>. <b>25</b>: 369\u2013375. <a href=\"/wiki/Mathematical_Reviews\" title=\"Mathematical Reviews\">MR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ams.org/mathscinet-getitem?mr=0178484\">0178484</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Sankhy%C4%81+Ser.+A.&amp;rft.atitle=On+tables+of+random+numbers&amp;rft.volume=25&amp;rft.pages=369-375&amp;rft.date=1963&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D178484&amp;rft.aulast=Kolmogorov&amp;rft.aufirst=Andrei+N.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span>  Reprinted as  <cite class=\"citation journal\">Kolmogorov, Andrei N. (1998). \"On tables of random numbers\". <i><a href=\"/wiki/Theoretical_Computer_Science_(journal)\" title=\"Theoretical Computer Science (journal)\">Theoretical Computer Science</a></i>. <b>207</b> (2): 387\u2013395. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/S0304-3975%2898%2900075-9\">10.1016/S0304-3975(98)00075-9</a>. <a href=\"/wiki/Mathematical_Reviews\" title=\"Mathematical Reviews\">MR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ams.org/mathscinet-getitem?mr=1643414\">1643414</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Theoretical+Computer+Science&amp;rft.atitle=On+tables+of+random+numbers&amp;rft.volume=207&amp;rft.issue=2&amp;rft.pages=387-395&amp;rft.date=1998&amp;rft_id=info%3Adoi%2F10.1016%2FS0304-3975%2898%2900075-9&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D1643414&amp;rft.aulast=Kolmogorov&amp;rft.aufirst=Andrei+N.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li>Konishi S., Kitagawa G. (2008),  <i>Information Criteria and Statistical Modeling</i>, Springer.</li>\n<li><cite class=\"citation journal\"><a href=\"/wiki/William_Kruskal\" title=\"William Kruskal\">Kruskal, William</a> (December 1988). \"Miracles and statistics: the casual assumption of independence (ASA Presidential Address)\". <i><a href=\"/wiki/Journal_of_the_American_Statistical_Association\" title=\"Journal of the American Statistical Association\">Journal of the American Statistical Association</a></i>. <b>83</b> (404): 929\u2013940. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.2307/2290117\">10.2307/2290117</a>. <a href=\"/wiki/JSTOR\" title=\"JSTOR\">JSTOR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.jstor.org/stable/2290117\">2290117</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Miracles+and+statistics%3A+the+casual+assumption+of+independence+%28ASA+Presidential+Address%29&amp;rft.volume=83&amp;rft.issue=404&amp;rft.pages=929-940&amp;rft.date=1988-12&amp;rft_id=info%3Adoi%2F10.2307%2F2290117&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2290117&amp;rft.aulast=Kruskal&amp;rft.aufirst=William&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><a href=\"/wiki/Lucien_Le_Cam\" title=\"Lucien Le Cam\">Le Cam, Lucian</a>. (1986) <i>Asymptotic Methods of Statistical Decision Theory</i>, Springer. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-387-96307-3\" title=\"Special:BookSources/0-387-96307-3\">0-387-96307-3</a></li>\n<li><a href=\"/wiki/David_S._Moore\" title=\"David S. Moore\">Moore, D. S.</a>; McCabe, G. P.; Craig, B. A. (2015), <i>Introduction to the Practice of Statistics</i>, Eighth Edition, Macmillan.</li>\n<li><cite class=\"citation journal\"><a href=\"/wiki/Jerzy_Neyman\" title=\"Jerzy Neyman\">Neyman, Jerzy</a> (1956). \"Note on an article by Sir Ronald Fisher\". <i><a href=\"/wiki/Journal_of_the_Royal_Statistical_Society,_Series_B\" class=\"mw-redirect\" title=\"Journal of the Royal Statistical Society, Series B\">Journal of the Royal Statistical Society, Series B</a></i>. <b>18</b> (2): 288\u2013294. <a href=\"/wiki/JSTOR\" title=\"JSTOR\">JSTOR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.jstor.org/stable/2983716\">2983716</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Royal+Statistical+Society%2C+Series+B&amp;rft.atitle=Note+on+an+article+by+Sir+Ronald+Fisher&amp;rft.volume=18&amp;rft.issue=2&amp;rft.pages=288-294&amp;rft.date=1956&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2983716&amp;rft.aulast=Neyman&amp;rft.aufirst=Jerzy&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span> (reply to Fisher 1955)</li>\n<li><a href=\"/wiki/Charles_Sanders_Peirce\" title=\"Charles Sanders Peirce\">Peirce, C. S.</a> (1877\u20131878), \"Illustrations of the logic of science\" (series), <i><a href=\"/wiki/Popular_Science_Monthly\" class=\"mw-redirect\" title=\"Popular Science Monthly\">Popular Science Monthly</a></i>, vols. 12-13. Relevant individual papers:\n<ul><li>(1878 March), \"The Doctrine of Chances\", <i>Popular Science Monthly</i>, v. 12, March issue, pp. <a rel=\"nofollow\" class=\"external text\" href=\"https://books.google.com/books?id=ZKMVAAAAYAAJ&amp;jtp=604\">604</a>\u2013615.  <i>Internet Archive</i> <a rel=\"nofollow\" class=\"external text\" href=\"https://archive.org/stream/popscimonthly12yoummiss#page/612/mode/1up\">Eprint</a>.</li>\n<li>(1878 April), \"The Probability of Induction\", <i>Popular Science Monthly</i>, v. 12, pp. <a rel=\"nofollow\" class=\"external text\" href=\"https://books.google.com/books?id=ZKMVAAAAYAAJ&amp;jtp=705\">705</a>\u2013718. <i>Internet Archive</i> <a rel=\"nofollow\" class=\"external text\" href=\"https://archive.org/stream/popscimonthly12yoummiss#page/715/mode/1up\">Eprint</a>.</li>\n<li>(1878 June), \"The Order of Nature\", <i>Popular Science Monthly</i>, v. 13, pp. <a rel=\"nofollow\" class=\"external text\" href=\"https://books.google.com/books?id=u8sWAQAAIAAJ&amp;jtp=203\">203</a>\u2013217.<i>Internet Archive</i> <a rel=\"nofollow\" class=\"external text\" href=\"https://archive.org/stream/popularsciencemo13newy#page/203/mode/1up\">Eprint</a>.</li>\n<li>(1878 August), \"Deduction, Induction, and Hypothesis\", <i>Popular Science Monthly</i>, v. 13, pp. <a rel=\"nofollow\" class=\"external text\" href=\"https://books.google.com/books?id=u8sWAQAAIAAJ&amp;jtp=470\">470</a>\u2013482. <i>Internet Archive</i> <a rel=\"nofollow\" class=\"external text\" href=\"https://archive.org/stream/popularsciencemo13newy#page/470/mode/1up\">Eprint</a>.</li></ul></li>\n<li><a href=\"/wiki/Charles_Sanders_Peirce\" title=\"Charles Sanders Peirce\">Peirce, C. S.</a> (1883), \"A Theory of probable inference\", <i>Studies in Logic</i>, pp. <a rel=\"nofollow\" class=\"external text\" href=\"https://books.google.com/books?id=V7oIAAAAQAAJ&amp;pg=PA126\">126-181</a>, Little, Brown, and Company. (Reprinted 1983, <a href=\"/wiki/John_Benjamins_Publishing_Company\" title=\"John Benjamins Publishing Company\">John Benjamins Publishing Company</a>, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/90-272-3271-7\" title=\"Special:BookSources/90-272-3271-7\">90-272-3271-7</a>)</li>\n<li><cite class=\"citation book\">Pfanzagl, Johann; with the assistance of R. Hamb\u00f6ker (1994). <i>Parametric Statistical Theory</i>. Berlin: <a href=\"/wiki/Walter_de_Gruyter\" title=\"Walter de Gruyter\">Walter de Gruyter</a>. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/3-11-013863-8\" title=\"Special:BookSources/3-11-013863-8\">3-11-013863-8</a>. <a href=\"/wiki/Mathematical_Reviews\" title=\"Mathematical Reviews\">MR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ams.org/mathscinet-getitem?mr=1291393\">1291393</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Parametric+Statistical+Theory&amp;rft.place=Berlin&amp;rft.pub=Walter+de+Gruyter&amp;rft.date=1994&amp;rft.isbn=3-11-013863-8&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D1291393&amp;rft.aulast=Pfanzagl&amp;rft.aufirst=Johann&amp;rft.au=with+the+assistance+of+R.+Hamb%C3%B6ker&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation book\"><a href=\"/wiki/Jorma_Rissanen\" title=\"Jorma Rissanen\">Rissanen, Jorma</a> (1989). <i>Stochastic Complexity in Statistical Inquiry</i>. Series in Computer Science. <b>15</b>. Singapore: <a href=\"/wiki/World_Scientific\" title=\"World Scientific\">World Scientific</a>. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/9971-5-0859-1\" title=\"Special:BookSources/9971-5-0859-1\">9971-5-0859-1</a>. <a href=\"/wiki/Mathematical_Reviews\" title=\"Mathematical Reviews\">MR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ams.org/mathscinet-getitem?mr=1082556\">1082556</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Stochastic+Complexity+in+Statistical+Inquiry&amp;rft.place=Singapore&amp;rft.series=Series+in+Computer+Science&amp;rft.pub=World+Scientific&amp;rft.date=1989&amp;rft.isbn=9971-5-0859-1&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D1082556&amp;rft.aulast=Rissanen&amp;rft.aufirst=Jorma&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation journal\">Soofi, Ehsan S. (December 2000). \"Principal information-theoretic approaches (Vignettes for the Year 2000: Theory and Methods, ed. by George Casella)\". <i><a href=\"/wiki/Journal_of_the_American_Statistical_Association\" title=\"Journal of the American Statistical Association\">Journal of the American Statistical Association</a></i>. <b>95</b> (452): 1349\u20131353. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1080/01621459.2000.10474346\">10.1080/01621459.2000.10474346</a>. <a href=\"/wiki/JSTOR\" title=\"JSTOR\">JSTOR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.jstor.org/stable/2669786\">2669786</a>. <a href=\"/wiki/Mathematical_Reviews\" title=\"Mathematical Reviews\">MR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ams.org/mathscinet-getitem?mr=1825292\">1825292</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Principal+information-theoretic+approaches+%28Vignettes+for+the+Year+2000%3A+Theory+and+Methods%2C+ed.+by+George+Casella%29&amp;rft.volume=95&amp;rft.issue=452&amp;rft.pages=1349-1353&amp;rft.date=2000-12&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D1825292&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2669786&amp;rft_id=info%3Adoi%2F10.1080%2F01621459.2000.10474346&amp;rft.aulast=Soofi&amp;rft.aufirst=Ehsan+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation book\"><a href=\"/wiki/Joseph_F._Traub\" title=\"Joseph F. Traub\">Traub, Joseph F.</a>; Wasilkowski, G. W.; Wozniakowski, H. (1988). <i>Information-Based Complexity</i>. Academic Press. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-12-697545-0\" title=\"Special:BookSources/0-12-697545-0\">0-12-697545-0</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Information-Based+Complexity&amp;rft.pub=Academic+Press&amp;rft.date=1988&amp;rft.isbn=0-12-697545-0&amp;rft.aulast=Traub&amp;rft.aufirst=Joseph+F.&amp;rft.au=Wasilkowski%2C+G.+W.&amp;rft.au=Wozniakowski%2C+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation journal\">Zabell, S. L. (Aug 1992). \"R. A. Fisher and Fiducial Argument\". <i>Statistical Science</i>. <b>7</b> (3): 369\u2013387. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1214/ss/1177011233\">10.1214/ss/1177011233</a>. <a href=\"/wiki/JSTOR\" title=\"JSTOR\">JSTOR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.jstor.org/stable/2246073\">2246073</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Statistical+Science&amp;rft.atitle=R.+A.+Fisher+and+Fiducial+Argument&amp;rft.volume=7&amp;rft.issue=3&amp;rft.pages=369-387&amp;rft.date=1992-08&amp;rft_id=info%3Adoi%2F10.1214%2Fss%2F1177011233&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2246073&amp;rft.aulast=Zabell&amp;rft.aufirst=S.+L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li></ul>\n<h2><span class=\"mw-headline\" id=\"Further_reading\">Further reading</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=25\" title=\"Edit section: Further reading\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a href=\"/wiki/George_Casella\" title=\"George Casella\">Casella, G.</a>, Berger, R.L. (2001). <i>Statistical Inference</i>. Duxbury Press. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-534-24312-6\" title=\"Special:BookSources/0-534-24312-6\">0-534-24312-6</a></li>\n<li><cite class=\"citation journal\"><a href=\"/wiki/David_A._Freedman\" title=\"David A. Freedman\">Freedman, D.A.</a> (1991). \"Statistical models and shoe leather\". <i>Sociological Methodology</i>. <b>21</b>: 291\u2013313. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.2307/270939\">10.2307/270939</a>. <a href=\"/wiki/JSTOR\" title=\"JSTOR\">JSTOR</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.jstor.org/stable/270939\">270939</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Sociological+Methodology&amp;rft.atitle=Statistical+models+and+shoe+leather&amp;rft.volume=21&amp;rft.pages=291-313&amp;rft.date=1991&amp;rft_id=info%3Adoi%2F10.2307%2F270939&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F270939&amp;rft.aulast=Freedman&amp;rft.aufirst=D.A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li>Held L., Bov\u00e9 D.S. (2014). <i>Applied Statistical Inference&#8212;Likelihood and Bayes</i> (Springer).</li>\n<li><cite class=\"citation journal\">Lenhard, Johannes (2006). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.stats.org.uk/statistical-inference/Lenhard2006.pdf\">\"Models and Statistical Inference: the controversy between Fisher and Neyman&#8211;Pearson\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i><a href=\"/wiki/British_Journal_for_the_Philosophy_of_Science\" title=\"British Journal for the Philosophy of Science\">British Journal for the Philosophy of Science</a></i>. <b>57</b>: 69\u201391. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1093/bjps/axi152\">10.1093/bjps/axi152</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=British+Journal+for+the+Philosophy+of+Science&amp;rft.atitle=Models+and+Statistical+Inference%3A+the+controversy+between+Fisher+and+Neyman%26ndash%3BPearson&amp;rft.volume=57&amp;rft.pages=69-91&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1093%2Fbjps%2Faxi152&amp;rft.aulast=Lenhard&amp;rft.aufirst=Johannes&amp;rft_id=http%3A%2F%2Fwww.stats.org.uk%2Fstatistical-inference%2FLenhard2006.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation journal\">Lindley, D (1958). \"Fiducial distribution and Bayes' theorem\". <i><a href=\"/wiki/Journal_of_the_Royal_Statistical_Society\" title=\"Journal of the Royal Statistical Society\">Journal of the Royal Statistical Society</a>, Series B</i>. <b>20</b>: 102\u20137.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Royal+Statistical+Society%2C+Series+B&amp;rft.atitle=Fiducial+distribution+and+Bayes%27+theorem&amp;rft.volume=20&amp;rft.pages=102-7&amp;rft.date=1958&amp;rft.aulast=Lindley&amp;rft.aufirst=D&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li>Rahlf, Thomas (2014). \"Statistical Inference\", in Claude Diebolt, and Michael Haupert (eds.), \"Handbook of Cliometrics ( Springer Reference Series)\", Berlin/Heidelberg: Springer. <a rel=\"nofollow\" class=\"external free\" href=\"http://www.springerreference.com/docs/html/chapterdbid/372458.html\">http://www.springerreference.com/docs/html/chapterdbid/372458.html</a></li>\n<li><cite class=\"citation journal\">Reid, N.; Cox, D. R. (2014). \"On Some Principles of Statistical Inference\". <i>International Statistical Review</i>. <b>83</b> (2): n/a. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1111/insr.12067\">10.1111/insr.12067</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Statistical+Review&amp;rft.atitle=On+Some+Principles+of+Statistical+Inference&amp;rft.volume=83&amp;rft.issue=2&amp;rft.pages=n%2Fa&amp;rft.date=2014&amp;rft_id=info%3Adoi%2F10.1111%2Finsr.12067&amp;rft.aulast=Reid&amp;rft.aufirst=N.&amp;rft.au=Cox%2C+D.+R.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+inference\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li>Young, G.A., Smith, R.L. (2005). <i>Essentials of Statistical Inference</i>, CUP. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-521-83971-8\" title=\"Special:BookSources/0-521-83971-8\">0-521-83971-8</a></li></ul>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Statistical_inference&amp;action=edit&amp;section=26\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<table role=\"presentation\" class=\"mbox-small plainlinks sistersitebox\" style=\"background-color:#f9f9f9;border:1px solid #aaa;color:#000\">\n<tbody><tr>\n<td class=\"mbox-image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png\" width=\"30\" height=\"40\" class=\"noviewer\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/45px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/59px-Commons-logo.svg.png 2x\" data-file-width=\"1024\" data-file-height=\"1376\" /></td>\n<td class=\"mbox-text plainlist\">Wikimedia Commons has media related to <i><b><a href=\"https://commons.wikimedia.org/wiki/Category:Statistical_inference\" class=\"extiw\" title=\"commons:Category:Statistical inference\">Statistical inference</a></b></i>.</td></tr></tbody></table>\n<table role=\"presentation\" class=\"mbox-small plainlinks sistersitebox\" style=\"background-color:#f9f9f9;border:1px solid #aaa;color:#000\">\n<tbody><tr>\n<td class=\"mbox-image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/91/Wikiversity-logo.svg/40px-Wikiversity-logo.svg.png\" width=\"40\" height=\"32\" class=\"noviewer\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/91/Wikiversity-logo.svg/60px-Wikiversity-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/91/Wikiversity-logo.svg/80px-Wikiversity-logo.svg.png 2x\" data-file-width=\"1000\" data-file-height=\"800\" /></td>\n<td class=\"mbox-text plainlist\">Wikiversity has learning resources about <i><b><a href=\"https://en.wikiversity.org/wiki/Special:Search/Statistical_inference\" class=\"extiw\" title=\"v:Special:Search/Statistical inference\">Statistical inference</a></b></i></td></tr></tbody></table>\n<ul><li>MIT <a rel=\"nofollow\" class=\"external text\" href=\"http://dspace.mit.edu/handle/1721.1/45587\">OpenCourseWare</a>: Statistical Inference</li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://www.nptel.ac.in/courses/111105043/\">NPTEL Statistical Inference</a>, <a rel=\"nofollow\" class=\"external text\" href=\"https://www.youtube.com/playlist?list=PLbMVogVj5nJRkNUH5v9qNEJvW7r2A7rEY\">youtube link</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"https://www.academia.edu/3247833/\">Statistical induction and prediction</a></li></ul>\n<div style=\"clear:both;\"></div>\n<div role=\"navigation\" class=\"navbox\" aria-labelledby=\"Statistics\" style=\"padding:3px\"><table class=\"nowraplinks hlist collapsible uncollapsed navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\"><div class=\"plainlinks hlist navbar mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Statistics\" title=\"Template:Statistics\"><abbr title=\"View this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Statistics\" title=\"Template talk:Statistics\"><abbr title=\"Discuss this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Template:Statistics&amp;action=edit\"><abbr title=\"Edit this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">e</abbr></a></li></ul></div><div id=\"Statistics\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Statistics\" title=\"Statistics\">Statistics</a></div></th></tr><tr><td class=\"navbox-abovebelow\" colspan=\"2\"><div id=\"*_Outline&amp;#10;*_Index\">\n<ul><li><a href=\"/wiki/Outline_of_statistics\" title=\"Outline of statistics\">Outline</a></li>\n<li><a href=\"/wiki/List_of_statistics_articles\" title=\"List of statistics articles\">Index</a></li></ul>\n</div></td></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks collapsible collapsed navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\" style=\";\"><div id=\"Descriptive_statistics\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Descriptive_statistics\" title=\"Descriptive statistics\">Descriptive statistics</a></div></th></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Continuous_probability_distribution\" class=\"mw-redirect\" title=\"Continuous probability distribution\">Continuous data</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Central_tendency\" title=\"Central tendency\">Center</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Mean\" title=\"Mean\">Mean</a>\n<ul><li><a href=\"/wiki/Arithmetic_mean\" title=\"Arithmetic mean\">arithmetic</a></li>\n<li><a href=\"/wiki/Geometric_mean\" title=\"Geometric mean\">geometric</a></li>\n<li><a href=\"/wiki/Harmonic_mean\" title=\"Harmonic mean\">harmonic</a></li></ul></li>\n<li><a href=\"/wiki/Median\" title=\"Median\">Median</a></li>\n<li><a href=\"/wiki/Mode_(statistics)\" title=\"Mode (statistics)\">Mode</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Statistical_dispersion\" title=\"Statistical dispersion\">Dispersion</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Variance#Sample_variance\" title=\"Variance\">Variance</a></li>\n<li><a href=\"/wiki/Standard_deviation\" title=\"Standard deviation\">Standard deviation</a></li>\n<li><a href=\"/wiki/Coefficient_of_variation\" title=\"Coefficient of variation\">Coefficient of variation</a></li>\n<li><a href=\"/wiki/Percentile\" title=\"Percentile\">Percentile</a></li>\n<li><a href=\"/wiki/Range_(statistics)\" title=\"Range (statistics)\">Range</a></li>\n<li><a href=\"/wiki/Interquartile_range\" title=\"Interquartile range\">Interquartile range</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Shape_of_the_distribution\" class=\"mw-redirect\" title=\"Shape of the distribution\">Shape</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Central_limit_theorem\" title=\"Central limit theorem\">Central limit theorem</a></li>\n<li><a href=\"/wiki/Moment_(mathematics)\" title=\"Moment (mathematics)\">Moments</a>\n<ul><li><a href=\"/wiki/Skewness\" title=\"Skewness\">Skewness</a></li>\n<li><a href=\"/wiki/Kurtosis\" title=\"Kurtosis\">Kurtosis</a></li>\n<li><a href=\"/wiki/L-moment\" title=\"L-moment\">L-moments</a></li></ul></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Count_data\" title=\"Count data\">Count data</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Index_of_dispersion\" title=\"Index of dispersion\">Index of dispersion</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\">Summary tables</th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Grouped_data\" title=\"Grouped data\">Grouped data</a></li>\n<li><a href=\"/wiki/Frequency_distribution\" title=\"Frequency distribution\">Frequency distribution</a></li>\n<li><a href=\"/wiki/Contingency_table\" title=\"Contingency table\">Contingency table</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Correlation_and_dependence\" title=\"Correlation and dependence\">Dependence</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Pearson_correlation_coefficient\" title=\"Pearson correlation coefficient\">Pearson product-moment correlation</a></li>\n<li><a href=\"/wiki/Rank_correlation\" title=\"Rank correlation\">Rank correlation</a>\n<ul><li><a href=\"/wiki/Spearman%27s_rank_correlation_coefficient\" title=\"Spearman&#39;s rank correlation coefficient\">Spearman's rho</a></li>\n<li><a href=\"/wiki/Kendall_rank_correlation_coefficient\" title=\"Kendall rank correlation coefficient\">Kendall's tau</a></li></ul></li>\n<li><a href=\"/wiki/Partial_correlation\" title=\"Partial correlation\">Partial correlation</a></li>\n<li><a href=\"/wiki/Scatter_plot\" title=\"Scatter plot\">Scatter plot</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Statistical_graphics\" title=\"Statistical graphics\">Graphics</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Bar_chart\" title=\"Bar chart\">Bar chart</a></li>\n<li><a href=\"/wiki/Biplot\" title=\"Biplot\">Biplot</a></li>\n<li><a href=\"/wiki/Box_plot\" title=\"Box plot\">Box plot</a></li>\n<li><a href=\"/wiki/Control_chart\" title=\"Control chart\">Control chart</a></li>\n<li><a href=\"/wiki/Correlogram\" title=\"Correlogram\">Correlogram</a></li>\n<li><a href=\"/wiki/Fan_chart_(statistics)\" title=\"Fan chart (statistics)\">Fan chart</a></li>\n<li><a href=\"/wiki/Forest_plot\" title=\"Forest plot\">Forest plot</a></li>\n<li><a href=\"/wiki/Histogram\" title=\"Histogram\">Histogram</a></li>\n<li><a href=\"/wiki/Pie_chart\" title=\"Pie chart\">Pie chart</a></li>\n<li><a href=\"/wiki/Q%E2%80%93Q_plot\" title=\"Q\u2013Q plot\">Q\u2013Q plot</a></li>\n<li><a href=\"/wiki/Run_chart\" title=\"Run chart\">Run chart</a></li>\n<li><a href=\"/wiki/Scatter_plot\" title=\"Scatter plot\">Scatter plot</a></li>\n<li><a href=\"/wiki/Stem-and-leaf_display\" title=\"Stem-and-leaf display\">Stem-and-leaf display</a></li>\n<li><a href=\"/wiki/Radar_chart\" title=\"Radar chart\">Radar chart</a></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks collapsible collapsed navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\" style=\";\"><div id=\"Data_collection\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Data_collection\" title=\"Data collection\">Data collection</a></div></th></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\">Study design</th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Population_(statistics)\" class=\"mw-redirect\" title=\"Population (statistics)\">Population</a></li>\n<li><a href=\"/wiki/Statistic\" title=\"Statistic\">Statistic</a></li>\n<li><a href=\"/wiki/Effect_size\" title=\"Effect size\">Effect size</a></li>\n<li><a href=\"/wiki/Statistical_power\" class=\"mw-redirect\" title=\"Statistical power\">Statistical power</a></li>\n<li><a href=\"/wiki/Sample_size_determination\" title=\"Sample size determination\">Sample size determination</a></li>\n<li><a href=\"/wiki/Missing_data\" title=\"Missing data\">Missing data</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Survey_methodology\" title=\"Survey methodology\">Survey methodology</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Sampling_(statistics)\" title=\"Sampling (statistics)\">Sampling</a>\n<ul><li><a href=\"/wiki/Stratified_sampling\" title=\"Stratified sampling\">stratified</a></li>\n<li><a href=\"/wiki/Cluster_sampling\" title=\"Cluster sampling\">cluster</a></li></ul></li>\n<li><a href=\"/wiki/Standard_error\" title=\"Standard error\">Standard error</a></li>\n<li><a href=\"/wiki/Opinion_poll\" title=\"Opinion poll\">Opinion poll</a></li>\n<li><a href=\"/wiki/Questionnaire\" title=\"Questionnaire\">Questionnaire</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Experiment\" title=\"Experiment\">Controlled experiments</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Design_of_experiments\" title=\"Design of experiments\">Design</a>\n<ul><li><a href=\"/wiki/Scientific_control\" title=\"Scientific control\">control</a></li>\n<li><a href=\"/wiki/Optimal_design\" title=\"Optimal design\">optimal</a></li></ul></li>\n<li><a href=\"/wiki/Randomized_controlled_trial\" title=\"Randomized controlled trial\">Controlled trial</a></li>\n<li><a href=\"/wiki/Randomized_experiment\" title=\"Randomized experiment\">Randomized</a></li>\n<li><a href=\"/wiki/Random_assignment\" title=\"Random assignment\">Random assignment</a></li>\n<li><a href=\"/wiki/Replication_(statistics)\" title=\"Replication (statistics)\">Replication</a></li>\n<li><a href=\"/wiki/Blocking_(statistics)\" title=\"Blocking (statistics)\">Blocking</a></li>\n<li><a href=\"/wiki/Interaction_(statistics)\" title=\"Interaction (statistics)\">Interaction</a></li>\n<li><a href=\"/wiki/Factorial_experiment\" title=\"Factorial experiment\">Factorial experiment</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\">Uncontrolled studies</th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Observational_study\" title=\"Observational study\">Observational study</a></li>\n<li><a href=\"/wiki/Natural_experiment\" title=\"Natural experiment\">Natural experiment</a></li>\n<li><a href=\"/wiki/Quasi-experiment\" title=\"Quasi-experiment\">Quasi-experiment</a></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks collapsible uncollapsed navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\" style=\";\"><div id=\"Statistical_inference\" style=\"font-size:114%;margin:0 4em\"><a class=\"mw-selflink selflink\">Statistical inference</a></div></th></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Statistical_theory\" title=\"Statistical theory\">Statistical theory</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Population_(statistics)\" class=\"mw-redirect\" title=\"Population (statistics)\">Population</a></li>\n<li><a href=\"/wiki/Statistic\" title=\"Statistic\">Statistic</a></li>\n<li><a href=\"/wiki/Probability_distribution\" title=\"Probability distribution\">Probability distribution</a></li>\n<li><a href=\"/wiki/Sampling_distribution\" title=\"Sampling distribution\">Sampling distribution</a>\n<ul><li><a href=\"/wiki/Order_statistic\" title=\"Order statistic\">Order statistic</a></li></ul></li>\n<li><a href=\"/wiki/Empirical_distribution_function\" title=\"Empirical distribution function\">Empirical distribution</a>\n<ul><li><a href=\"/wiki/Density_estimation\" title=\"Density estimation\">Density estimation</a></li></ul></li>\n<li><a href=\"/wiki/Statistical_model\" title=\"Statistical model\">Statistical model</a>\n<ul><li><a href=\"/wiki/Lp_space\" title=\"Lp space\">L<sup><i>p</i></sup> space</a></li></ul></li>\n<li><a href=\"/wiki/Statistical_parameter\" title=\"Statistical parameter\">Parameter</a>\n<ul><li><a href=\"/wiki/Location_parameter\" title=\"Location parameter\">location</a></li>\n<li><a href=\"/wiki/Scale_parameter\" title=\"Scale parameter\">scale</a></li>\n<li><a href=\"/wiki/Shape_parameter\" title=\"Shape parameter\">shape</a></li></ul></li>\n<li><a href=\"/wiki/Parametric_statistics\" title=\"Parametric statistics\">Parametric family</a>\n<ul><li><a href=\"/wiki/Likelihood_function\" title=\"Likelihood function\">Likelihood</a>&#160;<a href=\"/wiki/Monotone_likelihood_ratio\" title=\"Monotone likelihood ratio\"><span style=\"font-size:85%;\">(monotone)</span></a></li>\n<li><a href=\"/wiki/Location%E2%80%93scale_family\" title=\"Location\u2013scale family\">Location\u2013scale family</a></li>\n<li><a href=\"/wiki/Exponential_family\" title=\"Exponential family\">Exponential family</a></li></ul></li>\n<li><a href=\"/wiki/Completeness_(statistics)\" title=\"Completeness (statistics)\">Completeness</a></li>\n<li><a href=\"/wiki/Sufficient_statistic\" title=\"Sufficient statistic\">Sufficiency</a></li>\n<li><a href=\"/wiki/Plug-in_principle\" title=\"Plug-in principle\">Statistical functional</a>\n<ul><li><a href=\"/wiki/Bootstrapping_(statistics)\" title=\"Bootstrapping (statistics)\">Bootstrap</a></li>\n<li><a href=\"/wiki/U-statistic\" title=\"U-statistic\">U</a></li>\n<li><a href=\"/wiki/V-statistic\" title=\"V-statistic\">V</a></li></ul></li>\n<li><a href=\"/wiki/Optimal_decision\" title=\"Optimal decision\">Optimal decision</a>\n<ul><li><a href=\"/wiki/Loss_function\" title=\"Loss function\">loss function</a></li></ul></li>\n<li><a href=\"/wiki/Efficiency_(statistics)\" title=\"Efficiency (statistics)\">Efficiency</a></li>\n<li><a href=\"/wiki/Statistical_distance\" title=\"Statistical distance\">Statistical distance</a>\n<ul><li><a href=\"/wiki/Divergence_(statistics)\" title=\"Divergence (statistics)\">divergence</a></li></ul></li>\n<li><a href=\"/wiki/Asymptotic_theory_(statistics)\" title=\"Asymptotic theory (statistics)\">Asymptotics</a></li>\n<li><a href=\"/wiki/Robust_statistics\" title=\"Robust statistics\">Robustness</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Frequentist_inference\" title=\"Frequentist inference\">Frequentist inference</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Point_estimation\" title=\"Point estimation\">Point estimation</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Estimating_equations\" title=\"Estimating equations\">Estimating equations</a>\n<ul><li><a href=\"/wiki/Maximum_likelihood\" class=\"mw-redirect\" title=\"Maximum likelihood\">Maximum likelihood</a></li>\n<li><a href=\"/wiki/Method_of_moments_(statistics)\" title=\"Method of moments (statistics)\">Method of moments</a></li>\n<li><a href=\"/wiki/M-estimator\" title=\"M-estimator\">M-estimator</a></li>\n<li><a href=\"/wiki/Minimum_distance_estimation\" title=\"Minimum distance estimation\">Minimum distance</a></li></ul></li>\n<li><a href=\"/wiki/Bias_of_an_estimator\" title=\"Bias of an estimator\">Unbiased estimators</a>\n<ul><li><a href=\"/wiki/Minimum-variance_unbiased_estimator\" title=\"Minimum-variance unbiased estimator\">Mean-unbiased minimum-variance</a>\n<ul><li><a href=\"/wiki/Rao%E2%80%93Blackwell_theorem\" title=\"Rao\u2013Blackwell theorem\">Rao\u2013Blackwellization</a></li>\n<li><a href=\"/wiki/Lehmann%E2%80%93Scheff%C3%A9_theorem\" title=\"Lehmann\u2013Scheff\u00e9 theorem\">Lehmann\u2013Scheff\u00e9 theorem</a></li></ul></li>\n<li><a href=\"/wiki/Median-unbiased_estimator\" class=\"mw-redirect\" title=\"Median-unbiased estimator\">Median unbiased</a></li></ul></li>\n<li><a href=\"/wiki/Plug-in_principle\" title=\"Plug-in principle\">Plug-in</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Interval_estimation\" title=\"Interval estimation\">Interval estimation</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Confidence_interval\" title=\"Confidence interval\">Confidence interval</a></li>\n<li><a href=\"/wiki/Pivotal_quantity\" title=\"Pivotal quantity\">Pivot</a></li>\n<li><a href=\"/wiki/Likelihood_interval\" class=\"mw-redirect\" title=\"Likelihood interval\">Likelihood interval</a></li>\n<li><a href=\"/wiki/Prediction_interval\" title=\"Prediction interval\">Prediction interval</a></li>\n<li><a href=\"/wiki/Tolerance_interval\" title=\"Tolerance interval\">Tolerance interval</a></li>\n<li><a href=\"/wiki/Resampling_(statistics)\" title=\"Resampling (statistics)\">Resampling</a>\n<ul><li><a href=\"/wiki/Bootstrapping_(statistics)\" title=\"Bootstrapping (statistics)\">Bootstrap</a></li>\n<li><a href=\"/wiki/Jackknife_resampling\" title=\"Jackknife resampling\">Jackknife</a></li></ul></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Statistical_hypothesis_testing\" title=\"Statistical hypothesis testing\">Testing hypotheses</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/One-_and_two-tailed_tests\" title=\"One- and two-tailed tests\">1- &amp; 2-tails</a></li>\n<li><a href=\"/wiki/Power_(statistics)\" title=\"Power (statistics)\">Power</a>\n<ul><li><a href=\"/wiki/Uniformly_most_powerful_test\" title=\"Uniformly most powerful test\">Uniformly most powerful test</a></li></ul></li>\n<li><a href=\"/wiki/Permutation_test\" class=\"mw-redirect\" title=\"Permutation test\">Permutation test</a>\n<ul><li><a href=\"/wiki/Randomization_test\" class=\"mw-redirect\" title=\"Randomization test\">Randomization test</a></li></ul></li>\n<li><a href=\"/wiki/Multiple_comparisons\" class=\"mw-redirect\" title=\"Multiple comparisons\">Multiple comparisons</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Parametric_statistics\" title=\"Parametric statistics\">Parametric tests</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Likelihood-ratio_test\" title=\"Likelihood-ratio test\">Likelihood-ratio</a></li>\n<li><a href=\"/wiki/Wald_test\" title=\"Wald test\">Wald</a></li>\n<li><a href=\"/wiki/Score_test\" title=\"Score test\">Score</a></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\">Specific tests</th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><td colspan=\"2\" class=\"navbox-list navbox-even\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Z-test\" title=\"Z-test\"><i>Z</i>-test <span style=\"font-size:90%;\">(normal)</span></a></li>\n<li><a href=\"/wiki/Student%27s_t-test\" title=\"Student&#39;s t-test\">Student's <i>t</i>-test</a></li>\n<li><a href=\"/wiki/F-test\" title=\"F-test\"><i>F</i>-test</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Goodness_of_fit\" title=\"Goodness of fit\">Goodness of fit</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Chi-squared_test\" title=\"Chi-squared test\">Chi-squared</a></li>\n<li><a href=\"/wiki/G-test\" title=\"G-test\"><i>G</i>-test</a></li>\n<li><a href=\"/wiki/Kolmogorov%E2%80%93Smirnov_test\" title=\"Kolmogorov\u2013Smirnov test\">Kolmogorov\u2013Smirnov</a></li>\n<li><a href=\"/wiki/Anderson%E2%80%93Darling_test\" title=\"Anderson\u2013Darling test\">Anderson\u2013Darling</a></li>\n<li><a href=\"/wiki/Lilliefors_test\" title=\"Lilliefors test\">Lilliefors</a></li>\n<li><a href=\"/wiki/Jarque%E2%80%93Bera_test\" title=\"Jarque\u2013Bera test\">Jarque\u2013Bera</a></li>\n<li><a href=\"/wiki/Shapiro%E2%80%93Wilk_test\" title=\"Shapiro\u2013Wilk test\">Normality <span style=\"font-size:90%;\">(Shapiro\u2013Wilk)</span></a></li>\n<li><a href=\"/wiki/Likelihood-ratio_test\" title=\"Likelihood-ratio test\">Likelihood-ratio test</a></li>\n<li><a href=\"/wiki/Model_selection\" title=\"Model selection\">Model selection</a>\n<ul><li><a href=\"/wiki/Cross-validation_(statistics)\" title=\"Cross-validation (statistics)\">Cross validation</a></li>\n<li><a href=\"/wiki/Akaike_information_criterion\" title=\"Akaike information criterion\">AIC</a></li>\n<li><a href=\"/wiki/Bayesian_information_criterion\" title=\"Bayesian information criterion\">BIC</a></li></ul></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Rank_statistics\" class=\"mw-redirect\" title=\"Rank statistics\">Rank statistics</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Sign_test\" title=\"Sign test\">Sign</a>\n<ul><li><a href=\"/wiki/Sample_median\" class=\"mw-redirect\" title=\"Sample median\">Sample median</a></li></ul></li>\n<li><a href=\"/wiki/Wilcoxon_signed-rank_test\" title=\"Wilcoxon signed-rank test\">Signed rank <span style=\"font-size:90%;\">(Wilcoxon)</span></a>\n<ul><li><a href=\"/wiki/Hodges%E2%80%93Lehmann_estimator\" title=\"Hodges\u2013Lehmann estimator\">Hodges\u2013Lehmann estimator</a></li></ul></li>\n<li><a href=\"/wiki/Mann%E2%80%93Whitney_U_test\" title=\"Mann\u2013Whitney U test\">Rank sum <span style=\"font-size:90%;\">(Mann\u2013Whitney)</span></a></li>\n<li><a href=\"/wiki/Nonparametric_statistics\" title=\"Nonparametric statistics\">Nonparametric</a> <a href=\"/wiki/Analysis_of_variance\" title=\"Analysis of variance\">anova</a>\n<ul><li><a href=\"/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance\" title=\"Kruskal\u2013Wallis one-way analysis of variance\">1-way <span style=\"font-size:90%;\">(Kruskal\u2013Wallis)</span></a></li>\n<li><a href=\"/wiki/Friedman_test\" title=\"Friedman test\">2-way <span style=\"font-size:90%;\">(Friedman)</span></a></li>\n<li><a href=\"/wiki/Jonckheere%27s_trend_test\" title=\"Jonckheere&#39;s trend test\">Ordered alternative <span style=\"font-size:90%;\">(Jonckheere\u2013Terpstra)</span></a></li></ul></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Bayesian_inference\" title=\"Bayesian inference\">Bayesian inference</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Bayesian_probability\" title=\"Bayesian probability\">Bayesian probability</a>\n<ul><li><a href=\"/wiki/Prior_probability\" title=\"Prior probability\">prior</a></li>\n<li><a href=\"/wiki/Posterior_probability\" title=\"Posterior probability\">posterior</a></li></ul></li>\n<li><a href=\"/wiki/Credible_interval\" title=\"Credible interval\">Credible interval</a></li>\n<li><a href=\"/wiki/Bayes_factor\" title=\"Bayes factor\">Bayes factor</a></li>\n<li><a href=\"/wiki/Bayes_estimator\" title=\"Bayes estimator\">Bayesian estimator</a>\n<ul><li><a href=\"/wiki/Maximum_a_posteriori_estimation\" title=\"Maximum a posteriori estimation\">Maximum posterior estimator</a></li></ul></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks collapsible collapsed navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\" style=\";\"><div id=\"CorrelationRegression_analysis\" style=\"font-size:114%;margin:0 4em\"><div class=\"hlist hlist-separated\"><ul><li><a href=\"/wiki/Correlation_and_dependence\" title=\"Correlation and dependence\">Correlation</a></li><li><a href=\"/wiki/Regression_analysis\" title=\"Regression analysis\">Regression analysis</a></li></ul></div></div></th></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Correlation_and_dependence\" title=\"Correlation and dependence\">Correlation</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Pearson_product-moment_correlation_coefficient\" class=\"mw-redirect\" title=\"Pearson product-moment correlation coefficient\">Pearson product-moment</a></li>\n<li><a href=\"/wiki/Partial_correlation\" title=\"Partial correlation\">Partial correlation</a></li>\n<li><a href=\"/wiki/Confounding\" title=\"Confounding\">Confounding variable</a></li>\n<li><a href=\"/wiki/Coefficient_of_determination\" title=\"Coefficient of determination\">Coefficient of determination</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Regression_analysis\" title=\"Regression analysis\">Regression analysis</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Errors_and_residuals_in_statistics\" class=\"mw-redirect\" title=\"Errors and residuals in statistics\">Errors and residuals</a></li>\n<li><a href=\"/wiki/Regression_model_validation\" class=\"mw-redirect\" title=\"Regression model validation\">Regression model validation</a></li>\n<li><a href=\"/wiki/Mixed_model\" title=\"Mixed model\">Mixed effects models</a></li>\n<li><a href=\"/wiki/Simultaneous_equations_model\" title=\"Simultaneous equations model\">Simultaneous equations models</a></li>\n<li><a href=\"/wiki/Multivariate_adaptive_regression_splines\" title=\"Multivariate adaptive regression splines\">Multivariate adaptive regression splines (MARS)</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Linear_regression\" title=\"Linear regression\">Linear regression</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Simple_linear_regression\" title=\"Simple linear regression\">Simple linear regression</a></li>\n<li><a href=\"/wiki/Ordinary_least_squares\" title=\"Ordinary least squares\">Ordinary least squares</a></li>\n<li><a href=\"/wiki/General_linear_model\" title=\"General linear model\">General linear model</a></li>\n<li><a href=\"/wiki/Bayesian_linear_regression\" title=\"Bayesian linear regression\">Bayesian regression</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\">Non-standard predictors</th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Nonlinear_regression\" title=\"Nonlinear regression\">Nonlinear regression</a></li>\n<li><a href=\"/wiki/Nonparametric_regression\" title=\"Nonparametric regression\">Nonparametric</a></li>\n<li><a href=\"/wiki/Semiparametric_regression\" title=\"Semiparametric regression\">Semiparametric</a></li>\n<li><a href=\"/wiki/Isotonic_regression\" title=\"Isotonic regression\">Isotonic</a></li>\n<li><a href=\"/wiki/Robust_regression\" title=\"Robust regression\">Robust</a></li>\n<li><a href=\"/wiki/Heteroscedasticity\" title=\"Heteroscedasticity\">Heteroscedasticity</a></li>\n<li><a href=\"/wiki/Homoscedasticity\" title=\"Homoscedasticity\">Homoscedasticity</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Generalized_linear_model\" title=\"Generalized linear model\">Generalized linear model</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Exponential_family\" title=\"Exponential family\">Exponential families</a></li>\n<li><a href=\"/wiki/Logistic_regression\" title=\"Logistic regression\">Logistic <span style=\"font-size:90%;\">(Bernoulli)</span></a>&#160;/&#32;<a href=\"/wiki/Binomial_regression\" title=\"Binomial regression\">Binomial</a>&#160;/&#32;<a href=\"/wiki/Poisson_regression\" title=\"Poisson regression\">Poisson regressions</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Partition_of_sums_of_squares\" title=\"Partition of sums of squares\">Partition of variance</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Analysis_of_variance\" title=\"Analysis of variance\">Analysis of variance (ANOVA, anova)</a></li>\n<li><a href=\"/wiki/Analysis_of_covariance\" title=\"Analysis of covariance\">Analysis of covariance</a></li>\n<li><a href=\"/wiki/Multivariate_analysis_of_variance\" title=\"Multivariate analysis of variance\">Multivariate ANOVA</a></li>\n<li><a href=\"/wiki/Degrees_of_freedom_(statistics)\" title=\"Degrees of freedom (statistics)\">Degrees of freedom</a></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks collapsible collapsed navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\" style=\";\"><div id=\"Categorical_/_Multivariate_/_Time-series_/_Survival_analysis\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Categorical_variable\" title=\"Categorical variable\">Categorical</a>&#160;/&#32;<a href=\"/wiki/Multivariate_statistics\" title=\"Multivariate statistics\">Multivariate</a>&#160;/&#32;<a href=\"/wiki/Time_series\" title=\"Time series\">Time-series</a>&#160;/&#32;<a href=\"/wiki/Survival_analysis\" title=\"Survival analysis\">Survival analysis</a></div></th></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Categorical_variable\" title=\"Categorical variable\">Categorical</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Cohen%27s_kappa\" title=\"Cohen&#39;s kappa\">Cohen's kappa</a></li>\n<li><a href=\"/wiki/Contingency_table\" title=\"Contingency table\">Contingency table</a></li>\n<li><a href=\"/wiki/Graphical_model\" title=\"Graphical model\">Graphical model</a></li>\n<li><a href=\"/wiki/Poisson_regression\" title=\"Poisson regression\">Log-linear model</a></li>\n<li><a href=\"/wiki/McNemar%27s_test\" title=\"McNemar&#39;s test\">McNemar's test</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Multivariate_statistics\" title=\"Multivariate statistics\">Multivariate</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/General_linear_model\" title=\"General linear model\">Regression</a></li>\n<li><a href=\"/wiki/Multivariate_analysis_of_variance\" title=\"Multivariate analysis of variance\">Manova</a></li>\n<li><a href=\"/wiki/Principal_component_analysis\" title=\"Principal component analysis\">Principal components</a></li>\n<li><a href=\"/wiki/Canonical_correlation\" title=\"Canonical correlation\">Canonical correlation</a></li>\n<li><a href=\"/wiki/Linear_discriminant_analysis\" title=\"Linear discriminant analysis\">Discriminant analysis</a></li>\n<li><a href=\"/wiki/Cluster_analysis\" title=\"Cluster analysis\">Cluster analysis</a></li>\n<li><a href=\"/wiki/Statistical_classification\" title=\"Statistical classification\">Classification</a></li>\n<li><a href=\"/wiki/Structural_equation_modeling\" title=\"Structural equation modeling\">Structural equation model</a>\n<ul><li><a href=\"/wiki/Factor_analysis\" title=\"Factor analysis\">Factor analysis</a></li></ul></li>\n<li><a href=\"/wiki/Multivariate_distribution\" class=\"mw-redirect\" title=\"Multivariate distribution\">Multivariate distributions</a>\n<ul><li><a href=\"/wiki/Elliptical_distribution\" title=\"Elliptical distribution\">Elliptical distributions</a>\n<ul><li><a href=\"/wiki/Multivariate_normal_distribution\" title=\"Multivariate normal distribution\">Normal</a></li></ul></li></ul></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Time_series\" title=\"Time series\">Time-series</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\">General</th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Decomposition_of_time_series\" title=\"Decomposition of time series\">Decomposition</a></li>\n<li><a href=\"/wiki/Trend_estimation\" class=\"mw-redirect\" title=\"Trend estimation\">Trend</a></li>\n<li><a href=\"/wiki/Stationary_process\" title=\"Stationary process\">Stationarity</a></li>\n<li><a href=\"/wiki/Seasonal_adjustment\" title=\"Seasonal adjustment\">Seasonal adjustment</a></li>\n<li><a href=\"/wiki/Exponential_smoothing\" title=\"Exponential smoothing\">Exponential smoothing</a></li>\n<li><a href=\"/wiki/Cointegration\" title=\"Cointegration\">Cointegration</a></li>\n<li><a href=\"/wiki/Structural_break\" title=\"Structural break\">Structural break</a></li>\n<li><a href=\"/wiki/Granger_causality\" title=\"Granger causality\">Granger causality</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\">Specific tests</th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Dickey%E2%80%93Fuller_test\" title=\"Dickey\u2013Fuller test\">Dickey\u2013Fuller</a></li>\n<li><a href=\"/wiki/Johansen_test\" title=\"Johansen test\">Johansen</a></li>\n<li><a href=\"/wiki/Ljung%E2%80%93Box_test\" title=\"Ljung\u2013Box test\">Q-statistic <span style=\"font-size:90%;\">(Ljung\u2013Box)</span></a></li>\n<li><a href=\"/wiki/Durbin%E2%80%93Watson_statistic\" title=\"Durbin\u2013Watson statistic\">Durbin\u2013Watson</a></li>\n<li><a href=\"/wiki/Breusch%E2%80%93Godfrey_test\" title=\"Breusch\u2013Godfrey test\">Breusch\u2013Godfrey</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Time_domain\" title=\"Time domain\">Time domain</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Autocorrelation\" title=\"Autocorrelation\">Autocorrelation (ACF)</a>\n<ul><li><a href=\"/wiki/Partial_autocorrelation_function\" title=\"Partial autocorrelation function\">partial (PACF)</a></li></ul></li>\n<li><a href=\"/wiki/Cross-correlation\" title=\"Cross-correlation\">Cross-correlation (XCF)</a></li>\n<li><a href=\"/wiki/Autoregressive%E2%80%93moving-average_model\" title=\"Autoregressive\u2013moving-average model\">ARMA model</a></li>\n<li><a href=\"/wiki/Box%E2%80%93Jenkins_method\" title=\"Box\u2013Jenkins method\">ARIMA model <span style=\"font-size:90%;\">(Box\u2013Jenkins)</span></a></li>\n<li><a href=\"/wiki/Autoregressive_conditional_heteroskedasticity\" title=\"Autoregressive conditional heteroskedasticity\">Autoregressive conditional heteroskedasticity (ARCH)</a></li>\n<li><a href=\"/wiki/Vector_autoregression\" title=\"Vector autoregression\">Vector autoregression (VAR)</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Frequency_domain\" title=\"Frequency domain\">Frequency domain</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Spectral_density_estimation\" title=\"Spectral density estimation\">Spectral density estimation</a></li>\n<li><a href=\"/wiki/Fourier_analysis\" title=\"Fourier analysis\">Fourier analysis</a></li>\n<li><a href=\"/wiki/Wavelet\" title=\"Wavelet\">Wavelet</a></li>\n<li><a href=\"/wiki/Whittle_likelihood\" title=\"Whittle likelihood\">Whittle likelihood</a></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Survival_analysis\" title=\"Survival analysis\">Survival</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Survival_function\" title=\"Survival function\">Survival function</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Kaplan%E2%80%93Meier_estimator\" title=\"Kaplan\u2013Meier estimator\">Kaplan\u2013Meier estimator (product limit)</a></li>\n<li><a href=\"/wiki/Proportional_hazards_model\" title=\"Proportional hazards model\">Proportional hazards models</a></li>\n<li><a href=\"/wiki/Accelerated_failure_time_model\" title=\"Accelerated failure time model\">Accelerated failure time (AFT) model</a></li>\n<li><a href=\"/wiki/First-hitting-time_model\" title=\"First-hitting-time model\">First hitting time</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\"><a href=\"/wiki/Failure_rate\" title=\"Failure rate\">Hazard function</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Nelson%E2%80%93Aalen_estimator\" title=\"Nelson\u2013Aalen estimator\">Nelson\u2013Aalen estimator</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%;font-weight:normal;\">Test</th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Log-rank_test\" class=\"mw-redirect\" title=\"Log-rank test\">Log-rank test</a></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks collapsible collapsed navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\" style=\";\"><div id=\"Applications\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/List_of_fields_of_application_of_statistics\" title=\"List of fields of application of statistics\">Applications</a></div></th></tr><tr><td colspan=\"2\" class=\"navbox-list navbox-odd\" style=\"width:100%;padding:0px\"><div style=\"padding:0em 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Biostatistics\" title=\"Biostatistics\">Biostatistics</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Bioinformatics\" title=\"Bioinformatics\">Bioinformatics</a></li>\n<li><a href=\"/wiki/Clinical_trial\" title=\"Clinical trial\">Clinical trials</a>&#160;/&#32;<a href=\"/wiki/Clinical_study_design\" title=\"Clinical study design\">studies</a></li>\n<li><a href=\"/wiki/Epidemiology\" title=\"Epidemiology\">Epidemiology</a></li>\n<li><a href=\"/wiki/Medical_statistics\" title=\"Medical statistics\">Medical statistics</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Engineering_statistics\" title=\"Engineering statistics\">Engineering statistics</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Chemometrics\" title=\"Chemometrics\">Chemometrics</a></li>\n<li><a href=\"/wiki/Methods_engineering\" title=\"Methods engineering\">Methods engineering</a></li>\n<li><a href=\"/wiki/Probabilistic_design\" title=\"Probabilistic design\">Probabilistic design</a></li>\n<li><a href=\"/wiki/Statistical_process_control\" title=\"Statistical process control\">Process</a>&#160;/&#32;<a href=\"/wiki/Quality_control\" title=\"Quality control\">quality control</a></li>\n<li><a href=\"/wiki/Reliability_engineering\" title=\"Reliability engineering\">Reliability</a></li>\n<li><a href=\"/wiki/System_identification\" title=\"System identification\">System identification</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Social_statistics\" title=\"Social statistics\">Social statistics</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Actuarial_science\" title=\"Actuarial science\">Actuarial science</a></li>\n<li><a href=\"/wiki/Census\" title=\"Census\">Census</a></li>\n<li><a href=\"/wiki/Crime_statistics\" title=\"Crime statistics\">Crime statistics</a></li>\n<li><a href=\"/wiki/Demographic_statistics\" title=\"Demographic statistics\">Demography</a></li>\n<li><a href=\"/wiki/Econometrics\" title=\"Econometrics\">Econometrics</a></li>\n<li><a href=\"/wiki/National_accounts\" title=\"National accounts\">National accounts</a></li>\n<li><a href=\"/wiki/Official_statistics\" title=\"Official statistics\">Official statistics</a></li>\n<li><a href=\"/wiki/Population_statistics\" class=\"mw-redirect\" title=\"Population statistics\">Population statistics</a></li>\n<li><a href=\"/wiki/Psychometrics\" title=\"Psychometrics\">Psychometrics</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:12.5em\"><a href=\"/wiki/Spatial_analysis\" title=\"Spatial analysis\">Spatial statistics</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Cartography\" title=\"Cartography\">Cartography</a></li>\n<li><a href=\"/wiki/Environmental_statistics\" title=\"Environmental statistics\">Environmental statistics</a></li>\n<li><a href=\"/wiki/Geographic_information_system\" title=\"Geographic information system\">Geographic information system</a></li>\n<li><a href=\"/wiki/Geostatistics\" title=\"Geostatistics\">Geostatistics</a></li>\n<li><a href=\"/wiki/Kriging\" title=\"Kriging\">Kriging</a></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td class=\"navbox-abovebelow\" colspan=\"2\"><div>\n<ul><li><img alt=\"Category\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png\" title=\"Category\" width=\"16\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x\" data-file-width=\"36\" data-file-height=\"31\" /><b><a href=\"/wiki/Category:Statistics\" title=\"Category:Statistics\">Category</a></b></li>\n<li><img alt=\"Portal\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/16px-Portal-puzzle.svg.png\" title=\"Portal\" width=\"16\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/24px-Portal-puzzle.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/32px-Portal-puzzle.svg.png 2x\" data-file-width=\"32\" data-file-height=\"28\" /><b><a href=\"/wiki/Portal:Statistics\" title=\"Portal:Statistics\">Portal</a></b></li>\n<li><img alt=\"Commons page\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png\" title=\"Commons page\" width=\"12\" height=\"16\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x\" data-file-width=\"1024\" data-file-height=\"1376\" /><b><a href=\"https://commons.wikimedia.org/wiki/Category:Statistics\" class=\"extiw\" title=\"commons:Category:Statistics\">Commons</a></b></li>\n<li><img alt=\"WikiProject\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/3/37/People_icon.svg/16px-People_icon.svg.png\" title=\"WikiProject\" width=\"16\" height=\"16\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/3/37/People_icon.svg/24px-People_icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/37/People_icon.svg/32px-People_icon.svg.png 2x\" data-file-width=\"100\" data-file-height=\"100\" /> <b><a href=\"/wiki/Wikipedia:WikiProject_Statistics\" title=\"Wikipedia:WikiProject Statistics\">WikiProject</a></b></li></ul>\n</div></td></tr></tbody></table></div>\n<div class=\"noprint metadata navbox\" role=\"navigation\" aria-label=\"Portals\" style=\"font-weight:bold;padding:0.4em 2em\"><ul style=\"margin:0.1em 0 0\"><li style=\"display:inline\"><span style=\"display:inline-block;white-space:nowrap\"><span style=\"margin:0 0.5em\"><a href=\"/wiki/File:Fisher_iris_versicolor_sepalwidth.svg\" class=\"image\"><img alt=\"Fisher iris versicolor sepalwidth.svg\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/40/Fisher_iris_versicolor_sepalwidth.svg/24px-Fisher_iris_versicolor_sepalwidth.svg.png\" width=\"24\" height=\"17\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/40/Fisher_iris_versicolor_sepalwidth.svg/36px-Fisher_iris_versicolor_sepalwidth.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/40/Fisher_iris_versicolor_sepalwidth.svg/48px-Fisher_iris_versicolor_sepalwidth.svg.png 2x\" data-file-width=\"822\" data-file-height=\"567\" /></a></span><a href=\"/wiki/Portal:Statistics\" title=\"Portal:Statistics\">Statistics portal</a></span></li></ul></div>\n<div role=\"navigation\" class=\"navbox\" aria-labelledby=\"Authority_control_frameless_&amp;#124;text-top_&amp;#124;10px_&amp;#124;alt=Edit_this_at_Wikidata_&amp;#124;link=https&amp;#58;//www.wikidata.org/wiki/Q938438&amp;#124;Edit_this_at_Wikidata\" style=\"padding:3px\"><table class=\"nowraplinks hlist navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th id=\"Authority_control_frameless_&amp;#124;text-top_&amp;#124;10px_&amp;#124;alt=Edit_this_at_Wikidata_&amp;#124;link=https&amp;#58;//www.wikidata.org/wiki/Q938438&amp;#124;Edit_this_at_Wikidata\" scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Help:Authority_control\" title=\"Help:Authority control\">Authority control</a> <a href=\"https://www.wikidata.org/wiki/Q938438\" title=\"Edit this at Wikidata\"><img alt=\"Edit this at Wikidata\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/73/Blue_pencil.svg/10px-Blue_pencil.svg.png\" width=\"10\" height=\"10\" style=\"vertical-align: text-top\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/73/Blue_pencil.svg/15px-Blue_pencil.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/73/Blue_pencil.svg/20px-Blue_pencil.svg.png 2x\" data-file-width=\"600\" data-file-height=\"600\" /></a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><span class=\"nowrap\"><a href=\"/wiki/Integrated_Authority_File\" title=\"Integrated Authority File\">GND</a>: <span class=\"uid\"><a rel=\"nofollow\" class=\"external text\" href=\"https://d-nb.info/gnd/4182963-3\">4182963-3</a></span></span></li></ul>\n</div></td></tr></tbody></table></div>\n\n<!-- \nNewPP limit report\nParsed by mw2232\nCached time: 20180919141905\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.860 seconds\nReal time usage: 0.992 seconds\nPreprocessor visited node count: 6993/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 285439/2097152 bytes\nTemplate argument size: 35532/2097152 bytes\nHighest expansion depth: 16/40\nExpensive parser function count: 8/500\nUnstrip recursion depth: 1/20\nUnstrip post\u2010expand size: 22745/5000000 bytes\nNumber of Wikibase entities loaded: 1/400\nLua time usage: 0.344/10.000 seconds\nLua memory usage: 5.99 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  732.823      1 -total\n 32.60%  238.909      2 Template:Reflist\n 18.63%  136.559      1 Template:Statistics\n 17.99%  131.825      1 Template:Navbox_with_collapsible_groups\n 17.60%  128.979     12 Template:Fix\n 10.86%   79.569      5 Template:Citation_needed\n 10.64%   77.941      9 Template:Cite_book\n  9.62%   70.469      8 Template:Isbn\n  9.59%   70.291     11 Template:Navbox\n  9.10%   66.718     12 Template:Delink\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:27577-0!canonical!math=5 and timestamp 20180919141904 and revision id 846448830\n -->\n</div>"},"langlinks":[{"lang":"ar","url":"https://ar.wikipedia.org/wiki/%D8%A7%D8%B3%D8%AA%D8%AF%D9%84%D8%A7%D9%84_%D8%A5%D8%AD%D8%B5%D8%A7%D8%A6%D9%8A","langname":"Arabic","autonym":"\u0627\u0644\u0639\u0631\u0628\u064a\u0629","*":"\u0627\u0633\u062a\u062f\u0644\u0627\u0644 \u0625\u062d\u0635\u0627\u0626\u064a"},{"lang":"ca","url":"https://ca.wikipedia.org/wiki/Infer%C3%A8ncia_estad%C3%ADstica","langname":"Catalan","autonym":"catal\u00e0","*":"Infer\u00e8ncia estad\u00edstica"},{"lang":"de","url":"https://de.wikipedia.org/wiki/Mathematische_Statistik","langname":"German","autonym":"Deutsch","*":"Mathematische Statistik"},{"lang":"es","url":"https://es.wikipedia.org/wiki/Estad%C3%ADstica_inferencial","langname":"Spanish","autonym":"espa\u00f1ol","*":"Estad\u00edstica inferencial"},{"lang":"eu","url":"https://eu.wikipedia.org/wiki/Inferentzia_estatistiko","langname":"Basque","autonym":"euskara","*":"Inferentzia estatistiko"},{"lang":"fa","url":"https://fa.wikipedia.org/wiki/%D8%A7%D8%B3%D8%AA%D9%86%D8%A8%D8%A7%D8%B7_%D8%A2%D9%85%D8%A7%D8%B1%DB%8C","langname":"Persian","autonym":"\u0641\u0627\u0631\u0633\u06cc","*":"\u0627\u0633\u062a\u0646\u0628\u0627\u0637 \u0622\u0645\u0627\u0631\u06cc"},{"lang":"fr","url":"https://fr.wikipedia.org/wiki/Inf%C3%A9rence_statistique","langname":"French","autonym":"fran\u00e7ais","*":"Inf\u00e9rence statistique"},{"lang":"ko","url":"https://ko.wikipedia.org/wiki/%ED%86%B5%EA%B3%84%EC%A0%81_%EC%B6%94%EB%A1%A0","langname":"Korean","autonym":"\ud55c\uad6d\uc5b4","*":"\ud1b5\uacc4\uc801 \ucd94\ub860"},{"lang":"hi","url":"https://hi.wikipedia.org/wiki/%E0%A4%B8%E0%A4%BE%E0%A4%82%E0%A4%96%E0%A5%8D%E0%A4%AF%E0%A4%BF%E0%A4%95%E0%A5%80%E0%A4%AF_%E0%A4%85%E0%A4%A8%E0%A5%81%E0%A4%AE%E0%A4%BF%E0%A4%A4%E0%A4%BF","langname":"Hindi","autonym":"\u0939\u093f\u0928\u094d\u0926\u0940","*":"\u0938\u093e\u0902\u0916\u094d\u092f\u093f\u0915\u0940\u092f \u0905\u0928\u0941\u092e\u093f\u0924\u093f"},{"lang":"id","url":"https://id.wikipedia.org/wiki/Statistika_inferensi","langname":"Indonesian","autonym":"Bahasa Indonesia","*":"Statistika inferensi"},{"lang":"it","url":"https://it.wikipedia.org/wiki/Inferenza_statistica","langname":"Italian","autonym":"italiano","*":"Inferenza statistica"},{"lang":"he","url":"https://he.wikipedia.org/wiki/%D7%94%D7%A1%D7%A7%D7%94_%D7%A1%D7%98%D7%98%D7%99%D7%A1%D7%98%D7%99%D7%AA","langname":"Hebrew","autonym":"\u05e2\u05d1\u05e8\u05d9\u05ea","*":"\u05d4\u05e1\u05e7\u05d4 \u05e1\u05d8\u05d8\u05d9\u05e1\u05d8\u05d9\u05ea"},{"lang":"nl","url":"https://nl.wikipedia.org/wiki/Inferentie_(statistiek)","langname":"Dutch","autonym":"Nederlands","*":"Inferentie (statistiek)"},{"lang":"ja","url":"https://ja.wikipedia.org/wiki/%E6%8E%A8%E8%A8%88%E7%B5%B1%E8%A8%88%E5%AD%A6","langname":"Japanese","autonym":"\u65e5\u672c\u8a9e","*":"\u63a8\u8a08\u7d71\u8a08\u5b66"},{"lang":"no","url":"https://no.wikipedia.org/wiki/Statistisk_inferens","langname":"Norwegian","autonym":"norsk","*":"Statistisk inferens"},{"lang":"pl","url":"https://pl.wikipedia.org/wiki/Wnioskowanie_statystyczne","langname":"Polish","autonym":"polski","*":"Wnioskowanie statystyczne"},{"lang":"pt","url":"https://pt.wikipedia.org/wiki/Infer%C3%AAncia_estat%C3%ADstica","langname":"Portuguese","autonym":"portugu\u00eas","*":"Infer\u00eancia estat\u00edstica"},{"lang":"ru","url":"https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B2%D1%8B%D0%B2%D0%BE%D0%B4","langname":"Russian","autonym":"\u0440\u0443\u0441\u0441\u043a\u0438\u0439","*":"\u0421\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0432\u044b\u0432\u043e\u0434"},{"lang":"simple","url":"https://simple.wikipedia.org/wiki/Inference_(statistics)","langname":"Simple English","autonym":"Simple English","*":"Inference (statistics)"},{"lang":"sd","url":"https://sd.wikipedia.org/wiki/%D8%B4%D9%85%D8%A7%D8%B1%D9%8A%D8%A7%D8%AA%D9%8A_%D8%AA%D8%AE%D9%85%D9%8A%D9%86%D9%88","langname":"Sindhi","autonym":"\u0633\u0646\u068c\u064a","*":"\u0634\u0645\u0627\u0631\u064a\u0627\u062a\u064a \u062a\u062e\u0645\u064a\u0646\u0648"},{"lang":"su","url":"https://su.wikipedia.org/wiki/Inferensi_statistik","langname":"Sundanese","autonym":"Basa Sunda","*":"Inferensi statistik"},{"lang":"te","url":"https://te.wikipedia.org/wiki/%E0%B0%B8%E0%B1%8D%E0%B0%9F%E0%B0%BE%E0%B0%9F%E0%B0%BF%E0%B0%B8%E0%B1%8D%E0%B0%9F%E0%B0%BF%E0%B0%95%E0%B0%B2%E0%B1%8D_%E0%B0%87%E0%B0%A8%E0%B1%8D%E0%B0%AB%E0%B0%B0%E0%B1%86%E0%B0%A8%E0%B1%8D%E0%B0%B8%E0%B1%8D","langname":"Telugu","autonym":"\u0c24\u0c46\u0c32\u0c41\u0c17\u0c41","*":"\u0c38\u0c4d\u0c1f\u0c3e\u0c1f\u0c3f\u0c38\u0c4d\u0c1f\u0c3f\u0c15\u0c32\u0c4d \u0c07\u0c28\u0c4d\u0c2b\u0c30\u0c46\u0c28\u0c4d\u0c38\u0c4d"},{"lang":"tr","url":"https://tr.wikipedia.org/wiki/%C3%87%C4%B1kar%C4%B1msal_istatistik","langname":"Turkish","autonym":"T\u00fcrk\u00e7e","*":"\u00c7\u0131kar\u0131msal istatistik"},{"lang":"uk","url":"https://uk.wikipedia.org/wiki/%D0%A1%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%BD%D0%B5_%D0%B2%D0%B8%D1%81%D0%BD%D0%BE%D0%B2%D1%83%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F","langname":"Ukrainian","autonym":"\u0443\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430","*":"\u0421\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u043d\u0435 \u0432\u0438\u0441\u043d\u043e\u0432\u0443\u0432\u0430\u043d\u043d\u044f"},{"lang":"vi","url":"https://vi.wikipedia.org/wiki/Suy_lu%E1%BA%ADn_th%E1%BB%91ng_k%C3%AA","langname":"Vietnamese","autonym":"Ti\u1ebfng Vi\u1ec7t","*":"Suy lu\u1eadn th\u1ed1ng k\u00ea"},{"lang":"zh","url":"https://zh.wikipedia.org/wiki/%E6%8E%A8%E8%AB%96%E7%B5%B1%E8%A8%88%E5%AD%B8","langname":"Chinese","autonym":"\u4e2d\u6587","*":"\u63a8\u8ad6\u7d71\u8a08\u5b78"}],"categories":[{"sortkey":"","hidden":"","*":"Articles_with_incomplete_citations_from_November_2012"},{"sortkey":"","hidden":"","*":"All_articles_with_incomplete_citations"},{"sortkey":"","hidden":"","*":"Wikipedia_articles_needing_page_number_citations_from_June_2011"},{"sortkey":"Statistical Inference","hidden":"","*":"All_articles_with_unsourced_statements"},{"sortkey":"","hidden":"","*":"Articles_with_unsourced_statements_from_March_2010"},{"sortkey":"Statistical Inference","hidden":"","*":"Articles_with_unsourced_statements_from_December_2016"},{"sortkey":"Statistical Inference","hidden":"","*":"Articles_with_unsourced_statements_from_February_2012"},{"sortkey":"Statistical Inference","hidden":"","*":"Articles_with_unsourced_statements_from_April_2012"},{"sortkey":"Statistical Inference","hidden":"","*":"Articles_to_be_expanded_from_November_2017"},{"sortkey":"Statistical Inference","hidden":"","*":"All_articles_to_be_expanded"},{"sortkey":"Statistical Inference","hidden":"","*":"Articles_using_small_message_boxes"},{"sortkey":"Statistical Inference","hidden":"","*":"Wikipedia_articles_with_GND_identifiers"},{"sortkey":" ","*":"Statistical_inference"},{"sortkey":"Statistical Inference","*":"Inductive_reasoning"},{"sortkey":"Statistical Inference","*":"Deductive_reasoning"},{"sortkey":"Statistical Inference","*":"Logic_and_statistics"},{"sortkey":"Statistical Inference","*":"Philosophy_of_science"},{"sortkey":"Statistical Inference","*":"Psychometrics"}],"links":[{"ns":14,"exists":"","*":"Category:Articles with unsourced statements from December 2016"},{"ns":14,"exists":"","*":"Category:Articles with unsourced statements from February 2012"},{"ns":14,"exists":"","*":"Category:Articles with unsourced statements from April 2012"},{"ns":14,"exists":"","*":"Category:Articles to be expanded from November 2017"},{"ns":14,"exists":"","*":"Category:Articles with incomplete citations from November 2012"},{"ns":14,"exists":"","*":"Category:Wikipedia articles needing page number citations from June 2011"},{"ns":14,"exists":"","*":"Category:Articles with unsourced statements from March 2010"},{"ns":14,"exists":"","*":"Category:Wikipedia articles with GND identifiers"},{"ns":14,"exists":"","*":"Category:Statistics"},{"ns":10,"exists":"","*":"Template:Statistics"},{"ns":0,"exists":"","*":"Abraham Wald"},{"ns":0,"exists":"","*":"Absolute value"},{"ns":0,"exists":"","*":"Accelerated failure time model"},{"ns":0,"exists":"","*":"Actuarial science"},{"ns":0,"exists":"","*":"Akaike information criterion"},{"ns":0,"exists":"","*":"Algorithmic inference"},{"ns":0,"exists":"","*":"Analysis of covariance"},{"ns":0,"exists":"","*":"Analysis of variance"},{"ns":0,"exists":"","*":"Anderson\u2013Darling test"},{"ns":0,"exists":"","*":"Andrei N. Kolmogorov"},{"ns":0,"exists":"","*":"Andrew Gelman"},{"ns":0,"exists":"","*":"Approximation theory"},{"ns":0,"exists":"","*":"Arithmetic mean"},{"ns":0,"exists":"","*":"Asymptotic theory (statistics)"},{"ns":0,"exists":"","*":"Autocorrelation"},{"ns":0,"exists":"","*":"Autoregressive conditional heteroskedasticity"},{"ns":0,"exists":"","*":"Autoregressive\u2013moving-average model"},{"ns":0,"exists":"","*":"Bar chart"},{"ns":0,"exists":"","*":"Bayes estimator"},{"ns":0,"exists":"","*":"Bayes factor"},{"ns":0,"exists":"","*":"Bayesian Inference"},{"ns":0,"exists":"","*":"Bayesian inference"},{"ns":0,"exists":"","*":"Bayesian information criterion"},{"ns":0,"exists":"","*":"Bayesian linear regression"},{"ns":0,"exists":"","*":"Bayesian probability"},{"ns":0,"exists":"","*":"Berry\u2013Esseen theorem"},{"ns":0,"exists":"","*":"Bias of an estimator"},{"ns":0,"exists":"","*":"Bin Yu"},{"ns":0,"exists":"","*":"Binomial regression"},{"ns":0,"exists":"","*":"Bioinformatics"},{"ns":0,"exists":"","*":"Biostatistics"},{"ns":0,"exists":"","*":"Biplot"},{"ns":0,"exists":"","*":"Blocking (statistics)"},{"ns":0,"exists":"","*":"Bootstrapping (statistics)"},{"ns":0,"exists":"","*":"Box plot"},{"ns":0,"exists":"","*":"Box\u2013Jenkins method"},{"ns":0,"exists":"","*":"Bregman divergence"},{"ns":0,"exists":"","*":"Breusch\u2013Godfrey test"},{"ns":0,"exists":"","*":"British Journal for the Philosophy of Science"},{"ns":0,"exists":"","*":"C. R. Rao"},{"ns":0,"exists":"","*":"Cambridge University Press"},{"ns":0,"exists":"","*":"Canonical correlation"},{"ns":0,"exists":"","*":"Cartography"},{"ns":0,"exists":"","*":"Categorical variable"},{"ns":0,"exists":"","*":"Census"},{"ns":0,"exists":"","*":"Central limit theorem"},{"ns":0,"exists":"","*":"Central tendency"},{"ns":0,"exists":"","*":"Chapman & Hall"},{"ns":0,"exists":"","*":"Charles Sanders Peirce"},{"ns":0,"exists":"","*":"Chemometrics"},{"ns":0,"exists":"","*":"Chi-squared test"},{"ns":0,"exists":"","*":"Claude Shannon"},{"ns":0,"exists":"","*":"Clinical study design"},{"ns":0,"exists":"","*":"Clinical trial"},{"ns":0,"exists":"","*":"Cluster analysis"},{"ns":0,"exists":"","*":"Cluster sampling"},{"ns":0,"exists":"","*":"Coding theory"},{"ns":0,"exists":"","*":"Coefficient of determination"},{"ns":0,"exists":"","*":"Coefficient of variation"},{"ns":0,"exists":"","*":"Cohen's kappa"},{"ns":0,"exists":"","*":"Coherence (statistics)"},{"ns":0,"exists":"","*":"Cointegration"},{"ns":0,"exists":"","*":"Completeness (statistics)"},{"ns":0,"exists":"","*":"Computational complexity theory"},{"ns":0,"exists":"","*":"Confidence distribution"},{"ns":0,"exists":"","*":"Confidence interval"},{"ns":0,"exists":"","*":"Confidence level"},{"ns":0,"exists":"","*":"Confounding"},{"ns":0,"exists":"","*":"Contingency table"},{"ns":0,"exists":"","*":"Continuous probability distribution"},{"ns":0,"exists":"","*":"Control chart"},{"ns":0,"exists":"","*":"Correlation and dependence"},{"ns":0,"exists":"","*":"Correlogram"},{"ns":0,"exists":"","*":"Count data"},{"ns":0,"exists":"","*":"Covariate"},{"ns":0,"exists":"","*":"Cox model"},{"ns":0,"exists":"","*":"Credible interval"},{"ns":0,"exists":"","*":"Credible intervals"},{"ns":0,"exists":"","*":"Crime statistics"},{"ns":0,"exists":"","*":"Cross-correlation"},{"ns":0,"exists":"","*":"Cross-validation (statistics)"},{"ns":0,"exists":"","*":"Data analysis"},{"ns":0,"exists":"","*":"Data collection"},{"ns":0,"exists":"","*":"Data mining"},{"ns":0,"exists":"","*":"David A. Freedman"},{"ns":0,"exists":"","*":"David Cox (statistician)"},{"ns":0,"exists":"","*":"David R. Cox"},{"ns":0,"exists":"","*":"David S. Moore"},{"ns":0,"exists":"","*":"Decision theory"},{"ns":0,"exists":"","*":"Decomposition of time series"},{"ns":0,"exists":"","*":"Degrees of freedom (statistics)"},{"ns":0,"exists":"","*":"Demographic statistics"},{"ns":0,"exists":"","*":"Density estimation"},{"ns":0,"exists":"","*":"Descriptive statistics"},{"ns":0,"exists":"","*":"Design of experiments"},{"ns":0,"exists":"","*":"Dickey\u2013Fuller test"},{"ns":0,"exists":"","*":"Digital object identifier"},{"ns":0,"exists":"","*":"Divergence (statistics)"},{"ns":0,"exists":"","*":"Dorota Dabrowska"},{"ns":0,"exists":"","*":"Durbin\u2013Watson statistic"},{"ns":0,"exists":"","*":"Econometrics"},{"ns":0,"exists":"","*":"Effect size"},{"ns":0,"exists":"","*":"Efficiency (statistics)"},{"ns":0,"exists":"","*":"Elliptical distribution"},{"ns":0,"exists":"","*":"Elsevier"},{"ns":0,"exists":"","*":"Empirical distribution function"},{"ns":0,"exists":"","*":"Engineering statistics"},{"ns":0,"exists":"","*":"Environmental statistics"},{"ns":0,"exists":"","*":"Epidemiology"},{"ns":0,"exists":"","*":"Errors and residuals in statistics"},{"ns":0,"exists":"","*":"Estimating equations"},{"ns":0,"exists":"","*":"Estimation theory"},{"ns":0,"exists":"","*":"Estimator"},{"ns":0,"exists":"","*":"Estimators"},{"ns":0,"exists":"","*":"Exchangeability"},{"ns":0,"exists":"","*":"Experiment"},{"ns":0,"exists":"","*":"Exponential families"},{"ns":0,"exists":"","*":"Exponential family"},{"ns":0,"exists":"","*":"Exponential smoothing"},{"ns":0,"exists":"","*":"F-test"},{"ns":0,"exists":"","*":"Factor analysis"},{"ns":0,"exists":"","*":"Factorial experiment"},{"ns":0,"exists":"","*":"Failure rate"},{"ns":0,"exists":"","*":"Fan chart (statistics)"},{"ns":0,"exists":"","*":"Fiducial inference"},{"ns":0,"exists":"","*":"Fiducial probability"},{"ns":0,"exists":"","*":"First-hitting-time model"},{"ns":0,"exists":"","*":"Forest plot"},{"ns":0,"exists":"","*":"Fourier analysis"},{"ns":0,"exists":"","*":"Frequency distribution"},{"ns":0,"exists":"","*":"Frequency domain"},{"ns":0,"exists":"","*":"Frequency probability"},{"ns":0,"exists":"","*":"Frequentist inference"},{"ns":0,"exists":"","*":"Friedman test"},{"ns":0,"exists":"","*":"Functional analysis"},{"ns":0,"exists":"","*":"G-test"},{"ns":0,"exists":"","*":"General linear model"},{"ns":0,"exists":"","*":"Generalized estimating equation"},{"ns":0,"exists":"","*":"Generalized linear model"},{"ns":0,"exists":"","*":"Generalized method of moments"},{"ns":0,"exists":"","*":"Geographic information system"},{"ns":0,"exists":"","*":"Geometric mean"},{"ns":0,"exists":"","*":"George A. Barnard"},{"ns":0,"exists":"","*":"George Casella"},{"ns":0,"exists":"","*":"Geostatistics"},{"ns":0,"exists":"","*":"Goodness of fit"},{"ns":0,"exists":"","*":"Granger causality"},{"ns":0,"exists":"","*":"Graphical model"},{"ns":0,"exists":"","*":"Group family"},{"ns":0,"exists":"","*":"Grouped data"},{"ns":0,"exists":"","*":"Haar measure"},{"ns":0,"exists":"","*":"Harmonic mean"},{"ns":0,"exists":"","*":"Hellinger distance"},{"ns":0,"exists":"","*":"Heteroscedasticity"},{"ns":0,"exists":"","*":"Histogram"},{"ns":0,"exists":"","*":"Hodges\u2013Lehmann estimator"},{"ns":0,"exists":"","*":"Homoscedasticity"},{"ns":0,"exists":"","*":"Index of dispersion"},{"ns":0,"exists":"","*":"Induction (philosophy)"},{"ns":0,"exists":"","*":"Informal inferential reasoning"},{"ns":0,"exists":"","*":"Information field theory"},{"ns":0,"exists":"","*":"Information theory"},{"ns":0,"exists":"","*":"Integrated Authority File"},{"ns":0,"exists":"","*":"Interaction (statistics)"},{"ns":0,"exists":"","*":"International Standard Book Number"},{"ns":0,"exists":"","*":"Interquartile range"},{"ns":0,"exists":"","*":"Interval estimate"},{"ns":0,"exists":"","*":"Interval estimation"},{"ns":0,"exists":"","*":"Isotonic regression"},{"ns":0,"exists":"","*":"JSTOR"},{"ns":0,"exists":"","*":"Jackknife resampling"},{"ns":0,"exists":"","*":"Jarque\u2013Bera test"},{"ns":0,"exists":"","*":"Jerzy Neyman"},{"ns":0,"exists":"","*":"Johansen test"},{"ns":0,"exists":"","*":"John Benjamins Publishing Company"},{"ns":0,"exists":"","*":"Jonckheere's trend test"},{"ns":0,"exists":"","*":"Jorma Rissanen"},{"ns":0,"exists":"","*":"Joseph F. Traub"},{"ns":0,"exists":"","*":"Journal of the American Statistical Association"},{"ns":0,"exists":"","*":"Journal of the Royal Statistical Society"},{"ns":0,"exists":"","*":"Journal of the Royal Statistical Society, Series B"},{"ns":0,"exists":"","*":"Kaplan\u2013Meier estimator"},{"ns":0,"exists":"","*":"Kendall rank correlation coefficient"},{"ns":0,"exists":"","*":"Kolmogorov complexity"},{"ns":0,"exists":"","*":"Kolmogorov\u2013Smirnov test"},{"ns":0,"exists":"","*":"Kriging"},{"ns":0,"exists":"","*":"Kruskal\u2013Wallis one-way analysis of variance"},{"ns":0,"exists":"","*":"Kullback\u2013Leibler divergence"},{"ns":0,"exists":"","*":"Kurtosis"},{"ns":0,"exists":"","*":"L-moment"},{"ns":0,"exists":"","*":"Least squares"},{"ns":0,"exists":"","*":"Lehmann\u2013Scheff\u00e9 theorem"},{"ns":0,"exists":"","*":"Likelihood-ratio test"},{"ns":0,"exists":"","*":"Likelihood function"},{"ns":0,"exists":"","*":"Likelihood interval"},{"ns":0,"exists":"","*":"Lilliefors test"},{"ns":0,"exists":"","*":"Linear discriminant analysis"},{"ns":0,"exists":"","*":"Linear regression"},{"ns":0,"exists":"","*":"List of fields of application of statistics"},{"ns":0,"exists":"","*":"List of statistics articles"},{"ns":0,"exists":"","*":"Ljung\u2013Box test"},{"ns":0,"exists":"","*":"Location parameter"},{"ns":0,"exists":"","*":"Location\u2013scale family"},{"ns":0,"exists":"","*":"Log-rank test"},{"ns":0,"exists":"","*":"Logarithmically concave function"},{"ns":0,"exists":"","*":"Logical consequence"},{"ns":0,"exists":"","*":"Logistic regression"},{"ns":0,"exists":"","*":"Loss function"},{"ns":0,"exists":"","*":"Lp space"},{"ns":0,"exists":"","*":"Lucien Le Cam"},{"ns":0,"exists":"","*":"M-estimator"},{"ns":0,"exists":"","*":"Mann\u2013Whitney U test"},{"ns":0,"exists":"","*":"Mathematical Reviews"},{"ns":0,"exists":"","*":"Maximum a posteriori estimation"},{"ns":0,"exists":"","*":"Maximum entropy probability distribution"},{"ns":0,"exists":"","*":"Maximum likelihood"},{"ns":0,"exists":"","*":"Maximum likelihood estimation"},{"ns":0,"exists":"","*":"McNemar's test"},{"ns":0,"exists":"","*":"Mean"},{"ns":0,"exists":"","*":"Median"},{"ns":0,"exists":"","*":"Median-unbiased estimator"},{"ns":0,"exists":"","*":"Medical statistics"},{"ns":0,"exists":"","*":"Method of moments (statistics)"},{"ns":0,"exists":"","*":"Methods engineering"},{"ns":0,"exists":"","*":"Metric geometry"},{"ns":0,"exists":"","*":"Minimum-variance unbiased estimator"},{"ns":0,"exists":"","*":"Minimum description length"},{"ns":0,"exists":"","*":"Minimum distance estimation"},{"ns":0,"exists":"","*":"Missing at random"},{"ns":0,"exists":"","*":"Missing data"},{"ns":0,"exists":"","*":"Mixed model"},{"ns":0,"exists":"","*":"Mode (statistics)"},{"ns":0,"exists":"","*":"Model selection"},{"ns":0,"exists":"","*":"Moment (mathematics)"},{"ns":0,"exists":"","*":"Monotone likelihood ratio"},{"ns":0,"exists":"","*":"Multiple comparisons"},{"ns":0,"exists":"","*":"Multivariate adaptive regression splines"},{"ns":0,"exists":"","*":"Multivariate analysis of variance"},{"ns":0,"exists":"","*":"Multivariate distribution"},{"ns":0,"exists":"","*":"Multivariate normal distribution"},{"ns":0,"exists":"","*":"Multivariate statistics"},{"ns":0,"exists":"","*":"National accounts"},{"ns":0,"exists":"","*":"Natural experiment"},{"ns":0,"exists":"","*":"Nelson\u2013Aalen estimator"},{"ns":0,"exists":"","*":"Nonlinear regression"},{"ns":0,"exists":"","*":"Nonparametric regression"},{"ns":0,"exists":"","*":"Nonparametric statistics"},{"ns":0,"exists":"","*":"Normal distribution"},{"ns":0,"exists":"","*":"Observational study"},{"ns":0,"exists":"","*":"Official statistics"},{"ns":0,"exists":"","*":"One- and two-tailed tests"},{"ns":0,"exists":"","*":"Opinion poll"},{"ns":0,"exists":"","*":"Optimal decision"},{"ns":0,"exists":"","*":"Optimal design"},{"ns":0,"exists":"","*":"Order statistic"},{"ns":0,"exists":"","*":"Ordinary least squares"},{"ns":0,"exists":"","*":"Oscar Kempthorne"},{"ns":0,"exists":"","*":"Outline of statistics"},{"ns":0,"exists":"","*":"P-value"},{"ns":0,"exists":"","*":"Parametric model"},{"ns":0,"exists":"","*":"Parametric statistics"},{"ns":0,"exists":"","*":"Partial autocorrelation function"},{"ns":0,"exists":"","*":"Partial correlation"},{"ns":0,"exists":"","*":"Partition of sums of squares"},{"ns":0,"exists":"","*":"Pearson correlation coefficient"},{"ns":0,"exists":"","*":"Pearson product-moment correlation coefficient"},{"ns":0,"exists":"","*":"Percentile"},{"ns":0,"exists":"","*":"Permutation test"},{"ns":0,"exists":"","*":"Philosophy of statistics"},{"ns":0,"exists":"","*":"Pie chart"},{"ns":0,"exists":"","*":"Pivotal quantity"},{"ns":0,"exists":"","*":"Plug-in principle"},{"ns":0,"exists":"","*":"Point estimate"},{"ns":0,"exists":"","*":"Point estimation"},{"ns":0,"exists":"","*":"Poisson regression"},{"ns":0,"exists":"","*":"Popular Science Monthly"},{"ns":0,"exists":"","*":"Population (statistics)"},{"ns":0,"exists":"","*":"Population proportion"},{"ns":0,"exists":"","*":"Population statistics"},{"ns":0,"exists":"","*":"Posterior probability"},{"ns":0,"exists":"","*":"Power (statistics)"},{"ns":0,"exists":"","*":"Prediction interval"},{"ns":0,"exists":"","*":"Predictive inference"},{"ns":0,"exists":"","*":"Prentice Hall"},{"ns":0,"exists":"","*":"Principal component analysis"},{"ns":0,"exists":"","*":"Prior probability"},{"ns":0,"exists":"","*":"Probabilistic design"},{"ns":0,"exists":"","*":"Probability distribution"},{"ns":0,"exists":"","*":"Probability models"},{"ns":0,"exists":"","*":"Proportional hazards model"},{"ns":0,"exists":"","*":"Proposition"},{"ns":0,"exists":"","*":"Psychometrics"},{"ns":0,"exists":"","*":"Quality control"},{"ns":0,"exists":"","*":"Quasi-experiment"},{"ns":0,"exists":"","*":"Questionnaire"},{"ns":0,"exists":"","*":"Q\u2013Q plot"},{"ns":0,"exists":"","*":"Radar chart"},{"ns":0,"exists":"","*":"Random assignment"},{"ns":0,"exists":"","*":"Random sample"},{"ns":0,"exists":"","*":"Randomization"},{"ns":0,"exists":"","*":"Randomization test"},{"ns":0,"exists":"","*":"Randomized controlled trial"},{"ns":0,"exists":"","*":"Randomized experiment"},{"ns":0,"exists":"","*":"Range (statistics)"},{"ns":0,"exists":"","*":"Rank correlation"},{"ns":0,"exists":"","*":"Rank statistics"},{"ns":0,"exists":"","*":"Rao\u2013Blackwell theorem"},{"ns":0,"exists":"","*":"Regression analysis"},{"ns":0,"exists":"","*":"Regression model validation"},{"ns":0,"exists":"","*":"Reliability engineering"},{"ns":0,"exists":"","*":"Replication (statistics)"},{"ns":0,"exists":"","*":"Resampling (statistics)"},{"ns":0,"exists":"","*":"Robust regression"},{"ns":0,"exists":"","*":"Robust statistics"},{"ns":0,"exists":"","*":"Ronald A. Fisher"},{"ns":0,"exists":"","*":"Run chart"},{"ns":0,"exists":"","*":"Sample distribution"},{"ns":0,"exists":"","*":"Sample mean"},{"ns":0,"exists":"","*":"Sample median"},{"ns":0,"exists":"","*":"Sample size determination"},{"ns":0,"exists":"","*":"Sampling (statistics)"},{"ns":0,"exists":"","*":"Sampling distribution"},{"ns":0,"exists":"","*":"Sampling without replacement"},{"ns":0,"exists":"","*":"Sankhya (journal)"},{"ns":0,"exists":"","*":"Scale parameter"},{"ns":0,"exists":"","*":"Scatter plot"},{"ns":0,"exists":"","*":"Scientific control"},{"ns":0,"exists":"","*":"Score test"},{"ns":0,"exists":"","*":"Seasonal adjustment"},{"ns":0,"exists":"","*":"Semiparametric model"},{"ns":0,"exists":"","*":"Semiparametric regression"},{"ns":0,"exists":"","*":"Shape of the distribution"},{"ns":0,"exists":"","*":"Shape parameter"},{"ns":0,"exists":"","*":"Shapiro\u2013Wilk test"},{"ns":0,"exists":"","*":"Sign test"},{"ns":0,"exists":"","*":"Simple linear regression"},{"ns":0,"exists":"","*":"Simple random sample"},{"ns":0,"exists":"","*":"Simultaneous equations model"},{"ns":0,"exists":"","*":"Skewness"},{"ns":0,"exists":"","*":"Social statistics"},{"ns":0,"exists":"","*":"Source coding theorem"},{"ns":0,"exists":"","*":"Spatial analysis"},{"ns":0,"exists":"","*":"Spearman's rank correlation coefficient"},{"ns":0,"exists":"","*":"Spectral density estimation"},{"ns":0,"exists":"","*":"Standard deviation"},{"ns":0,"exists":"","*":"Standard error"},{"ns":0,"exists":"","*":"Stationary process"},{"ns":0,"exists":"","*":"Statistic"},{"ns":0,"exists":"","*":"Statistical assumptions"},{"ns":0,"exists":"","*":"Statistical classification"},{"ns":0,"exists":"","*":"Statistical decision theory"},{"ns":0,"exists":"","*":"Statistical dispersion"},{"ns":0,"exists":"","*":"Statistical distance"},{"ns":0,"exists":"","*":"Statistical graphics"},{"ns":0,"exists":"","*":"Statistical hypothesis testing"},{"ns":0,"exists":"","*":"Statistical interference"},{"ns":0,"exists":"","*":"Statistical model"},{"ns":0,"exists":"","*":"Statistical parameter"},{"ns":0,"exists":"","*":"Statistical population"},{"ns":0,"exists":"","*":"Statistical power"},{"ns":0,"exists":"","*":"Statistical process control"},{"ns":0,"exists":"","*":"Statistical theory"},{"ns":0,"exists":"","*":"Statistics"},{"ns":0,"exists":"","*":"Stem-and-leaf display"},{"ns":0,"exists":"","*":"Stratified sampling"},{"ns":0,"exists":"","*":"Structural break"},{"ns":0,"exists":"","*":"Structural equation modeling"},{"ns":0,"exists":"","*":"Student's t-test"},{"ns":0,"exists":"","*":"Sufficient statistic"},{"ns":0,"exists":"","*":"Summarizing statistical data"},{"ns":0,"exists":"","*":"Survey methodology"},{"ns":0,"exists":"","*":"Survey sampling"},{"ns":0,"exists":"","*":"Survival analysis"},{"ns":0,"exists":"","*":"Survival function"},{"ns":0,"exists":"","*":"System identification"},{"ns":0,"exists":"","*":"Test statistic"},{"ns":0,"exists":"","*":"Theoretical Computer Science (journal)"},{"ns":0,"exists":"","*":"Time domain"},{"ns":0,"exists":"","*":"Time series"},{"ns":0,"exists":"","*":"Tolerance interval"},{"ns":0,"exists":"","*":"Trend estimation"},{"ns":0,"exists":"","*":"U-statistic"},{"ns":0,"exists":"","*":"Uniformly most powerful test"},{"ns":0,"exists":"","*":"Upper and lower probabilities"},{"ns":0,"exists":"","*":"Utility function"},{"ns":0,"exists":"","*":"V-statistic"},{"ns":0,"exists":"","*":"Variance"},{"ns":0,"exists":"","*":"Vector autoregression"},{"ns":0,"exists":"","*":"Wald test"},{"ns":0,"exists":"","*":"Walter de Gruyter"},{"ns":0,"exists":"","*":"Wavelet"},{"ns":0,"exists":"","*":"Whittle likelihood"},{"ns":0,"exists":"","*":"Wilcoxon signed-rank test"},{"ns":0,"exists":"","*":"William Kruskal"},{"ns":0,"exists":"","*":"World Scientific"},{"ns":0,"exists":"","*":"Z-test"},{"ns":0,"*":"Revising opinions in statistics"},{"ns":4,"exists":"","*":"Wikipedia:Citation needed"},{"ns":4,"exists":"","*":"Wikipedia:Citing sources"},{"ns":4,"exists":"","*":"Wikipedia:WikiProject Statistics"},{"ns":11,"exists":"","*":"Template talk:Statistics"},{"ns":12,"exists":"","*":"Help:Authority control"},{"ns":100,"exists":"","*":"Portal:Statistics"}],"templates":[{"ns":10,"exists":"","*":"Template:Distinguish"},{"ns":10,"exists":"","*":"Template:Citation needed"},{"ns":10,"exists":"","*":"Template:Fix"},{"ns":10,"exists":"","*":"Template:Category handler"},{"ns":10,"exists":"","*":"Template:Fix/category"},{"ns":10,"exists":"","*":"Template:Delink"},{"ns":10,"exists":"","*":"Template:Efn"},{"ns":10,"exists":"","*":"Template:Main"},{"ns":10,"exists":"","*":"Template:See also"},{"ns":10,"exists":"","*":"Template:Expand section"},{"ns":10,"exists":"","*":"Template:Ambox"},{"ns":10,"exists":"","*":"Template:Sfn"},{"ns":10,"exists":"","*":"Template:Notelist"},{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:Isbn"},{"ns":10,"exists":"","*":"Template:ISBN"},{"ns":10,"exists":"","*":"Template:Catalog lookup link"},{"ns":10,"exists":"","*":"Template:Trim"},{"ns":10,"exists":"","*":"Template:Yesno-no"},{"ns":10,"exists":"","*":"Template:Yesno"},{"ns":10,"exists":"","*":"Template:Error-small"},{"ns":10,"exists":"","*":"Template:Tl"},{"ns":10,"exists":"","*":"Template:Cite book"},{"ns":10,"exists":"","*":"Template:Full citation needed"},{"ns":10,"exists":"","*":"Template:Page needed"},{"ns":10,"exists":"","*":"Template:Jstor"},{"ns":10,"exists":"","*":"Template:JSTOR"},{"ns":10,"exists":"","*":"Template:Hide in print"},{"ns":10,"exists":"","*":"Template:Only in print"},{"ns":10,"exists":"","*":"Template:Cite journal"},{"ns":10,"exists":"","*":"Template:Citation"},{"ns":10,"exists":"","*":"Template:Commons category"},{"ns":10,"exists":"","*":"Template:Commons"},{"ns":10,"exists":"","*":"Template:Sister project"},{"ns":10,"exists":"","*":"Template:Side box"},{"ns":10,"exists":"","*":"Template:Wikiversity"},{"ns":10,"exists":"","*":"Template:-"},{"ns":10,"exists":"","*":"Template:Clear"},{"ns":10,"exists":"","*":"Template:Statistics"},{"ns":10,"exists":"","*":"Template:Navbox with collapsible groups"},{"ns":10,"exists":"","*":"Template:Navbox"},{"ns":10,"exists":"","*":"Template:Small"},{"ns":10,"exists":"","*":"Template:Smaller"},{"ns":10,"exists":"","*":"Template:Resize"},{"ns":10,"exists":"","*":"Template:Hlist"},{"ns":10,"exists":"","*":"Template:\\"},{"ns":10,"exists":"","*":"Template:Icon"},{"ns":10,"exists":"","*":"Template:Portal bar"},{"ns":10,"exists":"","*":"Template:Authority control"},{"ns":10,"exists":"","*":"Template:EditAtWikidata"},{"ns":828,"exists":"","*":"Module:Distinguish"},{"ns":828,"exists":"","*":"Module:Hatnote"},{"ns":828,"exists":"","*":"Module:Hatnote list"},{"ns":828,"exists":"","*":"Module:Arguments"},{"ns":828,"exists":"","*":"Module:TableTools"},{"ns":828,"exists":"","*":"Module:Unsubst"},{"ns":828,"exists":"","*":"Module:Category handler"},{"ns":828,"exists":"","*":"Module:Yesno"},{"ns":828,"exists":"","*":"Module:Category handler/data"},{"ns":828,"exists":"","*":"Module:Category handler/config"},{"ns":828,"exists":"","*":"Module:Category handler/shared"},{"ns":828,"exists":"","*":"Module:Category handler/blacklist"},{"ns":828,"exists":"","*":"Module:Namespace detect/data"},{"ns":828,"exists":"","*":"Module:Namespace detect/config"},{"ns":828,"exists":"","*":"Module:Delink"},{"ns":828,"exists":"","*":"Module:No globals"},{"ns":828,"exists":"","*":"Module:Main"},{"ns":828,"exists":"","*":"Module:Labelled list hatnote"},{"ns":828,"exists":"","*":"Module:Message box"},{"ns":828,"exists":"","*":"Module:Message box/configuration"},{"ns":828,"exists":"","*":"Module:Footnotes"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"},{"ns":828,"exists":"","*":"Module:Check isxn"},{"ns":828,"exists":"","*":"Module:Error"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"},{"ns":828,"exists":"","*":"Module:Side box"},{"ns":828,"exists":"","*":"Module:Navbox"},{"ns":828,"exists":"","*":"Module:Navbar"},{"ns":828,"exists":"","*":"Module:List"},{"ns":828,"exists":"","*":"Module:Icon"},{"ns":828,"exists":"","*":"Module:Icon/data"},{"ns":828,"exists":"","*":"Module:Portal bar"},{"ns":828,"exists":"","*":"Module:Portal"},{"ns":828,"exists":"","*":"Module:Portal/images/s"},{"ns":828,"exists":"","*":"Module:Authority control"},{"ns":828,"exists":"","*":"Module:ResolveEntityId"},{"ns":828,"exists":"","*":"Module:EditAtWikidata"}],"images":["Wiki_letter_w_cropped.svg","Commons-logo.svg","Wikiversity-logo.svg","Folder_Hexagonal_Icon.svg","Portal-puzzle.svg","People_icon.svg","Fisher_iris_versicolor_sepalwidth.svg","Blue_pencil.svg"],"externallinks":["https://books.google.com/books?id=hkWK8kFzXWIC&printsec=frontcover#v=onepage&q=%22descriptive%20statistics%22&f=false","https://www.jstor.org/stable/2342192","//doi.org/10.1098/rsta.1937.0005","//www.jstor.org/stable/91337","https://www.jstor.org/stable/1403482","https://www.wikidata.org/wiki/Q938438","//www.ams.org/mathscinet-getitem?mr=0443141","//www.ams.org/mathscinet-getitem?mr=2489600","http://e-collection.library.ethz.ch/eserv/eth:26403/eth-26403-01.pdf","https://web.archive.org/web/20041116080440/http://www.stat.berkeley.edu/webmastr/users/binyu/ps/mdl.ps","//doi.org/10.1198/016214501753168398","//www.jstor.org/stable/2670311","//www.ams.org/mathscinet-getitem?mr=1939352","http://www.stat.berkeley.edu/webmastr/users/binyu/ps/mdl.ps","https://books.google.com/?id=T3wWj2kVYZgC&printsec=frontcover","//www.ams.org/mathscinet-getitem?mr=0178484","//doi.org/10.1016/S0304-3975(98)00075-9","//www.ams.org/mathscinet-getitem?mr=1643414","//doi.org/10.2307/2290117","//www.jstor.org/stable/2290117","//www.jstor.org/stable/2983716","https://books.google.com/books?id=ZKMVAAAAYAAJ&jtp=604","https://archive.org/stream/popscimonthly12yoummiss#page/612/mode/1up","https://books.google.com/books?id=ZKMVAAAAYAAJ&jtp=705","https://archive.org/stream/popscimonthly12yoummiss#page/715/mode/1up","https://books.google.com/books?id=u8sWAQAAIAAJ&jtp=203","https://archive.org/stream/popularsciencemo13newy#page/203/mode/1up","https://books.google.com/books?id=u8sWAQAAIAAJ&jtp=470","https://archive.org/stream/popularsciencemo13newy#page/470/mode/1up","https://books.google.com/books?id=V7oIAAAAQAAJ&pg=PA126","//www.ams.org/mathscinet-getitem?mr=1291393","//www.ams.org/mathscinet-getitem?mr=1082556","//doi.org/10.1080/01621459.2000.10474346","//www.jstor.org/stable/2669786","//www.ams.org/mathscinet-getitem?mr=1825292","//doi.org/10.1214/ss/1177011233","//www.jstor.org/stable/2246073","//doi.org/10.2307/270939","//www.jstor.org/stable/270939","http://www.stats.org.uk/statistical-inference/Lenhard2006.pdf","//doi.org/10.1093/bjps/axi152","//doi.org/10.1111/insr.12067","http://dspace.mit.edu/handle/1721.1/45587","http://www.nptel.ac.in/courses/111105043/","https://www.youtube.com/playlist?list=PLbMVogVj5nJRkNUH5v9qNEJvW7r2A7rEY","https://www.academia.edu/3247833/","https://d-nb.info/gnd/4182963-3","http://www.springerreference.com/docs/html/chapterdbid/372458.html"],"sections":[{"toclevel":1,"level":"2","line":"Introduction","number":"1","index":"1","fromtitle":"Statistical_inference","byteoffset":799,"anchor":"Introduction"},{"toclevel":1,"level":"2","line":"Models and assumptions","number":"2","index":"2","fromtitle":"Statistical_inference","byteoffset":2772,"anchor":"Models_and_assumptions"},{"toclevel":2,"level":"3","line":"Degree of models/assumptions","number":"2.1","index":"3","fromtitle":"Statistical_inference","byteoffset":3626,"anchor":"Degree_of_models/assumptions"},{"toclevel":2,"level":"3","line":"Importance of valid models/assumptions","number":"2.2","index":"4","fromtitle":"Statistical_inference","byteoffset":5712,"anchor":"Importance_of_valid_models/assumptions"},{"toclevel":3,"level":"4","line":"Approximate distributions","number":"2.2.1","index":"5","fromtitle":"Statistical_inference","byteoffset":7731,"anchor":"Approximate_distributions"},{"toclevel":2,"level":"3","line":"Randomization-based models","number":"2.3","index":"6","fromtitle":"Statistical_inference","byteoffset":12029,"anchor":"Randomization-based_models"},{"toclevel":3,"level":"4","line":"Model-based analysis of randomized experiments","number":"2.3.1","index":"7","fromtitle":"Statistical_inference","byteoffset":15864,"anchor":"Model-based_analysis_of_randomized_experiments"},{"toclevel":1,"level":"2","line":"Paradigms for inference","number":"3","index":"8","fromtitle":"Statistical_inference","byteoffset":16661,"anchor":"Paradigms_for_inference"},{"toclevel":2,"level":"3","line":"Frequentist inference","number":"3.1","index":"9","fromtitle":"Statistical_inference","byteoffset":17598,"anchor":"Frequentist_inference"},{"toclevel":3,"level":"4","line":"Examples of frequentist inference","number":"3.1.1","index":"10","fromtitle":"Statistical_inference","byteoffset":18047,"anchor":"Examples_of_frequentist_inference"},{"toclevel":3,"level":"4","line":"Frequentist inference, objectivity, and decision theory","number":"3.1.2","index":"11","fromtitle":"Statistical_inference","byteoffset":18143,"anchor":"Frequentist_inference,_objectivity,_and_decision_theory"},{"toclevel":2,"level":"3","line":"Bayesian inference","number":"3.2","index":"12","fromtitle":"Statistical_inference","byteoffset":20772,"anchor":"Bayesian_inference"},{"toclevel":3,"level":"4","line":"Examples of Bayesian inference","number":"3.2.1","index":"13","fromtitle":"Statistical_inference","byteoffset":21234,"anchor":"Examples_of_Bayesian_inference"},{"toclevel":3,"level":"4","line":"Bayesian inference, subjectivity and decision theory","number":"3.2.2","index":"14","fromtitle":"Statistical_inference","byteoffset":21368,"anchor":"Bayesian_inference,_subjectivity_and_decision_theory"},{"toclevel":2,"level":"3","line":"AIC-based inference","number":"3.3","index":"15","fromtitle":"Statistical_inference","byteoffset":23098,"anchor":"AIC-based_inference"},{"toclevel":2,"level":"3","line":"Other paradigms for inference","number":"3.4","index":"16","fromtitle":"Statistical_inference","byteoffset":23813,"anchor":"Other_paradigms_for_inference"},{"toclevel":3,"level":"4","line":"Minimum description length","number":"3.4.1","index":"17","fromtitle":"Statistical_inference","byteoffset":23850,"anchor":"Minimum_description_length"},{"toclevel":3,"level":"4","line":"Fiducial inference","number":"3.4.2","index":"18","fromtitle":"Statistical_inference","byteoffset":25636,"anchor":"Fiducial_inference"},{"toclevel":3,"level":"4","line":"Structural inference","number":"3.4.3","index":"19","fromtitle":"Statistical_inference","byteoffset":26539,"anchor":"Structural_inference"},{"toclevel":1,"level":"2","line":"Inference topics","number":"4","index":"20","fromtitle":"Statistical_inference","byteoffset":27178,"anchor":"Inference_topics"},{"toclevel":1,"level":"2","line":"See also","number":"5","index":"21","fromtitle":"Statistical_inference","byteoffset":27592,"anchor":"See_also"},{"toclevel":1,"level":"2","line":"Notes","number":"6","index":"22","fromtitle":"Statistical_inference","byteoffset":27817,"anchor":"Notes"},{"toclevel":1,"level":"2","line":"Citations","number":"7","index":"23","fromtitle":"Statistical_inference","byteoffset":27843,"anchor":"Citations"},{"toclevel":1,"level":"2","line":"References","number":"8","index":"24","fromtitle":"Statistical_inference","byteoffset":27870,"anchor":"References"},{"toclevel":1,"level":"2","line":"Further reading","number":"9","index":"25","fromtitle":"Statistical_inference","byteoffset":34696,"anchor":"Further_reading"},{"toclevel":1,"level":"2","line":"External links","number":"10","index":"26","fromtitle":"Statistical_inference","byteoffset":36468,"anchor":"External_links"}],"parsewarnings":[],"displaytitle":"Statistical inference","iwlinks":[{"prefix":"commons","url":"https://commons.wikimedia.org/wiki/Category:Statistical_inference","*":"commons:Category:Statistical inference"},{"prefix":"commons","url":"https://commons.wikimedia.org/wiki/Category:Statistics","*":"commons:Category:Statistics"},{"prefix":"v","url":"https://en.wikiversity.org/wiki/Special:Search/Statistical_inference","*":"v:Special:Search/Statistical inference"}],"properties":[{"name":"defaultsort","*":"Statistical Inference"},{"name":"wikibase_item","*":"Q938438"}]}}