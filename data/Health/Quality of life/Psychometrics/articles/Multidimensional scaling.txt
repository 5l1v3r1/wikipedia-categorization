Multidimensional scaling (MDS) is a means of visualizing the level of similarity of individual cases of a dataset.  It refers to a set of related ordination techniques used in information visualization, in particular to display the information contained in a distance matrix. It is a form of non-linear dimensionality reduction. An MDS algorithm aims to place each object in N-dimensional space such that the between-object distances are preserved as well as possible. Each object is then assigned coordinates in each of the N dimensions. The number of dimensions of an MDS plot N can exceed 2 and is specified a priori. Choosing N=2 optimizes the object locations for a two-dimensional scatterplot.  MDS algorithms fall into a taxonomy, depending on the meaning of the input matrix: It is also known as Principal Coordinates Analysis (PCoA), Torgerson Scaling or Torgerson–Gower scaling. It takes an input matrix giving dissimilarities between pairs of items and outputs a coordinate matrix whose configuration minimizes a loss function called strain.  For example, given the aerial distances between many cities in a matrix                         D         =         [                    d                        i             j                             ]                 {\textstyle D=[d_{ij}]}    , where                                    d                        i             j                                     {\textstyle d_{ij}}     is the distance between the coordinates of                                    i                        t             h                                     {\textstyle i^{th}}     and                                    j                        t             h                                     {\textstyle j^{th}}     city, given by                                    d                        i             j                             =                                 (                            x                                i                                         −                            x                                j                                                        )                                2                                         +             (                            y                                i                                         −                            y                                j                                                        )                                2                                                                 {\textstyle d_{ij}={\sqrt {(x_{i}-x_{j})^{2}+(y_{i}-y_{j})^{2}}}}    , you want to find the coordinates of the cities. This problem is addressed in classical MDS. General forms of loss functions called Stress in distance MDS and Strain in classical MDS. The strain is given by:                          S         t         r         a         i                    n                        D                             (                    x                        1                             ,                    x                        2                             ,         .         .         .         ,                    x                        N                             )         =                                 (                                                                                     ∑                                    i                   ,                   j                                                                                   (                                                                b                                    i                   j                                               −               ⟨                                x                                    i                                               ,                                x                                    j                                               ⟩                                                                        )                                                                        2                                                                                          ∑                                    i                   ,                   j                                                                b                                    i                   j                                                     2                                                                                                                 )                                                1                            /                          2                                     {\displaystyle Strain_{D}(x_{1},x_{2},...,x_{N})={\Biggl (}{\frac {\sum _{i,j}{\bigl (}b_{ij}-\langle x_{i},x_{j}\rangle {\bigr )}^{2}}{\sum _{i,j}b_{ij}^{2}}}{\Biggr )}^{1/2}}    , where                                    b                        i             j                                     {\displaystyle b_{ij}}     are the terms of the matrix                         B                 {\displaystyle B}     defined on step 2 of the following algorithm.  It is a superset of classical MDS that generalizes the optimization procedure to a variety of loss functions and input matrices of known distances with weights and so on.  A useful loss function in this context is called stress, which is often minimized using a procedure called stress majorization. Metric MDS minimizes the cost function called “Stress” which is a residual sum of squares:                        S         t         r         e         s                    s                        D                             (                    x                        1                             ,                    x                        2                             ,         .         .         .         ,                    x                        N                             )         =                                 (                                        ∑                        i             ≠             j             =             1             ,             .             .             .             ,             N                                                     (                                        d                        i             j                             −         ‖                    x                        i                             −                    x                        j                             ‖                                                )                                                2                                                                    )                                                1                            /                          2                                     {\displaystyle Stress_{D}(x_{1},x_{2},...,x_{N})={\Biggl (}\sum _{i\neq j=1,...,N}{\bigl (}d_{ij}-\|x_{i}-x_{j}\|{\bigr )}^{2}{\Biggr )}^{1/2}}    : or,                               S         t         r         e         s                    s                        D                             (                    x                        1                             ,                    x                        2                             ,         .         .         .         ,                    x                        N                             )         =                                 (                                                                                     ∑                                    i                   ,                   j                                                                                   (                                                                d                                    i                   j                                               −               ‖                                x                                    i                                               −                                x                                    j                                               ‖                                                                        )                                                                        2                                                                                          ∑                                    i                   ,                   j                                                                d                                    i                   j                                                     2                                                                                                                 )                                                1                            /                          2                                     {\displaystyle Stress_{D}(x_{1},x_{2},...,x_{N})={\Biggl (}{\frac {\sum _{i,j}{\bigl (}d_{ij}-\|x_{i}-x_{j}\|{\bigr )}^{2}}{\sum _{i,j}d_{ij}^{2}}}{\Biggr )}^{1/2}}     In contrast to metric MDS, non-metric MDS finds both a non-parametric monotonic relationship between the dissimilarities in the item-item matrix and the Euclidean distances between items, and the location of each item in the low-dimensional space. The relationship is typically found using isotonic regression: let                         x                 {\textstyle x}     denote the vector of proximities,                         f         (         x         )                 {\textstyle f(x)}     a monotonic transformation of                         x                 {\textstyle x}    , and                         d                 {\textstyle d}     the point distances; then coordinates have to be found, that minimize the so-called stress,                         S         t         r         e         s         s         =                                                                 ∑                                                         (                                                     f                 (                 x                 )                 −                 d                                                                                )                                                                                2                                                                                   ∑                                    d                                        2                                                                                                     {\displaystyle Stress={\sqrt {\frac {\sum {\bigl (}f(x)-d{\bigr )}^{2}}{\sum d^{2}}}}}    An extension of metric multidimensional scaling, in which the target space is an arbitrary smooth non-Euclidean space. In cases where the dissimilarities are distances on a surface and the target space is another surface, GMDS allows finding the minimum-distortion embedding of one surface into another.  The data to be analyzed is a collection of                         I                 {\displaystyle I}     objects (colors, faces, stocks, . . .) on which a distance function is defined, These distances are the entries of the dissimilarity matrix The goal of MDS is, given                         Δ                 {\displaystyle \Delta }    , to find                         I                 {\displaystyle I}     vectors                                     x                        1                             ,         …         ,                    x                        I                             ∈                                 R                                   N                                     {\displaystyle x_{1},\ldots ,x_{I}\in \mathbb {R} ^{N}}     such that where                         ‖         ⋅         ‖                 {\displaystyle \|\cdot \|}     is a vector norm.  In classical MDS, this norm is the Euclidean distance, but, in a broader sense, it may be a metric or arbitrary distance function.  In other words, MDS attempts to find an embedding from the                         I                 {\displaystyle I}     objects into                                                 R                                   N                                     {\displaystyle \mathbb {R} ^{N}}     such that distances are preserved.  If the dimension                         N                 {\displaystyle N}     is chosen to be 2 or 3, we may plot the vectors                                    x                        i                                     {\displaystyle x_{i}}     to obtain a visualization of the similarities between the                         I                 {\displaystyle I}     objects.  Note that the vectors                                    x                        i                                     {\displaystyle x_{i}}     are not unique: With the Euclidean distance, they may be arbitrarily translated, rotated, and reflected, since these transformations do not change the pairwise distances                         ‖                    x                        i                             −                    x                        j                             ‖                 {\displaystyle \|x_{i}-x_{j}\|}    . (Note: The symbol                                    R                          {\displaystyle \mathbb {R} }     indicates the set of real numbers, and the notation                                                 R                                   N                                     {\displaystyle \mathbb {R} ^{N}}     refers to the Cartesian product of                         N                 {\displaystyle N}     copies of                                    R                          {\displaystyle \mathbb {R} }    , which is an                         N                 {\displaystyle N}    -dimensional vector space over the field of the real numbers.) There are various approaches to determining the vectors                                    x                        i                                     {\displaystyle x_{i}}    .  Usually, MDS is formulated as an optimization problem, where                         (                    x                        1                             ,         …         ,                    x                        I                             )                 {\displaystyle (x_{1},\ldots ,x_{I})}     is found as a minimizer of some cost function, for example, A solution may then be found by numerical optimization techniques.  For some particularly chosen cost functions, minimizers can be stated analytically in terms of matrix eigendecompositions.  There are several steps in conducting MDS research: 