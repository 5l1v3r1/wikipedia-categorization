Optimal Discriminant Analysis (ODA)   and the related classification tree analysis (CTA) are exact statistical methods that maximize predictive accuracy.  For any specific sample and exploratory or confirmatory hypothesis, optimal discriminant analysis (ODA) identifies the statistical model that yields maximum predictive accuracy, assesses the exact Type I error rate, and evaluates potential cross-generalizability. Optimal discriminant analysis may be applied to >Â 0 dimensions, with the one-dimensional case being referred to as UniODA and the multidimensional case being referred to as MultiODA.  Classification tree analysis is a generalization of optimal discriminant analysis to non-orthogonal trees. Classification tree analysis has more recently been called "hierarchical optimal discriminant analysis".  Optimal discriminant analysis and classification tree analysis may be used to find the combination of variables and cut points that best separate classes of objects or events. These variables and cut points may then be used to reduce dimensions and to then build a  statistical model that optimally describes the data. Optimal discriminant analysis may be thought of as a generalization of Fisher's linear discriminant analysis.  Optimal discriminant analysis is an alternative to ANOVA (analysis of variance) and regression analysis, which attempt to express one dependent variable as a linear combination of other features or measurements. However, ANOVA and regression analysis give a dependent variable that is a numerical variable, while optimal discriminant analysis gives a dependent variable that is a class variable. 