{"parse":{"title":"Computer facial animation","pageid":2974157,"revid":801948317,"text":{"*":"<div class=\"mw-parser-output\"><table class=\"plainlinks metadata ambox ambox-content ambox-Refimprove\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><div style=\"width:52px\"><a href=\"/wiki/File:Question_book-new.svg\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png\" width=\"50\" height=\"39\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/75px-Question_book-new.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png 2x\" data-file-width=\"512\" data-file-height=\"399\" /></a></div></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">This article <b>needs additional citations for <a href=\"/wiki/Wikipedia:Verifiability\" title=\"Wikipedia:Verifiability\">verification</a></b>.<span class=\"hide-when-compact\"> Please help <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Computer_facial_animation&amp;action=edit\">improve this article</a> by <a href=\"/wiki/Help:Introduction_to_referencing_with_Wiki_Markup/1\" title=\"Help:Introduction to referencing with Wiki Markup/1\">adding citations to reliable sources</a>. Unsourced material may be challenged and removed.</span>  <small><i>(February 2010)</i></small><small class=\"hide-when-compact\"><i> (<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>\n<p><b>Computer facial animation</b> is primarily an area of <a href=\"/wiki/Computer_graphics\" title=\"Computer graphics\">computer graphics</a> that encapsulates methods and techniques for generating and animating images or models of a character face. The character can be a human, a humanoid, an animal, a fantasy creature or character, etc. Due to its subject and output type, it is also related to many other scientific and artistic fields from <a href=\"/wiki/Psychology\" title=\"Psychology\">psychology</a> to traditional <a href=\"/wiki/Animation\" title=\"Animation\">animation</a>. The importance of <a href=\"/wiki/Face\" title=\"Face\">human faces</a> in <a href=\"/wiki/Communication\" title=\"Communication\">verbal and non-verbal communication</a> and advances in <a href=\"/wiki/Graphics_processing_unit\" title=\"Graphics processing unit\">computer graphics hardware</a> and <a href=\"/wiki/Software\" title=\"Software\">software</a> have caused considerable scientific, technological, and artistic interests in computer facial animation.\n</p><p>Although development of <a href=\"/wiki/Computer_graphics\" title=\"Computer graphics\">computer graphics</a> methods for facial animation started in the early-1970s, major achievements in this field are more recent and happened since the late 1980s.\n</p><p>The body of work around computer facial animation can be divided into two main areas: techniques to generate animation data, and methods to apply such data to a character. Techniques such as <a href=\"/wiki/Motion_capture\" title=\"Motion capture\">motion capture</a> and <a href=\"/wiki/Keyframing\" class=\"mw-redirect\" title=\"Keyframing\">keyframing</a> belong to the first group, while <a href=\"/wiki/Morph_target_animation\" title=\"Morph target animation\">morph targets animation</a> (more commonly known as blendshape animation) and <a href=\"/wiki/Skeletal_animation\" title=\"Skeletal animation\">skeletal animation</a> belong to the second. Facial animation has become well-known and popular through animated feature <a href=\"/wiki/Film\" title=\"Film\">films</a> and <a href=\"/wiki/Computer_games\" class=\"mw-redirect\" title=\"Computer games\">computer games</a> but its applications include many more areas such as <a href=\"/wiki/Communication\" title=\"Communication\">communication</a>, <a href=\"/wiki/Education\" title=\"Education\">education</a>, scientific <a href=\"/wiki/Simulation\" title=\"Simulation\">simulation</a>, and <a href=\"/wiki/Software_agent\" title=\"Software agent\">agent</a>-based systems (for example online customer service representatives). With the recent advancements in computational power in personal and <a href=\"/wiki/Mobile_devices\" class=\"mw-redirect\" title=\"Mobile devices\">mobile devices</a>, facial animation has transitioned from appearing in pre-rendered content to being created at runtime.\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#History\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">History</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Techniques\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Techniques</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-3\"><a href=\"#Generating_facial_animation_data\"><span class=\"tocnumber\">2.1</span> <span class=\"toctext\">Generating facial animation data</span></a></li>\n<li class=\"toclevel-2 tocsection-4\"><a href=\"#Applying_facial_animation_to_a_character\"><span class=\"tocnumber\">2.2</span> <span class=\"toctext\">Applying facial animation to a character</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-5\"><a href=\"#Face_animation_languages\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Face animation languages</span></a></li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#See_also\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-7\"><a href=\"#References\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-8\"><a href=\"#Further_reading\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">Further reading</span></a></li>\n<li class=\"toclevel-1 tocsection-9\"><a href=\"#External_links\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"History\">History</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computer_facial_animation&amp;action=edit&amp;section=1\" title=\"Edit section: History\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Human <a href=\"/wiki/Facial_expression\" title=\"Facial expression\">facial expression</a> has been the subject of scientific investigation for more than one hundred years. Study of facial movements and expressions started from a biological point of view. After some older investigations, for example by <a href=\"/wiki/John_Bulwer\" title=\"John Bulwer\">John Bulwer</a> in the late 1640s, <a href=\"/wiki/Charles_Darwin\" title=\"Charles Darwin\">Charles Darwin</a>\u2019s book <i>The Expression of the Emotions in Men and Animals</i> can be considered a major departure for modern research in behavioural <a href=\"/wiki/Biology\" title=\"Biology\">biology</a>.\n</p><p>Computer based facial expression modelling and <a href=\"/wiki/Animation\" title=\"Animation\">animation</a> is not a new endeavour. The earliest work with computer based facial representation was done in the early-1970s. The first three-dimensional facial animation was created by <a href=\"/wiki/Fred_Parke\" class=\"mw-redirect\" title=\"Fred Parke\">Parke</a> in 1972. In 1973, Gillenson developed an interactive system to assemble and edit line drawn facial images. in 1974, <a href=\"/wiki/Fred_Parke\" class=\"mw-redirect\" title=\"Fred Parke\">Parke</a> developed a parameterized three-dimensional facial model.\n</p><p>One of the most important attempts to describe facial movements was <a href=\"/wiki/Facial_Action_Coding_System\" title=\"Facial Action Coding System\">Facial Action Coding System</a> (FACS). Originally developed by Carl-Herman Hjortsj\u00f6 <sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\">&#91;1&#93;</a></sup> in the 1960s and updated by <a href=\"/wiki/Paul_Ekman\" title=\"Paul Ekman\">Ekman</a> and <a href=\"/wiki/Friesen\" title=\"Friesen\">Friesen</a> in 1978, FACS defines 46 basic facial Action Units (AUs). A major group of these Action Units represent primitive movements of facial muscles in actions such as raising brows, winking, and talking. Eight AU's are for rigid three-dimensional head movements, (i.e. turning and tilting left and right and going up, down, forward and backward). FACS has been successfully used for describing desired movements of synthetic faces and also in tracking facial activities.\n</p><p>The early-1980s saw the development of the first physically based muscle-controlled face model by Platt and the development of techniques for facial caricatures by Brennan. In 1985, the animated short film <i><a href=\"/wiki/Tony_de_Peltrie\" title=\"Tony de Peltrie\">Tony de Peltrie</a></i> was a landmark for facial animation. This marked the first time computer facial expression and speech animation were a fundamental part of telling the story.\n</p><p>The late-1980s saw the development of a new muscle-based model by <a href=\"/wiki/Keith_Waters\" title=\"Keith Waters\">Waters</a>, the development of an abstract muscle action model by <a href=\"/wiki/Nadia_Magnenat_Thalmann\" title=\"Nadia Magnenat Thalmann\">Magnenat-Thalmann</a> and colleagues, and approaches to automatic speech synchronization by Lewis and Hill. The 1990s have seen increasing activity in the development of facial animation techniques and the use of computer facial animation as a key storytelling component as illustrated in animated films such as <i><a href=\"/wiki/Toy_Story\" title=\"Toy Story\">Toy Story</a></i> (1995), <i><a href=\"/wiki/Antz\" title=\"Antz\">Antz</a></i> (1998), <i><a href=\"/wiki/Shrek\" title=\"Shrek\">Shrek</a></i>, and <i><a href=\"/wiki/Monsters,_Inc.\" title=\"Monsters, Inc.\">Monsters, Inc.</a></i> (both 2001), and <a href=\"/wiki/Computer_games\" class=\"mw-redirect\" title=\"Computer games\">computer games</a> such as <i><a href=\"/wiki/The_Sims_(series)\" class=\"mw-redirect\" title=\"The Sims (series)\">Sims</a></i>.  <i><a href=\"/wiki/Casper_(film)\" title=\"Casper (film)\">Casper</a></i> (1995), a milestone in this decade, was the first movie in which a lead actor was produced exclusively using digital facial animation.\n</p><p>The sophistication of the films increased after 2000. In <i><a href=\"/wiki/The_Matrix_Reloaded\" title=\"The Matrix Reloaded\">The Matrix Reloaded</a></i> and <i><a href=\"/wiki/The_Matrix_Revolutions\" title=\"The Matrix Revolutions\">The Matrix Revolutions</a></i>, dense <a href=\"/wiki/Optical_flow\" title=\"Optical flow\">optical flow</a> from several high-definition cameras was used to capture realistic facial movement at every point on the face. <i><a href=\"/wiki/Polar_Express_(film)\" class=\"mw-redirect\" title=\"Polar Express (film)\">Polar Express (film)</a></i> used a large Vicon system to capture upward of 150 points. Although these systems are automated, a large amount of manual clean-up effort is still needed to make the data usable. Another milestone in facial animation was reached by <i><a href=\"/wiki/The_Lord_of_the_Rings_(film_series)\" title=\"The Lord of the Rings (film series)\">The Lord of the Rings</a></i>, where a character specific shape base system was developed. Mark Sagar pioneered the use of <a href=\"/wiki/Facial_Action_Coding_System\" title=\"Facial Action Coding System\">FACS</a> in entertainment facial animation, and FACS based systems developed by Sagar were used on <i><a href=\"/wiki/Monster_House_(film)\" title=\"Monster House (film)\">Monster House</a></i>, <i><a href=\"/wiki/King_Kong_(2005_film)\" title=\"King Kong (2005 film)\">King Kong</a></i>, and other films.\n</p>\n<h2><span class=\"mw-headline\" id=\"Techniques\">Techniques</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computer_facial_animation&amp;action=edit&amp;section=2\" title=\"Edit section: Techniques\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Generating_facial_animation_data\">Generating facial animation data</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computer_facial_animation&amp;action=edit&amp;section=3\" title=\"Edit section: Generating facial animation data\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>The generation of facial animation data can be approached in different ways: 1.) <a href=\"/wiki/Motion_capture\" title=\"Motion capture\">marker-based motion capture</a> on points or marks on the face of a performer, 2.) <a href=\"/wiki/Motion_capture#Markerless\" title=\"Motion capture\">markerless motion capture</a> techniques using different type of cameras, 3.) audio-driven techniques, and 4.) <a href=\"/wiki/Keyframe\" class=\"mw-redirect\" title=\"Keyframe\">keyframe</a> animation.\n</p>\n<ul><li><b><a href=\"/wiki/Motion_capture\" title=\"Motion capture\">Motion capture</a></b> uses cameras placed around a subject. The subject is generally fitted either with reflectors (passive motion capture) or sources (active motion capture) that precisely determine the subject's position in space. The data recorded by the cameras is then digitized and converted into a three-dimensional computer model of the subject. Until recently, the size of the detectors/sources used by motion capture systems made the technology inappropriate for facial capture. However, miniaturization and other advancements have made motion capture a viable tool for computer facial animation. Facial motion capture was used extensively in <a href=\"/wiki/Polar_Express\" class=\"mw-redirect\" title=\"Polar Express\">Polar Express</a> by <a href=\"/wiki/Sony_Pictures_Imageworks\" title=\"Sony Pictures Imageworks\">Imageworks</a> where hundreds of motion points were captured. This film was very accomplished and while it attempted to recreate realism, it was criticized for having fallen in the '<a href=\"/wiki/Uncanny_valley\" title=\"Uncanny valley\">uncanny valley</a>', the realm where animation realism is sufficient for human recognition and to convey the emotional message but where the characters fail to be perceived as realistic. The main difficulties of motion capture are the quality of the data which may include vibration as well as the retargeting of the geometry of the points.</li>\n<li><b><a href=\"/wiki/Motion_capture#Markerless\" title=\"Motion capture\">Markerless motion capture</a></b> aims at simplifying the motion capture process by avoiding encumbering the performer with markers. Several techniques came out recently leveraging different sensors, among which standard video cameras, Kinect and depth sensors or other structured-light based devices.  Systems based on <a href=\"/wiki/Structured_light\" title=\"Structured light\">structured light</a> may achieve real-time performance without the use of any markers using a high speed structured light scanner. The system is based on a robust offline face tracking stage which trains the system with different facial expressions. The matched sequences are used to build a person-specific linear face model that is subsequently used for online face tracking and expression transfer.</li>\n<li><b>Audio-driven techniques</b> are particularly well fitted for speech animation. Speech is usually treated in a different way to the animation of facial expressions, this is because simple <a href=\"/wiki/Keyframe\" class=\"mw-redirect\" title=\"Keyframe\">keyframe</a>-based approaches to animation typically provide a poor approximation to real speech dynamics. Often <a href=\"/wiki/Viseme\" title=\"Viseme\">visemes</a> are used to represent the key poses in observed speech (i.e. the position of the lips, jaw and tongue when producing a particular <a href=\"/wiki/Phoneme\" title=\"Phoneme\">phoneme</a>), however there is a great deal of variation in the realisation of visemes during the production of natural speech. The source of this variation is termed <a href=\"/wiki/Coarticulation\" title=\"Coarticulation\">coarticulation</a> which is the influence of surrounding visemes upon the current viseme (i.e. the effect of context). To account for coarticulation current systems either explicitly take into account context when blending viseme keyframes or use longer units such as <a href=\"/wiki/Diphone\" title=\"Diphone\">diphone</a>, <a href=\"/wiki/Triphone\" title=\"Triphone\">triphone</a>, <a href=\"/wiki/Syllable\" title=\"Syllable\">syllable</a> or even <a href=\"/wiki/Word\" title=\"Word\">word</a> and <a href=\"/wiki/Sentence_(linguistics)\" title=\"Sentence (linguistics)\">sentence</a>-length units. One of the most common approaches to speech animation is the use of dominance functions introduced by Cohen and Massaro. Each dominance function represents the influence over time that a viseme has on a speech utterance. Typically the influence will be greatest at the center of the viseme and will degrade with distance from the viseme center. Dominance functions are blended together to generate a speech trajectory in much the same way that <a href=\"/wiki/Spline_(mathematics)\" title=\"Spline (mathematics)\">spline</a> basis functions are blended together to generate a curve. The shape of each dominance function will be different according to both which viseme it represents and what aspect of the face is being controlled (e.g. lip width, jaw rotation etc.). This approach to computer-generated speech animation can be seen in the Baldi talking head. Other models of speech use basis units which include context (e.g. <a href=\"/wiki/Diphone\" title=\"Diphone\">diphones</a>, <a href=\"/wiki/Triphone\" title=\"Triphone\">triphones</a> etc.) instead of visemes. As the basis units already incorporate the variation of each viseme according to context and to some degree the dynamics of each viseme, no model of <a href=\"/wiki/Coarticulation\" title=\"Coarticulation\">coarticulation</a> is required. Speech is simply generated by selecting appropriate units from a database and blending the units together. This is similar to concatenative techniques in audio <a href=\"/wiki/Speech_synthesis\" title=\"Speech synthesis\">speech synthesis</a>. The disadvantage to these models is that a large amount of captured data is required to produce natural results, and whilst longer units produce more natural results the size of database required expands with the average length of each unit. Finally, some models directly generate speech animations from audio. These systems typically use <a href=\"/wiki/Hidden_markov_model\" class=\"mw-redirect\" title=\"Hidden markov model\">hidden markov models</a> or <a href=\"/wiki/Neural_net\" class=\"mw-redirect\" title=\"Neural net\">neural nets</a> to transform audio parameters into a stream of control parameters for a facial model. The advantage of this method is the capability of voice context handling, the natural rhythm, tempo, emotional and dynamics handling without complex approximation algorithms. The training database is not needed to be labeled since there are no phonemes or visemes needed; the only needed data is the voice and the animation parameters.</li>\n<li><b><a href=\"/wiki/Keyframe\" class=\"mw-redirect\" title=\"Keyframe\">Keyframe</a> animation</b> is the least automated of the processes to create animation data although it delivers the maximum amount of control over the animation. It is often used in combination with other techniques to deliver the final polish to the animation. The <a href=\"/wiki/Keyframe\" class=\"mw-redirect\" title=\"Keyframe\">keyframe</a> data can be made of scalar values defining the <a href=\"/wiki/Morph_target_animation\" title=\"Morph target animation\">morph targets</a> coefficients or rotation and translation values of the bones in models with a bone based rig. Often to speed up the <a href=\"/wiki/Keyframe\" class=\"mw-redirect\" title=\"Keyframe\">keyframe</a> animation process a control rig is used by the animation. The control rig represents a higher level of abstraction that can act on multiple <a href=\"/wiki/Morph_target_animation\" title=\"Morph target animation\">morph targets</a> coefficients or bones at the same time. For example, a \"smile\" control can act simultaneously on the mouth shape curving up and the eyes squinting.</li></ul>\n<h3><span class=\"mw-headline\" id=\"Applying_facial_animation_to_a_character\">Applying facial animation to a character</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computer_facial_animation&amp;action=edit&amp;section=4\" title=\"Edit section: Applying facial animation to a character\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>The main techniques used to apply facial animation to a character are: 1.) <a href=\"/wiki/Morph_target_animation\" title=\"Morph target animation\">morph targets animation</a>, 2.) <a href=\"/wiki/Skeletal_animation\" title=\"Skeletal animation\">bone driven animation</a>, 3.) texture-based animation (2D or 3D), and 4.) <a href=\"/wiki/Physiology\" title=\"Physiology\">physiological</a> models.\n</p>\n<ul><li><b><a href=\"/wiki/Morph_target_animation\" title=\"Morph target animation\">Morph targets</a></b> (also called <b>\"blendshapes\"</b>) based systems offer a fast playback as well as a high degree of fidelity of expressions. The technique involves modeling portions of the face mesh to approximate expressions and <a href=\"/wiki/Viseme\" title=\"Viseme\">visemes</a> and then blending the different sub meshes, known as morph targets or blendshapes. Perhaps the most accomplished character using this technique was Gollum, from <i>The Lord of the Rings</i>. Drawbacks of this technique are that they involve intensive manual labor and are specific to each character. Recently, new concepts in 3D modeling have started to emerge.  Recently, a new technology departing from the traditional techniques starts to emerge, such as <i><a href=\"/w/index.php?title=Curve_Controlled_Modeling&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"Curve Controlled Modeling (page does not exist)\">Curve Controlled Modeling</a></i><sup id=\"cite_ref-CurveControl_2-0\" class=\"reference\"><a href=\"#cite_note-CurveControl-2\">&#91;2&#93;</a></sup>  that emphasizes the modeling of the movement of a 3D object instead of the traditional modeling of the static shape.</li>\n<li><b><a href=\"/wiki/Skeletal_animation\" title=\"Skeletal animation\">Bone driven animation</a></b> is very broadly used in games. The bones setup can vary between few bones to close to a hundred to allow all subtle facial expressions. The main advantages of bone driven animation is that the same animation can be used for different characters as long as the morphology of their faces is similar, and secondly they do not require loading in memory all the <a href=\"/wiki/Morph_target_animation\" title=\"Morph target animation\">Morph targetsdata</a>. Bone driven animation is most widely supported by 3D game engines. Bone driven animation can be used both 2D and 3D animation. For example, it is possible to rig and animated using bones a 2D character using <a href=\"/wiki/Adobe_Flash\" title=\"Adobe Flash\">Adobe Flash</a>.</li></ul>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><a href=\"/wiki/File:Kara_-_animated_short_by_Quantic_Dreams.png\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/a/a8/Kara_-_animated_short_by_Quantic_Dreams.png/220px-Kara_-_animated_short_by_Quantic_Dreams.png\" width=\"220\" height=\"157\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/a/a8/Kara_-_animated_short_by_Quantic_Dreams.png/330px-Kara_-_animated_short_by_Quantic_Dreams.png 1.5x, //upload.wikimedia.org/wikipedia/en/a/a8/Kara_-_animated_short_by_Quantic_Dreams.png 2x\" data-file-width=\"373\" data-file-height=\"267\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Kara_-_animated_short_by_Quantic_Dreams.png\" class=\"internal\" title=\"Enlarge\"></a></div>Screenshot from \"Kara\" animated short by Quantic Dream</div></div></div>\n<ul><li><b>Texture-based animation</b> uses pixel color to create the animation on the character face. 2D facial animation is commonly based upon the transformation of images, including both images from still photography and sequences of video. Image <a href=\"/wiki/Morphing\" title=\"Morphing\">morphing</a> is a technique which allows in-between transitional images to be generated between a pair of target still images or between frames from sequences of video. These <a href=\"/wiki/Morphing\" title=\"Morphing\">morphing</a> techniques usually consist of a combination of a geometric deformation technique, which aligns the target images, and a cross-fade which creates the smooth transition in the image texture. An early example of image <a href=\"/wiki/Morphing\" title=\"Morphing\">morphing</a> can be seen in <a href=\"/wiki/Michael_Jackson\" title=\"Michael Jackson\">Michael Jackson</a>'s video for \"Black Or White\". In 3D animation texture based animation can be achieved by animating the texture itself or the UV mapping. In the latter case a texture map of all the facial expression is created and the UV map animation is used to transition from one expression to the next.</li>\n<li><b><a href=\"/wiki/Physiology\" title=\"Physiology\">Physiological</a> models</b>, such as skeletal muscle systems and physically based head models, form another approach in modeling the <a href=\"/wiki/Human_head\" title=\"Human head\">head</a> and <a href=\"/wiki/Face\" title=\"Face\">face</a>.<sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">&#91;3&#93;</a></sup> Here, the physical and <a href=\"/wiki/Anatomy\" title=\"Anatomy\">anatomical</a> characteristics of <a href=\"/wiki/Bone\" title=\"Bone\">bones</a>, <a href=\"/wiki/Biological_tissue\" class=\"mw-redirect\" title=\"Biological tissue\">tissues</a>, and <a href=\"/wiki/Human_skin\" title=\"Human skin\">skin</a> are simulated to provide a realistic appearance (e.g. spring-like elasticity). Such methods can be very powerful for creating realism but the complexity of facial structures make them computationally expensive, and difficult to create. Considering the effectiveness of parameterized models for communicative purposes (as explained in the next section), it may be argued that physically based models are not a very efficient choice in many applications. This does not deny the advantages of physically based models and the fact that they can even be used within the context of parameterized models to provide local details when needed.</li></ul>\n<h2><span class=\"mw-headline\" id=\"Face_animation_languages\">Face animation languages</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computer_facial_animation&amp;action=edit&amp;section=5\" title=\"Edit section: Face animation languages\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Many face animation languages are used to describe the content of facial animation. They can be input to a compatible \"player\" <a href=\"/wiki/Software\" title=\"Software\">software</a> which then creates the requested actions. Face animation languages are closely related to other <a href=\"/wiki/Multimedia\" title=\"Multimedia\">multimedia</a> presentation languages such as <a href=\"/wiki/Synchronized_Multimedia_Integration_Language\" title=\"Synchronized Multimedia Integration Language\">SMIL</a> and <a href=\"/wiki/VRML\" title=\"VRML\">VRML</a>. Due to the popularity and effectiveness of <a href=\"/wiki/XML\" title=\"XML\">XML</a> as a data representation mechanism, most face animation languages are XML-based. For instance, this is a sample from <a href=\"/wiki/Virtual_Human_Markup_Language\" title=\"Virtual Human Markup Language\">Virtual Human Markup Language</a> (VHML):\n</p>\n<div class=\"mw-highlight mw-content-ltr\" dir=\"ltr\"><pre><span></span> <span class=\"nt\">&lt;vhml&gt;</span>\n   <span class=\"nt\">&lt;person</span> <span class=\"na\">disposition=</span><span class=\"s\">&quot;angry&quot;</span><span class=\"nt\">&gt;</span>\n     First I speak with an angry voice and look very angry,\n     <span class=\"nt\">&lt;surprised</span> <span class=\"na\">intensity=</span><span class=\"s\">&quot;50&quot;</span><span class=\"nt\">&gt;</span>\n       but suddenly I change to look more surprised.\n     <span class=\"nt\">&lt;/surprised&gt;</span>\n   <span class=\"nt\">&lt;/person&gt;</span>\n <span class=\"nt\">&lt;/vhml&gt;</span>\n</pre></div>\n<p>More advanced languages allow decision-making, event handling, and parallel and sequential actions. Following is an example from <a href=\"/wiki/Face_Modeling_Language\" title=\"Face Modeling Language\">Face Modeling Language</a> (FML):\n</p>\n<div class=\"mw-highlight mw-content-ltr\" dir=\"ltr\"><pre><span></span> <span class=\"nt\">&lt;fml&gt;</span>\n   <span class=\"nt\">&lt;act&gt;</span>\n     <span class=\"nt\">&lt;par&gt;</span>\n &#9;<span class=\"nt\">&lt;hdmv</span> <span class=\"na\">type=</span><span class=\"s\">&quot;yaw&quot;</span> <span class=\"na\">value=</span><span class=\"s\">&quot;15&quot;</span> <span class=\"na\">begin=</span><span class=\"s\">&quot;0&quot;</span> <span class=\"na\">end=</span><span class=\"s\">&quot;2000&quot;</span> <span class=\"nt\">/&gt;</span>\n &#9;<span class=\"nt\">&lt;expr</span> <span class=\"na\">type=</span><span class=\"s\">&quot;joy&quot;</span> <span class=\"na\">value=</span><span class=\"s\">&quot;-60&quot;</span> <span class=\"na\">begin=</span><span class=\"s\">&quot;0&quot;</span> <span class=\"na\">end=</span><span class=\"s\">&quot;2000&quot;</span> <span class=\"nt\">/&gt;</span>\n     <span class=\"nt\">&lt;/par&gt;</span>\n     <span class=\"nt\">&lt;excl</span> <span class=\"na\">event_name=</span><span class=\"s\">&quot;kbd&quot;</span> <span class=\"na\">event_value=</span><span class=\"s\">&quot;&quot;</span> <span class=\"na\">repeat=</span><span class=\"s\">&quot;kbd;F3_up&quot;</span> <span class=\"nt\">&gt;</span>\n &#9;<span class=\"nt\">&lt;hdmv</span> <span class=\"na\">type=</span><span class=\"s\">&quot;yaw&quot;</span> <span class=\"na\">value=</span><span class=\"s\">&quot;40&quot;</span> <span class=\"na\">begin=</span><span class=\"s\">&quot;0&quot;</span> <span class=\"na\">end=</span><span class=\"s\">&quot;2000&quot;</span> <span class=\"na\">event_value=</span><span class=\"s\">&quot;F1_up&quot;</span> <span class=\"nt\">/&gt;</span>\n &#9;<span class=\"nt\">&lt;hdmv</span> <span class=\"na\">type=</span><span class=\"s\">&quot;yaw&quot;</span> <span class=\"na\">value=</span><span class=\"s\">&quot;-40&quot;</span> <span class=\"na\">begin=</span><span class=\"s\">&quot;0&quot;</span> <span class=\"na\">end=</span><span class=\"s\">&quot;2000&quot;</span> <span class=\"na\">event_value=</span><span class=\"s\">&quot;F2_up&quot;</span> <span class=\"nt\">/&gt;</span>\n     <span class=\"nt\">&lt;/excl&gt;</span>\n   <span class=\"nt\">&lt;/act&gt;</span>\n <span class=\"nt\">&lt;/fml&gt;</span>\n</pre></div>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computer_facial_animation&amp;action=edit&amp;section=6\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div role=\"navigation\" aria-label=\"Portals\" class=\"noprint portal plainlist tright\" style=\"margin:0.5em 0 0.5em 1em;border:solid #aaa 1px\">\n<ul style=\"display:table;box-sizing:border-box;padding:0.1em;max-width:175px;background:#f9f9f9;font-size:85%;line-height:110%;font-style:italic;font-weight:bold\">\n<li style=\"display:table-row\"><span style=\"display:table-cell;padding:0.2em;vertical-align:middle;text-align:center\"><a href=\"/wiki/File:Animation_disc.svg\" class=\"image\"><img alt=\"icon\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/30px-Animation_disc.svg.png\" width=\"30\" height=\"28\" class=\"noviewer\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/45px-Animation_disc.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/60px-Animation_disc.svg.png 2x\" data-file-width=\"30\" data-file-height=\"28\" /></a></span><span style=\"display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle\"><a href=\"/wiki/Portal:Animation\" title=\"Portal:Animation\">Animation portal</a></span></li>\n<li style=\"display:table-row\"><span style=\"display:table-cell;padding:0.2em;vertical-align:middle;text-align:center\"><a href=\"/wiki/File:Internet_map_1024.jpg\" class=\"image\"><img alt=\"icon\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Internet_map_1024.jpg/28px-Internet_map_1024.jpg\" width=\"28\" height=\"28\" class=\"noviewer\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Internet_map_1024.jpg/42px-Internet_map_1024.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Internet_map_1024.jpg/56px-Internet_map_1024.jpg 2x\" data-file-width=\"1280\" data-file-height=\"1280\" /></a></span><span style=\"display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle\"><a href=\"/wiki/Portal:Computer_science\" title=\"Portal:Computer science\">Computer science portal</a></span></li></ul></div>\n<ul><li><a href=\"/wiki/Animation\" title=\"Animation\">Animation</a></li>\n<li><a href=\"/wiki/Caricature\" title=\"Caricature\">Caricature</a></li>\n<li><a href=\"/wiki/Computer_animation\" title=\"Computer animation\">Computer animation</a></li>\n<li><a href=\"/wiki/Computer_graphics\" title=\"Computer graphics\">Computer graphics</a></li>\n<li><a href=\"/wiki/Facial_expression\" title=\"Facial expression\">Facial expression</a></li>\n<li><a href=\"/wiki/Face_Modeling_Language\" title=\"Face Modeling Language\">Face Modeling Language</a></li>\n<li><a href=\"/wiki/Interactive_online_characters\" class=\"mw-redirect\" title=\"Interactive online characters\">Interactive online characters</a></li>\n<li><a href=\"/wiki/Morphing\" title=\"Morphing\">Morphing</a></li>\n<li><a href=\"/wiki/Parametric_surface\" title=\"Parametric surface\">Parametric surface</a></li>\n<li><a href=\"/wiki/Texture_mapping\" title=\"Texture mapping\">Texture mapping</a></li></ul>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computer_facial_animation&amp;action=edit&amp;section=7\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap\"><ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\">Hjortsj\u00f6, CH (1969). <a rel=\"nofollow\" class=\"external text\" href=\"http://diglib.uibk.ac.at/ulbtirol/content/titleinfo/782346\">Man's face and mimic language</a>.</span>\n</li>\n<li id=\"cite_note-CurveControl-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-CurveControl_2-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Ding, H.; Hong, Y. (2003). \"NURBS curve controlled modeling for facial animation\". <i>Computers and Graphics</i>. <b>27</b> (3): 373\u2013385.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computers+and+Graphics&amp;rft.atitle=NURBS+curve+controlled+modeling+for+facial+animation&amp;rft.volume=27&amp;rft.issue=3&amp;rft.pages=373-385&amp;rft.date=2003&amp;rft.aulast=Ding&amp;rft.aufirst=H.&amp;rft.au=Hong%2C+Y.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AComputer+facial+animation\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Lucero, J.C.; Munhall, K.G. (1999). \"A model of facial biomechanics for speech production\". <i>Journal of the Acoustical Society of America</i>. <b>106</b>: 2834\u20132842. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1121/1.428108\">10.1121/1.428108</a>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/10573899\">10573899</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Acoustical+Society+of+America&amp;rft.atitle=A+model+of+facial+biomechanics+for+speech+production&amp;rft.volume=106&amp;rft.pages=2834-2842&amp;rft.date=1999&amp;rft_id=info%3Adoi%2F10.1121%2F1.428108&amp;rft_id=info%3Apmid%2F10573899&amp;rft.aulast=Lucero&amp;rft.aufirst=J.C.&amp;rft.au=Munhall%2C+K.G.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AComputer+facial+animation\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n</ol></div></div>\n<h2><span class=\"mw-headline\" id=\"Further_reading\">Further reading</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computer_facial_animation&amp;action=edit&amp;section=8\" title=\"Edit section: Further reading\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><i>Computer Facial Animation</i> by Frederic I. Parke, Keith Waters 2008 <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/1-56881-448-8\" title=\"Special:BookSources/1-56881-448-8\">1-56881-448-8</a></li>\n<li><i>Data-driven 3D facial animation</i> by Zhigang Deng, Ulrich Neumann 2007 <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/1-84628-906-8\" title=\"Special:BookSources/1-84628-906-8\">1-84628-906-8</a></li>\n<li><i>Handbook of Virtual Humans</i> by Nadia Magnenat-Thalmann and Daniel Thalmann, 2004 <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-470-02316-3\" title=\"Special:BookSources/0-470-02316-3\">0-470-02316-3</a></li>\n<li><cite class=\"citation book\">Osipa, Jason (2005). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.amazon.co.uk/gp/reader/0471789208/ref=sib_dp_pt#reader-link\"><i>Stop Staring: Facial Modeling and Animation Done Right</i></a> (2nd ed.). John Wiley &amp; Sons. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-0-471-78920-8\" title=\"Special:BookSources/978-0-471-78920-8\">978-0-471-78920-8</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Stop+Staring%3A+Facial+Modeling+and+Animation+Done+Right&amp;rft.edition=2nd&amp;rft.pub=John+Wiley+%26+Sons&amp;rft.date=2005&amp;rft.isbn=978-0-471-78920-8&amp;rft.aulast=Osipa&amp;rft.aufirst=Jason&amp;rft_id=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Freader%2F0471789208%2Fref%3Dsib_dp_pt%23reader-link&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AComputer+facial+animation\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li></ul>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Computer_facial_animation&amp;action=edit&amp;section=9\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a rel=\"nofollow\" class=\"external text\" href=\"http://www.hao-li.com/Hao_Li/Hao_Li_-_publications_%5BFace_Off__Live_Facial_Puppetry%5D.html\">Face/Off: Live Facial Puppetry - Realtime markerless facial animation technology developed at ETH Zurich</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://research.animationsinstitut.de\">The \"Artificial Actors\" Project - Institute of Animation</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20070606222118/http://img.csit.carleton.ca/iface/\">iFACE</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://mambo.ucsc.edu/pdf/HICCS05.pdf\">Animated Baldi</a></li>\n<li>download of <a rel=\"nofollow\" class=\"external text\" href=\"http://diglib.uibk.ac.at/ulbtirol/content/titleinfo/782346\">Carl-Herman Hjortsj\u00f6, Man's face and mimic language\"</a> (the original Swedish title of the book is: \"M\u00e4nniskans ansikte och mimiska spr\u00e5ket\". The correct translation would be: \"Man's face and facial language\")</li></ul>\n\n<!-- \nNewPP limit report\nParsed by mw1330\nCached time: 20180910091237\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.188 seconds\nReal time usage: 0.245 seconds\nPreprocessor visited node count: 1097/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 14048/2097152 bytes\nTemplate argument size: 1308/2097152 bytes\nHighest expansion depth: 15/40\nExpensive parser function count: 1/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 5533/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.065/10.000 seconds\nLua memory usage: 2.94 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  172.037      1 -total\n 32.61%   56.100      1 Template:Refimprove\n 31.63%   54.415      1 Template:Reflist\n 24.40%   41.979      2 Template:Cite_journal\n 21.46%   36.914      3 Template:ISBN\n 20.22%   34.778      1 Template:Ambox\n  8.17%   14.050      3 Template:Catalog_lookup_link\n  6.80%   11.700      1 Template:Portal\n  4.90%    8.433      3 Template:Error-small\n  4.76%    8.186      1 Template:Cite_book\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:2974157-0!canonical and timestamp 20180910091237 and revision id 801948317\n -->\n</div>"},"langlinks":[{"lang":"lv","url":"https://lv.wikipedia.org/wiki/Datoriz%C4%93ta_sejas_anim%C4%93%C5%A1ana","langname":"Latvian","autonym":"latvie\u0161u","*":"Datoriz\u0113ta sejas anim\u0113\u0161ana"},{"lang":"si","url":"https://si.wikipedia.org/wiki/%E0%B6%B4%E0%B6%BB%E0%B7%92%E0%B6%9C%E0%B6%AB%E0%B6%9A_%E0%B6%B7%E0%B7%8F%E0%B7%80%E0%B7%92%E0%B6%AD%E0%B6%BA%E0%B7%99%E0%B6%B1%E0%B7%8A_%E0%B6%B8%E0%B7%94%E0%B7%84%E0%B7%94%E0%B6%AB%E0%B7%94_%E0%B7%83%E0%B6%A2%E0%B7%92%E0%B7%80%E0%B7%92%E0%B6%9A%E0%B6%BB%E0%B6%AB%E0%B6%BA","langname":"Sinhala","autonym":"\u0dc3\u0dd2\u0d82\u0dc4\u0dbd","*":"\u0db4\u0dbb\u0dd2\u0d9c\u0dab\u0d9a \u0db7\u0dcf\u0dc0\u0dd2\u0dad\u0dba\u0dd9\u0db1\u0dca \u0db8\u0dd4\u0dc4\u0dd4\u0dab\u0dd4 \u0dc3\u0da2\u0dd2\u0dc0\u0dd2\u0d9a\u0dbb\u0dab\u0dba"}],"categories":[{"sortkey":"","hidden":"","*":"Articles_needing_additional_references_from_February_2010"},{"sortkey":"","hidden":"","*":"All_articles_needing_additional_references"},{"sortkey":"","*":"Computer_animation"},{"sortkey":"","*":"Anatomical_simulation"}],"links":[{"ns":14,"exists":"","*":"Category:Articles needing additional references from February 2010"},{"ns":0,"exists":"","*":"Adobe Flash"},{"ns":0,"exists":"","*":"Anatomy"},{"ns":0,"exists":"","*":"Animation"},{"ns":0,"exists":"","*":"Antz"},{"ns":0,"exists":"","*":"Biological tissue"},{"ns":0,"exists":"","*":"Biology"},{"ns":0,"exists":"","*":"Bone"},{"ns":0,"exists":"","*":"Caricature"},{"ns":0,"exists":"","*":"Casper (film)"},{"ns":0,"exists":"","*":"Charles Darwin"},{"ns":0,"exists":"","*":"Coarticulation"},{"ns":0,"exists":"","*":"Communication"},{"ns":0,"exists":"","*":"Computer animation"},{"ns":0,"exists":"","*":"Computer games"},{"ns":0,"exists":"","*":"Computer graphics"},{"ns":0,"exists":"","*":"Digital object identifier"},{"ns":0,"exists":"","*":"Diphone"},{"ns":0,"exists":"","*":"Education"},{"ns":0,"exists":"","*":"Face"},{"ns":0,"exists":"","*":"Face Modeling Language"},{"ns":0,"exists":"","*":"Facial Action Coding System"},{"ns":0,"exists":"","*":"Facial expression"},{"ns":0,"exists":"","*":"Film"},{"ns":0,"exists":"","*":"Fred Parke"},{"ns":0,"exists":"","*":"Friesen"},{"ns":0,"exists":"","*":"Graphics processing unit"},{"ns":0,"exists":"","*":"Hidden markov model"},{"ns":0,"exists":"","*":"Human head"},{"ns":0,"exists":"","*":"Human skin"},{"ns":0,"exists":"","*":"Interactive online characters"},{"ns":0,"exists":"","*":"International Standard Book Number"},{"ns":0,"exists":"","*":"John Bulwer"},{"ns":0,"exists":"","*":"Keith Waters"},{"ns":0,"exists":"","*":"Keyframe"},{"ns":0,"exists":"","*":"Keyframing"},{"ns":0,"exists":"","*":"King Kong (2005 film)"},{"ns":0,"exists":"","*":"Michael Jackson"},{"ns":0,"exists":"","*":"Mobile devices"},{"ns":0,"exists":"","*":"Monster House (film)"},{"ns":0,"exists":"","*":"Monsters, Inc."},{"ns":0,"exists":"","*":"Morph target animation"},{"ns":0,"exists":"","*":"Morphing"},{"ns":0,"exists":"","*":"Motion capture"},{"ns":0,"exists":"","*":"Multimedia"},{"ns":0,"exists":"","*":"Nadia Magnenat Thalmann"},{"ns":0,"exists":"","*":"Neural net"},{"ns":0,"exists":"","*":"Optical flow"},{"ns":0,"exists":"","*":"Parametric surface"},{"ns":0,"exists":"","*":"Paul Ekman"},{"ns":0,"exists":"","*":"Phoneme"},{"ns":0,"exists":"","*":"Physiology"},{"ns":0,"exists":"","*":"Polar Express"},{"ns":0,"exists":"","*":"Polar Express (film)"},{"ns":0,"exists":"","*":"Psychology"},{"ns":0,"exists":"","*":"PubMed Identifier"},{"ns":0,"exists":"","*":"Sentence (linguistics)"},{"ns":0,"exists":"","*":"Shrek"},{"ns":0,"exists":"","*":"Simulation"},{"ns":0,"exists":"","*":"Skeletal animation"},{"ns":0,"exists":"","*":"Software"},{"ns":0,"exists":"","*":"Software agent"},{"ns":0,"exists":"","*":"Sony Pictures Imageworks"},{"ns":0,"exists":"","*":"Speech synthesis"},{"ns":0,"exists":"","*":"Spline (mathematics)"},{"ns":0,"exists":"","*":"Structured light"},{"ns":0,"exists":"","*":"Syllable"},{"ns":0,"exists":"","*":"Synchronized Multimedia Integration Language"},{"ns":0,"exists":"","*":"Texture mapping"},{"ns":0,"exists":"","*":"The Lord of the Rings (film series)"},{"ns":0,"exists":"","*":"The Matrix Reloaded"},{"ns":0,"exists":"","*":"The Matrix Revolutions"},{"ns":0,"exists":"","*":"The Sims (series)"},{"ns":0,"exists":"","*":"Tony de Peltrie"},{"ns":0,"exists":"","*":"Toy Story"},{"ns":0,"exists":"","*":"Triphone"},{"ns":0,"exists":"","*":"Uncanny valley"},{"ns":0,"exists":"","*":"VRML"},{"ns":0,"exists":"","*":"Virtual Human Markup Language"},{"ns":0,"exists":"","*":"Viseme"},{"ns":0,"exists":"","*":"Word"},{"ns":0,"exists":"","*":"XML"},{"ns":0,"*":"Curve Controlled Modeling"},{"ns":4,"exists":"","*":"Wikipedia:Verifiability"},{"ns":12,"exists":"","*":"Help:Introduction to referencing with Wiki Markup/1"},{"ns":12,"exists":"","*":"Help:Maintenance template removal"},{"ns":100,"exists":"","*":"Portal:Animation"},{"ns":100,"exists":"","*":"Portal:Computer science"}],"templates":[{"ns":10,"exists":"","*":"Template:Refimprove"},{"ns":10,"exists":"","*":"Template:More citations needed"},{"ns":10,"exists":"","*":"Template:Ambox"},{"ns":10,"exists":"","*":"Template:Portal"},{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Cite journal"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:ISBN"},{"ns":10,"exists":"","*":"Template:Catalog lookup link"},{"ns":10,"exists":"","*":"Template:Trim"},{"ns":10,"exists":"","*":"Template:Yesno-no"},{"ns":10,"exists":"","*":"Template:Yesno"},{"ns":10,"exists":"","*":"Template:Error-small"},{"ns":10,"exists":"","*":"Template:Tl"},{"ns":10,"exists":"","*":"Template:Cite book"},{"ns":828,"exists":"","*":"Module:Unsubst"},{"ns":828,"exists":"","*":"Module:Message box"},{"ns":828,"exists":"","*":"Module:No globals"},{"ns":828,"exists":"","*":"Module:Yesno"},{"ns":828,"exists":"","*":"Module:Arguments"},{"ns":828,"exists":"","*":"Module:Message box/configuration"},{"ns":828,"exists":"","*":"Module:Category handler"},{"ns":828,"exists":"","*":"Module:Category handler/data"},{"ns":828,"exists":"","*":"Module:Category handler/config"},{"ns":828,"exists":"","*":"Module:Category handler/shared"},{"ns":828,"exists":"","*":"Module:Category handler/blacklist"},{"ns":828,"exists":"","*":"Module:Namespace detect/data"},{"ns":828,"exists":"","*":"Module:Namespace detect/config"},{"ns":828,"exists":"","*":"Module:Portal"},{"ns":828,"exists":"","*":"Module:Portal/images/a"},{"ns":828,"exists":"","*":"Module:Portal/images/c"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"},{"ns":828,"exists":"","*":"Module:Check isxn"},{"ns":828,"exists":"","*":"Module:Error"}],"images":["Question_book-new.svg","Kara_-_animated_short_by_Quantic_Dreams.png","Animation_disc.svg","Internet_map_1024.jpg"],"externallinks":["http://diglib.uibk.ac.at/ulbtirol/content/titleinfo/782346","//doi.org/10.1121/1.428108","//www.ncbi.nlm.nih.gov/pubmed/10573899","https://www.amazon.co.uk/gp/reader/0471789208/ref=sib_dp_pt#reader-link","http://www.hao-li.com/Hao_Li/Hao_Li_-_publications_%5BFace_Off__Live_Facial_Puppetry%5D.html","http://research.animationsinstitut.de","https://web.archive.org/web/20070606222118/http://img.csit.carleton.ca/iface/","http://mambo.ucsc.edu/pdf/HICCS05.pdf"],"sections":[{"toclevel":1,"level":"2","line":"History","number":"1","index":"1","fromtitle":"Computer_facial_animation","byteoffset":1860,"anchor":"History"},{"toclevel":1,"level":"2","line":"Techniques","number":"2","index":"2","fromtitle":"Computer_facial_animation","byteoffset":5678,"anchor":"Techniques"},{"toclevel":2,"level":"3","line":"Generating facial animation data","number":"2.1","index":"3","fromtitle":"Computer_facial_animation","byteoffset":5694,"anchor":"Generating_facial_animation_data"},{"toclevel":2,"level":"3","line":"Applying facial animation to a character","number":"2.2","index":"4","fromtitle":"Computer_facial_animation","byteoffset":11977,"anchor":"Applying_facial_animation_to_a_character"},{"toclevel":1,"level":"2","line":"Face animation languages","number":"3","index":"5","fromtitle":"Computer_facial_animation","byteoffset":16475,"anchor":"Face_animation_languages"},{"toclevel":1,"level":"2","line":"See also","number":"4","index":"6","fromtitle":"Computer_facial_animation","byteoffset":17905,"anchor":"See_also"},{"toclevel":1,"level":"2","line":"References","number":"5","index":"7","fromtitle":"Computer_facial_animation","byteoffset":18190,"anchor":"References"},{"toclevel":1,"level":"2","line":"Further reading","number":"6","index":"8","fromtitle":"Computer_facial_animation","byteoffset":18218,"anchor":"Further_reading"},{"toclevel":1,"level":"2","line":"External links","number":"7","index":"9","fromtitle":"Computer_facial_animation","byteoffset":18790,"anchor":"External_links"}],"parsewarnings":[],"displaytitle":"Computer facial animation","iwlinks":[],"properties":[{"name":"wikibase_item","*":"Q5157538"}]}}