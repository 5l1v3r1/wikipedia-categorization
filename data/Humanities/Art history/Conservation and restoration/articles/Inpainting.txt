Inpainting is the process of reconstructing lost or deteriorated parts of images and videos. In the museum world, in the case of a valuable painting, this task would be carried out by a skilled art conservator or art restorer. In the digital world, inpainting (also known as image interpolation or video interpolation) refers to the application of sophisticated algorithms to replace lost or corrupted parts of the image data (mainly small regions or to remove small defects). There are many objectives and applications of this technique. In photography and cinema, is used for film restoration; to reverse the deterioration (e.g., cracks in photographs or scratches and dust spots in film; see infrared cleaning). It is also used for removing red-eye, the stamped date from photographs and removing objects to creative effect. This technique can be used to replace the lost blocks in the coding and transmission of images, for example, in a streaming video. It can also be used to remove logos in videos. Inpainting is rooted in the restoration of images. Traditionally, inpainting has been done by professional restorers. The underlying methodology of their work is as follows: Since the wide applications of digital camera and the digitalization of old photos, inpainting has become an automatic process that is performed on digital images. More than scratch removing, the inpainting techniques are also applied to object removal, text removal and other automatic modifications of images and videos. Furthermore, they can also be observed in applications like image compression and super resolution. Three main groups of 2D image inpainting algorithms can be found in literature. The first one to be noted is structural inpainting, the second one is texture inpainting and the last one is a combination of these two techniques. All these inpainting methods have one thing in common - they use the information of the known or undestroyed image areas in order to fill the gap. Structural inpainting uses geometric approaches for filling in the missing information in the region which should be inpainted. These algorithms focus on the consistency of the geometric structure. Like everything else the structural inpainting methods have both advantages and disadvantages. The main problem is that all the structural inpainting methods are not able to restore texture. Texture has a repetitive pattern which means that a missing portion cannot be restored by continuing the level lines into the gap. Combined structural and textural inpainting approaches simultaneously try to perform texture and structure filling in regions of missing image information. Most parts of an image consist of texture and structure. The boundaries between image regions accumulate structural information which is a complex phenomenon. This is the result when blending different textures together. That is why, the state of the art inpainting method attempts to combine structural and textural inpainting. A more traditional method is to use differential equations (such as the Laplace's equation) with Dirichlet boundary conditions for continuity (a seamless fit). This works well if missing information lies within the homogeneous portion of an object area.  Other methods follow isophote directions (in an image, a contour of equal luminance), to do the inpainting.  Model based inpainting follows the Bayesian approach for which missing information is best fitted or estimated from the combination of the models of the underlying images as well as the image data actually being observed. In deterministic language, this has led to various variational inpainting models.  Manual computer methods include using a clone tool or healing tool, to copy existing parts of the image to restore a damaged texture. Texture synthesis may also be used.  Exemplar-based image inpainting attempts to automate the clone tool process.  It fills "holes" in the image by searching for similar patches in a nearby source region of the image, and copying the pixels from the most similar patch into the hole.  By performing the fill at the patch level as opposed to the pixel level, the algorithm reduces blurring artifacts caused by prior techniques.   