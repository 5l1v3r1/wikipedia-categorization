In corpus linguistics, a collocation is a sequence of words or terms that co-occur more often than would be expected by chance. In phraseology, collocation is a sub-type of phraseme. An example of a phraseological collocation, as propounded by  Michael Halliday,  is the expression strong tea. While the same meaning could be conveyed by the roughly equivalent powerful tea, this expression is considered excessive and awkward by English speakers. Conversely, the corresponding expression in technology, powerful computer is preferred over strong computer. Phraseological collocations should not be confused with idioms, where an idiom's meaning is derived from its convention as a stand-in for something else while collocation is a mere popular composition. There are about six main types of collocations: adjective+noun, noun+noun (such as collective nouns), verb+noun, adverb+adjective, verbs+prepositional phrase (phrasal verbs), and verb+adverb. Collocation extraction is a computational technique that finds collocations in a document or corpus, using various computational linguistics elements resembling data mining. Collocations are partly or fully fixed expressions that become established through repeated context-dependent use. Such terms as 'crystal clear', 'middle management', 'nuclear family', and 'cosmetic surgery' are examples of collocated pairs of words. Collocations can be in a syntactic relation (such as verb–object: 'make' and 'decision'), lexical relation (such as antonymy), or they can be in no linguistically defined relation.  Knowledge of collocations is vital for the competent use of a language: a grammatically correct sentence will stand out as awkward if collocational preferences are violated.  This makes collocation an interesting area for language teaching. Recently, a mobile version of Collocation Dictionary was published on Google Play.  Corpus linguists specify a key word in context (KWIC) and identify the words immediately surrounding them.  This gives an idea of the way words are used. The processing of collocations involves a number of parameters, the most important of which is the measure of association, which evaluates whether the co-occurrence is purely by chance or statistically significant.  Due to the non-random nature of language, most collocations are classed as significant, and the association scores are simply used to rank the results.  Commonly used measures of association include mutual information, t scores, and log-likelihood.   Rather than select a single definition, Gledhill  proposes that collocation involves at least three different perspectives: (i) co-occurrence, a statistical view, which sees collocation as the recurrent appearance in a text of a node and its collocates,    (ii) construction, which sees collocation either as a correlation between a lexeme and a lexical-grammatical pattern,  or as a relation between a base and its collocative partners  and (iii) expression, a pragmatic view of collocation as a conventional unit of expression, regardless of form.   It should be pointed out here that these different perspectives contrast with the usual way of presenting collocation in phraseological studies. Traditionally speaking, collocation is explained in terms of all three perspectives at once, in a continuum: In 1933, Harold Palmer's Second Interim Report on English Collocations highlighted the importance of collocation as a key to producing natural-sounding language, for anyone learning a foreign language.  Thus from the 1940s onwards, information about recurrent word combinations became a standard feature of monolingual learner's dictionaries. As these dictionaries became 'less word-centred and more phrase-centred',  more attention was paid to collocation. This trend was supported, from the beginning of the 21st century, by the availability of large text corpora and intelligent corpus-querying software such as Sketch Engine, making possible to provide a more systematic account of collocation in dictionaries. Using these tools, dictionaries such as the Macmillan English Dictionary and the Longman Dictionary of Contemporary English included boxes or panels with lists of frequent collocations.  There are also a number of specialized dictionaries devoted to describing the frequent collocations in a language.  These include (for Spanish) Redes: Diccionario combinatorio del español contemporaneo (2004),  (for French) Le Robert: Dictionnaire des combinaisons de mots (2007), and (for English) the LTP Dictionary of Selected Collocations (1997) and the Macmillan Collocations Dictionary (2010).  Student's t-test can be used to determine whether the occurrence of a collocation in a corpus is statistically significant.  For a bigram                                    w                        1                                        w                        2                                     {\displaystyle w_{1}w_{2}}    , let                         P         (                    w                        1                             )         =                                                #                                w                                    1                                                          N                                     {\displaystyle P(w_{1})={\frac {\#w_{1}}{N}}}     be the unconditional probability of occurrence of                                    w                        1                                     {\displaystyle w_{1}}     in a corpus with size                         N                 {\displaystyle N}    , and let                         P         (                    w                        2                             )         =                                                #                                w                                    2                                                          N                                     {\displaystyle P(w_{2})={\frac {\#w_{2}}{N}}}     be the unconditional probability of occurrence of                                    w                        2                                     {\displaystyle w_{2}}     in the corpus. Then the t-score for the bigram                                    w                        1                                        w                        2                                     {\displaystyle w_{1}w_{2}}     is calculated as:                         t         =                                                                                                         x                     ¯                                                                  −               μ                                                                             s                                        2                                                     N                                                         ,                 {\displaystyle t={\frac {{\bar {x}}-\mu }{\sqrt {\frac {s^{2}}{N}}}},}     where                                                                x               ¯                                          =                                                #                                w                                    i                                                                w                                    j                                                          N                                     {\displaystyle {\bar {x}}={\frac {\#w_{i}w_{j}}{N}}}     is the sample mean of the occurrence of                                    w                        1                                        w                        2                                     {\displaystyle w_{1}w_{2}}    ,                         #                    w                        1                                        w                        2                                     {\displaystyle \#w_{1}w_{2}}     is the number of occurrences of                                    w                        1                                        w                        2                                     {\displaystyle w_{1}w_{2}}    ,                         μ         =         P         (                    w                        i                             )         P         (                    w                        j                             )                 {\displaystyle \mu =P(w_{i})P(w_{j})}     is the probability of                                    w                        1                                        w                        2                                     {\displaystyle w_{1}w_{2}}     under the null-hypothesis that                                    w                        1                                     {\displaystyle w_{1}}     and                                    w                        2                                     {\displaystyle w_{2}}     appear independently in the text, and                                    s                        2                             =                                                x               ¯                                          (         1         −                                                x               ¯                                          )         ≈                                                x               ¯                                                  {\displaystyle s^{2}={\bar {x}}(1-{\bar {x}})\approx {\bar {x}}}     is the sample variance. With a large                         N                 {\displaystyle N}    , the t-test is equivalent to a z-test. 