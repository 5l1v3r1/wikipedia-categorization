{"parse":{"title":"Topic model","pageid":28934119,"revid":858467283,"text":{"*":"<div class=\"mw-parser-output\"><p>In <a href=\"/wiki/Machine_learning\" title=\"Machine learning\">machine learning</a> and <a href=\"/wiki/Natural_language_processing\" title=\"Natural language processing\">natural language processing</a>, a <b>topic model</b> is a type of <a href=\"/wiki/Statistical_model\" title=\"Statistical model\">statistical model</a> for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \"dog\" and \"bone\" will appear more often in documents about dogs, \"cat\" and \"meow\" will appear in documents about cats, and \"the\" and \"is\" will appear equally in both. A document typically concerns multiple topics in different proportions; thus, in a document that is 10% about cats and 90% about dogs, there would probably be about 9 times more dog words than cat words. The \"topics\" produced by topic modeling techniques are clusters of similar words. A topic model captures this intuition in a mathematical framework, which allows examining a set of documents and discovering, based on the statistics of the words in each, what the topics might be and what each document's balance of topics is.\n</p><p>Topic models are also referred to as probabilistic topic models, which refers to statistical algorithms for discovering the latent semantic structures of an extensive text body. In the age of information, the amount of the written material we encounter each day is simply beyond our processing capacity. Topic models can help to organize and offer insights for us to understand large collections of unstructured text bodies. Originally developed as a text-mining tool, topic models have been used to detect instructive structures in data such as genetic information, images, and networks. They also have applications in other fields such as <a href=\"/wiki/Bioinformatics\" title=\"Bioinformatics\">bioinformatics</a>.<sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\">&#91;1&#93;</a></sup>\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#History\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">History</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Topic_models_for_context_information\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Topic models for context information</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#Algorithms\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Algorithms</span></a></li>\n<li class=\"toclevel-1 tocsection-4\"><a href=\"#See_also\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">See also</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-5\"><a href=\"#Software/libraries\"><span class=\"tocnumber\">4.1</span> <span class=\"toctext\">Software/libraries</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#References\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-7\"><a href=\"#Further_reading\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">Further reading</span></a></li>\n<li class=\"toclevel-1 tocsection-8\"><a href=\"#External_links\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"History\">History</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Topic_model&amp;action=edit&amp;section=1\" title=\"Edit section: History\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>An early topic model was described by Papadimitriou, Raghavan, Tamaki and Vempala in 1998.<sup id=\"cite_ref-PRTV1998_2-0\" class=\"reference\"><a href=\"#cite_note-PRTV1998-2\">&#91;2&#93;</a></sup> Another one, called <a href=\"/wiki/Probabilistic_latent_semantic_indexing\" class=\"mw-redirect\" title=\"Probabilistic latent semantic indexing\">probabilistic latent semantic analysis</a> (PLSA), was created by Thomas Hofmann in 1999.<sup id=\"cite_ref-hofmann1999_3-0\" class=\"reference\"><a href=\"#cite_note-hofmann1999-3\">&#91;3&#93;</a></sup> <a href=\"/wiki/Latent_Dirichlet_allocation\" title=\"Latent Dirichlet allocation\">Latent Dirichlet allocation</a> (LDA), perhaps the most common topic model currently in use, is a generalization of PLSA. Developed by <a href=\"/wiki/David_Blei\" title=\"David Blei\">David Blei</a>, <a href=\"/wiki/Andrew_Ng\" title=\"Andrew Ng\">Andrew Ng</a>, and <a href=\"/wiki/Michael_I._Jordan\" title=\"Michael I. Jordan\">Michael I. Jordan</a> in 2002, LDA introduces sparse <a href=\"/wiki/Dirichlet_distribution\" title=\"Dirichlet distribution\">Dirichlet prior distributions</a> over document-topic and topic-word distributions, encoding the intuition that documents cover a small number of topics and that topics often use a small number of words.<sup id=\"cite_ref-blei2003_4-0\" class=\"reference\"><a href=\"#cite_note-blei2003-4\">&#91;4&#93;</a></sup> Other topic models are generally extensions on LDA, such as <a href=\"/wiki/Pachinko_allocation\" title=\"Pachinko allocation\">Pachinko allocation</a>, which improves on LDA by modeling correlations between topics in addition to the word correlations which constitute topics.\n</p>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:602px;\"><div class=\"mediaContainer\" style=\"width:600px\"><video id=\"mwe_player_0\" poster=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/70/Topic_model_scheme.webm/600px-seek%3D17.6-Topic_model_scheme.webm.jpg\" controls=\"\" preload=\"none\" style=\"width:600px;height:547px\" class=\"kskin\" data-durationhint=\"18.6\" data-startoffset=\"0\" data-mwtitle=\"Topic_model_scheme.webm\" data-mwprovider=\"wikimediacommons\"><source src=\"//upload.wikimedia.org/wikipedia/commons/7/70/Topic_model_scheme.webm#t=00:00:01,00:00:17.600\" type=\"video/webm; codecs=&quot;vp8&quot;\" data-title=\"Original WebM file, 600 \u00d7 547 (370 kbps)\" data-shorttitle=\"WebM source\" data-width=\"600\" data-height=\"547\" data-bandwidth=\"370370\" /><source src=\"//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Topic_model_scheme.webm/Topic_model_scheme.webm.480p.webm#t=00:00:01,00:00:17.600\" type=\"video/webm; codecs=&quot;vp8, vorbis&quot;\" data-title=\"SD WebM (480P)\" data-shorttitle=\"WebM 480P\" data-transcodekey=\"480p.webm\" data-width=\"526\" data-height=\"480\" data-bandwidth=\"766016\" data-framerate=\"0\" /><source src=\"//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Topic_model_scheme.webm/Topic_model_scheme.webm.160p.webm#t=00:00:01,00:00:17.600\" type=\"video/webm; codecs=&quot;vp8, vorbis&quot;\" data-title=\"Low bandwidth WebM (160P)\" data-shorttitle=\"WebM 160P\" data-transcodekey=\"160p.webm\" data-width=\"176\" data-height=\"160\" data-bandwidth=\"120352\" data-framerate=\"0\" /><source src=\"//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Topic_model_scheme.webm/Topic_model_scheme.webm.240p.webm#t=00:00:01,00:00:17.600\" type=\"video/webm; codecs=&quot;vp8, vorbis&quot;\" data-title=\"Small WebM (240P)\" data-shorttitle=\"WebM 240P\" data-transcodekey=\"240p.webm\" data-width=\"264\" data-height=\"240\" data-bandwidth=\"227712\" data-framerate=\"0\" /><source src=\"//upload.wikimedia.org/wikipedia/commons/transcoded/7/70/Topic_model_scheme.webm/Topic_model_scheme.webm.360p.webm#t=00:00:01,00:00:17.600\" type=\"video/webm; codecs=&quot;vp8, vorbis&quot;\" data-title=\"WebM (360P)\" data-shorttitle=\"WebM 360P\" data-transcodekey=\"360p.webm\" data-width=\"394\" data-height=\"360\" data-bandwidth=\"456944\" data-framerate=\"0\" /></video></div>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Topic_model_scheme.webm\" class=\"internal\" title=\"Enlarge\"></a></div>Animation of the topic detection process in a document-word matrix. Every column corresponds to a document, every row to a word. A cell stores the frequency of a word in a document, dark cells indicate high word frequencies. Topic models group both documents, which use similar words, as well as words which occur in a similar set of documents. The resulting patterns are called \"topics\".<sup id=\"cite_ref-5\" class=\"reference\"><a href=\"#cite_note-5\">&#91;5&#93;</a></sup></div></div></div>\n<h2><span class=\"mw-headline\" id=\"Topic_models_for_context_information\">Topic models for context information</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Topic_model&amp;action=edit&amp;section=2\" title=\"Edit section: Topic models for context information\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Approaches for temporal information include Block and Newman's determination the temporal dynamics of topics in the <i><a href=\"/wiki/Pennsylvania_Gazette\" title=\"Pennsylvania Gazette\">Pennsylvania Gazette</a></i> during 1728\u20131800. Griffiths &amp; Steyvers use topic modeling on abstract from the journal <i><a href=\"/wiki/PNAS\" class=\"mw-redirect\" title=\"PNAS\">PNAS</a></i> to identify topics that rose or fell in popularity from 1991 to 2001. Nelson has been analyzing change in topics over time in the <i><a href=\"/wiki/Richmond_Times-Dispatch\" title=\"Richmond Times-Dispatch\">Richmond Times-Dispatch</a></i> to understand social and political changes and continuities in Richmond during the <a href=\"/wiki/American_Civil_War\" title=\"American Civil War\">American Civil War</a>. Yang, Torget and Mihalcea applied topic modeling methods to newspapers from 1829\u20132008. Mimno used topic modelling with 24 journals on classical philology and archaeology spanning 150 years to look at how topics in the journals change over time and how the journals become more different or similar over time.\n</p><p>Yin et al.<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;6&#93;</a></sup> introduced a topic model for geographically distributed documents, where document positions are explained by latent regions which are detected during inference.\n</p><p>Chang and Blei<sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">&#91;7&#93;</a></sup> included network information between linked documents in the relational topic model, which allows to model links between websites.\n</p><p>The author-topic model by Rosen-Zvi et al.<sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">&#91;8&#93;</a></sup> models the topics associated with authors of documents to improve the topic detection for documents with authorship information.\n</p>\n<h2><span class=\"mw-headline\" id=\"Algorithms\">Algorithms</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Topic_model&amp;action=edit&amp;section=3\" title=\"Edit section: Algorithms\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>In practice researchers attempt to fit appropriate model parameters to the data corpus using one of several heuristics for maximum likelihood fit. A recent survey by Blei describes this suite of algorithms.<sup id=\"cite_ref-blei2011_9-0\" class=\"reference\"><a href=\"#cite_note-blei2011-9\">&#91;9&#93;</a></sup>\nSeveral groups of researchers starting with Papadimitriou et al.<sup id=\"cite_ref-PRTV1998_2-1\" class=\"reference\"><a href=\"#cite_note-PRTV1998-2\">&#91;2&#93;</a></sup> have attempted to design algorithms with probable guarantees. Assuming that the data were actually generated by the model in question, they try to design algorithms that probably find the model that was used to create the data. Techniques used here include <a href=\"/wiki/Singular_value_decomposition\" class=\"mw-redirect\" title=\"Singular value decomposition\">singular value decomposition</a> (SVD) and the <a href=\"/wiki/Method_of_moments_(statistics)\" title=\"Method of moments (statistics)\">method of moments</a>. In 2012 an algorithm based upon <a href=\"/wiki/Non-negative_matrix_factorization\" title=\"Non-negative matrix factorization\">non-negative matrix factorization</a> (NMF) was introduced that also generalizes to topic models with correlations among topics.<sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">&#91;10&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Topic_model&amp;action=edit&amp;section=4\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a href=\"/wiki/Explicit_semantic_analysis\" title=\"Explicit semantic analysis\">Explicit semantic analysis</a></li>\n<li><a href=\"/wiki/Latent_semantic_analysis\" title=\"Latent semantic analysis\">Latent semantic analysis</a></li>\n<li><a href=\"/wiki/Latent_Dirichlet_allocation\" title=\"Latent Dirichlet allocation\">Latent Dirichlet allocation</a></li>\n<li><a href=\"/wiki/Hierarchical_Dirichlet_process\" title=\"Hierarchical Dirichlet process\">Hierarchical Dirichlet process</a></li>\n<li><a href=\"/wiki/Non-negative_matrix_factorization\" title=\"Non-negative matrix factorization\">Non-negative matrix factorization</a></li></ul>\n<h3><span id=\"Software.2Flibraries\"></span><span class=\"mw-headline\" id=\"Software/libraries\">Software/libraries</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Topic_model&amp;action=edit&amp;section=5\" title=\"Edit section: Software/libraries\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<ul><li><a href=\"/w/index.php?title=BigARTM&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"BigARTM (page does not exist)\">BigARTM</a> (<a rel=\"nofollow\" class=\"external free\" href=\"https://github.com/bigartm/bigartm\">https://github.com/bigartm/bigartm</a>)</li>\n<li><a href=\"/wiki/Mallet_(software_project)\" title=\"Mallet (software project)\">Mallet (software project)</a> (<a rel=\"nofollow\" class=\"external free\" href=\"http://mallet.cs.umass.edu/\">http://mallet.cs.umass.edu/</a>)</li>\n<li>Stanford Topic Modeling Toolkit (<a rel=\"nofollow\" class=\"external free\" href=\"http://nlp.stanford.edu/software/tmt/tmt-0.4/\">http://nlp.stanford.edu/software/tmt/tmt-0.4/</a>)</li>\n<li><a href=\"/wiki/Gensim\" title=\"Gensim\">Gensim</a> \u2013 Topic Modeling for Humans (<a rel=\"nofollow\" class=\"external free\" href=\"http://radimrehurek.com/gensim/\">http://radimrehurek.com/gensim/</a>)</li>\n<li>topicmodels R package (<a rel=\"nofollow\" class=\"external free\" href=\"https://cran.r-project.org/package=topicmodels\">https://cran.r-project.org/package=topicmodels</a>)</li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"https://github.com/datquocnguyen/jLDADMM\">jLDADMM</a> A Java package for topic modeling on normal or short texts.  jLDADMM includes implementations of the LDA topic model and the <i>one-topic-per-document</i> Dirichlet Multinomial Mixture model. jLDADMM also provides an implementation for document clustering evaluation to compare topic models.</li>\n<li>TopicModelsVB.jl Julia package (<a rel=\"nofollow\" class=\"external free\" href=\"https://github.com/ericproffitt/TopicModelsVB.jl\">https://github.com/ericproffitt/TopicModelsVB.jl</a>)</li>\n<li><a href=\"/w/index.php?title=STTM&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"STTM (page does not exist)\">STTM</a> A Java package for short text topic modeling (<a rel=\"nofollow\" class=\"external free\" href=\"https://github.com/qiang2100/STTM\">https://github.com/qiang2100/STTM</a>). STTM includes these following algorithms: Dirichlet Multinomial Mixture (DMM) in conference KDD2014, Biterm Topic Model (BTM) in journal TKDE2016, Word Network Topic Model (WNTM ) in journal KAIS2018, Pseudo-Document-Based Topic Model (PTM) in conference KDD2016, Self-Aggregation-Based Topic Model (SATM) in conference IJCAI2015, (ETM) in conference PAKDD2017, Generalized P\u00b4olya Urn (GPU) based Dirichlet Multinomial Mixturemodel (GPU-DMM) in conference SIGIR2016, Generalized P\u00b4olya Urn (GPU) based Poisson-based Dirichlet Multinomial Mixturemodel (GPU-PDMM) in journal TIS2017 and Latent Feature Model with DMM (LF-DMM) in journal TACL2015. STTM also includes six short text corpus for evaluation.  STTM presents three aspects about how to evaluate the performance of the algorithms (i.e., topic coherence, clustering, and classification).</li></ul>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Topic_model&amp;action=edit&amp;section=6\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap\"><ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Blei, David (April 2012). \"Probabilistic Topic Models\". <i>Communications of the ACM</i>. <b>55</b> (4): 77\u201384. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1145/2133806.2133826\">10.1145/2133806.2133826</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=Probabilistic+Topic+Models&amp;rft.volume=55&amp;rft.issue=4&amp;rft.pages=77-84&amp;rft.date=2012-04&amp;rft_id=info%3Adoi%2F10.1145%2F2133806.2133826&amp;rft.aulast=Blei&amp;rft.aufirst=David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-PRTV1998-2\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-PRTV1998_2-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-PRTV1998_2-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation journal\">Papadimitriou, Christos; Raghavan, Prabhakar; Tamaki, Hisao; Vempala, Santosh (1998). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.cs.berkeley.edu/~christos/ir.ps\">\"Latent Semantic Indexing: A probabilistic analysis\"</a> <span style=\"font-size:85%;\">(Postscript)</span>. <i>Proceedings of ACM PODS</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+ACM+PODS&amp;rft.atitle=Latent+Semantic+Indexing%3A+A+probabilistic+analysis&amp;rft.date=1998&amp;rft.aulast=Papadimitriou&amp;rft.aufirst=Christos&amp;rft.au=Raghavan%2C+Prabhakar&amp;rft.au=Tamaki%2C+Hisao&amp;rft.au=Vempala%2C+Santosh&amp;rft_id=http%3A%2F%2Fwww.cs.berkeley.edu%2F~christos%2Fir.ps&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-hofmann1999-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-hofmann1999_3-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Hofmann, Thomas (1999). <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20101214074049/http://www.cs.brown.edu/~th/papers/Hofmann-SIGIR99.pdf\">\"Probabilistic Latent Semantic Indexing\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Proceedings of the Twenty-Second Annual International SIGIR Conference on Research and Development in Information Retrieval</i>. Archived from <a rel=\"nofollow\" class=\"external text\" href=\"http://www.cs.brown.edu/~th/papers/Hofmann-SIGIR99.pdf\">the original</a> <span style=\"font-size:85%;\">(PDF)</span> on 2010-12-14.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+Twenty-Second+Annual+International+SIGIR+Conference+on+Research+and+Development+in+Information+Retrieval&amp;rft.atitle=Probabilistic+Latent+Semantic+Indexing&amp;rft.date=1999&amp;rft.aulast=Hofmann&amp;rft.aufirst=Thomas&amp;rft_id=http%3A%2F%2Fwww.cs.brown.edu%2F~th%2Fpapers%2FHofmann-SIGIR99.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-blei2003-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-blei2003_4-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Blei, David M.; Ng, Andrew Y.; <a href=\"/wiki/Michael_I._Jordan\" title=\"Michael I. Jordan\">Jordan, Michael I</a>; Lafferty, John (January 2003). <a rel=\"nofollow\" class=\"external text\" href=\"http://jmlr.csail.mit.edu/papers/v3/blei03a.html\">\"Latent Dirichlet allocation\"</a>. <i><a href=\"/wiki/Journal_of_Machine_Learning_Research\" title=\"Journal of Machine Learning Research\">Journal of Machine Learning Research</a></i>. <b>3</b>: 993\u20131022. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1162/jmlr.2003.3.4-5.993\">10.1162/jmlr.2003.3.4-5.993</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Machine+Learning+Research&amp;rft.atitle=Latent+Dirichlet+allocation&amp;rft.volume=3&amp;rft.pages=993-1022&amp;rft.date=2003-01&amp;rft_id=info%3Adoi%2F10.1162%2Fjmlr.2003.3.4-5.993&amp;rft.aulast=Blei&amp;rft.aufirst=David+M.&amp;rft.au=Ng%2C+Andrew+Y.&amp;rft.au=Jordan%2C+Michael+I&amp;rft.au=Lafferty%2C+John&amp;rft_id=http%3A%2F%2Fjmlr.csail.mit.edu%2Fpapers%2Fv3%2Fblei03a.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\"><a rel=\"nofollow\" class=\"external free\" href=\"http://topicmodels.west.uni-koblenz.de/ckling/tmt/svd_ap.html\">http://topicmodels.west.uni-koblenz.de/ckling/tmt/svd_ap.html</a></span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Yin, Zhijun (2011). \"Geographical topic discovery and comparison\". <i>Proceedings of the 20th international conference on World wide web</i>: 247\u2013256.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+20th+international+conference+on+World+wide+web&amp;rft.atitle=Geographical+topic+discovery+and+comparison&amp;rft.pages=247-256&amp;rft.date=2011&amp;rft.aulast=Yin&amp;rft.aufirst=Zhijun&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Chang, Jonathan (2009). \"Relational Topic Models for Document Networks\". <i>AISTATS</i>. <b>9</b>: 81\u201388.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=AISTATS&amp;rft.atitle=Relational+Topic+Models+for+Document+Networks&amp;rft.volume=9&amp;rft.pages=81-88&amp;rft.date=2009&amp;rft.aulast=Chang&amp;rft.aufirst=Jonathan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Rosen-Zvi, Michal (2004). \"The author-topic model for authors and documents\". <i>Proceedings of the 20th conference on Uncertainty in artificial intelligence</i>: 487\u2013494.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+20th+conference+on+Uncertainty+in+artificial+intelligence&amp;rft.atitle=The+author-topic+model+for+authors+and+documents&amp;rft.pages=487-494&amp;rft.date=2004&amp;rft.aulast=Rosen-Zvi&amp;rft.aufirst=Michal&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-blei2011-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-blei2011_9-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Blei, David M. (April 2012). <a rel=\"nofollow\" class=\"external text\" href=\"https://cacm.acm.org/magazines/2012/4/147361-probabilistic-topic-models/fulltext\">\"Introduction to Probabilistic Topic Models\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Comm. ACM</i>. <b>55</b> (4): 77\u201384. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1145/2133806.2133826\">10.1145/2133806.2133826</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Comm.+ACM&amp;rft.atitle=Introduction+to+Probabilistic+Topic+Models&amp;rft.volume=55&amp;rft.issue=4&amp;rft.pages=77-84&amp;rft.date=2012-04&amp;rft_id=info%3Adoi%2F10.1145%2F2133806.2133826&amp;rft.aulast=Blei&amp;rft.aufirst=David+M.&amp;rft_id=https%3A%2F%2Fcacm.acm.org%2Fmagazines%2F2012%2F4%2F147361-probabilistic-topic-models%2Ffulltext&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation arxiv\">Sanjeev Arora; Rong Ge; Ankur Moitra (April 2012). \"Learning Topic Models\u2014Going beyond SVD\". <a href=\"/wiki/ArXiv\" title=\"ArXiv\">arXiv</a>:<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//arxiv.org/abs/1204.1956\">1204.1956</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Learning+Topic+Models%E2%80%94Going+beyond+SVD&amp;rft.date=2012-04&amp;rft_id=info%3Aarxiv%2F1204.1956&amp;rft.au=Sanjeev+Arora&amp;rft.au=Rong+Ge&amp;rft.au=Ankur+Moitra&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n</ol></div></div>\n<h2><span class=\"mw-headline\" id=\"Further_reading\">Further reading</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Topic_model&amp;action=edit&amp;section=7\" title=\"Edit section: Further reading\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><cite class=\"citation book\">Steyvers, Mark; Griffiths, Tom (2007). <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20130624013706/http://www.psypress.com/books/details/9780805854183/\">\"Probabilistic Topic Models\"</a>.  In Landauer, T.; McNamara, D; Dennis, S.;  et al. <a rel=\"nofollow\" class=\"external text\" href=\"http://www.psypress.com/books/details/9780805854183/\"><i>Handbook of Latent Semantic Analysis</i></a> <span style=\"font-size:85%;\">(PDF)</span>. Psychology Press. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-0-8058-5418-3\" title=\"Special:BookSources/978-0-8058-5418-3\">978-0-8058-5418-3</a>. Archived from <a rel=\"nofollow\" class=\"external text\" href=\"http://psiexp.ss.uci.edu/research/papers/SteyversGriffithsLSABookFormatted.pdf\">the original</a> <span style=\"font-size:85%;\">(PDF)</span> on 2013-06-24.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Probabilistic+Topic+Models&amp;rft.btitle=Handbook+of+Latent+Semantic+Analysis&amp;rft.pub=Psychology+Press&amp;rft.date=2007&amp;rft.isbn=978-0-8058-5418-3&amp;rft.aulast=Steyvers&amp;rft.aufirst=Mark&amp;rft.au=Griffiths%2C+Tom&amp;rft_id=http%3A%2F%2Fpsiexp.ss.uci.edu%2Fresearch%2Fpapers%2FSteyversGriffithsLSABookFormatted.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation web\">Blei, D.M.; Lafferty, J.D. (2009). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.cs.columbia.edu/~blei/papers/BleiLafferty2009.pdf\">\"Topic Models\"</a> <span style=\"font-size:85%;\">(PDF)</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Topic+Models&amp;rft.date=2009&amp;rft.aulast=Blei&amp;rft.aufirst=D.M.&amp;rft.au=Lafferty%2C+J.D.&amp;rft_id=http%3A%2F%2Fwww.cs.columbia.edu%2F~blei%2Fpapers%2FBleiLafferty2009.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation journal\">Blei, D.; Lafferty, J. (2007). \"A correlated topic model of <i>Science</i>\". <i>Annals of Applied Statistics</i>. <b>1</b> (1): 17\u201335. <a href=\"/wiki/ArXiv\" title=\"ArXiv\">arXiv</a>:<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//arxiv.org/abs/0708.3601\">0708.3601</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1214/07-AOAS114\">10.1214/07-AOAS114</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annals+of+Applied+Statistics&amp;rft.atitle=A+correlated+topic+model+of+Science&amp;rft.volume=1&amp;rft.issue=1&amp;rft.pages=17-35&amp;rft.date=2007&amp;rft_id=info%3Aarxiv%2F0708.3601&amp;rft_id=info%3Adoi%2F10.1214%2F07-AOAS114&amp;rft.aulast=Blei&amp;rft.aufirst=D.&amp;rft.au=Lafferty%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation journal\">Mimno, D. (April 2012). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.perseus.tufts.edu/~amahoney/02-jocch-mimno.pdf\">\"Computational Historiography: Data Mining in a Century of Classics Journals\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Journal on Computing and Cultural Heritage</i>. <b>5</b> (1). <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1145/2160165.2160168\">10.1145/2160165.2160168</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+on+Computing+and+Cultural+Heritage&amp;rft.atitle=Computational+Historiography%3A+Data+Mining+in+a+Century+of+Classics+Journals&amp;rft.volume=5&amp;rft.issue=1&amp;rft.date=2012-04&amp;rft_id=info%3Adoi%2F10.1145%2F2160165.2160168&amp;rft.aulast=Mimno&amp;rft.aufirst=D.&amp;rft_id=http%3A%2F%2Fwww.perseus.tufts.edu%2F~amahoney%2F02-jocch-mimno.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation book\">Marwick, Ben (2013). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.academia.edu/5508141/Discovery_of_Emergent_Issues_and_Controversies_in_Anthropology_Using_Text_Mining_Topic_Modeling_and_Social_Network_Analysis_of_Microblog_Content\">\"Discovery of Emergent Issues and Controversies in Anthropology Using Text Mining, Topic Modeling, and Social Network Analysis of Microblog Content\"</a>.  In Yanchang, Zhao; Yonghua, Cen. <i>Data Mining Applications with R</i>. Elsevier. pp.&#160;63\u201393.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Discovery+of+Emergent+Issues+and+Controversies+in+Anthropology+Using+Text+Mining%2C+Topic+Modeling%2C+and+Social+Network+Analysis+of+Microblog+Content&amp;rft.btitle=Data+Mining+Applications+with+R&amp;rft.pages=63-93&amp;rft.pub=Elsevier&amp;rft.date=2013&amp;rft.aulast=Marwick&amp;rft.aufirst=Ben&amp;rft_id=https%3A%2F%2Fwww.academia.edu%2F5508141%2FDiscovery_of_Emergent_Issues_and_Controversies_in_Anthropology_Using_Text_Mining_Topic_Modeling_and_Social_Network_Analysis_of_Microblog_Content&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li>Jockers, M. 2010 <a rel=\"nofollow\" class=\"external text\" href=\"http://www.matthewjockers.net/2010/03/19/whos-your-dh-blog-mate-match-making-the-day-of-dh-bloggers-with-topic-modeling/\">Who's your DH Blog Mate: Match-Making the Day of DH Bloggers with Topic Modeling</a> Matthew L. Jockers, posted 19 March 2010</li>\n<li>Drouin, J. 2011 <a rel=\"nofollow\" class=\"external text\" href=\"http://www.proustarchive.org/wp-trackback.php?p=60\">Foray Into Topic Modeling</a><sup class=\"noprint Inline-Template\"><span style=\"white-space: nowrap;\">&#91;<i><a href=\"/wiki/Wikipedia:Link_rot\" title=\"Wikipedia:Link rot\"><span title=\"&#160;Dead link since July 2018\">permanent dead link</span></a></i>&#93;</span></sup> Ecclesiastical Proust Archive. posted 17 March 2011</li>\n<li>Templeton, C. 2011 <a rel=\"nofollow\" class=\"external text\" href=\"http://mith.umd.edu/topic-modeling-in-the-humanities-an-overview/\">Topic Modeling in the Humanities: An Overview</a> Maryland Institute for Technology in the Humanities Blog. posted 1 August 2011</li>\n<li><cite class=\"citation journal\">Griffiths, T.; Steyvers, M. (2004). <a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC387300\">\"Finding scientific topics\"</a>. <i>Proceedings of the National Academy of Sciences</i>. <b>101</b> (Suppl 1): 5228\u201335. <a href=\"/wiki/Bibcode\" title=\"Bibcode\">Bibcode</a>:<a rel=\"nofollow\" class=\"external text\" href=\"http://adsabs.harvard.edu/abs/2004PNAS..101.5228G\">2004PNAS..101.5228G</a>. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1073/pnas.0307752101\">10.1073/pnas.0307752101</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC387300\">387300</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/14872004\">14872004</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+National+Academy+of+Sciences&amp;rft.atitle=Finding+scientific+topics&amp;rft.volume=101&amp;rft.issue=Suppl+1&amp;rft.pages=5228-35&amp;rft.date=2004&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC387300&amp;rft_id=info%3Apmid%2F14872004&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.0307752101&amp;rft_id=info%3Abibcode%2F2004PNAS..101.5228G&amp;rft.aulast=Griffiths&amp;rft.aufirst=T.&amp;rft.au=Steyvers%2C+M.&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC387300&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li>Yang, T., A Torget and R. Mihalcea (2011) Topic Modeling on Historical Newspapers. <a rel=\"nofollow\" class=\"external text\" href=\"http://www.aclweb.org/anthology/W/W11/W11-15.pdf#page=108\">Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</a>. The Association for Computational Linguistics, Madison, WI. pages 96\u2013104.</li>\n<li><cite class=\"citation journal\">Block, S. (January 2006). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.common-place.org/vol-06/no-02/tales/\">\"Doing More with Digitization: An introduction to topic modeling of early American sources\"</a>. <i>Common-place The Interactive Journal of Early American Life</i>. <b>6</b> (2).</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Common-place+The+Interactive+Journal+of+Early+American+Life&amp;rft.atitle=Doing+More+with+Digitization%3A+An+introduction+to+topic+modeling+of+early+American+sources&amp;rft.volume=6&amp;rft.issue=2&amp;rft.date=2006-01&amp;rft.aulast=Block&amp;rft.aufirst=S.&amp;rft_id=http%3A%2F%2Fwww.common-place.org%2Fvol-06%2Fno-02%2Ftales%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation journal\">Newman, D.; Block, S. (March 2006). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.ics.uci.edu/~newman/pubs/JASIST_Newman.pdf\">\"Probabilistic Topic Decomposition of an Eighteenth-Century Newspaper\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Journal of the American Society for Information Science and Technology</i>. <b>57</b> (5). <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1002/asi.20342\">10.1002/asi.20342</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Society+for+Information+Science+and+Technology&amp;rft.atitle=Probabilistic+Topic+Decomposition+of+an+Eighteenth-Century+Newspaper&amp;rft.volume=57&amp;rft.issue=5&amp;rft.date=2006-03&amp;rft_id=info%3Adoi%2F10.1002%2Fasi.20342&amp;rft.aulast=Newman&amp;rft.aufirst=D.&amp;rft.au=Block%2C+S.&amp;rft_id=http%3A%2F%2Fwww.ics.uci.edu%2F~newman%2Fpubs%2FJASIST_Newman.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li></ul>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Topic_model&amp;action=edit&amp;section=8\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><cite class=\"citation web\">Mimno, David. <a rel=\"nofollow\" class=\"external text\" href=\"http://mimno.infosci.cornell.edu/topics.html\">\"Topic modeling bibliography\"</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Topic+modeling+bibliography&amp;rft.aulast=Mimno&amp;rft.aufirst=David&amp;rft_id=http%3A%2F%2Fmimno.infosci.cornell.edu%2Ftopics.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><cite class=\"citation web\">Brett, Megan R. <a rel=\"nofollow\" class=\"external text\" href=\"http://journalofdigitalhumanities.org/2-1/topic-modeling-a-basic-introduction-by-megan-r-brett/\">\"Topic Modeling: A Basic Introduction\"</a>. Journal of Digital Humanities.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Topic+Modeling%3A+A+Basic+Introduction&amp;rft.pub=Journal+of+Digital+Humanities&amp;rft.aulast=Brett&amp;rft.aufirst=Megan+R.&amp;rft_id=http%3A%2F%2Fjournalofdigitalhumanities.org%2F2-1%2Ftopic-modeling-a-basic-introduction-by-megan-r-brett%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"https://www.youtube.com/watch?v=1wcX4fEdNUo\">Topic Models Applied to Online News and Reviews</a> Video of a Google Tech Talk presentation by Alice Oh on topic modeling with <a href=\"/wiki/Latent_Dirichlet_allocation\" title=\"Latent Dirichlet allocation\">LDA</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"https://www.youtube.com/watch?v=8nBE5Qm8y6I\">Modeling Science: Dynamic Topic Models of Scholarly Research</a> Video of a Google Tech Talk presentation by David M. Blei</li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://vimeo.com/13597441\">Automated Topic Models in Political Science</a> Video of a presentation by Brandon Stewart at the <a rel=\"nofollow\" class=\"external text\" href=\"http://toolsfortext.wordpress.com/\">Tools for Text Workshop</a>, 14 June 2010</li>\n<li>Shawn Graham, Ian Milligan, and Scott Weingart <cite class=\"citation web\"><a rel=\"nofollow\" class=\"external text\" href=\"http://programminghistorian.org/lessons/topic-modeling-and-mallet/\">\"Getting Started with Topic Modeling and MALLET\"</a>. The Programming Historian.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Getting+Started+with+Topic+Modeling+and+MALLET&amp;rft.pub=The+Programming+Historian&amp;rft_id=http%3A%2F%2Fprogramminghistorian.org%2Flessons%2Ftopic-modeling-and-mallet%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ATopic+model\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li>\n<li>Blei, David M. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20121002061418/http://www.cs.princeton.edu/~blei/topicmodeling.html\">\"Introductory material and software\"</a></li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"https://github.com/AmazaspShumik/sklearn-bayes/blob/master/skbayes/decomposition_models/gibbs_lda_cython.pyx\">code</a>, <a rel=\"nofollow\" class=\"external text\" href=\"https://github.com/AmazaspShumik/sklearn-bayes/blob/master/ipython_notebooks_tutorials/decomposition_models/example_lda.ipynb\">demo</a> - example of using LDA for topic modelling</li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://elcid.demon.nl/form.html\">demo</a> - Hierarchical topic extraction using compressor-based similarity measures</li></ul>\n<div role=\"navigation\" class=\"navbox\" aria-labelledby=\"Natural_language_processing\" style=\"padding:3px\"><table class=\"nowraplinks hlist collapsible collapsed navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\"><div class=\"plainlinks hlist navbar mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Natural_Language_Processing\" title=\"Template:Natural Language Processing\"><abbr title=\"View this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Natural_Language_Processing\" title=\"Template talk:Natural Language Processing\"><abbr title=\"Discuss this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Template:Natural_Language_Processing&amp;action=edit\"><abbr title=\"Edit this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">e</abbr></a></li></ul></div><div id=\"Natural_language_processing\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Natural_language_processing\" title=\"Natural language processing\">Natural language processing</a></div></th></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">General terms</th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Natural_language_understanding\" title=\"Natural language understanding\">Natural language understanding</a></li>\n<li><a href=\"/wiki/Text_corpus\" title=\"Text corpus\">Text corpus</a></li>\n<li><a href=\"/wiki/Speech_corpus\" title=\"Speech corpus\">Speech corpus</a></li>\n<li><a href=\"/wiki/Stop_words\" title=\"Stop words\">Stopwords</a></li>\n<li><a href=\"/wiki/Bag-of-words_model\" title=\"Bag-of-words model\">Bag-of-words</a></li>\n<li><a href=\"/wiki/AI-complete\" title=\"AI-complete\">AI-complete</a></li>\n<li><a href=\"/wiki/N-gram\" title=\"N-gram\">n-gram</a> (<a href=\"/wiki/Bigram\" title=\"Bigram\">Bigram</a>, <a href=\"/wiki/Trigram\" title=\"Trigram\">Trigram</a>)</li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Text_mining\" title=\"Text mining\">Text analysis</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Text_segmentation\" title=\"Text segmentation\">Text segmentation</a></li>\n<li><a href=\"/wiki/Part-of-speech_tagging\" title=\"Part-of-speech tagging\">Part-of-speech tagging</a></li>\n<li><a href=\"/wiki/Shallow_parsing\" title=\"Shallow parsing\">Text chunking</a></li>\n<li><a href=\"/wiki/Compound_term_processing\" title=\"Compound term processing\">Compound term processing</a></li>\n<li><a href=\"/wiki/Collocation_extraction\" title=\"Collocation extraction\">Collocation extraction</a></li>\n<li><a href=\"/wiki/Stemming\" title=\"Stemming\">Stemming</a></li>\n<li><a href=\"/wiki/Lemmatisation\" title=\"Lemmatisation\">Lemmatisation</a></li>\n<li><a href=\"/wiki/Named-entity_recognition\" title=\"Named-entity recognition\">Named-entity recognition</a></li>\n<li><a href=\"/wiki/Coreference#Coreference_resolution\" title=\"Coreference\">Coreference resolution</a></li>\n<li><a href=\"/wiki/Sentiment_analysis\" title=\"Sentiment analysis\">Sentiment analysis</a></li>\n<li><a href=\"/wiki/Concept_mining\" title=\"Concept mining\">Concept mining</a></li>\n<li><a href=\"/wiki/Parsing\" title=\"Parsing\">Parsing</a></li>\n<li><a href=\"/wiki/Word-sense_disambiguation\" title=\"Word-sense disambiguation\">Word-sense disambiguation</a></li>\n<li><a href=\"/wiki/Ontology_learning\" title=\"Ontology learning\">Ontology learning</a></li>\n<li><a href=\"/wiki/Terminology_extraction\" title=\"Terminology extraction\">Terminology extraction</a></li>\n<li><a href=\"/wiki/Truecasing\" title=\"Truecasing\">Truecasing</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Automatic_summarization\" title=\"Automatic summarization\">Automatic summarization</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Multi-document_summarization\" title=\"Multi-document summarization\">Multi-document summarization</a></li>\n<li><a href=\"/wiki/Sentence_extraction\" title=\"Sentence extraction\">Sentence extraction</a></li>\n<li><a href=\"/wiki/Text_simplification\" title=\"Text simplification\">Text simplification</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Machine_translation\" title=\"Machine translation\">Machine translation</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Computer-assisted_translation\" title=\"Computer-assisted translation\">Computer-assisted</a></li>\n<li><a href=\"/wiki/Example-based_machine_translation\" title=\"Example-based machine translation\">Example-based</a></li>\n<li><a href=\"/wiki/Rule-based_machine_translation\" title=\"Rule-based machine translation\">Rule-based</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Automatic_identification_and_data_capture\" title=\"Automatic identification and data capture\">Automatic identification<br />and data capture</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Speech_recognition\" title=\"Speech recognition\">Speech recognition</a></li>\n<li><a href=\"/wiki/Speech_synthesis\" title=\"Speech synthesis\">Speech synthesis</a></li>\n<li><a href=\"/wiki/Optical_character_recognition\" title=\"Optical character recognition\">Optical character recognition</a></li>\n<li><a href=\"/wiki/Natural_language_generation\" title=\"Natural language generation\">Natural language generation</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a class=\"mw-selflink selflink\">Topic model</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Pachinko_allocation\" title=\"Pachinko allocation\">Pachinko allocation</a></li>\n<li><a href=\"/wiki/Latent_Dirichlet_allocation\" title=\"Latent Dirichlet allocation\">Latent Dirichlet allocation</a></li>\n<li><a href=\"/wiki/Latent_semantic_analysis\" title=\"Latent semantic analysis\">Latent semantic analysis</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Computer-assisted_reviewing\" title=\"Computer-assisted reviewing\">Computer-assisted<br />reviewing</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Automated_essay_scoring\" title=\"Automated essay scoring\">Automated essay scoring</a></li>\n<li><a href=\"/wiki/Concordancer\" title=\"Concordancer\">Concordancer</a></li>\n<li><a href=\"/wiki/Grammar_checker\" title=\"Grammar checker\">Grammar checker</a></li>\n<li><a href=\"/wiki/Predictive_text\" title=\"Predictive text\">Predictive text</a></li>\n<li><a href=\"/wiki/Spell_checker\" title=\"Spell checker\">Spell checker</a></li>\n<li><a href=\"/wiki/Syntax_guessing\" title=\"Syntax guessing\">Syntax guessing</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Natural_language_user_interface\" class=\"mw-redirect\" title=\"Natural language user interface\">Natural language<br />user interface</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Automated_online_assistant\" class=\"mw-redirect\" title=\"Automated online assistant\">Automated online assistant</a></li>\n<li><a href=\"/wiki/Chatbot\" title=\"Chatbot\">Chatbot</a></li>\n<li><a href=\"/wiki/Interactive_fiction\" title=\"Interactive fiction\">Interactive fiction</a></li>\n<li><a href=\"/wiki/Question_answering\" title=\"Question answering\">Question answering</a></li>\n<li><a href=\"/wiki/Voice_user_interface\" title=\"Voice user interface\">Voice user interface</a></li></ul>\n</div></td></tr></tbody></table></div>\n\n<!-- \nNewPP limit report\nParsed by mw1325\nCached time: 20180911010027\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.236 seconds\nReal time usage: 0.288 seconds\nPreprocessor visited node count: 1066/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 50421/2097152 bytes\nTemplate argument size: 669/2097152 bytes\nHighest expansion depth: 11/40\nExpensive parser function count: 1/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 10787/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.118/10.000 seconds\nLua memory usage: 3.37 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  213.005      1 -total\n 55.82%  118.899      1 Template:Reflist\n 50.96%  108.544     13 Template:Cite_journal\n 16.10%   34.289      1 Template:Dead_link\n 13.80%   29.392      1 Template:Fix\n 12.57%   26.769      2 Template:Category_handler\n  7.10%   15.119      4 Template:Cite_web\n  5.71%   12.160      1 Template:Natural_Language_Processing\n  5.04%   10.746      2 Template:Cite_book\n  4.69%    9.996      1 Template:Navbox\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:28934119-0!canonical and timestamp 20180911010027 and revision id 858467283\n -->\n</div>"},"langlinks":[{"lang":"es","url":"https://es.wikipedia.org/wiki/Modelado_de_temas_(procesamiento_de_lenguaje_natural)","langname":"Spanish","autonym":"espa\u00f1ol","*":"Modelado de temas (procesamiento de lenguaje natural)"},{"lang":"fa","url":"https://fa.wikipedia.org/wiki/%D9%85%D8%AF%D9%84_%D8%B9%D9%86%D8%A7%D9%88%DB%8C%D9%86","langname":"Persian","autonym":"\u0641\u0627\u0631\u0633\u06cc","*":"\u0645\u062f\u0644 \u0639\u0646\u0627\u0648\u06cc\u0646"},{"lang":"fr","url":"https://fr.wikipedia.org/wiki/Topic_model","langname":"French","autonym":"fran\u00e7ais","*":"Topic model"},{"lang":"ko","url":"https://ko.wikipedia.org/wiki/%ED%86%A0%ED%94%BD_%EB%AA%A8%EB%8D%B8","langname":"Korean","autonym":"\ud55c\uad6d\uc5b4","*":"\ud1a0\ud53d \ubaa8\ub378"},{"lang":"ru","url":"https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5","langname":"Russian","autonym":"\u0440\u0443\u0441\u0441\u043a\u0438\u0439","*":"\u0422\u0435\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u043c\u043e\u0434\u0435\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435"},{"lang":"zh","url":"https://zh.wikipedia.org/wiki/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B","langname":"Chinese","autonym":"\u4e2d\u6587","*":"\u4e3b\u9898\u6a21\u578b"}],"categories":[{"sortkey":"","hidden":"","*":"All_articles_with_dead_external_links"},{"sortkey":"","hidden":"","*":"Articles_with_dead_external_links_from_July_2018"},{"sortkey":"","hidden":"","*":"Articles_with_permanently_dead_external_links"},{"sortkey":"","*":"Statistical_natural_language_processing"},{"sortkey":"","*":"Latent_variable_models"},{"sortkey":"","*":"Corpus_linguistics"}],"links":[{"ns":14,"exists":"","*":"Category:Articles with dead external links from July 2018"},{"ns":10,"exists":"","*":"Template:Natural Language Processing"},{"ns":0,"exists":"","*":"AI-complete"},{"ns":0,"exists":"","*":"American Civil War"},{"ns":0,"exists":"","*":"Andrew Ng"},{"ns":0,"exists":"","*":"ArXiv"},{"ns":0,"exists":"","*":"Automated essay scoring"},{"ns":0,"exists":"","*":"Automated online assistant"},{"ns":0,"exists":"","*":"Automatic identification and data capture"},{"ns":0,"exists":"","*":"Automatic summarization"},{"ns":0,"exists":"","*":"Bag-of-words model"},{"ns":0,"exists":"","*":"Bibcode"},{"ns":0,"exists":"","*":"Bigram"},{"ns":0,"exists":"","*":"Bioinformatics"},{"ns":0,"exists":"","*":"Chatbot"},{"ns":0,"exists":"","*":"Collocation extraction"},{"ns":0,"exists":"","*":"Compound term processing"},{"ns":0,"exists":"","*":"Computer-assisted reviewing"},{"ns":0,"exists":"","*":"Computer-assisted translation"},{"ns":0,"exists":"","*":"Concept mining"},{"ns":0,"exists":"","*":"Concordancer"},{"ns":0,"exists":"","*":"Coreference"},{"ns":0,"exists":"","*":"David Blei"},{"ns":0,"exists":"","*":"Digital object identifier"},{"ns":0,"exists":"","*":"Dirichlet distribution"},{"ns":0,"exists":"","*":"Example-based machine translation"},{"ns":0,"exists":"","*":"Explicit semantic analysis"},{"ns":0,"exists":"","*":"Gensim"},{"ns":0,"exists":"","*":"Grammar checker"},{"ns":0,"exists":"","*":"Hierarchical Dirichlet process"},{"ns":0,"exists":"","*":"Interactive fiction"},{"ns":0,"exists":"","*":"International Standard Book Number"},{"ns":0,"exists":"","*":"Journal of Machine Learning Research"},{"ns":0,"exists":"","*":"Latent Dirichlet allocation"},{"ns":0,"exists":"","*":"Latent semantic analysis"},{"ns":0,"exists":"","*":"Lemmatisation"},{"ns":0,"exists":"","*":"Machine learning"},{"ns":0,"exists":"","*":"Machine translation"},{"ns":0,"exists":"","*":"Mallet (software project)"},{"ns":0,"exists":"","*":"Method of moments (statistics)"},{"ns":0,"exists":"","*":"Michael I. Jordan"},{"ns":0,"exists":"","*":"Multi-document summarization"},{"ns":0,"exists":"","*":"N-gram"},{"ns":0,"exists":"","*":"Named-entity recognition"},{"ns":0,"exists":"","*":"Natural language generation"},{"ns":0,"exists":"","*":"Natural language processing"},{"ns":0,"exists":"","*":"Natural language understanding"},{"ns":0,"exists":"","*":"Natural language user interface"},{"ns":0,"exists":"","*":"Non-negative matrix factorization"},{"ns":0,"exists":"","*":"Ontology learning"},{"ns":0,"exists":"","*":"Optical character recognition"},{"ns":0,"exists":"","*":"PNAS"},{"ns":0,"exists":"","*":"Pachinko allocation"},{"ns":0,"exists":"","*":"Parsing"},{"ns":0,"exists":"","*":"Part-of-speech tagging"},{"ns":0,"exists":"","*":"Pennsylvania Gazette"},{"ns":0,"exists":"","*":"Predictive text"},{"ns":0,"exists":"","*":"Probabilistic latent semantic indexing"},{"ns":0,"exists":"","*":"PubMed Central"},{"ns":0,"exists":"","*":"PubMed Identifier"},{"ns":0,"exists":"","*":"Question answering"},{"ns":0,"exists":"","*":"Richmond Times-Dispatch"},{"ns":0,"exists":"","*":"Rule-based machine translation"},{"ns":0,"exists":"","*":"Sentence extraction"},{"ns":0,"exists":"","*":"Sentiment analysis"},{"ns":0,"exists":"","*":"Shallow parsing"},{"ns":0,"exists":"","*":"Singular value decomposition"},{"ns":0,"exists":"","*":"Speech corpus"},{"ns":0,"exists":"","*":"Speech recognition"},{"ns":0,"exists":"","*":"Speech synthesis"},{"ns":0,"exists":"","*":"Spell checker"},{"ns":0,"exists":"","*":"Statistical model"},{"ns":0,"exists":"","*":"Stemming"},{"ns":0,"exists":"","*":"Stop words"},{"ns":0,"exists":"","*":"Syntax guessing"},{"ns":0,"exists":"","*":"Terminology extraction"},{"ns":0,"exists":"","*":"Text corpus"},{"ns":0,"exists":"","*":"Text mining"},{"ns":0,"exists":"","*":"Text segmentation"},{"ns":0,"exists":"","*":"Text simplification"},{"ns":0,"exists":"","*":"Trigram"},{"ns":0,"exists":"","*":"Truecasing"},{"ns":0,"exists":"","*":"Voice user interface"},{"ns":0,"exists":"","*":"Word-sense disambiguation"},{"ns":0,"*":"BigARTM"},{"ns":0,"*":"STTM"},{"ns":4,"exists":"","*":"Wikipedia:Link rot"},{"ns":11,"exists":"","*":"Template talk:Natural Language Processing"}],"templates":[{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Cite journal"},{"ns":10,"exists":"","*":"Template:Cite arXiv"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:Cite book"},{"ns":10,"exists":"","*":"Template:Cite web"},{"ns":10,"exists":"","*":"Template:Dead link"},{"ns":10,"exists":"","*":"Template:Fix"},{"ns":10,"exists":"","*":"Template:Category handler"},{"ns":10,"exists":"","*":"Template:Fix/category"},{"ns":10,"exists":"","*":"Template:Natural Language Processing"},{"ns":10,"exists":"","*":"Template:Navbox"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"},{"ns":828,"exists":"","*":"Module:Unsubst"},{"ns":828,"exists":"","*":"Module:Category handler"},{"ns":828,"exists":"","*":"Module:Yesno"},{"ns":828,"exists":"","*":"Module:Category handler/data"},{"ns":828,"exists":"","*":"Module:Category handler/config"},{"ns":828,"exists":"","*":"Module:Category handler/shared"},{"ns":828,"exists":"","*":"Module:Category handler/blacklist"},{"ns":828,"exists":"","*":"Module:Namespace detect/data"},{"ns":828,"exists":"","*":"Module:Namespace detect/config"},{"ns":828,"exists":"","*":"Module:Arguments"},{"ns":828,"exists":"","*":"Module:Navbox"},{"ns":828,"exists":"","*":"Module:Navbar"}],"images":["Lock-green.svg","Topic_model_scheme.webm"],"externallinks":["//doi.org/10.1145/2133806.2133826","http://www.cs.berkeley.edu/~christos/ir.ps","https://web.archive.org/web/20101214074049/http://www.cs.brown.edu/~th/papers/Hofmann-SIGIR99.pdf","http://www.cs.brown.edu/~th/papers/Hofmann-SIGIR99.pdf","http://jmlr.csail.mit.edu/papers/v3/blei03a.html","//doi.org/10.1162/jmlr.2003.3.4-5.993","https://cacm.acm.org/magazines/2012/4/147361-probabilistic-topic-models/fulltext","//arxiv.org/abs/1204.1956","http://topicmodels.west.uni-koblenz.de/ckling/tmt/svd_ap.html","https://github.com/datquocnguyen/jLDADMM","https://web.archive.org/web/20130624013706/http://www.psypress.com/books/details/9780805854183/","http://www.psypress.com/books/details/9780805854183/","http://psiexp.ss.uci.edu/research/papers/SteyversGriffithsLSABookFormatted.pdf","http://www.cs.columbia.edu/~blei/papers/BleiLafferty2009.pdf","//arxiv.org/abs/0708.3601","//doi.org/10.1214/07-AOAS114","http://www.perseus.tufts.edu/~amahoney/02-jocch-mimno.pdf","//doi.org/10.1145/2160165.2160168","https://www.academia.edu/5508141/Discovery_of_Emergent_Issues_and_Controversies_in_Anthropology_Using_Text_Mining_Topic_Modeling_and_Social_Network_Analysis_of_Microblog_Content","http://www.matthewjockers.net/2010/03/19/whos-your-dh-blog-mate-match-making-the-day-of-dh-bloggers-with-topic-modeling/","http://www.proustarchive.org/wp-trackback.php?p=60","http://mith.umd.edu/topic-modeling-in-the-humanities-an-overview/","//www.ncbi.nlm.nih.gov/pmc/articles/PMC387300","http://adsabs.harvard.edu/abs/2004PNAS..101.5228G","//doi.org/10.1073/pnas.0307752101","//www.ncbi.nlm.nih.gov/pubmed/14872004","http://www.aclweb.org/anthology/W/W11/W11-15.pdf#page=108","http://www.common-place.org/vol-06/no-02/tales/","http://www.ics.uci.edu/~newman/pubs/JASIST_Newman.pdf","//doi.org/10.1002/asi.20342","http://mimno.infosci.cornell.edu/topics.html","http://journalofdigitalhumanities.org/2-1/topic-modeling-a-basic-introduction-by-megan-r-brett/","https://www.youtube.com/watch?v=1wcX4fEdNUo","https://www.youtube.com/watch?v=8nBE5Qm8y6I","http://vimeo.com/13597441","http://toolsfortext.wordpress.com/","http://programminghistorian.org/lessons/topic-modeling-and-mallet/","https://web.archive.org/web/20121002061418/http://www.cs.princeton.edu/~blei/topicmodeling.html","https://github.com/AmazaspShumik/sklearn-bayes/blob/master/skbayes/decomposition_models/gibbs_lda_cython.pyx","https://github.com/AmazaspShumik/sklearn-bayes/blob/master/ipython_notebooks_tutorials/decomposition_models/example_lda.ipynb","http://elcid.demon.nl/form.html","https://github.com/bigartm/bigartm","http://mallet.cs.umass.edu/","http://nlp.stanford.edu/software/tmt/tmt-0.4/","http://radimrehurek.com/gensim/","https://cran.r-project.org/package=topicmodels","https://github.com/ericproffitt/TopicModelsVB.jl","https://github.com/qiang2100/STTM"],"sections":[{"toclevel":1,"level":"2","line":"History","number":"1","index":"1","fromtitle":"Topic_model","byteoffset":2009,"anchor":"History"},{"toclevel":1,"level":"2","line":"Topic models for context information","number":"2","index":"2","fromtitle":"Topic_model","byteoffset":4876,"anchor":"Topic_models_for_context_information"},{"toclevel":1,"level":"2","line":"Algorithms","number":"3","index":"3","fromtitle":"Topic_model","byteoffset":6834,"anchor":"Algorithms"},{"toclevel":1,"level":"2","line":"See also","number":"4","index":"4","fromtitle":"Topic_model","byteoffset":8184,"anchor":"See_also"},{"toclevel":2,"level":"3","line":"Software/libraries","number":"4.1","index":"5","fromtitle":"Topic_model","byteoffset":8375,"anchor":"Software/libraries"},{"toclevel":1,"level":"2","line":"References","number":"5","index":"6","fromtitle":"Topic_model","byteoffset":10109,"anchor":"References"},{"toclevel":1,"level":"2","line":"Further reading","number":"6","index":"7","fromtitle":"Topic_model","byteoffset":10137,"anchor":"Further_reading"},{"toclevel":1,"level":"2","line":"External links","number":"7","index":"8","fromtitle":"Topic_model","byteoffset":14165,"anchor":"External_links"}],"parsewarnings":[],"displaytitle":"Topic model","iwlinks":[],"properties":[{"name":"wikibase_item","*":"Q3532085"}]}}