Conceptual semantics is a framework for semantic analysis developed mainly by Ray Jackendoff in 1976. Its aim is to provide a characterization of the conceptual elements by which a person understands words and sentences, and thus to provide an explanatory semantic representation (title of a Jackendoff 1976 paper).  Explanatory in this sense refers to the ability of a given linguistic theory to describe how a component of language is acquired by a child (as proposed by Noam Chomsky; see Levels of adequacy). Recently, conceptual semantics in particular, and lexical semantics in general, have taken on increasing importance in linguistics and psycholinguistics.  Many contemporary theories of syntax (how sentences are constructed from individual words) rely on elements that are idiosyncratic to words themselves.  As a result, a sound theory accounting for the properties of  the meanings of words is required. Jackendoff has claimed that the goal of conceptual semantics is to investigate: “…how linguistic utterances are related to human cognition, where cognition is a human capacity that is to a considerable degree independent of language, interacting with the perceptual and action systems as well as language.Conceptual semantics distinguishes a single, universal meaning to a word. Instead of having a lexical semantic meaning in addition to the conceptual representation of the actual referent, here the two are combined into what Jackendoff calls “lexical concepts” (Murphy 2010:59). Conceptual semantics is considered to be not just a linguistic theory, but a theory on human cognition. Like many semantic theories, Jackendoff claims that a decompositional method is necessary to explore conceptualization. Just as one of the ways a physical scientist tries to understand matter is by breaking it down into progressively smaller parts, so a scientific study of conceptualization proceeds by breaking down, or decomposing, meanings into smaller parts. However, this decomposition cannot go on forever, for at some point, meanings can no longer be broken down. This is the level of conceptual structure, the level of mental representations which encode the human understanding of the world, containing the primitive conceptual elements out of which meanings are built, plus their rules of combination. Conceptual semantics does not work with a mental dictionary, in the classical sense. There are no definitions attached to concepts and reference, only the idea of the concept or reference itself. Just as generative syntax posits a finite set of syntactic categories and rules for combining them, so, too, does Conceptual Semantics posit ‘a finite set of mental primitives and a finite set of principles of mental combination’ governing their interaction (Jackendoff 1990: 9). Jackendoff refers to this set of primitives and the rules governing them as the ‘grammar of sentential concepts’ ( Jackendoff 1990: 9). His starting point is a close analysis of the meanings of lexemes dedicated to bringing out parallelisms and contrasts which reveal the nature of the conceptual structures underlying them. Jackendoff considers the lexicon to be made of three parts: phonological, syntactic, and conceptual. These three aspects of a concept give a “full picture of a word” (Murphy 2010:60). What his method shows, he says, is that the psychological organization on which meaning rests ‘lies a very short distance below the surface of everyday lexical items – and that progress can be made in exploring it’ (1991: 44). Jackendoff claims that a decompositional method is necessary to explore conceptual structure, in which the concepts underlying word meaning are broken down into their smallest elements: conceptual primitives envisaged as the semantic equivalents of phonological features. Conceptual Semantics posits ‘a finite set of mental primitives and a finite set of principles of mental combination’ governing their interaction. The conceptual structure of a lexical item is an element with zero or more open argument slots, which are filled by the syntactic complements of the lexical item. Conceptual semantics breaks lexical concepts up into ontological categories: events, states, places, amounts, things, and property, to name a few. These ontological categories are called semantic primes, or semantic primitives. Jackendoff poses that any concept in the human brain can be expressed using these semantic primes. Conceptual semantics is compositional, in that the meanings of phrases, clauses, and sentences can be determined from the lexical concepts that make them up. (Murphy 2010:66) Jackendoff’s system has been criticised for its highly abstract primitives, which linguists such as Wierzbicka (2007a, 2007b) and Goddard (1998, 2001) have called “obscure”. The main reason for this is because one requires special training to understand them, and they often must be translated into plain English to be communicated. Another criticism often raised against conceptual semantics is that it is arbitrary. In its current state, there are no clear procedures for determining when a primitive is justified. Another criticism Wierzbicka and Goddard have raised is that the theory was formulated around and applied only to English, though it claims to be universal.  Jackendoff responds to these criticisms by saying:In fact, an isolated primitive can never be justified: a primitive makes sense only in the context of the overall system of primitives in which it is embedded. With this proviso, however, I think a particular choice of primitives should be justified on the grounds of its capacity for expressing generalizations and explaining the distribution of the data. That is, a proposed system of primitives is subject to the usual scientific standards of evaluation.