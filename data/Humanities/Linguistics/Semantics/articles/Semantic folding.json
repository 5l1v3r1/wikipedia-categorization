{"parse":{"title":"Semantic folding","pageid":50222574,"revid":846760293,"text":{"*":"<div class=\"mw-parser-output\"><p><b>Semantic folding</b> theory describes a procedure for encoding the <a href=\"/wiki/Semantics\" title=\"Semantics\">semantics</a> of <a href=\"/wiki/Natural_language\" title=\"Natural language\">natural language</a> text in a semantically grounded <a href=\"/wiki/Binary_number\" title=\"Binary number\">binary representation</a>. This approach provides a framework for modelling how language data is processed by the <a href=\"/wiki/Neocortex\" title=\"Neocortex\">neocortex</a>.<sup id=\"cite_ref-webber_1-0\" class=\"reference\"><a href=\"#cite_note-webber-1\">&#91;1&#93;</a></sup>\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Theory\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Theory</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Two-dimensional_semantic_space\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Two-dimensional semantic space</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#Semantic_spaces\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Semantic spaces</span></a></li>\n<li class=\"toclevel-1 tocsection-4\"><a href=\"#Visualization\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Visualization</span></a></li>\n<li class=\"toclevel-1 tocsection-5\"><a href=\"#Notes\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">Notes</span></a></li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#References\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">References</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"Theory\">Theory</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Semantic_folding&amp;action=edit&amp;section=1\" title=\"Edit section: Theory\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Semantic folding theory draws inspiration from <a href=\"/wiki/Douglas_Hofstadter\" title=\"Douglas Hofstadter\">Douglas R. Hofstadter</a>'s <i>Analogy as the Core of Cognition</i> which suggests that the brain makes sense of the world by identifying and applying <a href=\"/wiki/Analogy\" title=\"Analogy\">analogies</a>.<sup id=\"cite_ref-hofstadter_2-0\" class=\"reference\"><a href=\"#cite_note-hofstadter-2\">&#91;2&#93;</a></sup> The theory hypothesises that semantic data must therefore be introduced to the neocortex in such a form as to allow the application of a <a href=\"/wiki/Similarity_measure\" title=\"Similarity measure\">similarity measure</a> and offers, as a solution, the <a href=\"/wiki/Sparse_matrix\" title=\"Sparse matrix\">sparse</a> <a href=\"/wiki/Bit_array\" title=\"Bit array\">binary vector</a> employing a two-dimensional topographic <a href=\"/wiki/Semantic_space\" title=\"Semantic space\">semantic space</a> as a distributional reference frame. The theory builds on the computational theory of the human cortex known as <a href=\"/wiki/Hierarchical_temporal_memory\" title=\"Hierarchical temporal memory\">hierarchical temporal memory</a> (HTM), and positions itself as a complementary theory for the representation of language semantics.\n</p><p>A particular strength claimed by this approach is that the resulting binary representation enables complex semantic operations to be performed simply and efficiently at the most basic computational level.\n</p>\n<h2><span class=\"mw-headline\" id=\"Two-dimensional_semantic_space\">Two-dimensional semantic space</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Semantic_folding&amp;action=edit&amp;section=2\" title=\"Edit section: Two-dimensional semantic space\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Analogous to the structure of the neocortex, Semantic Folding theory posits the implementation of a semantic space as a two-dimensional grid. This grid is populated by context-vectors<sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">&#91;note 1&#93;</a></sup> in such a way as to place similar context-vectors closer to each other, for instance, by using competitive learning principles. This <a href=\"/wiki/Vector_space_model\" title=\"Vector space model\">vector space model</a> is presented in the theory as an equivalence to the well known word space model<sup id=\"cite_ref-:0_4-0\" class=\"reference\"><a href=\"#cite_note-:0-4\">&#91;3&#93;</a></sup> described in the <a href=\"/wiki/Information_retrieval\" title=\"Information retrieval\">Information Retrieval</a> literature.\n</p><p>Given a semantic space (implemented as described above) a word-vector<sup id=\"cite_ref-5\" class=\"reference\"><a href=\"#cite_note-5\">&#91;note 2&#93;</a></sup> can be obtained for any given word Y by employing the following <a href=\"/wiki/Algorithm\" title=\"Algorithm\">algorithm</a>:\n</p><p>For each position X in the semantic map (where X represents <a href=\"/wiki/Cartesian_coordinate_system\" title=\"Cartesian coordinate system\">cartesian coordinates</a>)\n</p>\n<pre>    if the word Y is contained in the context-vector at position X\n         then add 1 to the corresponding position in the word-vector for Y\n    else \n         add 0 to the corresponding position in the word-vector for Y\n</pre>\n<p>The result of this process will be a word-vector containing all the contexts in which the word Y appears and will therefore be representative of the semantics of that word in the semantic space. It can be seen that the resulting word-vector is also in a sparse distributed representation (SDR) format [Sch\u00fctze, 1993] &amp; [Sahlgreen, 2006].<sup id=\"cite_ref-:0_4-1\" class=\"reference\"><a href=\"#cite_note-:0-4\">&#91;3&#93;</a></sup><sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;4&#93;</a></sup> Some properties of word-SDRs that are of particular interest with respect to computational semantics are:<sup id=\"cite_ref-:1_7-0\" class=\"reference\"><a href=\"#cite_note-:1-7\">&#91;5&#93;</a></sup>\n</p>\n<ul><li>high <a href=\"/wiki/Noise_and_Resistance\" title=\"Noise and Resistance\">noise resistance</a>: As a result of similar contexts being placed closer together in the underlying map, word-SDRs are highly tolerant of false or shifted \"bits\".</li>\n<li><a href=\"/wiki/Boolean_algebra\" title=\"Boolean algebra\">boolean</a> logic: It is possible to manipulate word-SDRs in a meaningful way using boolean (OR, AND, exclusive-OR) and/or <a href=\"/wiki/Arithmetical_operations\" class=\"mw-redirect\" title=\"Arithmetical operations\">arithmetical</a> (SUBtract) functions .</li>\n<li>sub-sampling: Word-SDRs can be sub-sampled to a high degree without any appreciable loss of semantic information.</li>\n<li>topological two-dimensional representation: The SDR representation maintains the topological distribution of the underlying map therefore words with similar meanings will have similar word-vectors. This suggests that a variety of measures can be applied to the calculation of <a href=\"/wiki/Semantic_similarity\" title=\"Semantic similarity\">semantic similarity</a>, from a simple overlap of vector elements, to a range of distance measures such as: <a href=\"/wiki/Euclidean_distance\" title=\"Euclidean distance\">Euclidean distance</a>, <a href=\"/wiki/Hamming_distance\" title=\"Hamming distance\">Hamming distance</a>, <a href=\"/wiki/Jaccard_index\" title=\"Jaccard index\">Jaccard distance</a>, <a href=\"/wiki/Cosine_similarity\" title=\"Cosine similarity\">cosine similarity</a>, <a href=\"/wiki/Levenshtein_distance\" title=\"Levenshtein distance\">Levenshtein distance</a>, <a href=\"/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\" title=\"S\u00f8rensen\u2013Dice coefficient\">S\u00f8rensen-Dice index</a>, etc.</li></ul>\n<h2><span class=\"mw-headline\" id=\"Semantic_spaces\">Semantic spaces</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Semantic_folding&amp;action=edit&amp;section=3\" title=\"Edit section: Semantic spaces\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Semantic spaces<sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">&#91;note 3&#93;</a></sup><sup id=\"cite_ref-9\" class=\"reference\"><a href=\"#cite_note-9\">&#91;6&#93;</a></sup> in the natural language domain aim to create representations of natural language that are capable of capturing meaning. The original motivation for semantic spaces stems from two core challenges of natural language: <a href=\"/wiki/Vocabulary_mismatch\" title=\"Vocabulary mismatch\">Vocabulary mismatch</a> (the fact that the same meaning can be expressed in many ways) and <a href=\"/wiki/Ambiguity\" title=\"Ambiguity\">ambiguity</a> of natural language (the fact that the same term can have several meanings).\n</p><p>The application of semantic spaces in <a href=\"/wiki/Natural_language_processing\" title=\"Natural language processing\">natural language processing</a> (NLP) aims at overcoming limitations of <a href=\"/wiki/Rule-based_system\" title=\"Rule-based system\">rule-based</a> or model-based approaches operating on the <a href=\"/wiki/Keyword_research\" title=\"Keyword research\">keyword</a> level. The main drawback with these approaches is their brittleness, and the large manual effort required to create either rule-based NLP systems or training corpora for model learning.<sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">&#91;7&#93;</a></sup><sup id=\"cite_ref-11\" class=\"reference\"><a href=\"#cite_note-11\">&#91;8&#93;</a></sup> Rule-based and <a href=\"/wiki/Machine_learning\" title=\"Machine learning\">machine learning</a> based models are fixed on the keyword level and break down if the vocabulary differs from that defined in the rules or from the training material used for the statistical models.\n</p><p>Research in semantic spaces dates back more than 20 years. In 1996, two papers were published that raised a lot of attention around the general idea of creating semantic spaces: <a href=\"/wiki/Latent_semantic_analysis\" title=\"Latent semantic analysis\">latent semantic analysis</a><sup id=\"cite_ref-12\" class=\"reference\"><a href=\"#cite_note-12\">&#91;9&#93;</a></sup> from <a href=\"/wiki/Microsoft\" title=\"Microsoft\">Microsoft</a> and <a href=\"/wiki/Hyperspace_Analogue_to_Language\" class=\"mw-redirect\" title=\"Hyperspace Analogue to Language\">Hyperspace Analogue to Language</a><sup id=\"cite_ref-13\" class=\"reference\"><a href=\"#cite_note-13\">&#91;10&#93;</a></sup> from the <a href=\"/wiki/University_of_California,_Riverside\" title=\"University of California, Riverside\">University of California</a>. However, their adoption was limited by the large computational effort required to construct and use those semantic spaces. A breakthrough with regard to the <a href=\"/wiki/Accuracy_and_precision\" title=\"Accuracy and precision\">accuracy</a> of modelling associative relations between words (e.g. \"spider-web\", \"lighter-cigarette\", as opposed to synonymous relations such as \"whale-dolphin\", \"astronaut-driver\") was achieved by <a href=\"/wiki/Explicit_semantic_analysis\" title=\"Explicit semantic analysis\">explicit semantic analysis</a> (ESA)<sup id=\"cite_ref-14\" class=\"reference\"><a href=\"#cite_note-14\">&#91;11&#93;</a></sup> in 2007. ESA was a novel (non-machine learning) based approach that represented words in the form of vectors with 100,000 <a href=\"/wiki/Dimension\" title=\"Dimension\">dimensions</a> (where each dimension represents an Article in <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a>). However practical applications of the approach are limited due to the large number of required dimensions in the vectors.\n</p><p>More recently, advances in <a href=\"/wiki/Neural_networks\" class=\"mw-redirect\" title=\"Neural networks\">neural networking</a> techniques in combination with other new approaches (<a href=\"/wiki/Tensor\" title=\"Tensor\">tensors</a>) led to a host of new recent developments: <a href=\"/wiki/Word2vec\" title=\"Word2vec\">Word2vec</a><sup id=\"cite_ref-15\" class=\"reference\"><a href=\"#cite_note-15\">&#91;12&#93;</a></sup> from <a href=\"/wiki/Google\" title=\"Google\">Google</a> and <a href=\"/wiki/GloVe_(machine_learning)\" title=\"GloVe (machine learning)\">GloVe</a><sup id=\"cite_ref-16\" class=\"reference\"><a href=\"#cite_note-16\">&#91;13&#93;</a></sup> from <a href=\"/wiki/Stanford_University\" title=\"Stanford University\">Stanford University</a>.\n</p><p>Semantic folding represents a novel, biologically inspired approach to semantic spaces where each word is represented as a sparse binary vector with 16,000 dimensions (a semantic fingerprint) in a 2D semantic map (the semantic universe). Sparse binary representation are advantageous in terms of computational efficiency, and allow for the storage of very large numbers of possible patterns.<sup id=\"cite_ref-:1_7-1\" class=\"reference\"><a href=\"#cite_note-:1-7\">&#91;5&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Visualization\">Visualization</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Semantic_folding&amp;action=edit&amp;section=4\" title=\"Edit section: Visualization\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><a href=\"/wiki/File:Semantic_fingerprint_comparing_the_terms_%22dog%22_and_%22car%22.png\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/3/32/Semantic_fingerprint_comparing_the_terms_%22dog%22_and_%22car%22.png/220px-Semantic_fingerprint_comparing_the_terms_%22dog%22_and_%22car%22.png\" width=\"220\" height=\"73\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/3/32/Semantic_fingerprint_comparing_the_terms_%22dog%22_and_%22car%22.png/330px-Semantic_fingerprint_comparing_the_terms_%22dog%22_and_%22car%22.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/32/Semantic_fingerprint_comparing_the_terms_%22dog%22_and_%22car%22.png/440px-Semantic_fingerprint_comparing_the_terms_%22dog%22_and_%22car%22.png 2x\" data-file-width=\"1926\" data-file-height=\"642\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Semantic_fingerprint_comparing_the_terms_%22dog%22_and_%22car%22.png\" class=\"internal\" title=\"Enlarge\"></a></div>Semantic fingerprint image comparing the terms \"dog\" and \"car\".</div></div></div>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><a href=\"/wiki/File:Semantic_fingerprint_comparing_the_terms_%22jaguar%22_and_%22Porsche%22.png\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/06/Semantic_fingerprint_comparing_the_terms_%22jaguar%22_and_%22Porsche%22.png/220px-Semantic_fingerprint_comparing_the_terms_%22jaguar%22_and_%22Porsche%22.png\" width=\"220\" height=\"73\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/06/Semantic_fingerprint_comparing_the_terms_%22jaguar%22_and_%22Porsche%22.png/330px-Semantic_fingerprint_comparing_the_terms_%22jaguar%22_and_%22Porsche%22.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/06/Semantic_fingerprint_comparing_the_terms_%22jaguar%22_and_%22Porsche%22.png/440px-Semantic_fingerprint_comparing_the_terms_%22jaguar%22_and_%22Porsche%22.png 2x\" data-file-width=\"1926\" data-file-height=\"642\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Semantic_fingerprint_comparing_the_terms_%22jaguar%22_and_%22Porsche%22.png\" class=\"internal\" title=\"Enlarge\"></a></div>Semantic fingerprint image comparing the terms \"jaguar\" and \"Porsche\"</div></div></div>\n<p>The topological distribution over a two-dimensional grid (outlined above) lends itself to a <a href=\"/wiki/Bitmap\" title=\"Bitmap\">bitmap</a> type visualization of the semantics of any word or text, where each active semantic feature can be displayed as e.g. a <a href=\"/wiki/Pixel\" title=\"Pixel\">pixel</a>. As can be seen in the images shown here, this representation allows for a direct visual comparison of the semantics of two (or more) linguistic items.\n</p><p>Image 1 clearly demonstrates that the two disparate terms \"dog\" and \"car\" have, as expected, very obviously different semantics.\n</p><p>Image 2 shows that only one of the meaning contexts of  \"jaguar\", that of \"Jaguar\" the car, overlaps with the meaning of Porsche (indicating partial similarity). Other meaning contexts of \"jaguar\" e.g. \"jaguar\" the animal clearly have different non-overlapping contexts.\n</p><p>Note also that the visualization of semantic similarity using Semantic Folding bears a strong resemblance to the <a href=\"/wiki/FMRI\" class=\"mw-redirect\" title=\"FMRI\">fMRI</a> images produced in a research study conducted by A.G. Huth et al.,<sup id=\"cite_ref-17\" class=\"reference\"><a href=\"#cite_note-17\">&#91;14&#93;</a></sup> where it is claimed that words are grouped in the brain by meaning.\n</p>\n<h2><span class=\"mw-headline\" id=\"Notes\">Notes</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Semantic_folding&amp;action=edit&amp;section=5\" title=\"Edit section: Notes\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap\"><ol class=\"references\">\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\">A context-vector is defined as a vector containing all the words in a particular context.</span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\">A word-vector or word-SDR is referred to as a Semantic Fingerprint in Semantic Folding theory.</span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\">also referred to as distributed semantic spaces or distributed semantic memory</span>\n</li>\n</ol></div></div>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Semantic_folding&amp;action=edit&amp;section=6\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist columns references-column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;\">\n<ol class=\"references\">\n<li id=\"cite_note-webber-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-webber_1-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">De Sousa Webber, Francisco (2015). \"Semantic Folding theory and its Application in Semantic Fingerprinting\". <i>Cornell University Library</i>. <a href=\"/wiki/ArXiv\" title=\"ArXiv\">arXiv</a>:<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//arxiv.org/abs/1511.08855\">1511.08855</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/Bibcode\" title=\"Bibcode\">Bibcode</a>:<a rel=\"nofollow\" class=\"external text\" href=\"http://adsabs.harvard.edu/abs/2015arXiv151108855D\">2015arXiv151108855D</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Cornell+University+Library&amp;rft.atitle=Semantic+Folding+theory+and+its+Application+in+Semantic+Fingerprinting&amp;rft.date=2015&amp;rft_id=info%3Aarxiv%2F1511.08855&amp;rft_id=info%3Abibcode%2F2015arXiv151108855D&amp;rft.aulast=De+Sousa+Webber&amp;rft.aufirst=Francisco&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-hofstadter-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-hofstadter_2-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a rel=\"nofollow\" class=\"external text\" href=\"https://mitpress.mit.edu/books/analogical-mind\">\"The Analogical Mind\"</a>. <i>MIT Press</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2016-04-18</span></span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Press&amp;rft.atitle=The+Analogical+Mind&amp;rft_id=https%3A%2F%2Fmitpress.mit.edu%2Fbooks%2Fanalogical-mind&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-:0-4\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:0_4-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:0_4-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation web\">Sahlgreen, Magnus (2006). <a rel=\"nofollow\" class=\"external text\" href=\"http://su.diva-portal.org/smash/get/diva2:189276/FULLTEXT01\">\"The Word-Space Model\"</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Word-Space+Model&amp;rft.date=2006&amp;rft.aulast=Sahlgreen&amp;rft.aufirst=Magnus&amp;rft_id=http%3A%2F%2Fsu.diva-portal.org%2Fsmash%2Fget%2Fdiva2%3A189276%2FFULLTEXT01&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\">Sch\u00fctze, Hinrich (1993). <a rel=\"nofollow\" class=\"external text\" href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.8856\">\"Word Space\"</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Word+Space&amp;rft.date=1993&amp;rft.aulast=Sch%C3%BCtze&amp;rft.aufirst=Hinrich&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.41.8856&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-:1-7\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:1_7-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:1_7-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation arxiv\">Subutai Ahmad; Jeff Hawkins (2015). \"Properties of Sparse Distributed Representations and their Application to Hierarchical Temporal Memory\". <a href=\"/wiki/ArXiv\" title=\"ArXiv\">arXiv</a>:<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//arxiv.org/abs/1503.07469\">1503.07469</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Properties+of+Sparse+Distributed+Representations+and+their+Application+to+Hierarchical+Temporal+Memory&amp;rft.date=2015&amp;rft_id=info%3Aarxiv%2F1503.07469&amp;rft.au=Subutai+Ahmad&amp;rft.au=Jeff+Hawkins&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-9\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Baroni, Marco; Lenci, Alessandro. <a rel=\"nofollow\" class=\"external text\" href=\"http://www.mitpressjournals.org/doi/pdf/10.1162/coli_a_00016\">\"Distributional Memory: A General Framework for Corpus-Based Semantics\"</a>. <i>Computational Linguistics</i>. <b>36</b> (4): 673\u2013721. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1162/coli_a_00016\">10.1162/coli_a_00016</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computational+Linguistics&amp;rft.atitle=Distributional+Memory%3A+A+General+Framework+for+Corpus-Based+Semantics&amp;rft.volume=36&amp;rft.issue=4&amp;rft.pages=673-721&amp;rft_id=info%3Adoi%2F10.1162%2Fcoli_a_00016&amp;rft.aulast=Baroni&amp;rft.aufirst=Marco&amp;rft.au=Lenci%2C+Alessandro&amp;rft_id=http%3A%2F%2Fwww.mitpressjournals.org%2Fdoi%2Fpdf%2F10.1162%2Fcoli_a_00016&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Scott C. Deerwester; Susan T. Dumais; Thomas K. Landauer; George W. Furnas; Richard A. Harshen (1990). <a rel=\"nofollow\" class=\"external text\" href=\"http://lsa.colorado.edu/papers/JASIS.lsi.90.pdf\">\"Indexing by Latent Semantic Analysis\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Journal of the American Society of Information Science</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Society+of+Information+Science&amp;rft.atitle=Indexing+by+Latent+Semantic+Analysis&amp;rft.date=1990&amp;rft.au=Scott+C.+Deerwester&amp;rft.au=Susan+T.+Dumais&amp;rft.au=Thomas+K.+Landauer&amp;rft.au=George+W.+Furnas&amp;rft.au=Richard+A.+Harshen&amp;rft_id=http%3A%2F%2Flsa.colorado.edu%2Fpapers%2FJASIS.lsi.90.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-11\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Xing Wei; W. Bruce Croft (2007). <a rel=\"nofollow\" class=\"external text\" href=\"http://dl.acm.org/citation.cfm?id=1931390.1931423\">\"Investigating retrieval performance with manually-built topic models\"</a>. <i>Proceeding RIAO '07 Large Scale Semantic Access to Content (Text, Image, Video, and Sound)</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceeding+RIAO+%2707+Large+Scale+Semantic+Access+to+Content+%28Text%2C+Image%2C+Video%2C+and+Sound%29&amp;rft.atitle=Investigating+retrieval+performance+with+manually-built+topic+models&amp;rft.date=2007&amp;rft.au=Xing+Wei&amp;rft.au=W.+Bruce+Croft&amp;rft_id=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D1931390.1931423&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a rel=\"nofollow\" class=\"external text\" href=\"http://lsa.colorado.edu/papers/plato/plato.annote.html\">\"LSA: A Solution to Plato's Problem\"</a>. <i>lsa.colorado.edu</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2016-04-19</span></span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=lsa.colorado.edu&amp;rft.atitle=LSA%3A+A+Solution+to+Plato%27s+Problem&amp;rft_id=http%3A%2F%2Flsa.colorado.edu%2Fpapers%2Fplato%2Fplato.annote.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-13\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-13\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Lund, Kevin; Burgess, Curt (1996-06-01). <a rel=\"nofollow\" class=\"external text\" href=\"https://link.springer.com/article/10.3758/BF03204766\">\"Producing high-dimensional semantic spaces from lexical co-occurrence\"</a>. <i>Behavior Research Methods, Instruments, &amp; Computers</i>. <b>28</b> (2): 203\u2013208. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.3758/BF03204766\">10.3758/BF03204766</a>. <a href=\"/wiki/International_Standard_Serial_Number\" title=\"International Standard Serial Number\">ISSN</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.worldcat.org/issn/0743-3808\">0743-3808</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Behavior+Research+Methods%2C+Instruments%2C+%26+Computers&amp;rft.atitle=Producing+high-dimensional+semantic+spaces+from+lexical+co-occurrence&amp;rft.volume=28&amp;rft.issue=2&amp;rft.pages=203-208&amp;rft.date=1996-06-01&amp;rft_id=info%3Adoi%2F10.3758%2FBF03204766&amp;rft.issn=0743-3808&amp;rft.aulast=Lund&amp;rft.aufirst=Kevin&amp;rft.au=Burgess%2C+Curt&amp;rft_id=https%3A%2F%2Flink.springer.com%2Farticle%2F10.3758%2FBF03204766&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Evgeniy Gabrilovich &amp; Shaul Markovitch (2007). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.cs.technion.ac.il/~gabr/papers/ijcai-2007-sim.pdf\">\"Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Proc. 20th Int'l Joint Conf. on Artificial Intelligence (IJCAI). pp. 1606\u20131611</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proc.+20th+Int%27l+Joint+Conf.+on+Artificial+Intelligence+%28IJCAI%29.+pp.+1606%E2%80%931611.&amp;rft.atitle=Computing+Semantic+Relatedness+using+Wikipedia-based+Explicit+Semantic+Analysis&amp;rft.date=2007&amp;rft.au=Evgeniy+Gabrilovich&amp;rft.au=Shaul+Markovitch&amp;rft_id=http%3A%2F%2Fwww.cs.technion.ac.il%2F~gabr%2Fpapers%2Fijcai-2007-sim.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-15\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-15\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation arxiv\">Tomas Mikolov; Ilya Sutskever; Kai Chen; Greg Corrado; Jeffrey Dean (2013). \"Distributed Representations of Words and Phrases and their Compositionality\". <a href=\"/wiki/ArXiv\" title=\"ArXiv\">arXiv</a>:<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//arxiv.org/abs/1310.4546\">1310.4546</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Distributed+Representations+of+Words+and+Phrases+and+their+Compositionality&amp;rft.date=2013&amp;rft_id=info%3Aarxiv%2F1310.4546&amp;rft.au=Tomas+Mikolov&amp;rft.au=Ilya+Sutskever&amp;rft.au=Kai+Chen&amp;rft.au=Greg+Corrado&amp;rft.au=Jeffrey+Dean&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-16\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\">Jeffrey Pennington; Richard Socher; Christopher D. Manning (2014). <a rel=\"nofollow\" class=\"external text\" href=\"http://www-nlp.stanford.edu/pubs/glove.pdf\">\"GloVe: Global Vectors for Word Representation\"</a> <span style=\"font-size:85%;\">(PDF)</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=GloVe%3A+Global+Vectors+for+Word+Representation&amp;rft.date=2014&amp;rft.au=Jeffrey+Pennington&amp;rft.au=Richard+Socher&amp;rft.au=Christopher+D.+Manning&amp;rft_id=http%3A%2F%2Fwww-nlp.stanford.edu%2Fpubs%2Fglove.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-17\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-17\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Huth, Alexander (27 April 2016). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.nature.com/nature/journal/v532/n7600/abs/nature17637.html\">\"Natural speech reveals the semantic maps that tile human cerebral cortex\"</a>. <i>Nature</i>. <b>532</b> (7600): 453\u2013458. <a href=\"/wiki/Bibcode\" title=\"Bibcode\">Bibcode</a>:<a rel=\"nofollow\" class=\"external text\" href=\"http://adsabs.harvard.edu/abs/2016Natur.532..453H\">2016Natur.532..453H</a>. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1038/nature17637\">10.1038/nature17637</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a>&#160;<span class=\"plainlinks\"><a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC4852309\">4852309</a>&#8239;<img alt=\"Freely accessible\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\" title=\"Freely accessible\" width=\"9\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/14px-Lock-green.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/18px-Lock-green.svg.png 2x\" data-file-width=\"512\" data-file-height=\"813\" /></span>. <a href=\"/wiki/PubMed_Identifier\" class=\"mw-redirect\" title=\"PubMed Identifier\">PMID</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/27121839\">27121839</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">19 October</span> 2016</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature&amp;rft.atitle=Natural+speech+reveals+the+semantic+maps+that+tile+human+cerebral+cortex&amp;rft.volume=532&amp;rft.issue=7600&amp;rft.pages=453-458&amp;rft.date=2016-04-27&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4852309&amp;rft_id=info%3Apmid%2F27121839&amp;rft_id=info%3Adoi%2F10.1038%2Fnature17637&amp;rft_id=info%3Abibcode%2F2016Natur.532..453H&amp;rft.aulast=Huth&amp;rft.aufirst=Alexander&amp;rft_id=http%3A%2F%2Fwww.nature.com%2Fnature%2Fjournal%2Fv532%2Fn7600%2Fabs%2Fnature17637.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemantic+folding\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n</ol></div>\n\n<!-- \nNewPP limit report\nParsed by mw1266\nCached time: 20180902023815\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.160 seconds\nReal time usage: 0.186 seconds\nPreprocessor visited node count: 895/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 26059/2097152 bytes\nTemplate argument size: 498/2097152 bytes\nHighest expansion depth: 7/40\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 19152/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.068/10.000 seconds\nLua memory usage: 3.12 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  144.852      1 -total\n 88.37%  128.004      2 Template:Reflist\n 39.53%   57.265      7 Template:Cite_journal\n 13.16%   19.068      5 Template:Cite_web\n  6.81%    9.860      2 Template:Cite_arXiv\n  5.19%    7.518      2 Template:R\n  2.87%    4.153      2 Template:R/ref\n  1.39%    2.014      2 Template:Main_other\n  1.04%    1.508      1 Template:Column-width\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:50222574-0!canonical and timestamp 20180902023815 and revision id 846760293\n -->\n</div>"},"langlinks":[],"categories":[{"sortkey":"","*":"Computational_linguistics"},{"sortkey":"","*":"Natural_language_processing"},{"sortkey":"","*":"Semantics"},{"sortkey":"","*":"Machine_learning"}],"links":[{"ns":0,"exists":"","*":"Accuracy and precision"},{"ns":0,"exists":"","*":"Algorithm"},{"ns":0,"exists":"","*":"Ambiguity"},{"ns":0,"exists":"","*":"Analogy"},{"ns":0,"exists":"","*":"ArXiv"},{"ns":0,"exists":"","*":"Arithmetical operations"},{"ns":0,"exists":"","*":"Bibcode"},{"ns":0,"exists":"","*":"Binary number"},{"ns":0,"exists":"","*":"Bit array"},{"ns":0,"exists":"","*":"Bitmap"},{"ns":0,"exists":"","*":"Boolean algebra"},{"ns":0,"exists":"","*":"Cartesian coordinate system"},{"ns":0,"exists":"","*":"Cosine similarity"},{"ns":0,"exists":"","*":"Digital object identifier"},{"ns":0,"exists":"","*":"Dimension"},{"ns":0,"exists":"","*":"Douglas Hofstadter"},{"ns":0,"exists":"","*":"Euclidean distance"},{"ns":0,"exists":"","*":"Explicit semantic analysis"},{"ns":0,"exists":"","*":"FMRI"},{"ns":0,"exists":"","*":"GloVe (machine learning)"},{"ns":0,"exists":"","*":"Google"},{"ns":0,"exists":"","*":"Hamming distance"},{"ns":0,"exists":"","*":"Hierarchical temporal memory"},{"ns":0,"exists":"","*":"Hyperspace Analogue to Language"},{"ns":0,"exists":"","*":"Information retrieval"},{"ns":0,"exists":"","*":"International Standard Serial Number"},{"ns":0,"exists":"","*":"Jaccard index"},{"ns":0,"exists":"","*":"Keyword research"},{"ns":0,"exists":"","*":"Latent semantic analysis"},{"ns":0,"exists":"","*":"Levenshtein distance"},{"ns":0,"exists":"","*":"Machine learning"},{"ns":0,"exists":"","*":"Microsoft"},{"ns":0,"exists":"","*":"Natural language"},{"ns":0,"exists":"","*":"Natural language processing"},{"ns":0,"exists":"","*":"Neocortex"},{"ns":0,"exists":"","*":"Neural networks"},{"ns":0,"exists":"","*":"Noise and Resistance"},{"ns":0,"exists":"","*":"Pixel"},{"ns":0,"exists":"","*":"PubMed Central"},{"ns":0,"exists":"","*":"PubMed Identifier"},{"ns":0,"exists":"","*":"Rule-based system"},{"ns":0,"exists":"","*":"Semantic similarity"},{"ns":0,"exists":"","*":"Semantic space"},{"ns":0,"exists":"","*":"Semantics"},{"ns":0,"exists":"","*":"Similarity measure"},{"ns":0,"exists":"","*":"Sparse matrix"},{"ns":0,"exists":"","*":"Stanford University"},{"ns":0,"exists":"","*":"S\u00f8rensen\u2013Dice coefficient"},{"ns":0,"exists":"","*":"Tensor"},{"ns":0,"exists":"","*":"University of California, Riverside"},{"ns":0,"exists":"","*":"Vector space model"},{"ns":0,"exists":"","*":"Vocabulary mismatch"},{"ns":0,"exists":"","*":"Wikipedia"},{"ns":0,"exists":"","*":"Word2vec"}],"templates":[{"ns":10,"exists":"","*":"Template:R"},{"ns":10,"exists":"","*":"Template:R/ref"},{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:Column-width"},{"ns":10,"exists":"","*":"Template:Cite journal"},{"ns":10,"exists":"","*":"Template:Cite web"},{"ns":10,"exists":"","*":"Template:Cite arXiv"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"}],"images":["Lock-green.svg","Semantic_fingerprint_comparing_the_terms_\"dog\"_and_\"car\".png","Semantic_fingerprint_comparing_the_terms_\"jaguar\"_and_\"Porsche\".png"],"externallinks":["//arxiv.org/abs/1511.08855","http://adsabs.harvard.edu/abs/2015arXiv151108855D","https://mitpress.mit.edu/books/analogical-mind","http://su.diva-portal.org/smash/get/diva2:189276/FULLTEXT01","http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.8856","//arxiv.org/abs/1503.07469","http://www.mitpressjournals.org/doi/pdf/10.1162/coli_a_00016","//doi.org/10.1162/coli_a_00016","http://lsa.colorado.edu/papers/JASIS.lsi.90.pdf","http://dl.acm.org/citation.cfm?id=1931390.1931423","http://lsa.colorado.edu/papers/plato/plato.annote.html","https://link.springer.com/article/10.3758/BF03204766","//doi.org/10.3758/BF03204766","//www.worldcat.org/issn/0743-3808","http://www.cs.technion.ac.il/~gabr/papers/ijcai-2007-sim.pdf","//arxiv.org/abs/1310.4546","http://www-nlp.stanford.edu/pubs/glove.pdf","http://www.nature.com/nature/journal/v532/n7600/abs/nature17637.html","http://adsabs.harvard.edu/abs/2016Natur.532..453H","//doi.org/10.1038/nature17637","//www.ncbi.nlm.nih.gov/pmc/articles/PMC4852309","//www.ncbi.nlm.nih.gov/pubmed/27121839"],"sections":[{"toclevel":1,"level":"2","line":"Theory","number":"1","index":"1","fromtitle":"Semantic_folding","byteoffset":295,"anchor":"Theory"},{"toclevel":1,"level":"2","line":"Two-dimensional semantic space","number":"2","index":"2","fromtitle":"Semantic_folding","byteoffset":1314,"anchor":"Two-dimensional_semantic_space"},{"toclevel":1,"level":"2","line":"Semantic spaces","number":"3","index":"3","fromtitle":"Semantic_folding","byteoffset":4510,"anchor":"Semantic_spaces"},{"toclevel":1,"level":"2","line":"Visualization","number":"4","index":"4","fromtitle":"Semantic_folding","byteoffset":10086,"anchor":"Visualization"},{"toclevel":1,"level":"2","line":"Notes","number":"5","index":"5","fromtitle":"Semantic_folding","byteoffset":11824,"anchor":"Notes"},{"toclevel":1,"level":"2","line":"References","number":"6","index":"6","fromtitle":"Semantic_folding","byteoffset":11860,"anchor":"References"}],"parsewarnings":[],"displaytitle":"Semantic folding","iwlinks":[],"properties":[{"name":"wikibase_item","*":"Q24950372"}]}}