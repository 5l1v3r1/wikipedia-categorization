In linguistics, a distinctive feature is the most basic unit of phonological structure that may be analyzed in phonological theory. Distinctive features are grouped into categories according to the natural classes of segments they describe: major class features, laryngeal features, manner features, and place features. These feature categories in turn are further specified on the basis of the phonetic properties of the segments in question. Since the inception of the phonological analysis of distinctive features in the 1950s, features traditionally have been specified by binary values to signify whether a segment is described by the feature; a positive value, [+], denotes the presence of a feature, while a negative value, [−], indicates its absence. In addition, a phoneme may be unmarked with respect to a feature. However, in recent developments to the theory of distinctive features, phonologists have proposed the existence of single-valued features. These features, called univalent or privative features, can only describe the classes of segments that are said to possess those features, and not the classes that are without them. Major class features: The features that represent the major classes of sounds. Laryngeal features: The features that specify the glottal states of sounds. Manner features: The features that specify the manner of articulation. Place features: The features that specify the place of articulation. Vowels are traditionally distinguished by  However, laryngoscopic studies suggest the features are This system is given by Jakobson & Halle (1971, 3.6, 3.7). The concept of a distinctive feature matrix to distinguish similar elements is identified with phonology, but there have been at least two efforts to use a distinctive feature matrix in related fields. Close to phonology, and clearly acknowledging its debt to phonology, distinctive features have been used to describe and differentiate handshapes in fingerspelling in American Sign Language.  Distinctive features have also been used to distinguish proverbs from other types of language such as slogans, clichés, and aphorisms.  Analogous feature systems are also used throughout Natural Language Processing (NLP). For example, part-of-speech tagging divides words into categories. These include "major" categories such as Noun vs. Verb, but also other dimensions such as person and number, plurality, tense, and others. Some mnemonics for part-of-speech tags conjoin multiple features, such as "NN" for singular noun, vs. "NNS" for plural noun, vs. "NNS$" for plural possessive noun (see Brown Corpus). Others provide more explicit separation of features, even formalizing them via markup such as the Text Encoding Initiative's feature structures. Modern statistical NLP uses vectors of very many features, although many of those features are not formally "distinctive" in the sense described here. 