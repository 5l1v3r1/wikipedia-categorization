{"parse":{"title":"Eye movement in music reading","pageid":8128722,"revid":838686051,"text":{"*":"<div class=\"mw-parser-output\"><div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:302px;\"><a href=\"/wiki/File:Auditorio1.jpg\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Auditorio1.jpg/300px-Auditorio1.jpg\" width=\"300\" height=\"225\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Auditorio1.jpg/450px-Auditorio1.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/da/Auditorio1.jpg/600px-Auditorio1.jpg 2x\" data-file-width=\"640\" data-file-height=\"480\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Auditorio1.jpg\" class=\"internal\" title=\"Enlarge\"></a></div>A piano trio comprising a pianist, violinist and cellist. Chamber groups traditionally perform publicly from score rather than from memory.</div></div></div>\n<p><b>Eye movement in music reading</b> is the scanning of a <a href=\"/wiki/Sheet_music\" title=\"Sheet music\">musical score</a> by a musician's eyes. This usually occurs as the music is read during performance, although musicians sometimes scan music silently to study it. The phenomenon has been studied by researchers from a range of backgrounds, including <a href=\"/wiki/Cognitive_psychology\" title=\"Cognitive psychology\">cognitive psychology</a> and <a href=\"/wiki/Music_education\" title=\"Music education\">music education</a>. These studies have typically reflected a curiosity among performing musicians about a central process in their craft, and a hope that investigating eye movement might help in the development of more effective methods of training musicians' <a href=\"/wiki/Sight_reading\" class=\"mw-redirect\" title=\"Sight reading\">sight reading</a> skills.\n</p><p>A central aspect of music reading is the sequence of alternating <a href=\"/wiki/Saccade\" title=\"Saccade\">saccades</a> and <a href=\"/wiki/Fixation_(visual)\" title=\"Fixation (visual)\">fixations</a>, as it is for most oculomotor tasks. Saccades are the rapid \u2018flicks\u2019 that move the eyes from location to location over a music score. Saccades are separated from each other by fixations, during which the eyes are relatively stationary on the page. It is well established that the perception of visual information occurs almost entirely during fixations and that little if any information is picked up during saccades.<sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\">&#91;1&#93;</a></sup> Fixations comprise about 90% of music reading time, typically averaging 250\u2013400 ms in duration.<sup id=\"cite_ref-2\" class=\"reference\"><a href=\"#cite_note-2\">&#91;2&#93;</a></sup>\n</p><p>Eye movement in music reading is an extremely complex phenomenon that involves a number of unresolved issues in psychology, and which requires intricate experimental conditions to produce meaningful data. Despite some 30 studies in this area over the past 70 years, little is known about the underlying patterns of eye movement in music reading.\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Relationship_with_eye_movement_in_language_reading\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Relationship with eye movement in language reading</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Equipment_and_related_methodology\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Equipment and related methodology</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#Tempo_and_data_contamination\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Tempo and data contamination</span></a></li>\n<li class=\"toclevel-1 tocsection-4\"><a href=\"#Musical_complexity\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Musical complexity</span></a></li>\n<li class=\"toclevel-1 tocsection-5\"><a href=\"#Reader_skill\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">Reader skill</span></a></li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#Stimulus_familiarity\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">Stimulus familiarity</span></a></li>\n<li class=\"toclevel-1 tocsection-7\"><a href=\"#Top\u2013down/bottom\u2013up_question\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">Top\u2013down/bottom\u2013up question</span></a></li>\n<li class=\"toclevel-1 tocsection-8\"><a href=\"#Peripheral_visual_input\"><span class=\"tocnumber\">8</span> <span class=\"toctext\">Peripheral visual input</span></a></li>\n<li class=\"toclevel-1 tocsection-9\"><a href=\"#Refixation\"><span class=\"tocnumber\">9</span> <span class=\"toctext\">Refixation</span></a></li>\n<li class=\"toclevel-1 tocsection-10\"><a href=\"#Eye\u2013hand_span\"><span class=\"tocnumber\">10</span> <span class=\"toctext\">Eye\u2013hand span</span></a></li>\n<li class=\"toclevel-1 tocsection-11\"><a href=\"#Tempo\"><span class=\"tocnumber\">11</span> <span class=\"toctext\">Tempo</span></a></li>\n<li class=\"toclevel-1 tocsection-12\"><a href=\"#Conclusions\"><span class=\"tocnumber\">12</span> <span class=\"toctext\">Conclusions</span></a></li>\n<li class=\"toclevel-1 tocsection-13\"><a href=\"#Notes\"><span class=\"tocnumber\">13</span> <span class=\"toctext\">Notes</span></a></li>\n<li class=\"toclevel-1 tocsection-14\"><a href=\"#References\"><span class=\"tocnumber\">14</span> <span class=\"toctext\">References</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"Relationship_with_eye_movement_in_language_reading\">Relationship with eye movement in language reading</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=1\" title=\"Edit section: Relationship with eye movement in language reading\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:322px;\"><a href=\"/wiki/File:BWV847_measures_1-9_Fuga_a_3_voci.svg\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b5/BWV847_measures_1-9_Fuga_a_3_voci.svg/320px-BWV847_measures_1-9_Fuga_a_3_voci.svg.png\" width=\"320\" height=\"277\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b5/BWV847_measures_1-9_Fuga_a_3_voci.svg/480px-BWV847_measures_1-9_Fuga_a_3_voci.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/b5/BWV847_measures_1-9_Fuga_a_3_voci.svg/640px-BWV847_measures_1-9_Fuga_a_3_voci.svg.png 2x\" data-file-width=\"925\" data-file-height=\"800\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:BWV847_measures_1-9_Fuga_a_3_voci.svg\" class=\"internal\" title=\"Enlarge\"></a></div>An excerpt from one of JS Bach's compositions for keyboard: a player's scanpath across such a score will be a complex pattern of horizontal and vertical movement.</div></div></div>\n<p>Eye movement in music reading may at first appear to be similar to that in <a href=\"/wiki/Eye_movement_in_language_reading\" class=\"mw-redirect\" title=\"Eye movement in language reading\">language reading</a>, since in both activities the eyes move over the page in fixations and saccades, picking up and processing coded meanings. However, it is here that the obvious similarities end. Not only is the coding system of music nonlinguistic; it involves what is apparently a unique combination of features among human activities: a strict and continuous time constraint on an output that is generated by a continuous stream of coded instructions. Even the reading of language aloud, which, like musical performance involves turning coded information into a musculoskeletal response, is relatively free of temporal constraint\u2014the pulse in reading aloud is a fluid, improvised affair compared with its rigid presence in most Western music. It is this uniquely strict temporal requirement in musical performance that has made the observation of eye movement in music reading fraught with more difficulty than that in language reading.\n</p><p>Another critical difference between reading music and reading language is the role of skill. Most people become reasonably efficient at language reading by adulthood, even though almost all language reading is <a href=\"/wiki/Sight_reading\" class=\"mw-redirect\" title=\"Sight reading\">sight reading</a>.<sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">&#91;3&#93;</a></sup> By contrast, some musicians regard themselves as poor sight readers of music even after years of study. Thus, the improvement of music sight reading and the differences between skilled and unskilled readers have always been of prime importance to research into eye movement in music reading, whereas research into eye movement in language reading has been more concerned with the development of a unified psychological model of the reading process.<sup id=\"cite_ref-4\" class=\"reference\"><a href=\"#cite_note-4\">&#91;4&#93;</a></sup> It is therefore unsurprising that most research into eye movement in music reading has aimed to compare the eye movement patterns of the skilled and the unskilled.\n</p>\n<h2><span class=\"mw-headline\" id=\"Equipment_and_related_methodology\">Equipment and related methodology</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=2\" title=\"Edit section: Equipment and related methodology\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>From the start, there were basic problems with <a href=\"/wiki/Eye_tracker\" class=\"mw-redirect\" title=\"Eye tracker\">eye-tracking equipment</a>. The five earliest studies<sup id=\"cite_ref-5\" class=\"reference\"><a href=\"#cite_note-5\">&#91;5&#93;</a></sup> used photographic techniques. These methods involved either training a continuous beam of visible light onto the eye to produce an unbroken line on photographic paper, or a flashing light to produce a series of white spots on photographic paper at sampling intervals around 25 ms (i.e., 40 samples a second). Because the film rolled through the device vertically, the vertical movement of the eyes in their journey across the page was either unrecorded<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;6&#93;</a></sup> or was recorded using a second camera and subsequently combined to provide data on both dimensions, a cumbersome and inaccurate solution.\n</p><p>These systems were sensitive to even small movement of the head or body, which appear to have significantly contaminated the data. Some studies used devices such as a headrest and bite-plate to minimise this contamination, with limited success, and in one case a camera affixed to a motorcycle helmet\u2014weighing nearly 3&#160;kg\u2014which was supported by a system of counterbalancing weights and pulleys attached to the ceiling.<sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">&#91;7&#93;</a></sup> In addition to extraneous head movement, researchers faced other physical, bodily problems. The musculoskeletal response required to play a musical instrument involves substantial body movement, usually of the hands, arms and torso. This can upset the delicate balance of tracking equipment and confound the registration of data. Another issue that affects almost all unskilled keyboardists and a considerable proportion of skilled keyboardists is the common tendency to frequently glance down at the hands and back to the score during performance. The disadvantage of this behaviour is that it causes signal dropout in the data every time it occurs, which is sometimes up to several times per bar.<sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">&#91;8&#93;</a></sup> When participants are prevented from looking down at their hands, typically the quality of their performance is degraded. Rayner &amp; Pollatsek (1997:49) wrote that:\n</p>\n<dl><dd>\"even skilled musicians naturally look at their hands at times. ... [Because] accurate eye movement recording [is generally incompatible with] these head movements ... musicians often need appreciable training with the apparatus before their eye movements can be measured.\"</dd></dl>\n<p>Since Lang (1961), all reported studies into eye movement in music reading, aside from Smith (1988), appear to have used infrared tracking technology. However, research into the field has mostly been conducted using less than optimal equipment. This has had a pervasive negative impact on almost all research up until a few recent studies. In summary, the four main equipment problems have been that tracking devices:\n</p>\n<ul><li>measured eye movement inaccurately or provided insufficient data;</li>\n<li>were uncomfortable for participants and therefore risked a reduction in <a href=\"/wiki/Ecological_validity\" title=\"Ecological validity\">ecological validity</a>;</li>\n<li>did not allow for the display of records of eye movement in relation to the musical score, or at least made such a display difficult to achieve; and</li>\n<li>were adversely affected by most participants' tendency to look down at their hands, to move their bodies significantly during performance, and to blink.</li></ul>\n<p>Not until recently has eye movement in music reading been investigated with more satisfactory equipment. Kinsler and Carpenter (1995) were able to identify eye position to within 0.25\u00ba, that is, the size of the individual musical notes, at intervals of 1&#160;ms. Truitt et al. (1997) used a similarly accurate infrared system capable of displaying a movement window and integrated into a computer-monitored musical keyboard. Waters &amp; Underwood (1998) used a machine with an accuracy of plus or minus one character space and a sampling interval of only 4&#160;ms.\n</p>\n<h2><span class=\"mw-headline\" id=\"Tempo_and_data_contamination\">Tempo and data contamination</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=3\" title=\"Edit section: Tempo and data contamination\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Most research into eye movement in music reading has primarily aimed to compare the eye movement patterns of skilled and unskilled performers.<sup id=\"cite_ref-9\" class=\"reference\"><a href=\"#cite_note-9\">&#91;9&#93;</a></sup> The implicit presumption appears to have been that this might lay the foundation for developing better ways of training musicians. However, there are significant methodological problems in attempting this comparison. Skilled and unskilled performers typically sight read the same passage at different <a href=\"/wiki/Tempo\" title=\"Tempo\">tempos</a> and/or levels of accuracy. At a sufficiently slow tempo, players over a large range of skill-levels are capable of accurate performance, but the skilled will have excess capacity in their perception and processing of the information on the page. There is evidence that excess capacity contaminates eye-movement data with a \u2018wandering\u2019 effect, in which the eyes tend to stray from the course of the music. Weaver (1943:15) implied the existence of the wandering effect and its confounding influence, as did Truitt et al. (1997:51), who suspected that at slow tempo their participants' eyes were \"hanging around rather than extracting information\". The wandering effect is undesirable, because it is an unquantifiable and possibly random distortion of normal eye movement patterns.\n</p><p>Souter (2001:81) claimed that the ideal tempo for observing eye movement is a range lying between one that is so fast as to produce a significant level of action slips, and one that is so slow as to produce a significant wandering effect. The skilled and the unskilled have quite different ranges for sight reading the same music. On the other hand, a faster tempo may minimise excess capacity in the skilled, but will tend to induce inaccurate performance in the unskilled; inaccuracies rob us of the only evidence that a performer has processed the information on the page, and the danger cannot be discounted that feedback from action-slips contaminates eye movement data.\n</p><p>Almost all studies have compared temporal variables among participants, chiefly the durations of their fixations and saccades. In these cases, it is self-evident that useful comparisons require consistency in performance tempo and accuracy within and between performances. However, most studies have accommodated their participants\u2019 varied performance ability in the reading of the same stimulus, by allowing them to choose their own tempo or by not strictly controlling that tempo. Theoretically, there is a relatively narrow range, referred to here as the \u2018optimal range\u2019, in which capacity matches the task at hand; on either side of this range lie the two problematic tempo ranges within which a performer\u2019s capacity is excessive or insufficient, respectively. The location of the boundaries of the optimal range depends on the skill-level of an individual performer and the relative difficulty of reading/performing the stimulus.<sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">&#91;10&#93;</a></sup>\n</p><p>Thus, unless participants are drawn from a narrow range of skill-levels, their optimal ranges will be mutually exclusive, and observations at a single, controlled tempo will be likely to result in significant contamination of eye movement data. Most studies <i>have</i> sought to compare the skilled and the unskilled in the hope of generating pedagogically useful data; aside from Smith (1988), in which tempo itself was an independent variable, Polanka (1995), who analysed only data from silent preparatory readings, and Souter (2001), who observed only the highly skilled, none has set out to control tempo strictly. Investigators have apparently attempted to overcome the consequences of the fallacy by making compromises, such as (1) exercising little or no control over the tempos at which participants performed in trials, and/or (2) tolerating significant disparity in the level of action slips between skilled and unskilled groups.\n</p><p>This issue is part of the broader tempo/skill/action-slip fallacy, which concerns the relationship between tempo, skill and the level of action slips (performance errors).<sup id=\"cite_ref-11\" class=\"reference\"><a href=\"#cite_note-11\">&#91;11&#93;</a></sup> The fallacy is that it is possible to reliably compare the eye movement patterns of skilled and unskilled performers under the same conditions.\n</p>\n<h2><span class=\"mw-headline\" id=\"Musical_complexity\">Musical complexity</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=4\" title=\"Edit section: Musical complexity\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Many researchers have been interested in learning whether fixation durations are influenced by the complexity of the music. At least three types of complexity need to be accounted for in music reading: the visual complexity of the <a href=\"/wiki/Musical_notation\" title=\"Musical notation\">musical notation</a>; the complexity of processing visual input into musculoskeletal commands; and the complexity of executing those commands. For example, visual complexity might be in the form of the density of the notational symbols on the page, or of the presence of accidentals, triplet signs, slurs and other expression markings. The complexity of processing visual input into musculoskeletal commands might involve a lack of <a href=\"/wiki/Chunking_(psychology)\" title=\"Chunking (psychology)\">'chunkability'</a> or predictability in the music. The complexity of executing musculoskeletal commands might be seen in terms of the demands of fingering and hand position. It is in isolating and accounting for the interplay between these types that the difficulty lies in making sense of musical complexity. For this reason, little useful information has emerged from investigating the relationship between musical complexity and eye movement.\n</p><p>Jacobsen (1941:213) concluded that \"the complexity of the reading material influenced the number and the duration of [fixations]\"; where the texture, rhythm, key and accidentals were \"more difficult\", there was, on average, a slowing of tempo and an increase in both the duration and the number of fixations in his participants. However, performance tempos were uncontrolled in this study, so the data on which this conclusion was based are likely to have been contaminated by the slower tempos that were reported for the reading of the more difficult stimuli.<sup id=\"cite_ref-12\" class=\"reference\"><a href=\"#cite_note-12\">&#91;12&#93;</a></sup> Weaver (1943) claimed that fixation durations\u2014which ranged from 270\u2013530&#160;ms\u2014lengthened when the notation was more compact and/or complex, as Jacobsen had found, but did not disclose whether slower tempos were used. Halverson (1974), who controlled tempo more closely, observed a mild opposite effect. Schmidt's (1981) participants used longer fixation durations in reading easier melodies (consistent with Halverson); Goolsby's (1987) data mildly supported Halverson's finding, but only for skilled readers. He wrote \"both Jacobsen and Weaver ... in letting participants select their own tempo found the opposite effect of notational complexity\".<sup id=\"cite_ref-13\" class=\"reference\"><a href=\"#cite_note-13\">&#91;13&#93;</a></sup>\n</p><p>On balance, it appears likely that under controlled temporal conditions, denser and more complex music is associated with a higher number of fixations, of shorter mean duration. This might be explained as an attempt by the music-reading process to provide more frequent 'refreshment' of the material being held in working memory, and may compensate for the need to hold more information in working memory.<sup id=\"cite_ref-14\" class=\"reference\"><a href=\"#cite_note-14\">&#91;14&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Reader_skill\">Reader skill</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=5\" title=\"Edit section: Reader skill\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>There is no disagreement among the major studies, from Jacobsen (1941) to Smith (1988), that skilled readers appear to use more and shorter fixations across all conditions than do the unskilled. Goolsby (1987) found that mean 'progressive' (forward-moving) fixation duration was significantly longer (474 versus 377&#160;ms) and mean saccade length significantly greater for the less skilled. Although Goolsby did not report the total reading durations of his trials, they can be derived from the mean tempos of his 12 skilled and 12 unskilled participants for each of the four stimuli.<sup id=\"cite_ref-15\" class=\"reference\"><a href=\"#cite_note-15\">&#91;15&#93;</a></sup> His data appear to  show that the unskilled played at 93.6% of the tempo of the skilled, and that their mean fixation durations were 25.6% longer.\n</p><p>This raises the question as to why skilled readers should distribute more numerous and shorter fixations over a score than the unskilled. Only one plausible explanation appears in the literature. Kinsler &amp; Carpenter (1995) proposed a model for the processing of music notation, based on their data from the reading of rhythm patterns, in which an iconic representation of each fixated image is scanned by a 'processor' and interpreted to a given level of accuracy. The scan ends when this level cannot be reached, its end-point determining the position of the upcoming fixation. The time taken before this decision depends on the complexity of a note, and is presumably shorter for skilled readers, thus promoting more numerous fixations of shorter duration. This model has not been further investigated, and does not explain what <i>advantage</i> there is to using short, numerous fixations. Another possible explanation is that skilled readers maintain a larger <a href=\"/wiki/Eye%E2%80%93hand_span\" title=\"Eye\u2013hand span\">eye\u2013hand span</a> and therefore hold a larger amount of information in their <a href=\"/wiki/Working_memory\" title=\"Working memory\">working memory</a>; thus, they need to refresh that information more frequently from the music score, and may do so by refixating more frequently.<sup id=\"cite_ref-16\" class=\"reference\"><a href=\"#cite_note-16\">&#91;16&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Stimulus_familiarity\">Stimulus familiarity</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=6\" title=\"Edit section: Stimulus familiarity\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:302px;\"><a href=\"/wiki/File:Michelangelo_Caravaggio_026.jpg\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Michelangelo_Caravaggio_026.jpg/300px-Michelangelo_Caravaggio_026.jpg\" width=\"300\" height=\"366\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Michelangelo_Caravaggio_026.jpg/450px-Michelangelo_Caravaggio_026.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Michelangelo_Caravaggio_026.jpg/600px-Michelangelo_Caravaggio_026.jpg 2x\" data-file-width=\"2024\" data-file-height=\"2472\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Michelangelo_Caravaggio_026.jpg\" class=\"internal\" title=\"Enlarge\"></a></div><a href=\"/wiki/Caravaggio\" title=\"Caravaggio\">Caravaggio</a>'s <i>Rest on the Flight into Egypt</i> (1594\u201396)</div></div></div>\n<p>The more familiar readers become with a musical excerpt, the less their reliance on visual input from the score and the correspondingly greater reliance on their stored memory of the music. On logical grounds, it would be expected that this shift would result in fewer and longer fixations. The data from all three studies into eye movement in the reading of increasingly familiar music support this reasoning. York's (1952) participants read each stimulus twice, with each reading preceded by a 28-second silent preview. On average, both skilled and unskilled readers used fewer and longer fixations during the second reading. Goolsby's (1987) participants were observed during three immediately successive readings of the same musical stimulus. Familiarity in these trials appeared to increase fixation duration, but not nearly as much as might have been expected. The second reading produced no significant difference in mean fixation duration (from 422 to 418&#160;ms). On the third encounter, mean fixation duration was higher for both groups (437&#160;ms) but by a barely significant amount, thus mildly supporting York's earlier finding. The smallness of these changes might be explained by the unchallenging reading conditions in the trials. The tempo of MM120 suggested at the start of each of Goolsby's trials appears to be slow for tackling the given melodies, which contained many semibreves and minims, and there may have simply been insufficient pressure to produce significant results. A more likely explanation is that the participants played the stimuli at faster tempos as they grew more familiar with them through the three readings. (The metronome was initially sounded, but was silent during the performances, allowing readers to vary their pace at will.) Thus, it is possible that two influences were at odds with each other: growing familiarity may have promoted low numbers of fixations, and long fixation durations, while faster tempo may have promoted low numbers and short durations. This might explain why mean fixation duration fell in the opposite direction to the prediction for the second encounter, and by the third encounter had risen by only 3.55% across both groups.<sup id=\"cite_ref-17\" class=\"reference\"><a href=\"#cite_note-17\">&#91;17&#93;</a></sup> (Smith's (1988) results, reinforced by those of Kinsler &amp; Carpenter (1995), suggest that faster tempos are likely to reduce both the number and duration of fixations in the reading of a single-line melody. If this hypothesis is correct, it may be connected with the possibility that the more familiar a stimulus, the less the workload on the reader's memory.)\n</p>\n<h2><span id=\"Top.E2.80.93down.2Fbottom.E2.80.93up_question\"></span><span class=\"mw-headline\" id=\"Top\u2013down/bottom\u2013up_question\">Top\u2013down/bottom\u2013up question</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=7\" title=\"Edit section: Top\u2013down/bottom\u2013up question\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>There was considerable debate from the 1950s to 1970s as to whether eye movement in language reading is solely or mainly influenced by (1) the pre-existing (top\u2013down) behavioural patterns of an individual's reading technique, (2) the nature of the stimulus (bottom\u2013up), or (3) both factors. Rayner et al. (1971) provides a review of the relevant studies.\n</p><p>Decades before this debate, Weaver (1943) had set out to determine the (bottom\u2013up) effects of musical texture on eye movement. He hypothesised that vertical compositional patterns in a two-stave keyboard score would promote vertical saccades, and horizontal compositional patterns horizontal saccades. Weaver's participants read a two-part <a href=\"/wiki/Polyphony\" title=\"Polyphony\">polyphonic</a> stimulus in which the musical patterns were strongly horizontal, and a four-part <a href=\"/wiki/Homophony\" title=\"Homophony\">homophonic</a> stimulus comprising plain, hymn-like chords, in which the compositional patterns were strongly vertical. Weaver was apparently unaware of the difficulty of proving this hypothesis in the light of the continual need to scan up and down between the staves and move forward along the score. Thus, it is unsurprising that the hypothesis was not confirmed.\n</p><p>Four decades later, when evidence was being revealed of the bottom\u2013up influence on eye movement in language reading, Sloboda (1985) was interested in the possibility that there might be an equivalent influence on eye movement in music reading, and appeared to assume that Weaver's hypothesis had been confirmed. \"Weaver found that [the vertical] pattern was indeed used when the music was homophonic and chordal in nature. When the music was contrapuntal, however, he found fixation sequences which were grouped in horizontal sweeps along a single line, with a return to another line afterwards.\"<sup id=\"cite_ref-18\" class=\"reference\"><a href=\"#cite_note-18\">&#91;18&#93;</a></sup> To support this assertion, Sloboda quoted two one-bar fragments taken from Weaver's illustrations that do not appear to be representative of the overall examples.<sup id=\"cite_ref-19\" class=\"reference\"><a href=\"#cite_note-19\">&#91;19&#93;</a></sup>\n</p><p>Although Sloboda's claim may be questionable, and despite Weaver's failure to find dimensional links between eye movement and stimulus, eye movement in music reading shows clear evidence in most studies\u2014in particular, Truit et al. (1997) and Goolsby (1987)\u2014of the influence of bottom\u2013up graphical features <i>and</i> top\u2013down global factors related to the meaning of the symbols.\n</p>\n<h2><span class=\"mw-headline\" id=\"Peripheral_visual_input\">Peripheral visual input</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=8\" title=\"Edit section: Peripheral visual input\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<table class=\"plainlinks metadata ambox ambox-content ambox-Unreferenced\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><div style=\"width:52px\"><a href=\"/wiki/File:Question_book-new.svg\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png\" width=\"50\" height=\"39\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/75px-Question_book-new.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png 2x\" data-file-width=\"512\" data-file-height=\"399\" /></a></div></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">This section <b>does not <a href=\"/wiki/Wikipedia:Citing_sources\" title=\"Wikipedia:Citing sources\">cite</a> any <a href=\"/wiki/Wikipedia:Verifiability\" title=\"Wikipedia:Verifiability\">sources</a></b>.<span class=\"hide-when-compact\"> Please help <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit\">improve this section</a> by <a href=\"/wiki/Help:Introduction_to_referencing_with_Wiki_Markup/1\" title=\"Help:Introduction to referencing with Wiki Markup/1\">adding citations to reliable sources</a>. Unsourced material may be challenged and <a href=\"/wiki/Wikipedia:Verifiability#Burden_of_evidence\" title=\"Wikipedia:Verifiability\">removed</a>.</span>  <small><i>(January 2013)</i></small><small class=\"hide-when-compact\"><i> (<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>\n<p>The role of peripheral visual input in language reading remains the subject of much research. Peripheral input in music reading was a particular focus of Truitt et al. (1997). They used the <a href=\"/wiki/Gaze-contingency_paradigm\" title=\"Gaze-contingency paradigm\">gaze-contingency paradigm</a> to measure the extent of peripheral perception to the right of a fixation. This paradigm involves the spontaneous manipulation of a display in direct response to where the eyes are gazing at any one point of time. Performance was degraded only slightly when four <a href=\"/wiki/Crotchet\" class=\"mw-redirect\" title=\"Crotchet\">crotchets</a> to the right were presented as the ongoing preview, but significantly when only two crotchets were presented. Under these conditions, peripheral input extended over a little more than a four-beat measure, on average. For the less skilled, useful peripheral perception extended from half a beat up to between two and four beats. For the more skilled, useful peripheral perception extended up to five beats.\n</p><p>Peripheral visual input in music reading is clearly in need of more investigation, particularly now that the paradigm has become more accessible to researchers. A case could be made that Western music notation has developed in such a way as to optimise the use of peripheral input in the reading process. Noteheads, stems, beams, barlines and other notational symbols are all sufficiently bold and distinctive to be useful when picked up peripherally, even when at some distance from the fovea. The upcoming <a href=\"/wiki/Pitch_contour\" title=\"Pitch contour\">pitch contour</a> and prevailing rhythmic values of a musical line can typically be ascertained ahead of foveal perception. For example, a run of continuous semiquavers beamed together by two thick, roughly horizontal beams, will convey potentially valuable information about rhythm and texture, whether to the right on the currently fixated stave, or above, or above or below in a neighbouring stave. This is reason enough to suspect that the peripheral preprocessing of notational information is a factor in fluent music reading, just as it has been found to be the case for language reading. This would be consistent with the findings of Smith (1988) and Kinsler &amp; Carpenter (1995), who reported that the eyes do not fixate on every note in the reading of melodies.\n</p>\n<h2><span class=\"mw-headline\" id=\"Refixation\">Refixation</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=9\" title=\"Edit section: Refixation\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>A refixation is a fixation on information that has already been fixated on during the same reading. In the reading of two-stave keyboard music, there are two forms of refixation: (1) up or down within a chord, after the chord has already been inspected on both staves (vertical refixation), and (2) leftward refixation to a previous chord (either back horizontally on the same stave or diagonally to the other stave). These are analogous to Pollatsek &amp; Rayner\u2019s two categories of refixation in the reading of language: (1) \u201csame-word rightward refixation\u201d, i.e., on different syllables in the same word, and (2) \u201cleftward refixation\u201d to previously read words (also known as \u201cregression\u201d).<sup id=\"cite_ref-20\" class=\"reference\"><a href=\"#cite_note-20\">&#91;20&#93;</a></sup>\n</p><p>Leftward refixation occurs in music reading at all skill-levels.<sup id=\"cite_ref-Goolsby_1987,_Smith_1988_21-0\" class=\"reference\"><a href=\"#cite_note-Goolsby_1987,_Smith_1988-21\">&#91;21&#93;</a></sup> It involves a saccade back to the previous note/chord (occasionally even back two notes/chords), followed by at least one returning saccade to the right, to regain lost ground. Weaver reported that leftward regressions run from 7% to a substantial 23% of all saccades in the sight-reading of keyboard music. Goolsby and Smith reported significant levels of leftward refixation across all skill-levels in the sight-reading of melodies.<sup id=\"cite_ref-Goolsby_1987,_Smith_1988_21-1\" class=\"reference\"><a href=\"#cite_note-Goolsby_1987,_Smith_1988-21\">&#91;21&#93;</a></sup>\n</p><p>Looking at the same information more than once is, <i>prima facie</i>, a costly behaviour that must be weighed against the need to keep pace with the tempo of the music. Leftward refixation involves a greater investment of time than vertical refixation, and on logical grounds is likely to be considerably less common. For the same reason, the rates of both forms of refixation are likely to be sensitive to tempo, with lower rates at faster speed to meet the demand for making swifter progress across the score. Souter confirmed both of these suppositions in the skilled sight-reading of keyboard music. He found that at slow tempo (one chord a second), 23.13% (SD 5.76%) of saccades were involved in vertical refixation compared with 5.05% (4.81%) in leftward refixation (<i>p</i> &lt; 0.001). At fast tempo (two chords a second), the rates were 8.15% (SD 4.41%) for vertical refixation compared with 2.41% (2.37%) for leftward refixation (<i>p</i> = 0.011). These significant differences occurred even though recovery saccades were included in the counts for leftward refixations, effectively doubling their number. The reductions in the rate of vertical refixation  upon the doubling of tempo was highly significant (<i>p</i> &lt; 0.001), but for leftward refixation was not (<i>p</i> = 0.209), possibly because of the low baseline.<sup id=\"cite_ref-22\" class=\"reference\"><a href=\"#cite_note-22\">&#91;22&#93;</a></sup>\n</p>\n<h2><span id=\"Eye.E2.80.93hand_span\"></span><span class=\"mw-headline\" id=\"Eye\u2013hand_span\">Eye\u2013hand span</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=10\" title=\"Edit section: Eye\u2013hand span\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:302px;\"><a href=\"/wiki/File:Mozart_and_Linley_1770.jpg\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Mozart_and_Linley_1770.jpg/300px-Mozart_and_Linley_1770.jpg\" width=\"300\" height=\"207\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/c/c2/Mozart_and_Linley_1770.jpg 1.5x\" data-file-width=\"389\" data-file-height=\"269\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Mozart_and_Linley_1770.jpg\" class=\"internal\" title=\"Enlarge\"></a></div>WA Mozart meets violinist Thomas Linley in 1770, anon. French painting, 18th century</div></div></div>\n<p>The <a href=\"/wiki/Eye%E2%80%93hand_span\" title=\"Eye\u2013hand span\">eye\u2013hand span</a> (EHS) is the separation between eye position on the score and hand position. It can be measured in two ways: in notes (the number of notes between hand and eye; the 'note index'), or in time (the length of time between fixation and performance; the 'time index'). The main findings in relation to the eye\u2013voice span in the reading aloud of language were that (1) a larger span is associated with faster, more skilled readers,<sup id=\"cite_ref-23\" class=\"reference\"><a href=\"#cite_note-23\">&#91;23&#93;</a></sup> (2) a shorter span is associated with greater stimulus-difficulty,<sup id=\"cite_ref-24\" class=\"reference\"><a href=\"#cite_note-24\">&#91;24&#93;</a></sup> and (3) the span appears to vary according to linguistic phrasing.<sup id=\"cite_ref-25\" class=\"reference\"><a href=\"#cite_note-25\">&#91;25&#93;</a></sup> At least eight studies into eye movement in music reading have investigated analogous issues. For example, Jacobsen (1941) measured the average span to the right in the sight singing of melodies as up to two notes for the unskilled and between one and four notes for the skilled, whose faster average tempo in that study raises doubt as to whether skill alone was responsible for this difference. In Weaver (1943:28), the eye\u2013hand span varied greatly, but never exceeded 'a separation of eight successive notes or chords, a figure that seems impossibly large for the reading of keyboard scores. Young (1971) found that both skilled and unskilled participants previewed about one chord ahead of their hands, an  uncertain finding in view of the methodological problems in that study. Goolsby (1994) found that skilled <a href=\"/wiki/Sight-reading\" title=\"Sight-reading\">sight singers'</a> eyes were on average about four beats ahead of their voice, and less for the unskilled. He claimed that when sight singing, 'skilled music readers look farther ahead in the notation and then back to the point of performance' (p.&#160;77). To put this another way, skilled music readers maintain a larger eye\u2013hand span and are more likely to refixate within it. This association between span size and leftward refixation could arise from a greater need for the refreshment of information in <a href=\"/wiki/Working_memory\" title=\"Working memory\">working memory</a>. Furneax &amp; Land (1999) found that professional pianists' spans are significantly larger than those of amateurs. The time index was significantly affected by the performance tempo: when fast tempos were imposed on performance, all participants showed a reduction in the time index (to about 0.7&#160;s), and slow tempos increased the time index (to about 1.3&#160; s). This means that the length of time that information is stored in the buffer is related to performance tempo rather than ability, but that professionals can fit more information into their buffers.<sup id=\"cite_ref-26\" class=\"reference\"><a href=\"#cite_note-26\">&#91;26&#93;</a></sup>\n</p><p>Sloboda (1974, 1977) cleverly applied Levin &amp; Kaplin's (1970) 'light-out' method in an experiment designed to measure the size of the span in music reading. <a href=\"/wiki/Sloboda\" title=\"Sloboda\">Sloboda</a> (1977) asked his participants to sight read a melody and turned the lights out at an unpredictable point during each reading. The participants were instructed to continue playing correctly 'without guessing' for as long as they could after visual input was effectively removed, giving an indication as to how far ahead of their hands they were perceiving at that moment. Here, the span was defined as including peripheral input. Participants were allowed to choose their own performing speed for each piece, introducing a layer of uncertainty into the interpretation of the results. Sloboda reported that there was a tendency for the span to coincide with the musical phrasing, so that 'a boundary just beyond the average span \"stretches\" the span, and a boundary just before the average \"contracts\" it' (as reported in Sloboda 1985:72). Good readers, he found, maintain a larger span size (up to seven notes) than do poor readers (up to four notes).\n</p><p>Truitt et al. (1997) found that in sight reading melodies on the <a href=\"/wiki/Electronic_keyboard\" title=\"Electronic keyboard\">electronic keyboard</a>, span size averaged a little over one beat and ranged from two beats behind the currently fixated point to an incredibly large 12 beats ahead. The normal range of span size was rather smaller: between one beat behind and three beats ahead of the hands for 88% of the total reading duration, and between 0 and 2 beats ahead for 68% of the duration. Such large ranges, in particular, those that extend leftwards from the point of fixation, may have been due to the 'wandering effect'. For the less skilled, the average span was about half a crotchet beat. For the skilled, the span averaged about two beats and useful peripheral perception extended up to five beats. This, in the view of Rayner &amp; Pollatsek (1997:52), suggests that:\n</p>\n<dl><dd>\"a major constraint on tasks that require translation of complex inputs into continuous <a href=\"/w/index.php?title=Motor_transcription&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"Motor transcription (page does not exist)\">motor transcription</a> is [the limited capacity of] <a href=\"/wiki/Short-term_memory\" title=\"Short-term memory\">short-term memory</a>. If the encoding process gets too far ahead of the output, there is likely to be a loss of material that is stored in the queue.\"</dd></dl>\n<p>Rayner &amp; Pollatsek (1997:52) explained the size of the eye\u2013hand span as a continuous tug-o-war, as it were, between two forces: (1) the need for material to be held in working memory long enough to be processed into <a href=\"/wiki/Musculoskeletal\" class=\"mw-redirect\" title=\"Musculoskeletal\">musculoskeletal</a> commands, and (2) the need to limit the demand on span size and therefore the workload in the memory system. They claimed that most music pedagogy supports the first aspect [in advising] the student that the eyes should be well ahead of the hands for effective sight reading. They held that despite such advice, for most readers, the second aspect prevails; that is, the need to limit the workload of the <a href=\"/wiki/Memory\" title=\"Memory\">memory</a> system. This, they contended, results in a very small span under normal conditions.\n</p>\n<h2><span class=\"mw-headline\" id=\"Tempo\">Tempo</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=11\" title=\"Edit section: Tempo\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Smith (1988) found that when <a href=\"/wiki/Tempo\" title=\"Tempo\">tempo</a> is increased, fixations are fewer in number and shorter in mean duration, and that fixations tend to be spaced further apart on the score. Kinsler &amp; Carpenter (1995) investigated the effect of increased tempo in reading rhythmic notation, rather than real melodies. They similarly found that increased tempo causes a decrease in mean fixation duration and an increase in mean saccade amplitude (i.e., the distance on the page between successive fixations). Souter (2001) used novel theory and methodology to investigate the effects of tempo on key variables in the sight reading of highly skilled keyboardists. Eye movement studies have typically measured saccade and fixation durations as separate variables. Souter (2001) used a novel variable: pause duration. This is a measure of the duration between the end of one fixation and the end of the next; that is, the sum of the duration of each saccade and of the fixation it leads to. Using this composite variable brings into play a simple relationship between the number of pauses, their mean duration, and the tempo: the number of pauses factored by their mean duration equals the total reading duration. In other words, the time taken to read a passage equals the sum of the durations of the individual pauses, or nd = r, where n is the number of pauses, d is their mean duration, and r is the total reading time. Since the total reading duration is inversely proportional to the tempo\u2014double the tempo and the total reading time will be halved\u2014the relationship can be expressed as nd is proportional to  r, where t is tempo.\n</p><p>This study observed the effect of a change in tempo on the number and mean duration of pauses; thus, now using the letters to represent proportional changes in values,\n</p><p>nd = <sup>1</sup>\u2044<sub>t</sub>, where n is the proportional change in pause number, d is the proportional change in their mean duration, and t is the proportional change in tempo. This expression describes a number\u2013duration curve, in which the number and mean duration of pauses form a hyperbolic relationship (since neither n nor d ever reaches zero). The curve represents the range of possible ratios for using these variables to adapt to a change in tempo. In Souter (2001), tempo was doubled from the first to the second reading, from 60 to 120 MM; thus, t = 2, and the number\u2013duration curve is described by nd = 0.5 (Figure 2). In other words, factoring the proportional change in the number and mean duration of pauses between these readings will always equal \u00bd. Each participant\u2019s two readings thus corresponded to a point on this curve.\n</p><p>Irrespective of the value of t, all number\u2013duration curves pass through three points of theoretical interest: two \u2018sole-contribution\u2019 points and one \u2018equal-contribution\u2019 point. At each sole-contribution point, a reader has relied entirely on one of the two variables to adapt to a new tempo. In Souter's study, if a participant adapted to the doubling of tempo by using the same number of pauses and halving their mean duration, the reading would fall on the sole-contribution point (1.0,0.5). Conversely, if a participant adapted by halving the number of pauses and maintaining their mean duration, the reading would fall on the other sole-contribution point (0.5,1.0). These two points represent completely one-sided behaviour. On the other hand, if a reader\u2019s adaptation drew on both variables equally, and factoring them gives 0.5, they must both equal  the square root of t (since t = 2 in this case, the <a href=\"/wiki/Square_root_of_2\" title=\"Square root of 2\">square root of 2</a>). The adaptation thus fell on the equal-contribution point:\n</p><p>(<span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"  alttext=\"{\\displaystyle 1/{\\sqrt {2}}}\">\n  <semantics>\n    <mrow class=\"MJX-TeXAtom-ORD\">\n      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n        <mn>1</mn>\n        <mrow class=\"MJX-TeXAtom-ORD\">\n          <mo>/</mo>\n        </mrow>\n        <mrow class=\"MJX-TeXAtom-ORD\">\n          <msqrt>\n            <mn>2</mn>\n          </msqrt>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding=\"application/x-tex\">{\\displaystyle 1/{\\sqrt {2}}}</annotation>\n  </semantics>\n</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/75a0bbdb60fcb73ac67d9970a5eb0808b87fd37d\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -0.838ex; width:5.423ex; height:3.176ex;\" alt=\"1/{\\sqrt {2}}\"/></span>, <span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"  alttext=\"{\\displaystyle 1/{\\sqrt {2}}}\">\n  <semantics>\n    <mrow class=\"MJX-TeXAtom-ORD\">\n      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n        <mn>1</mn>\n        <mrow class=\"MJX-TeXAtom-ORD\">\n          <mo>/</mo>\n        </mrow>\n        <mrow class=\"MJX-TeXAtom-ORD\">\n          <msqrt>\n            <mn>2</mn>\n          </msqrt>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding=\"application/x-tex\">{\\displaystyle 1/{\\sqrt {2}}}</annotation>\n  </semantics>\n</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/75a0bbdb60fcb73ac67d9970a5eb0808b87fd37d\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -0.838ex; width:5.423ex; height:3.176ex;\" alt=\"1/{\\sqrt {2}}\"/></span>), equivalent to (0.707,0.707).\n</p><p>Predicting where performers would fall on the curve involved considering the possible advantages and disadvantages of using these two adaptive resources. A strategy of relying entirely on altering pause duration to adapt to a new tempo\u2014falling on (1.0,0.5)\u2014would permit the same number of pauses to be used irrespective of tempo. Theoretically, this would enable readers to use a standardised scanpath across a score, whereas if they changed the number of their pauses to adapt to a new tempo, their scanpath would need to be redesigned, sacrificing the benefits of a standardised approach. There is no doubt that readers are able to change their pause duration and number both from moment to moment and averaged over longer stretches of reading. Musicians typically use a large range of fixation durations within a single reading, even at a stable tempo.<sup id=\"cite_ref-27\" class=\"reference\"><a href=\"#cite_note-27\">&#91;27&#93;</a></sup> Indeed, successive fixation durations appear to vary considerably, and seemingly at random; one fixation might be 200&#160;ms, the next 370&#160;ms, and the next 240&#160;ms. (There are no data on successive pause durations in the literature, so mean fixation duration is cited here as a near-equivalent.)\n</p>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:402px;\"><a href=\"/wiki/File:Number%E2%80%93duration_ratios.jpg\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/f/f7/Number%E2%80%93duration_ratios.jpg/400px-Number%E2%80%93duration_ratios.jpg\" width=\"400\" height=\"376\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/en/f/f7/Number%E2%80%93duration_ratios.jpg 1.5x\" data-file-width=\"591\" data-file-height=\"556\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Number%E2%80%93duration_ratios.jpg\" class=\"internal\" title=\"Enlarge\"></a></div>Seven of Souter's (2001:139) nine participants clustered around the equal-contribution point</div></div></div><p>In the light of this flexibility in varying fixation duration, and since the process of picking up, processing and performing the information on the page is elaborate, it might be imagined that readers prefer to use a standardised scanpath. For example, in four-part, hymn-style textures for keyboard, such as were used in Souter (2001), the information on the score is presented as a series of two-note, optically separated units\u2014two allocated to an upper stave and two to a lower stave for each chord. A standardised scanpath might consist of a sequence of \u2018saw-tooth\u2019 movements from the upper stave to the lower stave for a chord, then diagonally across to the upper stave and down to the lower stave of the next chord, and so on. However, numerous studies<sup id=\"cite_ref-28\" class=\"reference\"><a href=\"#cite_note-28\">&#91;28&#93;</a></sup> have shown that scanpaths in the reading of a number of musical textures\u2014including melody, four-part hymns, and counterpoint\u2014are not predictable and orderly, but are inherently changeable, with a certain ragged, ad-hoc quality. Music readers appear to turn their backs on the theoretical advantage of standardised scanpath: they are either flexible or ad hoc when it comes to the number of pauses\u2014just as they are with respect to their pause durations\u2014and do not scan a score in a strict, predetermined manner.\n</p><p>Souter hypothesised that the most likely scenario is that both pause duration and number are used to adapt to tempo, and that a number\u2013duration relationship that lies close to the equal-contribution point allows the apparatus the greatest flexibility to adapt to further changes in reading conditions. He reasoned that it may be dysfunctional to use only one of two available adaptive resources, since that would make it more difficult to subsequently use that direction for further adaptation. This hypothesis\u2014that when tempo is increased, the mean number\u2013duration relationship will be in the vicinity of the equal-contribution point\u2014was confirmed by the data in terms of the mean result: when tempo doubled, both the mean number of pauses per chord and the mean pause duration overall fell such that the mean number\u2013duration relationship was (0.705,0.709), close to the equal-contribution point of (0.708, 0.708), with standard deviations of (0.138,0.118). Thus, the stability of scanpath\u2014tenable only when the relationship is (0.5,1.0)\u2014was sacrificed to maintain a relatively stable mean pause duration.<sup id=\"cite_ref-29\" class=\"reference\"><a href=\"#cite_note-29\">&#91;29&#93;</a></sup>\n</p><p>This challenged the notion that scanpath (largely or solely) reflects the horizontal or vertical emphasis of the musical texture, as proposed by Sloboda (1985) and Weaver (1943), since these dimensions depend significantly on tempo.\n</p>\n<h2><span class=\"mw-headline\" id=\"Conclusions\">Conclusions</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=12\" title=\"Edit section: Conclusions\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Both logical inference and evidence in the literature point to the fact that there are three oculomotor imperatives in the task of eye movement in music reading. The first imperative seems obvious: the eyes must maintain a pace across the page that is appropriate to the tempo of the music, and they do this by manipulating the number and durations of fixations, and thereby the scanpath across the score. The second imperative is to provide an appropriate rate of refreshment of the information being stored and processed in working memory by manipulating the number and duration of fixations. This workload appears to be related to tempo, stimulus complexity and stimulus familiarity, and there is strong evidence that the capacity for high workload in relation to these variables is also connected with the skill of the reader. The third imperative is to maintain a span size that is appropriate to the reading conditions. The span must not be so small that there is insufficient time to perceive visual input and process it into musculoskeletal commands; it must not be so large that the capacity of the memory system to store and process information is exceeded. Musicians appear to use oculomotor commands to address all three imperatives simultaneously, which are in effect mapped onto each other in the reading process. Eye movement thus embodies a fluid set of characteristics that are not only intimately engaged in engineering the optimal visual input to the apparatus, but in servicing the process of that information in the memory system.<sup id=\"cite_ref-30\" class=\"reference\"><a href=\"#cite_note-30\">&#91;30&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Notes\">Notes</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=13\" title=\"Edit section: Notes\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist columns references-column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;\">\n<ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\">e.g., Matin (1974)</span>\n</li>\n<li id=\"cite_note-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-2\">^</a></b></span> <span class=\"reference-text\">e.g., Goolsby, 1987; Smith, 1988</span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\">Sloboda (1985)</span>\n</li>\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\">Rayner et al. (1990)</span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\">(Jacobsen 1941; Weaver 1943; Weaver &amp; Nuys 1943; York 1951; and Lang 1961)</span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\">Jacobsen 1941; York 1951; and Lang 1961</span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\">Young 1971)</span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\">Weaver (1943), York (1951) and Young (1971)</span>\n</li>\n<li id=\"cite_note-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-9\">^</a></b></span> <span class=\"reference-text\">e.g., Weaver (1943), Young (1971), Goolsby (1987)</span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\">Souter (2001:80\u201381)</span>\n</li>\n<li id=\"cite_note-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-11\">^</a></b></span> <span class=\"reference-text\">Souter (2001:80\u201385)</span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\">Souter (2001:90)</span>\n</li>\n<li id=\"cite_note-13\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-13\">^</a></b></span> <span class=\"reference-text\">Goolsby 1987:107</span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\">Souter (2001:89\u201390)</span>\n</li>\n<li id=\"cite_note-15\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-15\">^</a></b></span> <span class=\"reference-text\">Goolsby (1987:88), assuming there were no extraneous methodological factor, such as failing to exclude from total durations the 'return-sweep' saccades and non-reading time at the start and end of readings.</span>\n</li>\n<li id=\"cite_note-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-16\">^</a></b></span> <span class=\"reference-text\">Souter (2001:91\u201392)</span>\n</li>\n<li id=\"cite_note-17\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-17\">^</a></b></span> <span class=\"reference-text\">Souter (2001:93)</span>\n</li>\n<li id=\"cite_note-18\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-18\">^</a></b></span> <span class=\"reference-text\">Sloboda (1985:70)</span>\n</li>\n<li id=\"cite_note-19\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-19\">^</a></b></span> <span class=\"reference-text\">Souter (2001:97)</span>\n</li>\n<li id=\"cite_note-20\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-20\">^</a></b></span> <span class=\"reference-text\">Pollatsek &amp; Rayner (1990:153)</span>\n</li>\n<li id=\"cite_note-Goolsby_1987,_Smith_1988-21\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Goolsby_1987,_Smith_1988_21-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Goolsby_1987,_Smith_1988_21-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Goolsby (1987), Smith (1988)</span>\n</li>\n<li id=\"cite_note-22\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-22\">^</a></b></span> <span class=\"reference-text\">Souter (2001:138,140)</span>\n</li>\n<li id=\"cite_note-23\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-23\">^</a></b></span> <span class=\"reference-text\">e.g., Buswell (1920), <a href=\"/w/index.php?title=Judd_and_Buswell&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"Judd and Buswell (page does not exist)\">Judd and Buswell</a> (1922), Tinker (1958), Morton (1964)</span>\n</li>\n<li id=\"cite_note-24\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-24\">^</a></b></span> <span class=\"reference-text\">Buswell (1920), Lawson (1961), Morton (1964)</span>\n</li>\n<li id=\"cite_note-25\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-25\">^</a></b></span> <span class=\"reference-text\">Levin and Kaplin (1970), Levin and Addis (1980)</span>\n</li>\n<li id=\"cite_note-26\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-26\">^</a></b></span> <span class=\"reference-text\">Furneax S &amp; Land MF (1999) The effects of skill on the eye-hand span during musical sight-reading, <i>Proceedings: Biological Sciences</i>, <b>266</b>, 2435\u201340</span>\n</li>\n<li id=\"cite_note-27\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-27\">^</a></b></span> <span class=\"reference-text\">e.g., Smith (1988)</span>\n</li>\n<li id=\"cite_note-28\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-28\">^</a></b></span> <span class=\"reference-text\">e.g., Weaver (1943), Goolsby (1987)</span>\n</li>\n<li id=\"cite_note-29\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-29\">^</a></b></span> <span class=\"reference-text\">Souter (2001:137). Mean pause duration was 368&#160;ms at slow tempo (SD = 44&#160;ms) falling to 263&#160;ms at fast tempo (SD = 42&#160;ms), t(8) = 5.75, <i>p</i> &lt; 0.001. Correspondingly, the mean number of pauses per chord fell from a mean of 2.75 (SD = 0.30) at slow tempo to 1.94 (SD = 0.28) at fast tempo, t(8) = 6.97, <i>p</i> &lt; 0.001.</span>\n</li>\n<li id=\"cite_note-30\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-30\">^</a></b></span> <span class=\"reference-text\">Souter (2001:103)</span>\n</li>\n</ol></div>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Eye_movement_in_music_reading&amp;action=edit&amp;section=14\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<style data-mw-deduplicate=\"TemplateStyles:r853264625\">.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li,.mw-parser-output .refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}</style><div class=\"refbegin\" style=\"\">\n<ul><li>Drai-Zerbib V &amp; Baccino T (2005) L'expertise dans la lecture musicale: int\u00e9gration intermodale [Expertise in music reading: intermodal integration]. <i>L'Ann\u00e9e Psychologique</i>, <b>105</b>, 387\u2013422 <a rel=\"nofollow\" class=\"external autonumber\" href=\"http://www.unice.fr/LPEQ/pagesperso/thierry/thierrybaccino.htm\">[1]</a></li>\n<li>Furneaux S &amp; Land MF (1999) The effects of skill on the eye-hand span during musical sight-reading, <i>Proceedings of the Royal Society of London, Series B: Biological Sciences</i>, <b>266</b>, 2435\u201340</li>\n<li>Goolsby TW (1987) The parameters of eye movement in vocal music reading. Doctoral dissertation, University of Illinois at Urbana-Champaign, AAC8721641</li>\n<li>Goolsby TW (1994a)  Eye movement in music reading: effects of reading ability, notational complexity, and encounters. <i>Music Perception</i>, <b>12(1)</b>, 77\u201396</li>\n<li>Goolsby TW (1994b)  Profiles of processing: eye movements during sightreading. <i>Music Perception</i>, <b>12(1)</b>, 97\u2013123</li>\n<li>Kinsler V &amp; Carpenter RHS (1995) Saccadic eye movements while reading music. <i>Vision Research</i>, <b>35</b>, 1447\u201358</li>\n<li>Lang MM (1961) An investigation of eye-movements involved in the reading of music. <i>Transactions of the International Ophthalmic Optical Congress</i>, London: Lockwood &amp; Son, 329\u201354</li>\n<li>Matin E (1974) Saccadic suppression: a review and analysis. <i>Psychological Bulletin</i>, <b>81</b>, 899\u2013917</li>\n<li>McConkie GW &amp; Rayner K (1975) The span of the effective stimulus during a fixation in reading. <i>Perception and Psychophysics</i>, <b>17</b>, 578\u201386</li>\n<li>Pollatsek A &amp; Rayner K (1990) Eye movements, the eye-hand span, and the perceptual span in sight-reading of music. <i>Current Directions in Psychological Science</i>, 149\u2013153</li>\n<li>O'Regan KJ (1979) Moment to moment control of eye saccades as a function of textual parameters in reading. In PA Kolers, Me Wrolstad, H Bouma (eds), <i>Processing of Visible Language</i>, <b>1</b>, New York: Plenum Press</li>\n<li>Reder SM (1973) On-line monitoring ef eye position signals in contingent and noncontinent paradigms. <i>Behavior Research Methods and Instrumentation</i>, <b>5</b>, 218\u201328</li>\n<li>Servant I &amp; Baccino T (1999) Lire Beethoven: une \u00e9tude exploratoire des mouvements des yeux {Reading Beethoven: an exploratory study of eye movement]. <i>Scientae Musicae</i>, <b>3(1)</b>, 67\u201394 <a rel=\"nofollow\" class=\"external autonumber\" href=\"http://www.unice.fr/LPEQ/pagesperso/thierry/thierrybaccino.htm\">[2]</a></li>\n<li>Sloboda JA (1974) The eye\u2013hand span\u2014an approach to the study of sight reading. <i>Psychology of Music</i>, <b>2(2)</b>, 4\u201310</li>\n<li>Sloboda JA (1985) <i>The musical mind: the cognitive psychology of music</i>. Oxford: Clarendon Press</li>\n<li>Smith DJ (1988) An investigation of the effects of varying temporal settings on eye movements while sight reading trumpet music and while reading language aloud. Doctoral dissertation, UMI 890066)</li>\n<li>Souter T (2001) <i>Eye movement and memory in the sight reading of keyboard music</i>. Doctoral dissertation, University of Sydney (<a rel=\"nofollow\" class=\"external text\" href=\"http://ses.library.usyd.edu.au/handle/2123/8983\">pdf download</a>)</li>\n<li>Truitt FE, Clifton C, Pollatsek A, Rayner K (1997) The perceptual span and the eye\u2013hand span in sight reading music. <i>Visual cognition</i>, <b>4(2)</b>, 143\u201361</li>\n<li>Weaver HA (1943) A survey of visual precesses in reading differently constructed musical selections. <i>Psychological Monographs</i>, <b>55(1)</b>, 1\u201330</li>\n<li>York R (1952) An experimental study of vocal music reading using eye movement photography and voice recording. Doctoral dissertation, Syracuse University</li>\n<li>Young LJ (1971) A study of the eye-movements and eye-hand temporal relationships of successful and unsuccessful piano sight-readers while piano sight-reading. Doctoral dissertation, Indiana University, RSD72-1341</li></ul>\n</div>\n<div role=\"navigation\" class=\"navbox\" aria-labelledby=\"Music_psychology\" style=\"padding:3px\"><table class=\"nowraplinks collapsible autocollapse navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\"><div class=\"plainlinks hlist navbar mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Music_psychology\" title=\"Template:Music psychology\"><abbr title=\"View this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Music_psychology\" title=\"Template talk:Music psychology\"><abbr title=\"Discuss this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Template:Music_psychology&amp;action=edit\"><abbr title=\"Edit this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">e</abbr></a></li></ul></div><div id=\"Music_psychology\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Music_psychology\" title=\"Music psychology\">Music psychology</a></div></th></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Areas</th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Biomusicology\" title=\"Biomusicology\">Biomusicology</a></li>\n<li><a href=\"/wiki/Cognitive_musicology\" title=\"Cognitive musicology\">Cognitive musicology</a></li>\n<li><a href=\"/wiki/Cognitive_neuroscience_of_music\" title=\"Cognitive neuroscience of music\">Cognitive neuroscience of music</a></li>\n<li><a href=\"/wiki/Culture_in_music_cognition\" title=\"Culture in music cognition\">Culture in music cognition</a></li>\n<li><a href=\"/wiki/Evolutionary_musicology\" title=\"Evolutionary musicology\">Evolutionary musicology</a></li>\n<li><a href=\"/wiki/Psychoacoustics\" title=\"Psychoacoustics\">Psychoacoustics</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Category:Music_psychology\" title=\"Category:Music psychology\">Topics</a></th><td class=\"navbox-list navbox-even hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Absolute_pitch\" title=\"Absolute pitch\">Absolute pitch</a></li>\n<li><a href=\"/wiki/Auditory_illusion\" title=\"Auditory illusion\">Auditory illusion</a></li>\n<li><a href=\"/wiki/Auditory_imagery\" title=\"Auditory imagery\">Auditory imagery</a></li>\n<li><a href=\"/wiki/Background_music\" title=\"Background music\">Background music</a></li>\n<li><a href=\"/wiki/Consonance_and_dissonance\" title=\"Consonance and dissonance\">Consonance and dissonance</a></li>\n<li><a href=\"/wiki/Deutsch%27s_scale_illusion\" title=\"Deutsch&#39;s scale illusion\">Deutsch's scale illusion</a></li>\n<li><a href=\"/wiki/Earworm\" title=\"Earworm\">Earworm</a></li>\n<li><a href=\"/wiki/Embodied_music_cognition\" title=\"Embodied music cognition\">Embodied music cognition</a></li>\n<li><a href=\"/wiki/Entrainment_(biomusicology)\" title=\"Entrainment (biomusicology)\">Entrainment</a></li>\n<li><a href=\"/wiki/Exercise_and_music\" title=\"Exercise and music\">Exercise and music</a></li>\n<li><a class=\"mw-selflink selflink\">Eye movement in music reading</a></li>\n<li><a href=\"/wiki/Franssen_effect\" title=\"Franssen effect\">Franssen effect</a></li>\n<li><a href=\"/wiki/Generative_theory_of_tonal_music\" title=\"Generative theory of tonal music\">Generative theory of tonal music</a></li>\n<li><a href=\"/wiki/Glissando_illusion\" title=\"Glissando illusion\">Glissando illusion</a></li>\n<li><a href=\"/wiki/Hedonic_music_consumption_model\" title=\"Hedonic music consumption model\">Hedonic music consumption model</a></li>\n<li><a href=\"/wiki/Illusory_continuity_of_tones\" title=\"Illusory continuity of tones\">Illusory continuity of tones</a></li>\n<li><a href=\"/wiki/Levitin_effect\" title=\"Levitin effect\">Levitin effect</a></li>\n<li><a href=\"/wiki/Lipps%E2%80%93Meyer_law\" title=\"Lipps\u2013Meyer law\">Lipps\u2013Meyer law</a></li>\n<li><a href=\"/wiki/Melodic_expectation\" title=\"Melodic expectation\">Melodic expectation</a></li>\n<li><a href=\"/wiki/Melodic_fission\" title=\"Melodic fission\">Melodic fission</a></li>\n<li><a href=\"/wiki/Mozart_effect\" title=\"Mozart effect\">Mozart effect</a></li>\n<li><a href=\"/wiki/Music_and_emotion\" title=\"Music and emotion\">Music and emotion</a></li>\n<li><a href=\"/wiki/Dance\" title=\"Dance\">Music and movement</a></li>\n<li><a href=\"/wiki/Music_in_psychological_operations\" title=\"Music in psychological operations\">Music in psychological operations</a></li>\n<li><a href=\"/wiki/Psychology_of_music_preference\" title=\"Psychology of music preference\">Music preference</a></li>\n<li><a href=\"/wiki/Music-related_memory\" title=\"Music-related memory\">Music-related memory</a></li>\n<li><a href=\"/wiki/Musical_gesture\" title=\"Musical gesture\">Musical gesture</a></li>\n<li><a href=\"/wiki/Musical_semantics\" title=\"Musical semantics\">Musical semantics</a></li>\n<li><a href=\"/wiki/Musical_syntax\" title=\"Musical syntax\">Musical syntax</a></li>\n<li><a href=\"/wiki/Octave_illusion\" title=\"Octave illusion\">Octave illusion</a></li>\n<li><a href=\"/wiki/Relative_pitch\" title=\"Relative pitch\">Relative pitch</a></li>\n<li><a href=\"/wiki/Shepard_tone\" title=\"Shepard tone\">Shepard tone</a></li>\n<li><a href=\"/wiki/Temporal_dynamics_of_music_and_language\" title=\"Temporal dynamics of music and language\">Temporal dynamics of music and language</a></li>\n<li><a href=\"/wiki/Tonal_memory\" title=\"Tonal memory\">Tonal memory</a></li>\n<li><a href=\"/wiki/Tritone_paradox\" title=\"Tritone paradox\">Tritone paradox</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Music-specific_disorders\" title=\"Music-specific disorders\">Disorders</a></th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Amusia\" title=\"Amusia\">Amusia</a></li>\n<li><a href=\"/wiki/Auditory_arrhythmia\" title=\"Auditory arrhythmia\">Auditory arrhythmia</a></li>\n<li><a href=\"/wiki/Beat_deafness\" title=\"Beat deafness\">Beat deafness</a></li>\n<li><a href=\"/wiki/Musical_hallucinations\" title=\"Musical hallucinations\">Musical hallucinations</a></li>\n<li><a href=\"/wiki/Focal_dystonia\" title=\"Focal dystonia\">Musician's dystonia</a></li>\n<li><a href=\"/wiki/Music-specific_disorders\" title=\"Music-specific disorders\">Music-specific disorders</a></li>\n<li><a href=\"/wiki/Tone_deafness\" class=\"mw-redirect\" title=\"Tone deafness\">Tone deafness</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Related fields</th><td class=\"navbox-list navbox-even hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Aesthetics_of_music\" title=\"Aesthetics of music\">Aesthetics of music</a></li>\n<li><a href=\"/wiki/Bioacoustics\" title=\"Bioacoustics\">Bioacoustics</a></li>\n<li><a href=\"/wiki/Ethnomusicology\" title=\"Ethnomusicology\">Ethnomusicology</a></li>\n<li><a href=\"/wiki/Hearing\" title=\"Hearing\">Hearing</a></li>\n<li><a href=\"/wiki/Melodic_intonation_therapy\" class=\"mw-redirect\" title=\"Melodic intonation therapy\">Melodic intonation therapy</a></li>\n<li><a href=\"/wiki/Music_education\" title=\"Music education\">Music education</a></li>\n<li><a href=\"/wiki/Music_therapy\" title=\"Music therapy\">Music therapy</a></li>\n<li><a href=\"/wiki/Musical_acoustics\" title=\"Musical acoustics\">Musical acoustics</a></li>\n<li><a href=\"/wiki/Musicology\" title=\"Musicology\">Musicology</a></li>\n<li><a href=\"/wiki/Music_therapy\" title=\"Music therapy\">Neurologic music therapy</a></li>\n<li><a href=\"/wiki/Neuronal_encoding_of_sound\" title=\"Neuronal encoding of sound\">Neuronal encoding of sound</a></li>\n<li><a href=\"/wiki/Performance_science\" title=\"Performance science\">Performance science</a></li>\n<li><a href=\"/wiki/Philosophy_of_music\" title=\"Philosophy of music\">Philosophy of music</a></li>\n<li><a href=\"/wiki/Psychoanalysis_and_music\" title=\"Psychoanalysis and music\">Psychoanalysis and music</a></li>\n<li><a href=\"/wiki/Sociomusicology\" title=\"Sociomusicology\">Sociomusicology</a></li>\n<li><a href=\"/wiki/Systematic_musicology\" title=\"Systematic musicology\">Systematic musicology</a></li>\n<li><a href=\"/wiki/Zoomusicology\" title=\"Zoomusicology\">Zoomusicology</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Category:Music_psychologists\" title=\"Category:Music psychologists\">Researchers</a></th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Jamshed_Bharucha\" title=\"Jamshed Bharucha\">Jamshed Bharucha</a></li>\n<li><a href=\"/wiki/Robert_Cutietta\" title=\"Robert Cutietta\">Robert Cutietta</a></li>\n<li><a href=\"/wiki/Jane_W._Davidson\" title=\"Jane W. Davidson\">Jane W. Davidson</a></li>\n<li><a href=\"/wiki/Ir%C3%A8ne_Deli%C3%A8ge\" title=\"Ir\u00e8ne Deli\u00e8ge\">Ir\u00e8ne Deli\u00e8ge</a></li>\n<li><a href=\"/wiki/Diana_Deutsch\" title=\"Diana Deutsch\">Diana Deutsch</a></li>\n<li><a href=\"/wiki/Tuomas_Eerola\" title=\"Tuomas Eerola\">Tuomas Eerola</a></li>\n<li><a href=\"/wiki/Henkjan_Honing\" title=\"Henkjan Honing\">Henkjan Honing</a></li>\n<li><a href=\"/wiki/Nina_Kraus\" title=\"Nina Kraus\">Nina Kraus</a></li>\n<li><a href=\"/wiki/Carol_L._Krumhansl\" title=\"Carol L. Krumhansl\">Carol L. Krumhansl</a></li>\n<li><a href=\"/wiki/Fred_Lerdahl\" title=\"Fred Lerdahl\">Fred Lerdahl</a></li>\n<li><a href=\"/wiki/Daniel_Levitin\" title=\"Daniel Levitin\">Daniel Levitin</a></li>\n<li><a href=\"/wiki/Leonard_B._Meyer\" title=\"Leonard B. Meyer\">Leonard B. Meyer</a></li>\n<li><a href=\"/wiki/Max_Friedrich_Meyer\" title=\"Max Friedrich Meyer\">Max Friedrich Meyer</a></li>\n<li><a href=\"/wiki/James_Mursell\" title=\"James Mursell\">James Mursell</a></li>\n<li><a href=\"/wiki/Richard_Parncutt\" title=\"Richard Parncutt\">Richard Parncutt</a></li>\n<li><a href=\"/wiki/Oliver_Sacks\" title=\"Oliver Sacks\">Oliver Sacks</a></li>\n<li><a href=\"/wiki/Carl_Seashore\" title=\"Carl Seashore\">Carl Seashore</a></li>\n<li><a href=\"/wiki/Max_Schoen\" title=\"Max Schoen\">Max Schoen</a></li>\n<li><a href=\"/wiki/Roger_Shepard\" title=\"Roger Shepard\">Roger Shepard</a></li>\n<li><a href=\"/wiki/John_Sloboda\" title=\"John Sloboda\">John Sloboda</a></li>\n<li><a href=\"/wiki/Carl_Stumpf\" title=\"Carl Stumpf\">Carl Stumpf</a></li>\n<li><a href=\"/wiki/William_Forde_Thompson\" title=\"William Forde Thompson\">William Forde Thompson</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Books and journals</th><td class=\"navbox-list navbox-even hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><i><a href=\"/wiki/Musicophilia\" title=\"Musicophilia\">Musicophilia</a></i></li>\n<li><i><a href=\"/wiki/Music,_Thought,_and_Feeling\" title=\"Music, Thought, and Feeling\">Music, Thought, and Feeling</a></i></li>\n<li><i><a href=\"/wiki/Psychology_of_Music_(journal)\" title=\"Psychology of Music (journal)\">Psychology of Music (journal)</a></i></li>\n<li><i><a href=\"/wiki/Psychomusicology:_Music,_Mind_and_Brain\" title=\"Psychomusicology: Music, Mind and Brain\">Psychomusicology: Music, Mind and Brain (journal)</a></i></li>\n<li><i><a href=\"/wiki/The_World_in_Six_Songs\" title=\"The World in Six Songs\">The World in Six Songs</a></i></li>\n<li><i><a href=\"/wiki/This_Is_Your_Brain_on_Music\" title=\"This Is Your Brain on Music\">This Is Your Brain on Music</a></i></li></ul>\n</div></td></tr></tbody></table></div>\n\n<!-- \nNewPP limit report\nParsed by mw2233\nCached time: 20180917185502\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.168 seconds\nReal time usage: 0.235 seconds\nPreprocessor visited node count: 651/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 22640/2097152 bytes\nTemplate argument size: 193/2097152 bytes\nHighest expansion depth: 9/40\nExpensive parser function count: 1/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 9109/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.026/10.000 seconds\nLua memory usage: 1.18 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  116.981      1 -total\n 44.55%   52.111      1 Template:Unreferenced_section\n 28.48%   33.313      1 Template:Unreferenced\n 25.76%   30.130      1 Template:Ambox\n 23.98%   28.049      1 Template:Reflist\n 13.68%   15.999      1 Template:Refbegin\n 10.09%   11.805      1 Template:Music_psychology\n  8.10%    9.477      1 Template:Navbox\n  3.71%    4.343      1 Template:Column-width\n  2.27%    2.659      1 Template:Main_other\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:8128722-0!canonical!math=5 and timestamp 20180917185502 and revision id 838686051\n -->\n</div>"},"langlinks":[{"lang":"pt","url":"https://pt.wikipedia.org/wiki/Movimento_ocular_na_leitura_musical","langname":"Portuguese","autonym":"portugu\u00eas","*":"Movimento ocular na leitura musical"}],"categories":[{"sortkey":"","hidden":"","*":"Articles_needing_additional_references_from_January_2013"},{"sortkey":"","hidden":"","*":"All_articles_needing_additional_references"},{"sortkey":"","*":"Reading_(process)"},{"sortkey":"","*":"Motor_control"},{"sortkey":"","*":"Music_psychology"},{"sortkey":"","*":"Musical_notation"}],"links":[{"ns":14,"exists":"","*":"Category:Articles needing additional references from January 2013"},{"ns":14,"exists":"","*":"Category:Music psychologists"},{"ns":14,"exists":"","*":"Category:Music psychology"},{"ns":10,"exists":"","*":"Template:Music psychology"},{"ns":0,"exists":"","*":"Absolute pitch"},{"ns":0,"exists":"","*":"Aesthetics of music"},{"ns":0,"exists":"","*":"Amusia"},{"ns":0,"exists":"","*":"Auditory arrhythmia"},{"ns":0,"exists":"","*":"Auditory illusion"},{"ns":0,"exists":"","*":"Auditory imagery"},{"ns":0,"exists":"","*":"Background music"},{"ns":0,"exists":"","*":"Beat deafness"},{"ns":0,"exists":"","*":"Bioacoustics"},{"ns":0,"exists":"","*":"Biomusicology"},{"ns":0,"exists":"","*":"Caravaggio"},{"ns":0,"exists":"","*":"Carl Seashore"},{"ns":0,"exists":"","*":"Carl Stumpf"},{"ns":0,"exists":"","*":"Carol L. Krumhansl"},{"ns":0,"exists":"","*":"Chunking (psychology)"},{"ns":0,"exists":"","*":"Cognitive musicology"},{"ns":0,"exists":"","*":"Cognitive neuroscience of music"},{"ns":0,"exists":"","*":"Cognitive psychology"},{"ns":0,"exists":"","*":"Consonance and dissonance"},{"ns":0,"exists":"","*":"Crotchet"},{"ns":0,"exists":"","*":"Culture in music cognition"},{"ns":0,"exists":"","*":"Dance"},{"ns":0,"exists":"","*":"Daniel Levitin"},{"ns":0,"exists":"","*":"Deutsch's scale illusion"},{"ns":0,"exists":"","*":"Diana Deutsch"},{"ns":0,"exists":"","*":"Earworm"},{"ns":0,"exists":"","*":"Ecological validity"},{"ns":0,"exists":"","*":"Electronic keyboard"},{"ns":0,"exists":"","*":"Embodied music cognition"},{"ns":0,"exists":"","*":"Entrainment (biomusicology)"},{"ns":0,"exists":"","*":"Ethnomusicology"},{"ns":0,"exists":"","*":"Evolutionary musicology"},{"ns":0,"exists":"","*":"Exercise and music"},{"ns":0,"exists":"","*":"Eye movement in language reading"},{"ns":0,"exists":"","*":"Eye tracker"},{"ns":0,"exists":"","*":"Eye\u2013hand span"},{"ns":0,"exists":"","*":"Fixation (visual)"},{"ns":0,"exists":"","*":"Focal dystonia"},{"ns":0,"exists":"","*":"Franssen effect"},{"ns":0,"exists":"","*":"Fred Lerdahl"},{"ns":0,"exists":"","*":"Gaze-contingency paradigm"},{"ns":0,"exists":"","*":"Generative theory of tonal music"},{"ns":0,"exists":"","*":"Glissando illusion"},{"ns":0,"exists":"","*":"Hearing"},{"ns":0,"exists":"","*":"Hedonic music consumption model"},{"ns":0,"exists":"","*":"Henkjan Honing"},{"ns":0,"exists":"","*":"Homophony"},{"ns":0,"exists":"","*":"Illusory continuity of tones"},{"ns":0,"exists":"","*":"Ir\u00e8ne Deli\u00e8ge"},{"ns":0,"exists":"","*":"James Mursell"},{"ns":0,"exists":"","*":"Jamshed Bharucha"},{"ns":0,"exists":"","*":"Jane W. Davidson"},{"ns":0,"exists":"","*":"John Sloboda"},{"ns":0,"exists":"","*":"Leonard B. Meyer"},{"ns":0,"exists":"","*":"Levitin effect"},{"ns":0,"exists":"","*":"Lipps\u2013Meyer law"},{"ns":0,"exists":"","*":"Max Friedrich Meyer"},{"ns":0,"exists":"","*":"Max Schoen"},{"ns":0,"exists":"","*":"Melodic expectation"},{"ns":0,"exists":"","*":"Melodic fission"},{"ns":0,"exists":"","*":"Melodic intonation therapy"},{"ns":0,"exists":"","*":"Memory"},{"ns":0,"exists":"","*":"Mozart effect"},{"ns":0,"exists":"","*":"Musculoskeletal"},{"ns":0,"exists":"","*":"Music, Thought, and Feeling"},{"ns":0,"exists":"","*":"Music-related memory"},{"ns":0,"exists":"","*":"Music-specific disorders"},{"ns":0,"exists":"","*":"Music and emotion"},{"ns":0,"exists":"","*":"Music education"},{"ns":0,"exists":"","*":"Music in psychological operations"},{"ns":0,"exists":"","*":"Music psychology"},{"ns":0,"exists":"","*":"Music therapy"},{"ns":0,"exists":"","*":"Musical acoustics"},{"ns":0,"exists":"","*":"Musical gesture"},{"ns":0,"exists":"","*":"Musical hallucinations"},{"ns":0,"exists":"","*":"Musical notation"},{"ns":0,"exists":"","*":"Musical semantics"},{"ns":0,"exists":"","*":"Musical syntax"},{"ns":0,"exists":"","*":"Musicology"},{"ns":0,"exists":"","*":"Musicophilia"},{"ns":0,"exists":"","*":"Neuronal encoding of sound"},{"ns":0,"exists":"","*":"Nina Kraus"},{"ns":0,"exists":"","*":"Octave illusion"},{"ns":0,"exists":"","*":"Oliver Sacks"},{"ns":0,"exists":"","*":"Performance science"},{"ns":0,"exists":"","*":"Philosophy of music"},{"ns":0,"exists":"","*":"Pitch contour"},{"ns":0,"exists":"","*":"Polyphony"},{"ns":0,"exists":"","*":"Psychoacoustics"},{"ns":0,"exists":"","*":"Psychoanalysis and music"},{"ns":0,"exists":"","*":"Psychology of Music (journal)"},{"ns":0,"exists":"","*":"Psychology of music preference"},{"ns":0,"exists":"","*":"Psychomusicology: Music, Mind and Brain"},{"ns":0,"exists":"","*":"Relative pitch"},{"ns":0,"exists":"","*":"Richard Parncutt"},{"ns":0,"exists":"","*":"Robert Cutietta"},{"ns":0,"exists":"","*":"Roger Shepard"},{"ns":0,"exists":"","*":"Saccade"},{"ns":0,"exists":"","*":"Sheet music"},{"ns":0,"exists":"","*":"Shepard tone"},{"ns":0,"exists":"","*":"Short-term memory"},{"ns":0,"exists":"","*":"Sight-reading"},{"ns":0,"exists":"","*":"Sight reading"},{"ns":0,"exists":"","*":"Sloboda"},{"ns":0,"exists":"","*":"Sociomusicology"},{"ns":0,"exists":"","*":"Square root of 2"},{"ns":0,"exists":"","*":"Systematic musicology"},{"ns":0,"exists":"","*":"Tempo"},{"ns":0,"exists":"","*":"Temporal dynamics of music and language"},{"ns":0,"exists":"","*":"The World in Six Songs"},{"ns":0,"exists":"","*":"This Is Your Brain on Music"},{"ns":0,"exists":"","*":"Tonal memory"},{"ns":0,"exists":"","*":"Tone deafness"},{"ns":0,"exists":"","*":"Tritone paradox"},{"ns":0,"exists":"","*":"Tuomas Eerola"},{"ns":0,"exists":"","*":"William Forde Thompson"},{"ns":0,"exists":"","*":"Working memory"},{"ns":0,"exists":"","*":"Zoomusicology"},{"ns":0,"*":"Judd and Buswell"},{"ns":0,"*":"Motor transcription"},{"ns":4,"exists":"","*":"Wikipedia:Citing sources"},{"ns":4,"exists":"","*":"Wikipedia:Verifiability"},{"ns":11,"exists":"","*":"Template talk:Music psychology"},{"ns":12,"exists":"","*":"Help:Introduction to referencing with Wiki Markup/1"},{"ns":12,"exists":"","*":"Help:Maintenance template removal"}],"templates":[{"ns":10,"exists":"","*":"Template:Unreferenced section"},{"ns":10,"exists":"","*":"Template:Unreferenced"},{"ns":10,"exists":"","*":"Template:Ambox"},{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Column-width"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:Refbegin"},{"ns":10,"exists":"","*":"Template:Refbegin/styles.css"},{"ns":10,"exists":"","*":"Template:Refend"},{"ns":10,"exists":"","*":"Template:Music psychology"},{"ns":10,"exists":"","*":"Template:Navbox"},{"ns":828,"exists":"","*":"Module:Unsubst"},{"ns":828,"exists":"","*":"Module:Message box"},{"ns":828,"exists":"","*":"Module:No globals"},{"ns":828,"exists":"","*":"Module:Yesno"},{"ns":828,"exists":"","*":"Module:Arguments"},{"ns":828,"exists":"","*":"Module:Message box/configuration"},{"ns":828,"exists":"","*":"Module:Category handler"},{"ns":828,"exists":"","*":"Module:Category handler/data"},{"ns":828,"exists":"","*":"Module:Category handler/config"},{"ns":828,"exists":"","*":"Module:Category handler/shared"},{"ns":828,"exists":"","*":"Module:Category handler/blacklist"},{"ns":828,"exists":"","*":"Module:Namespace detect/data"},{"ns":828,"exists":"","*":"Module:Namespace detect/config"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"},{"ns":828,"exists":"","*":"Module:Navbox"},{"ns":828,"exists":"","*":"Module:Navbar"}],"images":["Auditorio1.jpg","BWV847_measures_1-9_Fuga_a_3_voci.svg","Michelangelo_Caravaggio_026.jpg","Question_book-new.svg","Mozart_and_Linley_1770.jpg","Number\u2013duration_ratios.jpg"],"externallinks":["http://www.unice.fr/LPEQ/pagesperso/thierry/thierrybaccino.htm","http://ses.library.usyd.edu.au/handle/2123/8983"],"sections":[{"toclevel":1,"level":"2","line":"Relationship with eye movement in language reading","number":"1","index":"1","fromtitle":"Eye_movement_in_music_reading","byteoffset":1867,"anchor":"Relationship_with_eye_movement_in_language_reading"},{"toclevel":1,"level":"2","line":"Equipment and related methodology","number":"2","index":"2","fromtitle":"Eye_movement_in_music_reading","byteoffset":4105,"anchor":"Equipment_and_related_methodology"},{"toclevel":1,"level":"2","line":"Tempo and data contamination","number":"3","index":"3","fromtitle":"Eye_movement_in_music_reading","byteoffset":8076,"anchor":"Tempo_and_data_contamination"},{"toclevel":1,"level":"2","line":"Musical complexity","number":"4","index":"4","fromtitle":"Eye_movement_in_music_reading","byteoffset":12337,"anchor":"Musical_complexity"},{"toclevel":1,"level":"2","line":"Reader skill","number":"5","index":"5","fromtitle":"Eye_movement_in_music_reading","byteoffset":15198,"anchor":"Reader_skill"},{"toclevel":1,"level":"2","line":"Stimulus familiarity","number":"6","index":"6","fromtitle":"Eye_movement_in_music_reading","byteoffset":17385,"anchor":"Stimulus_familiarity"},{"toclevel":1,"level":"2","line":"Top\u2013down/bottom\u2013up question","number":"7","index":"7","fromtitle":"Eye_movement_in_music_reading","byteoffset":20125,"anchor":"Top\u2013down/bottom\u2013up_question"},{"toclevel":1,"level":"2","line":"Peripheral visual input","number":"8","index":"8","fromtitle":"Eye_movement_in_music_reading","byteoffset":22534,"anchor":"Peripheral_visual_input"},{"toclevel":1,"level":"2","line":"Refixation","number":"9","index":"9","fromtitle":"Eye_movement_in_music_reading","byteoffset":24789,"anchor":"Refixation"},{"toclevel":1,"level":"2","line":"Eye\u2013hand span","number":"10","index":"10","fromtitle":"Eye_movement_in_music_reading","byteoffset":27496,"anchor":"Eye\u2013hand_span"},{"toclevel":1,"level":"2","line":"Tempo","number":"11","index":"11","fromtitle":"Eye_movement_in_music_reading","byteoffset":35084,"anchor":"Tempo"},{"toclevel":1,"level":"2","line":"Conclusions","number":"12","index":"12","fromtitle":"Eye_movement_in_music_reading","byteoffset":43157,"anchor":"Conclusions"},{"toclevel":1,"level":"2","line":"Notes","number":"13","index":"13","fromtitle":"Eye_movement_in_music_reading","byteoffset":44756,"anchor":"Notes"},{"toclevel":1,"level":"2","line":"References","number":"14","index":"14","fromtitle":"Eye_movement_in_music_reading","byteoffset":44795,"anchor":"References"}],"parsewarnings":[],"displaytitle":"Eye movement in music reading","iwlinks":[],"properties":[{"name":"wikibase_item","*":"Q5422665"}]}}