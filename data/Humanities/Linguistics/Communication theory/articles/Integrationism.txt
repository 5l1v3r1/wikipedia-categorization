Integrationism (also known as integrational linguistics) is an approach in the theory of communication that emphasizes innovative participation by communicators within contexts and rejects rule-based models of language. It was developed by a group of linguists at the University of Oxford during the 1980s, notably Roy Harris. The International Association for the Integrational Study of Language and Communication was founded in 1998 and has members in more than twenty-five countries around the world.  While the integrationist views of Harris and Dr Adrian Pablé, among others, differ from those who believe that cognition is distributed (i.e.  Kravchenko and Love), the view on language between the two fields are quite similar.  Both sides criticize the traditional view of linguistics which holds language as an individual internal psychological concern that takes written language as the base from which to begin analysis. Instead, integrationists view knowledge (which includes language) as “(i) linked to an individual’s experience, and therefore dependent on the ‘evidence available’ to that particular individual, but at the same time (ii) unpredictable because any integrational task involving sign-making and sign-interpreting is carried out in actual, time-embedded situations, which are not simply ‘given’, either.”.   In other words, language usage is intrinsically, and without fail, contextual in all of its uses.  Furthermore, Pablé, Haas & Christe  question whether language is even amenable to scientific description, based upon its contextual nature. The contextual nature of language leads to a rejection of the notion that language is a ‘fixed code’.  Harris discusses this extensively: Instead of parts of a fixed code, language is looked at as a resource to conduct action with, an idea that echoes the notions put forth by speech act theorists such as Austin and Searle, interactional sociolinguists such as Gumperz, conversation analysts such as Sacks, Schegloff, and Goodwin, as well as others such as Goffman, all of whom were or are active in fields outside of linguistics, including language philosophy, sociology, and anthropology. Harris claims that to not know what a word means is to not know what to do with the words, to not know “how to integrate the occurrence of the word into enough of our linguistic experience to satisfy the requirement of the [present] case”.  Pablé explores the integrationist views of language in terms of the naming practices related to castles in Bellinzona, Switzerland.    By asking locals the directions to castles using non-standard names for the castles, Pablé elicited various forms by which the locals referred to them, highlighting the idea that references to the places were “highly context sensitive” and that the “meaning” is created on the spot,  and that “speakers always make sense of language in light of their own experience”.  According to integrationist principles, the separation of linguistic phenomena into distinct parts of study is a fundamental error in the conceptualization of language. In 'The Language Myth', Harris postulates that the isolation and subsequent segregational approach of orthodox linguistics is a result of the fact of language itself being the descriptive medium for its own study. A problem arises when we consider words as stand-ins for things. When we then have a word for a language, the word misleads us to consider languages to be things out there in the world rather than real time, second order processes undergoing constant adjustment.  Integrationism overlaps with recent and not so recent epistemologies concerning communication and interaction. It retains an interest in understanding the system of language-making as an emergent, context-bound, and fundamentally human activity. This view is philosophically consistent with sociocultural theories such as activity theory where the historicity of human experience is recognized to have implications on our activities in ways that shape how they unfold.  Integrationist linguistics overlaps with pragmatic and phenomenological approaches such as ethnomethodology and conversation analysis. The latter being rightly susceptible to a written and spoken word bias yet this is not without current attempts to broaden and include a wider range of semiotic contingencies into analyses. The more fundamental overlap is epistemological. Harold Garfinkel's (1994) ethnomethodological policies prioritize the context of interaction with strict objection to analytic presupposed systems of any kind other than that which is made so by the sequentially ordered interactions of participants. Conversation analysts have developed an empirical approach stemming from those policies where spoken and written words are centralized. A recent decentralizing move to the analysis and theorization of multimodal sequential analysis is very much consistent with an integrationist point of view.   While integrationism has been in existence for over three decades, advocating against the “language myth”  and indicating that linguistic sign alone cannot function as the basis of an independent, self-sufficient form of communication, but depends for effectiveness on its integration with non-verbal activities of many different kinds, some integrationists have recently directed this perspective to revisit another important concept in sociolinguistics – “social identity”. This integrational view of identity concurs with the sociocultural perspective that identity is not a rigid and static system predetermined on the basis of either social class, gender, ethnicity, age or education, but rather a discursive and constantly emerging experience that is locally shared and situationally evoked. On the other hand, however, stressing that identity cannot be examined exclusively from an individual’s integrational practice (including both linguistic and non-linguistic practice), integrationists cast doubt on the way sociocultural approach analyzes identity by specifically questioning three of the latter’s tenets: (i) data, (ii) phenomenological inductivism,  and (iii) indirect indexicality.  They point out an intrinsic controversy that while identity, as the speaker’s first-order experience, is highly context-dependent, the attempt to detect identity merely through inspecting the linguistic components in the tape-recorded data and interpret the data through postulating the existence of linguistically pre-labeled “concrete universals” (e.g. ‘varieties of language’, ‘style’) is actually de-contextualizing the speakers’ identity. Also, they identified another conflict in the sociocultural approach of interpreting a speaker’s identity between the claim of a socially indexical value of linguistic features (“social marker”) that is beyond a single occurrence and the one of locally indexical value of linguistic features that is analyzable only in term of one specific local context. Compared with sociolinguistic perspective on social identity, integrationists emphasize the integrational phenomenon that occurs when we converse with each other. Sociolinguists concentrate on how people utilize linguistic structures and items, cultural norms, and macro identities that they are normatively assigned in conversation. Based on utterances, sociolinguists attempt to capture speakers’ positionality and relationality in terms of identity, emergence of identity, and indexicality of the language that speakers used.  It is problematic to integrationists that sociolinguists only focus upon what is said. In other words, sociolinguists take language as an independent structure that can be isolated from the ongoing conversation. Integrationists argue that utterances cannot be dissociated from the context where he utters statements. Utterances have to be integrated with the activities, linguistic and non-linguistic, at that moment. In conclusion, from an integrational view, “social identity” is rather a “meta-discursive label used by lay speakers to cope with their everyday first-order experience”  than a term or object of scientific study that is static and communicationally predetermined. In other words, along with their refusal of language as a static code system to be decoded for meaning transmission, they specifically emphasize that identity is not amenable to scientific description, as “sign-making and sign-interpreting are ‘private’ and cannot be detached from an individual’s integrational activities in the here-and-now”.  The remaining question for integrationists is how to study ‘identity’ then. One suggestion integrationalists may be more up to is to treat what is displayed in the temporal situations as “beings” and “becomings” rather than fixed identities, and study it multimodally, which is to take different modalities and time scales into consideration, instead of merely relying on the pre-labelled linguistic features. According to the United Nations Educational, Scientific and Cultural Organization (UNESCO),  literacy is defined as the ability to identify, understand, interpret, create, communicate, compute and use printed and written materials associated with varying contexts. In other words, the ability to read and write does not only to fulfill one’s own need but also to communicate with the community and society where one stays. With regard to it, this section first focuses on the distinction between spoken language (first-order language) and written language (second-order language)  and how reading comprehension is achieved, and then aims at the impact of technology-enhanced interaction on reading comprehension. Traditionally, spoken language and written language are regarded as the two sides of the same coin   In other words, written language is believed to fully represent its corresponding spoken language. Therefore, educators believe by teaching words, or the symbolization of phonetic signs, students are equipped with the literacy to understand the written texts. However, it is often the case that students have a hard time understanding and interpreting a poem even though they know every single word. The glittering example reveals the problem of treating spoken language and written language as the same and implies the need to treat them differently. According to Kravchenko, spoken language and written language are different in that spoken language is temporal and local, while written language is atemporal and non-local.  The understanding of spoken language relies on the common knowledge shared by the participants who are involved in the conversation, and the cognition required is situated and highly interactional. As for written language, the understanding takes place when the text is written (product) rather than is being written (process). Therefore, it is less interactional. Despite the difference, the understanding of both linguistic systems calls for the appropriate background knowledge. An example adapted from Kravchenko is that if a traveler wants to check in and the clerk tells him/her, “I’ll be back in 20 minutes”, the traveler may check the watch and calculate when to come back for the check-in, so he/she does not have to stand at the front desk for 20 minutes. However, if the traveler sees a note on the front desk saying, “I’ll be back in 20 minutes”, he/she may be baffled due to no point of reference, so he/she does not know how long is needed.  This example shows that it takes more efforts to establish background knowledge for the understanding of written language than spoken language. By extension, successful reading comprehension depends upon the establishment of shared knowledge between writers and readers. With the development of technologies, written language includes not only printed work but also hypertexts. Because of the new genres of written language, new literacy is needed. Kravchenko maintained that literacy is the knowledge of using knowledge, so students have to develop the ability of reasoning and judgment based on the written texts.  Jenkins et al. go further by claiming that the form of reasoning plays a more important role than the content of learning in the era of technology-enhanced interaction.  To put it another way, the content can be easily stored and retrieved by means of technologies, so the practice of reasoning centers on how to generate, evaluate, interpret, and deploy the electronic resources. Different electronic resources can provide different affordances, so one of the aims of teaching new literacy is to help students develop the ability of knowing what functions that the certain electronic resource is good at. For instance, the text mediation through computers can facilitate the thinking, reflecting, and revising of one’s own thought.   Videos, with the visual and auditory modality, can better help knowledge acquisition than pictures, which have the visual modality alone.  The hypertexts available online enable readers to create their own reading paths and recontextualize the resources of websites.  Through the recontextualization, the thematic regions and semiotic formations are more idiosyncratic than fixed. The readers play a role in picking up the meaning through the created reading paths. According to Harris, linguistic signs should be understood with non-verbal activities.  In addition to reading the hypertexts, the readers have access to other non-textual resources online, such as pictures, diagrams, videos, etc. The use of those non-verbal semiotic resources within the texts has its function and offers affordances to the readers to make meaning.  