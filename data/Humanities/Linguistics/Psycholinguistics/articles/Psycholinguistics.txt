Psycholinguistics or psychology of language is the study of the interrelation between linguistic factors and psychological aspects.  It also studies  psychological and neurobiological factors that enable humans to acquire, use, comprehend and produce language. The discipline is mainly concerned with the mechanisms in which languages are processed and represented in the brain.  Initial forays into psycholinguistics were largely philosophical or educational schools of thought, due mainly to their location in departments other than applied sciences (e.g., cohesive data on how the human brain functioned). Modern research makes use of biology, neuroscience, cognitive science, linguistics, and information science to study how the brain processes language, and less so the known processes of social sciences, human development, communication theories and infant development, among others. There are a number of subdisciplines with non-invasive techniques for studying the neurological workings of the brain; for example, neurolinguistics has become a field in its own right. Psycholinguistics has roots in education and philosophy, and covers the "cognitive processes" that make it possible to generate a grammatical and meaningful sentence out of vocabulary and grammatical structures, as well as the processes that make it possible to understand utterances, words, text, etc. Developmental psycholinguistics studies children's ability to learn language. The term psycholinguistics was coined in 1936 by Jacob Robert Kantor in his book An Objective Psychology of Grammar and started being used among his team at Indiana University, but its use finally became frequent thanks to the 1946 article "Language and psycholinguistics: a review," by his student Nicholas Henry Pronko.  It was used for the first time to talk about an interdisciplinary science "that could be coherent"  as well as in the title of Psycholinguistics: A Survey of Theory and Research Problems, a 1954 book by Charles E. Osgood and Thomas A. Sebeok.  Psycholinguistics is an interdisciplinary field. Hence, it is studied by researchers from a variety of different backgrounds, such as psychology, cognitive science, linguistics, and speech and language pathology. Psycholinguists study many different topics, but these topics can generally be divided into answering the following questions: (1) how do children acquire language (language acquisition)?; (2) how do people process and comprehend language (language comprehension)?; (3) how do people produce language (language production)?; and (4) how do people acquire a new language (second language acquisition)? Subdivisions in psycholinguistics are also made based on the different components that make up human language. Linguistics-related areas: A researcher interested in language comprehension may study word recognition during reading to examine the processes involved in the extraction of orthographic, morphological, phonological, and semantic information from patterns in printed text. A researcher interested in language production might study how words are prepared to be spoken starting from the conceptual or semantic level. Developmental psycholinguists study infants' and children's ability to learn and process language.  In this section, some influential theories are discussed for each of the fundamental questions listed in the section above. There are essentially two schools of thought as to how children acquire or learn language, and there is still much debate as to which theory is the correct one. The first theory states that all language must be learned by the child.  The second view states that the abstract system of language cannot be learned, but that humans possess an innate language faculty, or an access to what has been called universal grammar. The view that language must be learned was especially popular before 1960 and is well represented by the mentalistic theories of Jean Piaget and the empiricist Rudolf Carnap. Likewise, the school of psychology known as behaviorism (see Verbal Behavior (1957) by B.F. Skinner) puts forth the point of view that language is a behavior shaped by conditioned response, hence it is learned. The innatist perspective began with Noam Chomsky's highly critical review of Skinner's book in 1959.  This review helped to start what has been termed "the cognitive revolution" in psychology.  Chomsky posited humans possess a special, innate ability for language and that complex syntactic features, such as recursion, are "hard-wired" in the brain. These abilities are thought to be beyond the grasp of the most intelligent and social non-humans. According to Chomsky, children acquiring a language have a vast search space to explore among all possible human grammars, yet at the time there was no evidence that children receive sufficient input to learn all the rules of their language (see poverty of the stimulus). Hence, there must be some other innate mechanism that endows a language ability to humans. Such a language faculty is, according to the innateness hypothesis, what defines human language and makes it different from even the most sophisticated forms of animal communication. The field of linguistics and psycholinguistics since then has been defined by reactions to Chomsky, pro and con. The pro view still holds that the human ability to use language (specifically the ability to use recursion) is qualitatively different from any sort of animal ability.  This ability may  have resulted from a favorable mutation or from an adaptation of skills evolved for other purposes. The view that language can be learned has had a recent resurgence inspired by emergentism. This view challenges the "innate" view as scientifically unfalsifiable; that is to say, it can't be tested. With the amount of computer power increasing since the 1980s, researchers have been able to simulate language acquisition using neural network models.  These models provide evidence that there may, in fact, be sufficient information contained in the input to learn language, even syntax. If this is true, then an innate mechanism is no longer necessary to explain language acquisition. One question in the realm of language comprehension is how people understand sentences as they read (also known as sentence processing). Experimental research has spawned a number of theories about the architecture and mechanisms of sentence comprehension. Typically these theories are concerned with what types of information contained in the sentence the reader can use to build meaning, and at what point in reading does that information become available to the reader. Issues such as "modular" versus "interactive" processing have been theoretical divides in the field. A modular view of sentence processing assumes that the stages involved in reading a sentence function independently in separate modules. These modulates have limited interaction with one another. For example, one influential theory of sentence processing, the garden-path theory,  states that syntactic analysis takes place first. Under this theory as the reader is reading a sentence, he or she creates the simplest structure possible in order to minimize effort and cognitive load. This is done without any input from semantic analysis or context-dependent information. Hence, in the sentence "The evidence examined by the lawyer turned out to be unreliable," by the time the reader gets to the word "examined" he or she has committed to a reading of the sentence in which the evidence is examining something because it is the simplest parse. This commitment is made despite the fact that it results in an implausible situation; we know from experience that evidence can rarely if ever examine something. Under this "syntax first" theory, semantic information is processed at a later stage. It is only later that the reader will recognize that he or she needs to revise the initial parse into one in which "the evidence" is being examined. In this example, readers typically recognize their misparse by the time they reach "by the lawyer" and must go back and re-parse the sentence.  This reanalysis is costly and contributes to slower reading times. In contrast to a modular account, an interactive theory of sentence processing, such as a constraint-based lexical approach  assumes that all available information contained within a sentence can be processed at any time. Under an interactive account, for example, the semantics of a sentence (such as plausibility) can come into play early on in order to help determine the structure of a sentence. Hence, in the sentence above, the reader would be able to make use of plausibility information in order to assume that "the evidence" is being examined instead of doing the examining. There are data to support both modular and interactive accounts; which account is the correct one is still up for debate. Language production concerns how people produce language, either in written or spoken form, in a way that conveys meanings comprehensible to others. One of the most effective ways to explain the way people represent meanings using rule-governed languages is by observing and analyzing instances of speech errors. They include speech dysfluencies like false starts, repetition, reformulation and constant pauses in between words or sentences; also, slips of tongue, like blendings, substitutions, exchanges (e.g. Spoonerism), and various pronunciation errors. These speech errors yield significant implication on language production, in that they reflect that:  It is useful to differentiate between three separate phases of production: conceptualization "(determining what to say), formulation (translating the intention to say something into linguistic form), and execution (the detailed articulatory planning and articulation itself)."  Most psycholinguistic research has largely concerned itself with the study for formulation as the phase of conceptualization largely remains an elusive and mysterious period of development.  For models of speech production, see Psycholinguistics/Models of Speech Production. Many of the experiments conducted in psycholinguistics, especially earlier on, are behavioral in nature. In these types of studies, subjects are presented with linguistic stimuli and asked to perform an action. For example, they may be asked to make a judgment about a word (lexical decision), reproduce the stimulus, or name a visually presented word aloud. Reaction times to respond to the stimuli (usually on the order of milliseconds) and proportion of correct responses are the most often employed measures of performance in behavioral tasks. Such experiments often take advantage of priming effects, whereby a "priming" word or phrase appearing in the experiment can speed up the lexical decision for a related "target" word later.  As an example of how behavioral methods can be used in psycholinguistics research, Fischler (1977) investigated word encoding using the lexical decision task. He asked participants to make decisions about whether two strings of letters were English words. Sometimes the strings would be actual English words requiring a "yes" response, and other times they would be nonwords requiring a "no" response. A subset of the licit words were related semantically (e.g., cat-dog) while others were unrelated (e.g., bread-stem). Fischler found that related word pairs were responded to faster when compared to unrelated word pairs. This facilitation suggests that semantic relatedness can facilitate word encoding.  Recently, eye tracking has been used to study online language processing. Beginning with Rayner (1978)  the importance and informativity of eye-movements during reading was established. Later, Tanenhaus et al. (1995)  used the visual-world paradigm to study the cognitive processes related to spoken language. Assuming that eye movements are closely linked to the current focus of attention, language processing can be studied by monitoring eye movements while a subject is presented auditorily with linguistic input. The analysis of systematic errors in speech, writing and typing of language as it is produced can provide evidence of the process which has generated it.  Errors of speech, in particular, grant insight into how the mind processes language production while a speaker is in the midst of an utterance. Speech errors tend to occur in the lexical, morpheme, and phoneme encoding steps of language production, as seen by the ways errors can manifest.  The types of speech errors, and some examples, are:    Speech errors will usually occur in the stages that involve lexical, morpheme, or phoneme encoding, and usually not the first step of semantic encoding.  This can be credited to how a speaker is still conjuring the idea of what to say, and unless he changes his mind, can not be mistaken in what he wanted to say. Until the recent advent of non-invasive medical techniques, brain surgery was the preferred way for language researchers to discover how language works in the brain. For example, severing the corpus callosum (the bundle of nerves that connects the two hemispheres of the brain) was at one time a treatment for some forms of epilepsy. Researchers could then study the ways in which the comprehension and production of language were affected by such drastic surgery. Where an illness made brain surgery necessary, language researchers had an opportunity to pursue their research. Newer, non-invasive techniques now include brain imaging by positron emission tomography (PET); functional magnetic resonance imaging (fMRI); event-related potentials (ERPs) in electroencephalography (EEG) and magnetoencephalography (MEG); and transcranial magnetic stimulation (TMS). Brain imaging techniques vary in their spatial and temporal resolutions (fMRI has a resolution of a few thousand neurons per pixel, and ERP has millisecond accuracy). Each type of methodology presents a set of advantages and disadvantages for studying a particular problem in psycholinguistics.  Computational modelling, such as the DRC model of reading and word recognition proposed by Max Coltheart and colleagues,  is another methodology and refers to the practice of setting up cognitive models in the form of executable computer programs. Such programs are useful because they require theorists to be explicit in their hypotheses and because they can be used to generate accurate predictions for theoretical models that are so complex that they render discursive analysis unreliable. Other examples of computational modelling is McClelland and Elman's TRACE model of speech perception  and Franklin Chang's Dual-Path model of sentence production.  Psycholinguistics is concerned with the nature of the computations and processes that the brain undergoes to comprehend and produce language. For example, the cohort model seeks to describe how words are retrieved from the mental lexicon when an individual hears or sees linguistic input.   Recent research using new non-invasive imaging techniques seeks to shed light on just where certain language processes occur in the brain. There are a number of unanswered questions in psycholinguistics, such as whether the human ability to use syntax is based on innate mental structures or emerges from interaction with other humans, and whether some animals can be taught the syntax of human language. Two other major subfields of psycholinguistics investigate first language acquisition, the process by which infants acquire language, and second language acquisition. In addition, it is much more difficult for adults to acquire second languages than it is for infants to learn their first language (bilingual infants are able to learn both of their native languages easily). Thus, sensitive periods may exist during which language can be learned readily.  A great deal of research in psycholinguistics focuses on how this ability develops and diminishes over time. It also seems to be the case that the more languages one knows, the easier it is to learn more.  The field of aphasiology deals with language deficits that arise because of brain damage. Studies in aphasiology can both offer advances in therapy for individuals suffering from aphasia, and further insight into how the brain processes language. A short list of books that deal with psycholinguistics, written in language accessible to the non-expert, includes: 