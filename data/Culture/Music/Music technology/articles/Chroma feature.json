{"parse":{"title":"Chroma feature","pageid":49957896,"revid":835556753,"text":{"*":"<div class=\"mw-parser-output\"><div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:402px;\"><a href=\"/wiki/File:ChromaFeatureCmajorScaleScoreAudioColor.png\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/25/ChromaFeatureCmajorScaleScoreAudioColor.png/400px-ChromaFeatureCmajorScaleScoreAudioColor.png\" width=\"400\" height=\"350\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/25/ChromaFeatureCmajorScaleScoreAudioColor.png/600px-ChromaFeatureCmajorScaleScoreAudioColor.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/25/ChromaFeatureCmajorScaleScoreAudioColor.png/800px-ChromaFeatureCmajorScaleScoreAudioColor.png 2x\" data-file-width=\"1341\" data-file-height=\"1174\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:ChromaFeatureCmajorScaleScoreAudioColor.png\" class=\"internal\" title=\"Enlarge\"></a></div>(a) Musical score of a C-major scale. (b) Chromagram obtained from the score. (c) Audio recording of the C-major scale played on a piano. (d) Chromagram obtained from the audio recording.</div></div></div>\n<p>In the music context, the term <b>chroma feature</b> or <b>chromagram</b> closely relates to the twelve different <a href=\"/wiki/Pitch_classes\" class=\"mw-redirect\" title=\"Pitch classes\">pitch classes</a>. Chroma-based features, which are also referred to <a href=\"/wiki/Harmonic_pitch_class_profiles\" title=\"Harmonic pitch class profiles\">pitch class profiles</a>, are a powerful tool for analyzing music whose pitches can be meaningfully categorized (often into twelve categories) and whose tuning approximates to the <a href=\"/wiki/Equal_temperament\" title=\"Equal temperament\">equal-tempered scale</a>. One main property of chroma features is that they capture harmonic and melodic characteristics of music, while being robust to changes in timbre and instrumentation.\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Definition\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Definition</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Applications\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Applications</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#Computation_of_audio_chromagrams\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Computation of audio chromagrams</span></a></li>\n<li class=\"toclevel-1 tocsection-4\"><a href=\"#See_also\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-5\"><a href=\"#References\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#External_links\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"Definition\">Definition</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Chroma_feature&amp;action=edit&amp;section=1\" title=\"Edit section: Definition\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>The underyling observation is that humans perceive two musical pitches as similar in color if they differ by an octave. Based on this observation, a pitch can be separated into two components, which are referred to as <i>tone height</i> and <i>chroma</i>.<sup id=\"cite_ref-Shepard64_pitch_ASA_1-0\" class=\"reference\"><a href=\"#cite_note-Shepard64_pitch_ASA-1\">&#91;1&#93;</a></sup> Assuming the <a href=\"/wiki/Equal_temperament\" title=\"Equal temperament\">equal-tempered scale</a>, one considers twelve chroma values represented by the set\n</p>\n<dl><dd>{C, C<span class=\"music-symbol\" style=\"font-family: Arial Unicode MS, Lucida Sans Unicode;\"><span class=\"music-sharp\">&#x266f;</span></span>, D, D<span class=\"music-symbol\" style=\"font-family: Arial Unicode MS, Lucida Sans Unicode;\"><span class=\"music-sharp\">&#x266f;</span></span>, E ,F, F<span class=\"music-symbol\" style=\"font-family: Arial Unicode MS, Lucida Sans Unicode;\"><span class=\"music-sharp\">&#x266f;</span></span>, G, G<span class=\"music-symbol\" style=\"font-family: Arial Unicode MS, Lucida Sans Unicode;\"><span class=\"music-sharp\">&#x266f;</span></span>, A, A<span class=\"music-symbol\" style=\"font-family: Arial Unicode MS, Lucida Sans Unicode;\"><span class=\"music-sharp\">&#x266f;</span></span>, B}</dd></dl>\n<p>that consists of the twelve pitch spelling attributes as used in Western music notation. Note that in the equal-tempered scale different pitch spellings such\nC<span class=\"music-symbol\" style=\"font-family: Arial Unicode MS, Lucida Sans Unicode;\"><span class=\"music-sharp\">&#x266f;</span></span> and D<span class=\"music-symbol\" style=\"font-family: Arial Unicode MS, Lucida Sans Unicode;\"><span class=\"music-flat\">&#x266d;</span></span> refer to the same chroma. Enumerating the chroma values, one can identify the set of chroma values with the set of integers {1,2,...,12}, where 1 refers to chroma C, 2 to C<span class=\"music-symbol\" style=\"font-family: Arial Unicode MS, Lucida Sans Unicode;\"><span class=\"music-sharp\">&#x266f;</span></span>, and so on. A <a href=\"/wiki/Pitch_class\" title=\"Pitch class\">pitch class</a> is defined as the set of all pitches that share the same chroma. For example, using the <a href=\"/wiki/Scientific_pitch_notation\" title=\"Scientific pitch notation\">scientific pitch notation</a>, the pitch class corresponding to the chroma C is the set\n</p>\n<dl><dd>{..., C<sub>\u22122</sub>, C<sub>\u22121</sub>, C<sub>0</sub>, C<sub>1</sub>, C<sub>2</sub>, C<sub>3</sub> ...}</dd></dl>\n<p>consisting of all pitches separated by an integer number of octaves. Given a music representation (e.g. a musical score or an audio recording), the  main idea of chroma features is to aggregate for a given local time window (e.g. specified in beats or in seconds) all information that relates to a given chroma into a single coefficient. Shifting the time window across the music representation results in a sequence of chroma features each expressing how the representation's pitch content within the time window is spread over the twelve chroma bands. The resulting time-chroma representation is also referred to as <a href=\"/wiki/Chromagram\" class=\"mw-redirect\" title=\"Chromagram\">chromagram</a>. The figure above shows chromagrams for a C-major scale, once obtained from a musical score and once from an audio recording. Because of the close relation between the terms chroma and pitch class, chroma features are also referred to as <a href=\"/wiki/Harmonic_pitch_class_profiles\" title=\"Harmonic pitch class profiles\">pitch class profiles</a>.\n</p>\n<h2><span class=\"mw-headline\" id=\"Applications\">Applications</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Chroma_feature&amp;action=edit&amp;section=2\" title=\"Edit section: Applications\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Identifying pitches that differ by an octave, chroma features show a high degree of robustness to variations in timbre and closely correlate to the musical aspect of harmony. This is the reason why chroma features are a well-established tool for processing and analyzing music data.<sup id=\"cite_ref-Mueller15_FundamentalsMusicProcessig_SPRINGER_2-0\" class=\"reference\"><a href=\"#cite_note-Mueller15_FundamentalsMusicProcessig_SPRINGER-2\">&#91;2&#93;</a></sup> For example, basically every chord recognition procedure relies on some kind of chroma representation.<sup id=\"cite_ref-ChoB14_Chord_IEEE-TASLP_3-0\" class=\"reference\"><a href=\"#cite_note-ChoB14_Chord_IEEE-TASLP-3\">&#91;3&#93;</a></sup><sup id=\"cite_ref-MauchD10_SimultaneousEstimation_TASLP_4-0\" class=\"reference\"><a href=\"#cite_note-MauchD10_SimultaneousEstimation_TASLP-4\">&#91;4&#93;</a></sup><sup id=\"cite_ref-Fujishima99_ChordRecognition_ICMC_5-0\" class=\"reference\"><a href=\"#cite_note-Fujishima99_ChordRecognition_ICMC-5\">&#91;5&#93;</a></sup><sup id=\"cite_ref-JiangGKM11_Chord_AES_6-0\" class=\"reference\"><a href=\"#cite_note-JiangGKM11_Chord_AES-6\">&#91;6&#93;</a></sup> Also, chroma features have become the de facto standard for tasks such as <a href=\"/wiki/Music_alignment\" title=\"Music alignment\">music alignment</a> and synchronization<sup id=\"cite_ref-HuDT03_audiomatching_WASPAA_7-0\" class=\"reference\"><a href=\"#cite_note-HuDT03_audiomatching_WASPAA-7\">&#91;7&#93;</a></sup><sup id=\"cite_ref-EwertMG09_HighResAudioSync_ICASSP_8-0\" class=\"reference\"><a href=\"#cite_note-EwertMG09_HighResAudioSync_ICASSP-8\">&#91;8&#93;</a></sup> as well as audio structure analysis.<sup id=\"cite_ref-PaulusMK10_MusicStructure-STAR_ISMIR_9-0\" class=\"reference\"><a href=\"#cite_note-PaulusMK10_MusicStructure-STAR_ISMIR-9\">&#91;9&#93;</a></sup> Finally, chroma features have turned out to be a powerful mid-level feature representation in content-based audio retrieval such as cover song\nidentification<sup id=\"cite_ref-EllisP07_CoverSong_ICASSP_10-0\" class=\"reference\"><a href=\"#cite_note-EllisP07_CoverSong_ICASSP-10\">&#91;10&#93;</a></sup><sup id=\"cite_ref-SerraGHS08_CoverSong_IEEE-TASLP_11-0\" class=\"reference\"><a href=\"#cite_note-SerraGHS08_CoverSong_IEEE-TASLP-11\">&#91;11&#93;</a></sup> or audio matching.<sup id=\"cite_ref-MuellerKC05_ChromaFeatures_ISMIR_12-0\" class=\"reference\"><a href=\"#cite_note-MuellerKC05_ChromaFeatures_ISMIR-12\">&#91;12&#93;</a></sup><sup id=\"cite_ref-KurthM08_IndexBasedAudioMatching_TASLP_13-0\" class=\"reference\"><a href=\"#cite_note-KurthM08_IndexBasedAudioMatching_TASLP-13\">&#91;13&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Computation_of_audio_chromagrams\">Computation of audio chromagrams</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Chroma_feature&amp;action=edit&amp;section=3\" title=\"Edit section: Computation of audio chromagrams\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>There are many ways for converting an audio recording into a chromagram. For example, the conversion of an audio recording into a chroma representation (or chromagram) may be performed either by using short-time Fourier transforms in combination with binning strategies<sup id=\"cite_ref-BartschW05_chroma_IEEEMULTIMEDIA_14-0\" class=\"reference\"><a href=\"#cite_note-BartschW05_chroma_IEEEMULTIMEDIA-14\">&#91;14&#93;</a></sup><sup id=\"cite_ref-Gomez06_PhD_15-0\" class=\"reference\"><a href=\"#cite_note-Gomez06_PhD-15\">&#91;15&#93;</a></sup><sup id=\"cite_ref-Mueller15_Chapter3FMP_SPRINGER_16-0\" class=\"reference\"><a href=\"#cite_note-Mueller15_Chapter3FMP_SPRINGER-16\">&#91;16&#93;</a></sup> or by employing suitable multirate filter banks.<sup id=\"cite_ref-MuellerKC05_ChromaFeatures_ISMIR_12-1\" class=\"reference\"><a href=\"#cite_note-MuellerKC05_ChromaFeatures_ISMIR-12\">&#91;12&#93;</a></sup>\nFurthermore, the properties of chroma features can be significantly changed by\nintroducing suitable pre- and post-processing steps modifying spectral, temporal,\nand dynamical aspects. This leads to a large number of chroma variants, which\nmay show a quite different behavior in the context of a specific music analysis scenario.<sup id=\"cite_ref-MuellerE11_ChromaToolbox_ISMIR_17-0\" class=\"reference\"><a href=\"#cite_note-MuellerE11_ChromaToolbox_ISMIR-17\">&#91;17&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Chroma_feature&amp;action=edit&amp;section=4\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a href=\"/wiki/Time-frequency_analysis\" class=\"mw-redirect\" title=\"Time-frequency analysis\">Time-frequency analysis</a></li>\n<li><a href=\"/wiki/Time-frequency_analysis_for_music_signal\" class=\"mw-redirect\" title=\"Time-frequency analysis for music signal\">Time-frequency analysis for music signal</a></li>\n<li><a href=\"/wiki/Pitch_(music)\" title=\"Pitch (music)\">Pitch (music)</a></li>\n<li><a href=\"/wiki/Musical_theory\" class=\"mw-redirect\" title=\"Musical theory\">Musical theory</a></li></ul>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Chroma_feature&amp;action=edit&amp;section=5\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist columns references-column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;\">\n<ol class=\"references\">\n<li id=\"cite_note-Shepard64_pitch_ASA-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Shepard64_pitch_ASA_1-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Shepard, Roger N. (1964). \"Circularity in judgments of relative pitch\". <i>Journal of the Acoustical Society of America</i>. <b>36</b> (212): 2346\u20132353.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Acoustical+Society+of+America&amp;rft.atitle=Circularity+in+judgments+of+relative+pitch&amp;rft.volume=36&amp;rft.issue=212&amp;rft.pages=2346-2353&amp;rft.date=1964&amp;rft.aulast=Shepard&amp;rft.aufirst=Roger+N.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-Mueller15_FundamentalsMusicProcessig_SPRINGER-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Mueller15_FundamentalsMusicProcessig_SPRINGER_2-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation book\">M\u00fcller, Meinard (2015). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.music-processing.de\"><i>Fundamentals of Music Processing</i></a>. Springer. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1007/978-3-319-21945-5\">10.1007/978-3-319-21945-5</a>. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-3-319-21944-8\" title=\"Special:BookSources/978-3-319-21944-8\">978-3-319-21944-8</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Fundamentals+of+Music+Processing&amp;rft.pub=Springer&amp;rft.date=2015&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-319-21945-5&amp;rft.isbn=978-3-319-21944-8&amp;rft.aulast=M%C3%BCller&amp;rft.aufirst=Meinard&amp;rft_id=http%3A%2F%2Fwww.music-processing.de&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-ChoB14_Chord_IEEE-TASLP-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-ChoB14_Chord_IEEE-TASLP_3-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Cho, Taemin; Bello, Juan Pablo (2014). \"On the Relative Importance of Individual Components of Chord Recognition Systems\". <i>IEEE/ACM Transactions on Audio, Speech, and Language Processing</i>. <b>22</b> (2): 477\u2013\u20134920.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE%2FACM+Transactions+on+Audio%2C+Speech%2C+and+Language+Processing&amp;rft.atitle=On+the+Relative+Importance+of+Individual+Components+of+Chord+Recognition+Systems&amp;rft.volume=22&amp;rft.issue=2&amp;rft.pages=477--4920&amp;rft.date=2014&amp;rft.aulast=Cho&amp;rft.aufirst=Taemin&amp;rft.au=Bello%2C+Juan+Pablo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-MauchD10_SimultaneousEstimation_TASLP-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-MauchD10_SimultaneousEstimation_TASLP_4-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Mauch, Matthias; Dixon, Simon (2010). \"Simultaneous estimation of chords and musical context from audio\". <i>IEEE Transactions on Audio, Speech, and Language Processing</i>. <b>18</b> (6): 138\u2013153.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Audio%2C+Speech%2C+and+Language+Processing&amp;rft.atitle=Simultaneous+estimation+of+chords+and+musical+context+from+audio&amp;rft.volume=18&amp;rft.issue=6&amp;rft.pages=138-153&amp;rft.date=2010&amp;rft.aulast=Mauch&amp;rft.aufirst=Matthias&amp;rft.au=Dixon%2C+Simon&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-Fujishima99_ChordRecognition_ICMC-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Fujishima99_ChordRecognition_ICMC_5-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Fujishima, Takuya (1999). \"Realtime Chord Recognition of Musical Sound: a System Using Common Lisp Music\". <i>Proceedings of the International Computer Music Conference</i>: 464\u2013467.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+International+Computer+Music+Conference&amp;rft.atitle=Realtime+Chord+Recognition+of+Musical+Sound%3A+a+System+Using+Common+Lisp+Music&amp;rft.pages=464-467&amp;rft.date=1999&amp;rft.aulast=Fujishima&amp;rft.aufirst=Takuya&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-JiangGKM11_Chord_AES-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-JiangGKM11_Chord_AES_6-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Jiang, Nanzhu; Grosche, Peter; Konz, Verena; M\u00fcller, Meinard (2011). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.audiolabs-erlangen.de/content/05-fau/professor/00-mueller/03-publications/2011_JiangGroscheKonzMueller_ChordRecognitionEvaluation_AES42-Ilmenau.pdf\">\"Analyzing Chroma Feature Types for Automated Chord Recognition\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Proceedings of the AES Conference on Semantic Audio</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+AES+Conference+on+Semantic+Audio&amp;rft.atitle=Analyzing+Chroma+Feature+Types+for+Automated+Chord+Recognition&amp;rft.date=2011&amp;rft.aulast=Jiang&amp;rft.aufirst=Nanzhu&amp;rft.au=Grosche%2C+Peter&amp;rft.au=Konz%2C+Verena&amp;rft.au=M%C3%BCller%2C+Meinard&amp;rft_id=https%3A%2F%2Fwww.audiolabs-erlangen.de%2Fcontent%2F05-fau%2Fprofessor%2F00-mueller%2F03-publications%2F2011_JiangGroscheKonzMueller_ChordRecognitionEvaluation_AES42-Ilmenau.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-HuDT03_audiomatching_WASPAA-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-HuDT03_audiomatching_WASPAA_7-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Hu, Ning; Dannenberg, Roger B.; Tzanetakis, George (2003). \"Polyphonic Audio Matching and Alignment for Music Retrieval\". <i>Proceedings of the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+IEEE+Workshop+on+Applications+of+Signal+Processing+to+Audio+and+Acoustics&amp;rft.atitle=Polyphonic+Audio+Matching+and+Alignment+for+Music+Retrieval&amp;rft.date=2003&amp;rft.aulast=Hu&amp;rft.aufirst=Ning&amp;rft.au=Dannenberg%2C+Roger+B.&amp;rft.au=Tzanetakis%2C+George&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-EwertMG09_HighResAudioSync_ICASSP-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-EwertMG09_HighResAudioSync_ICASSP_8-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Ewert, Sebastian; M\u00fcller, Meinard; Grosche, Peter (2009). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.audiolabs-erlangen.de/content/05-fau/professor/00-mueller/03-publications/2009_EwertMuellerGrosche_HighResAudioSync_ICASSP.pdf\">\"High Resolution Audio Synchronization Using Chroma Onset Features\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</i>: 1869\u20131872.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+IEEE+International+Conference+on+Acoustics%2C+Speech%2C+and+Signal+Processing&amp;rft.atitle=High+Resolution+Audio+Synchronization+Using+Chroma+Onset+Features&amp;rft.pages=1869-1872&amp;rft.date=2009&amp;rft.aulast=Ewert&amp;rft.aufirst=Sebastian&amp;rft.au=M%C3%BCller%2C+Meinard&amp;rft.au=Grosche%2C+Peter&amp;rft_id=https%3A%2F%2Fwww.audiolabs-erlangen.de%2Fcontent%2F05-fau%2Fprofessor%2F00-mueller%2F03-publications%2F2009_EwertMuellerGrosche_HighResAudioSync_ICASSP.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-PaulusMK10_MusicStructure-STAR_ISMIR-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-PaulusMK10_MusicStructure-STAR_ISMIR_9-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Paulus, Jouni; M\u00fcller, Meinard; Klapuri, Anssi (2010). <a rel=\"nofollow\" class=\"external text\" href=\"http://ismir2010.ismir.net/proceedings/ismir2010-107.pdf\">\"Audio-based Music Structure Analysis\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Proceedings of the International Conference on Music Information Retrieval</i>: 625\u2013636.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+International+Conference+on+Music+Information+Retrieval&amp;rft.atitle=Audio-based+Music+Structure+Analysis&amp;rft.pages=625-636&amp;rft.date=2010&amp;rft.aulast=Paulus&amp;rft.aufirst=Jouni&amp;rft.au=M%C3%BCller%2C+Meinard&amp;rft.au=Klapuri%2C+Anssi&amp;rft_id=http%3A%2F%2Fismir2010.ismir.net%2Fproceedings%2Fismir2010-107.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-EllisP07_CoverSong_ICASSP-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-EllisP07_CoverSong_ICASSP_10-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Ellis, Daniel P.W.; Poliner, Graham (2007). \"Identifying 'Cover Songs' with Chroma Features and Dynamic Programming Beat Tracking\". <i>Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+IEEE+International+Conference+on+Acoustics%2C+Speech%2C+and+Signal+Processing&amp;rft.atitle=Identifying+%27Cover+Songs%27+with+Chroma+Features+and+Dynamic+Programming+Beat+Tracking&amp;rft.date=2007&amp;rft.aulast=Ellis&amp;rft.aufirst=Daniel+P.W.&amp;rft.au=Poliner%2C+Graham&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-SerraGHS08_CoverSong_IEEE-TASLP-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-SerraGHS08_CoverSong_IEEE-TASLP_11-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Serr\u00e0, Joan; G\u00f3mez, Emilia; Herrera, Perfecto; Serra, Xavier (2008). \"Chroma Binary Similarity and Local Alignment Applied to Cover Song Identification\". <i>IEEE Transactions on Audio, Speech, and Language Processing</i>. <b>16</b>: 1138\u20131151.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Audio%2C+Speech%2C+and+Language+Processing&amp;rft.atitle=Chroma+Binary+Similarity+and+Local+Alignment+Applied+to+Cover+Song+Identification&amp;rft.volume=16&amp;rft.pages=1138-1151&amp;rft.date=2008&amp;rft.aulast=Serr%C3%A0&amp;rft.aufirst=Joan&amp;rft.au=G%C3%B3mez%2C+Emilia&amp;rft.au=Herrera%2C+Perfecto&amp;rft.au=Serra%2C+Xavier&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-MuellerKC05_ChromaFeatures_ISMIR-12\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-MuellerKC05_ChromaFeatures_ISMIR_12-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-MuellerKC05_ChromaFeatures_ISMIR_12-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">M\u00fcller, Meinard; Kurth, Frank; Clausen, Michael (2005). <a rel=\"nofollow\" class=\"external text\" href=\"http://ismir2005.ismir.net/proceedings/1019.pdf\">\"Audio Matching via Chroma-Based Statistical Features\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Proceedings of the International Conference on Music Information Retrieval</i>: 288\u2013295.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+International+Conference+on+Music+Information+Retrieval&amp;rft.atitle=Audio+Matching+via+Chroma-Based+Statistical+Features&amp;rft.pages=288-295&amp;rft.date=2005&amp;rft.aulast=M%C3%BCller&amp;rft.aufirst=Meinard&amp;rft.au=Kurth%2C+Frank&amp;rft.au=Clausen%2C+Michael&amp;rft_id=http%3A%2F%2Fismir2005.ismir.net%2Fproceedings%2F1019.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-KurthM08_IndexBasedAudioMatching_TASLP-13\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-KurthM08_IndexBasedAudioMatching_TASLP_13-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Kurth, Frank; M\u00fcller, Meinard (2008). <a rel=\"nofollow\" class=\"external text\" href=\"https://dx.doi.org/10.1109/TASL.2007.911552\">\"Efficient Index-Based Audio Matching\"</a>. <i>IEEE Transactions on Audio, Speech, and Language Processing</i>. <b>16</b>: 382\u2013395.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Audio%2C+Speech%2C+and+Language+Processing&amp;rft.atitle=Efficient+Index-Based+Audio+Matching&amp;rft.volume=16&amp;rft.pages=382-395&amp;rft.date=2008&amp;rft.aulast=Kurth&amp;rft.aufirst=Frank&amp;rft.au=M%C3%BCller%2C+Meinard&amp;rft_id=https%3A%2F%2Fdx.doi.org%2F10.1109%2FTASL.2007.911552&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-BartschW05_chroma_IEEEMULTIMEDIA-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-BartschW05_chroma_IEEEMULTIMEDIA_14-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Bartsch, Mark A.; Wakefield, Gregory H. (2005). \"Audio thumbnailing of popular music using chroma-based representations\". <i>IEEE Transactions on Multimedia</i>. <b>7</b> (1): 96\u2013104.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Multimedia&amp;rft.atitle=Audio+thumbnailing+of+popular+music+using+chroma-based+representations&amp;rft.volume=7&amp;rft.issue=1&amp;rft.pages=96-104&amp;rft.date=2005&amp;rft.aulast=Bartsch&amp;rft.aufirst=Mark+A.&amp;rft.au=Wakefield%2C+Gregory+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-Gomez06_PhD-15\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Gomez06_PhD_15-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">G\u00f3mez, Emilia (2006). \"Tonal Description of Music Audio Signals\". <i>PhD thesis, UPF Barcelona, Spain</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=PhD+thesis%2C+UPF+Barcelona%2C+Spain&amp;rft.atitle=Tonal+Description+of+Music+Audio+Signals&amp;rft.date=2006&amp;rft.aulast=G%C3%B3mez&amp;rft.aufirst=Emilia&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-Mueller15_Chapter3FMP_SPRINGER-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Mueller15_Chapter3FMP_SPRINGER_16-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation book\">M\u00fcller, Meinard (2015). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.music-processing.de\"><i>Music Synchronization. In Fundamentals of Music Processing, chapter 3, pages 115-166</i></a>. Springer. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-3-319-21944-8\" title=\"Special:BookSources/978-3-319-21944-8\">978-3-319-21944-8</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Music+Synchronization.+In+Fundamentals+of+Music+Processing%2C+chapter+3%2C+pages+115-166&amp;rft.pub=Springer&amp;rft.date=2015&amp;rft.isbn=978-3-319-21944-8&amp;rft.aulast=M%C3%BCller&amp;rft.aufirst=Meinard&amp;rft_id=http%3A%2F%2Fwww.music-processing.de&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-MuellerE11_ChromaToolbox_ISMIR-17\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-MuellerE11_ChromaToolbox_ISMIR_17-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">M\u00fcller, Meinard; Ewert, Sebastian (2011). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.audiolabs-erlangen.de/content/05-fau/professor/00-mueller/03-publications/2011_MuellerEwert_ChromaToolbox_ISMIR.pdf\">\"Chroma Toolbox: MATLAB Implementations For Extracting Variants of Chroma-Based Audio Features\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Proceedings of the International Society for Music Information Retrieval Conference</i>: 215\u2013220.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+International+Society+for+Music+Information+Retrieval+Conference&amp;rft.atitle=Chroma+Toolbox%3A+MATLAB+Implementations+For+Extracting+Variants+of+Chroma-Based+Audio+Features&amp;rft.pages=215-220&amp;rft.date=2011&amp;rft.aulast=M%C3%BCller&amp;rft.aufirst=Meinard&amp;rft.au=Ewert%2C+Sebastian&amp;rft_id=https%3A%2F%2Fwww.audiolabs-erlangen.de%2Fcontent%2F05-fau%2Fprofessor%2F00-mueller%2F03-publications%2F2011_MuellerEwert_ChromaToolbox_ISMIR.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AChroma+feature\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n</ol></div>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Chroma_feature&amp;action=edit&amp;section=6\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a rel=\"nofollow\" class=\"external text\" href=\"https://www.audiolabs-erlangen.de/resources/MIR/chromatoolbox\">Chroma Toolbox</a> Free MATLAB implementations of various chroma types of pitch-based and chroma-based audio features</li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://mtg.upf.edu/technologies/hpcp\">Harmonic Pitch Class Profile plugin</a></li></ul>\n\n<!-- \nNewPP limit report\nParsed by mw1267\nCached time: 20180908134741\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.196 seconds\nReal time usage: 0.217 seconds\nPreprocessor visited node count: 1028/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 29799/2097152 bytes\nTemplate argument size: 118/2097152 bytes\nHighest expansion depth: 7/40\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 21343/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.094/10.000 seconds\nLua memory usage: 2.9 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  179.219      1 -total\n 86.18%  154.445      1 Template:Reflist\n 62.88%  112.701     15 Template:Cite_journal\n  6.46%   11.584      8 Template:Music\n  6.00%   10.755      2 Template:Cite_book\n  1.19%    2.134      1 Template:Column-width\n  0.97%    1.739      1 Template:Main_other\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:49957896-0!canonical and timestamp 20180908134741 and revision id 835556753\n -->\n</div>"},"langlinks":[],"categories":[{"sortkey":"","*":"Music_information_retrieval"},{"sortkey":"","*":"Music_technology"},{"sortkey":"","*":"Musicology"},{"sortkey":"","*":"Time\u2013frequency_analysis"}],"links":[{"ns":0,"exists":"","*":"Chromagram"},{"ns":0,"exists":"","*":"Digital object identifier"},{"ns":0,"exists":"","*":"Equal temperament"},{"ns":0,"exists":"","*":"Harmonic pitch class profiles"},{"ns":0,"exists":"","*":"International Standard Book Number"},{"ns":0,"exists":"","*":"Music alignment"},{"ns":0,"exists":"","*":"Musical theory"},{"ns":0,"exists":"","*":"Pitch (music)"},{"ns":0,"exists":"","*":"Pitch class"},{"ns":0,"exists":"","*":"Pitch classes"},{"ns":0,"exists":"","*":"Scientific pitch notation"},{"ns":0,"exists":"","*":"Time-frequency analysis"},{"ns":0,"exists":"","*":"Time-frequency analysis for music signal"}],"templates":[{"ns":10,"exists":"","*":"Template:Music"},{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Column-width"},{"ns":10,"exists":"","*":"Template:Cite journal"},{"ns":10,"exists":"","*":"Template:Cite book"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"}],"images":["ChromaFeatureCmajorScaleScoreAudioColor.png"],"externallinks":["http://www.music-processing.de","//doi.org/10.1007/978-3-319-21945-5","https://www.audiolabs-erlangen.de/content/05-fau/professor/00-mueller/03-publications/2011_JiangGroscheKonzMueller_ChordRecognitionEvaluation_AES42-Ilmenau.pdf","https://www.audiolabs-erlangen.de/content/05-fau/professor/00-mueller/03-publications/2009_EwertMuellerGrosche_HighResAudioSync_ICASSP.pdf","http://ismir2010.ismir.net/proceedings/ismir2010-107.pdf","http://ismir2005.ismir.net/proceedings/1019.pdf","https://dx.doi.org/10.1109/TASL.2007.911552","https://www.audiolabs-erlangen.de/content/05-fau/professor/00-mueller/03-publications/2011_MuellerEwert_ChromaToolbox_ISMIR.pdf","https://www.audiolabs-erlangen.de/resources/MIR/chromatoolbox","http://mtg.upf.edu/technologies/hpcp"],"sections":[{"toclevel":1,"level":"2","line":"Definition","number":"1","index":"1","fromtitle":"Chroma_feature","byteoffset":863,"anchor":"Definition"},{"toclevel":1,"level":"2","line":"Applications","number":"2","index":"2","fromtitle":"Chroma_feature","byteoffset":3188,"anchor":"Applications"},{"toclevel":1,"level":"2","line":"Computation of audio chromagrams","number":"3","index":"3","fromtitle":"Chroma_feature","byteoffset":8254,"anchor":"Computation_of_audio_chromagrams"},{"toclevel":1,"level":"2","line":"See also","number":"4","index":"4","fromtitle":"Chroma_feature","byteoffset":10235,"anchor":"See_also"},{"toclevel":1,"level":"2","line":"References","number":"5","index":"5","fromtitle":"Chroma_feature","byteoffset":10363,"anchor":"References"},{"toclevel":1,"level":"2","line":"External links","number":"6","index":"6","fromtitle":"Chroma_feature","byteoffset":10396,"anchor":"External_links"}],"parsewarnings":[],"displaytitle":"Chroma feature","iwlinks":[],"properties":[{"name":"wikibase_item","*":"Q25305103"}]}}