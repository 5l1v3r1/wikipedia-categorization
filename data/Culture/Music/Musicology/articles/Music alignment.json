{"parse":{"title":"Music alignment","pageid":49926925,"revid":844248059,"text":{"*":"<div class=\"mw-parser-output\"><div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:302px;\"><a href=\"/wiki/File:MusicAlignment_BeethovenFifth.png\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/5a/MusicAlignment_BeethovenFifth.png/300px-MusicAlignment_BeethovenFifth.png\" width=\"300\" height=\"236\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/5a/MusicAlignment_BeethovenFifth.png/450px-MusicAlignment_BeethovenFifth.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/5a/MusicAlignment_BeethovenFifth.png/600px-MusicAlignment_BeethovenFifth.png 2x\" data-file-width=\"624\" data-file-height=\"490\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:MusicAlignment_BeethovenFifth.png\" class=\"internal\" title=\"Enlarge\"></a></div>First theme of Symphony No. 5 by Ludwig van Beethoven in a sheet music, audio, and piano-roll representation. The red bidirectional arrows indicate the aligned time positions of corresponding note events in the different representations.</div></div></div>\n<p><a href=\"/wiki/Music\" title=\"Music\">Music</a> can be described and represented in many different ways including <a href=\"/wiki/Sheet_music\" title=\"Sheet music\">sheet music</a>, symbolic representations, and audio recordings. For each of these representations, there may exist different versions that correspond to the same musical work. The general goal of <b>music alignment</b> (sometimes also referred to as <b>music synchronization</b>) is to automatically link the various data streams, thus interrelating the multiple information sets related to a given musical work. More precisely, music alignment is taken to mean a procedure which, for a given position in one representation of a piece of music, determines the corresponding position within another representation.<sup id=\"cite_ref-Mueller15_Chapter3FMP_SPRINGER_1-0\" class=\"reference\"><a href=\"#cite_note-Mueller15_Chapter3FMP_SPRINGER-1\">&#91;1&#93;</a></sup> In the figure on the right, such an alignment is visualized by the red bidirectional arrows. Such <a href=\"/wiki/Synchronization\" title=\"Synchronization\">synchronization</a> results form the basis for novel interfaces that allow users to access, search, and browse musical content in a convenient way.<sup id=\"cite_ref-DammFTCKM12_DML_IJDL_2-0\" class=\"reference\"><a href=\"#cite_note-DammFTCKM12_DML_IJDL-2\">&#91;2&#93;</a></sup><sup id=\"cite_ref-MuellerCKEF10_Sync_ISR_3-0\" class=\"reference\"><a href=\"#cite_note-MuellerCKEF10_Sync_ISR-3\">&#91;3&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Basic_procedure\">Basic procedure</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Music_alignment&amp;action=edit&amp;section=1\" title=\"Edit section: Basic procedure\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:302px;\"><a href=\"/wiki/File:MusicAlignment_Procedure.png\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/92/MusicAlignment_Procedure.png/300px-MusicAlignment_Procedure.png\" width=\"300\" height=\"346\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/92/MusicAlignment_Procedure.png/450px-MusicAlignment_Procedure.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/92/MusicAlignment_Procedure.png/600px-MusicAlignment_Procedure.png 2x\" data-file-width=\"762\" data-file-height=\"879\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:MusicAlignment_Procedure.png\" class=\"internal\" title=\"Enlarge\"></a></div>Overview of the processing pipeline of a typical music alignment procedure.</div></div></div>\n<p>Given two different music representations, typical music alignment approaches proceed in two steps.<sup id=\"cite_ref-Mueller15_Chapter3FMP_SPRINGER_1-1\" class=\"reference\"><a href=\"#cite_note-Mueller15_Chapter3FMP_SPRINGER-1\">&#91;1&#93;</a></sup> In the first step, the two representations are transformed into sequences of suitable features. In general, such feature representations need to find a compromise between two conflicting goals. On the one hand, features should show a large degree of <a href=\"/wiki/Robustness\" title=\"Robustness\">robustness</a> to variations that are to be left unconsidered for the task at hand. On the other hand, features should capture enough characteristic information to accomplish the given task. For music alignment, one often uses <b><a href=\"/wiki/Chroma_feature\" title=\"Chroma feature\">chroma-based features</a></b> (also called <a href=\"/wiki/Chromagram\" class=\"mw-redirect\" title=\"Chromagram\">chromagrams</a> or <a href=\"/wiki/Harmonic_pitch_class_profiles\" title=\"Harmonic pitch class profiles\">pitch class profiles</a>), which capture harmonic and melodic characteristics of music, while being robust to changes in timbre and instrumentation, are being used.\n</p><p>In the second step, the derived feature sequences have to be brought into (temporal) correspondence. To this end, techniques related to <b><a href=\"/wiki/Dynamic_time_warping\" title=\"Dynamic time warping\">dynamic time warping (DTW)</a></b> or <b><a href=\"/wiki/Hidden_Markov_model\" title=\"Hidden Markov model\">hidden Markov models (HMMs)</a></b> are used to compute an optimal alignment between two given feature sequences.\n</p>\n<h2><span class=\"mw-headline\" id=\"Related_tasks\">Related tasks</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Music_alignment&amp;action=edit&amp;section=2\" title=\"Edit section: Related tasks\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Music alignment and related synchronization tasks have been studied extensively within the field of <a href=\"/wiki/Music_information_retrieval\" title=\"Music information retrieval\">music information retrieval</a>. In the following, we give some pointers to related tasks. Depending upon the respective types of music representations, one can distinguish between various synchronization scenarios. For example, audio alignment refers to the task of temporally aligning two different audio recordings of a piece of music. Similarly, the goal of score\u2013audio alignment is to coordinate note events given in the score representation with audio data. In the  <a href=\"/wiki/Offline\" class=\"mw-redirect\" title=\"Offline\">offline</a> scenario, the two data streams to be aligned are known prior to the actual alignment. In this case, one can use global optimization procedures such as <a href=\"/wiki/Dynamic_time_warping\" title=\"Dynamic time warping\">dynamic time warping (DTW)</a> to find an optimal alignment. In general, it is harder to deal with scenarios where the data streams are to be processed online. One prominent online scenario is known as <b><a href=\"/wiki/Score_following\" title=\"Score following\">score following</a></b>, where a musician is performing a piece according to a given musical score. The goal is then to identify the currently played musical events depicted in the score with high accuracy and low latency.<sup id=\"cite_ref-4\" class=\"reference\"><a href=\"#cite_note-4\">&#91;4&#93;</a></sup><sup id=\"cite_ref-5\" class=\"reference\"><a href=\"#cite_note-5\">&#91;5&#93;</a></sup> In this scenario, the score is known as a whole in advance, but the performance is known only up to the current point in time. In this context, alignment techniques such as hidden Markov models or particle filters have been employed, where the current score position and tempo are modeled in a statistical sense.<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;6&#93;</a></sup><sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">&#91;7&#93;</a></sup> As opposed to classical DTW, such an online synchronization procedure inherently has a running time that is linear in the duration of the performed version. However, as a main disadvantage, an online strategy is very sensitive to local tempo variations and deviations from the score - once the procedure is out of sync, it is very hard to recover and return to the right track. A further online synchronization problem is known as <b><a href=\"/wiki/Pop_music_automation#Automatic_accompaniment\" title=\"Pop music automation\">automatic accompaniment</a></b>. Having a solo part played by a musician, the task of the computer is to accompany the musician according to a given score by adjusting the tempo and other parameters in real time. Such systems were already proposed some decades ago.<sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">&#91;8&#93;</a></sup><sup id=\"cite_ref-9\" class=\"reference\"><a href=\"#cite_note-9\">&#91;9&#93;</a></sup><sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">&#91;10&#93;</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Music_alignment&amp;action=edit&amp;section=3\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap\"><ol class=\"references\">\n<li id=\"cite_note-Mueller15_Chapter3FMP_SPRINGER-1\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Mueller15_Chapter3FMP_SPRINGER_1-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Mueller15_Chapter3FMP_SPRINGER_1-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">\n<cite class=\"citation book\">M\u00fcller, Meinard (2015). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.music-processing.de\"><i>Music Synchronization. In Fundamentals of Music Processing, chapter 3, pages 115-166</i></a>. Springer. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1007/978-3-319-21945-5\">10.1007/978-3-319-21945-5</a>. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-3-319-21944-8\" title=\"Special:BookSources/978-3-319-21944-8\">978-3-319-21944-8</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Music+Synchronization.+In+Fundamentals+of+Music+Processing%2C+chapter+3%2C+pages+115-166&amp;rft.pub=Springer&amp;rft.date=2015&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-319-21945-5&amp;rft.isbn=978-3-319-21944-8&amp;rft.aulast=M%C3%BCller&amp;rft.aufirst=Meinard&amp;rft_id=http%3A%2F%2Fwww.music-processing.de&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMusic+alignment\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-DammFTCKM12_DML_IJDL-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-DammFTCKM12_DML_IJDL_2-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Damm, David; Fremerey, Christian; Thomas, Verena; Clausen, Michael; Kurth, Frank; M\u00fcller, Meinard (2012). <a rel=\"nofollow\" class=\"external text\" href=\"https://link.springer.com/article/10.1007%2Fs00799-012-0087-y\">\"A digital library framework for heterogeneous music collections: from document acquisition to cross-modal interaction\"</a>. <i>International Journal on Digital Libraries: Special Issue on Music Digital Libraries</i>. <b>12</b> (2-3): 53\u201371. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1007/s00799-012-0087-y\">10.1007/s00799-012-0087-y</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Journal+on+Digital+Libraries%3A+Special+Issue+on+Music+Digital+Libraries&amp;rft.atitle=A+digital+library+framework+for+heterogeneous+music+collections%3A+from+document+acquisition+to+cross-modal+interaction&amp;rft.volume=12&amp;rft.issue=2-3&amp;rft.pages=53-71&amp;rft.date=2012&amp;rft_id=info%3Adoi%2F10.1007%2Fs00799-012-0087-y&amp;rft.aulast=Damm&amp;rft.aufirst=David&amp;rft.au=Fremerey%2C+Christian&amp;rft.au=Thomas%2C+Verena&amp;rft.au=Clausen%2C+Michael&amp;rft.au=Kurth%2C+Frank&amp;rft.au=M%C3%BCller%2C+Meinard&amp;rft_id=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%252Fs00799-012-0087-y&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMusic+alignment\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-MuellerCKEF10_Sync_ISR-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-MuellerCKEF10_Sync_ISR_3-0\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">M\u00fcller, Meinard; Clausen, Michael; Konz, Verena; Ewert, Sebastian; Fremerey, Christian (2010). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.audiolabs-erlangen.de/content/05-fau/professor/00-mueller/03-publications/2010_MuellerClausenKonzEwertFremerey_MusicSynchronization_ISR.pdf\">\"A Multimodal Way of Experiencing and Exploring Music\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Interdisciplinary Science Reviews (ISR)</i>. <b>35</b> (2): 138\u2013153. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1179/030801810X12723585301110\">10.1179/030801810X12723585301110</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Interdisciplinary+Science+Reviews+%28ISR%29&amp;rft.atitle=A+Multimodal+Way+of+Experiencing+and+Exploring+Music&amp;rft.volume=35&amp;rft.issue=2&amp;rft.pages=138-153&amp;rft.date=2010&amp;rft_id=info%3Adoi%2F10.1179%2F030801810X12723585301110&amp;rft.aulast=M%C3%BCller&amp;rft.aufirst=Meinard&amp;rft.au=Clausen%2C+Michael&amp;rft.au=Konz%2C+Verena&amp;rft.au=Ewert%2C+Sebastian&amp;rft.au=Fremerey%2C+Christian&amp;rft_id=https%3A%2F%2Fwww.audiolabs-erlangen.de%2Fcontent%2F05-fau%2Fprofessor%2F00-mueller%2F03-publications%2F2010_MuellerClausenKonzEwertFremerey_MusicSynchronization_ISR.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMusic+alignment\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Cont, Arshia (2010). \"A Coupled Duration-Focused Architecture for Real-Time Music-to-Score Alignment\". <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>. <b>32</b> (6): 974\u2013987. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1109/TPAMI.2009.106\">10.1109/TPAMI.2009.106</a>. <a href=\"/wiki/International_Standard_Serial_Number\" title=\"International Standard Serial Number\">ISSN</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.worldcat.org/issn/0162-8828\">0162-8828</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence&amp;rft.atitle=A+Coupled+Duration-Focused+Architecture+for+Real-Time+Music-to-Score+Alignment&amp;rft.volume=32&amp;rft.issue=6&amp;rft.pages=974-987&amp;rft.date=2010&amp;rft_id=info%3Adoi%2F10.1109%2FTPAMI.2009.106&amp;rft.issn=0162-8828&amp;rft.aulast=Cont&amp;rft.aufirst=Arshia&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMusic+alignment\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Orio, Nicola; Lemouton, Serge; Schwarz, Diemo (2003). <a rel=\"nofollow\" class=\"external text\" href=\"http://recherche.ircam.fr/equipes/temps-reel/suivi/resources/orio.2002.nime.pdf\">\"Score following: State of the art and new developments\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Proceedings of the International Conference on New Interfaces for Musical Expression (NIME)</i>: 36\u201341.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+International+Conference+on+New+Interfaces+for+Musical+Expression+%28NIME%29&amp;rft.atitle=Score+following%3A+State+of+the+art+and+new+developments&amp;rft.pages=36-41&amp;rft.date=2003&amp;rft.aulast=Orio&amp;rft.aufirst=Nicola&amp;rft.au=Lemouton%2C+Serge&amp;rft.au=Schwarz%2C+Diemo&amp;rft_id=http%3A%2F%2Frecherche.ircam.fr%2Fequipes%2Ftemps-reel%2Fsuivi%2Fresources%2Forio.2002.nime.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMusic+alignment\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Duan, Zhiyao; Pardo, Bryan (2011). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.ece.rochester.edu/~zduan/resource/DuanPardo_ScoreFollowing_ICASSP11.pdf\">\"A state space model for online polyphonic audio-score alignment\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i>: 197\u2013200. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1109/ICASSP.2011.5946374\">10.1109/ICASSP.2011.5946374</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+IEEE+International+Conference+on+Acoustics%2C+Speech%2C+and+Signal+Processing+%28ICASSP%29&amp;rft.atitle=A+state+space+model+for+online+polyphonic+audio-score+alignment&amp;rft.pages=197-200&amp;rft.date=2011&amp;rft_id=info%3Adoi%2F10.1109%2FICASSP.2011.5946374&amp;rft.aulast=Duan&amp;rft.aufirst=Zhiyao&amp;rft.au=Pardo%2C+Bryan&amp;rft_id=http%3A%2F%2Fwww.ece.rochester.edu%2F~zduan%2Fresource%2FDuanPardo_ScoreFollowing_ICASSP11.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMusic+alignment\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Montecchio, Nicola; Cont, Arshia (2011). <a rel=\"nofollow\" class=\"external text\" href=\"http://articles.ircam.fr/textes/Montecchio11a/index.pdf\">\"A unified approach to real time audio-to-score and audio-to-audio alignment using sequential Montecarlo inference techniques\"</a> <span style=\"font-size:85%;\">(PDF)</span>: 193\u2013196. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1109/ICASSP.2011.5946373\">10.1109/ICASSP.2011.5946373</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=A+unified+approach+to+real+time+audio-to-score+and+audio-to-audio+alignment+using+sequential+Montecarlo+inference+techniques&amp;rft.pages=193-196&amp;rft.date=2011&amp;rft_id=info%3Adoi%2F10.1109%2FICASSP.2011.5946373&amp;rft.aulast=Montecchio&amp;rft.aufirst=Nicola&amp;rft.au=Cont%2C+Arshia&amp;rft_id=http%3A%2F%2Farticles.ircam.fr%2Ftextes%2FMontecchio11a%2Findex.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMusic+alignment\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Dannenberg, Roger B. (1984). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.cs.cmu.edu/~rbd/papers/icmc84accomp.pdf\">\"An on-line algorithm for real-time accompaniment\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Proceedings of the International Computer Music Conference (ICMC)</i>: 193\u2013198.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+International+Computer+Music+Conference+%28ICMC%29&amp;rft.atitle=An+on-line+algorithm+for+real-time+accompaniment&amp;rft.pages=193-198&amp;rft.date=1984&amp;rft.aulast=Dannenberg&amp;rft.aufirst=Roger+B.&amp;rft_id=http%3A%2F%2Fwww.cs.cmu.edu%2F~rbd%2Fpapers%2Ficmc84accomp.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMusic+alignment\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-9\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Raphael, Christopher (2001). <a rel=\"nofollow\" class=\"external text\" href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.6559&amp;rep=rep1&amp;type=pdf\">\"A probabilistic expert system for automatic musical accompaniment\"</a>. <i>Journal of Computational and Graphical Statistics</i>: 487\u2013512.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Computational+and+Graphical+Statistics&amp;rft.atitle=A+probabilistic+expert+system+for+automatic+musical+accompaniment&amp;rft.pages=487-512&amp;rft.date=2001&amp;rft.aulast=Raphael&amp;rft.aufirst=Christopher&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.20.6559%26rep%3Drep1%26type%3Dpdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMusic+alignment\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Dannenberg, Roger B.; Raphael, Christopher (2006). <a rel=\"nofollow\" class=\"external text\" href=\"http://www.cs.cmu.edu/~rbd/papers/accompaniment-cacm-06.pdf\">\"Music score alignment and computer accompaniment\"</a> <span style=\"font-size:85%;\">(PDF)</span>. <i>Communications of the ACM</i>. <b>49</b> (8): 38\u201343. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1145/1145287.1145311\">10.1145/1145287.1145311</a>. <a href=\"/wiki/International_Standard_Serial_Number\" title=\"International Standard Serial Number\">ISSN</a>&#160;<a rel=\"nofollow\" class=\"external text\" href=\"//www.worldcat.org/issn/0001-0782\">0001-0782</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=Music+score+alignment+and+computer+accompaniment&amp;rft.volume=49&amp;rft.issue=8&amp;rft.pages=38-43&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1145%2F1145287.1145311&amp;rft.issn=0001-0782&amp;rft.aulast=Dannenberg&amp;rft.aufirst=Roger+B.&amp;rft.au=Raphael%2C+Christopher&amp;rft_id=http%3A%2F%2Fwww.cs.cmu.edu%2F~rbd%2Fpapers%2Faccompaniment-cacm-06.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMusic+alignment\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n</ol></div></div>\n\n<!-- \nNewPP limit report\nParsed by mw1327\nCached time: 20180909161237\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.136 seconds\nReal time usage: 0.161 seconds\nPreprocessor visited node count: 511/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 21145/2097152 bytes\nTemplate argument size: 79/2097152 bytes\nHighest expansion depth: 7/40\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 14553/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.073/10.000 seconds\nLua memory usage: 2.79 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  125.449      1 Template:Reflist\n100.00%  125.449      1 -total\n 41.65%   52.253      9 Template:Cite_journal\n 39.41%   49.436      1 Template:Cite_book\n  1.67%    2.089      1 Template:Main_other\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:49926925-0!canonical and timestamp 20180909161236 and revision id 844248059\n -->\n</div>"},"langlinks":[],"categories":[{"sortkey":"","*":"Music_information_retrieval"},{"sortkey":"","*":"Music_technology"},{"sortkey":"","*":"Musicology"},{"sortkey":"","*":"Information_retrieval_techniques"}],"links":[{"ns":0,"exists":"","*":"Chroma feature"},{"ns":0,"exists":"","*":"Chromagram"},{"ns":0,"exists":"","*":"Digital object identifier"},{"ns":0,"exists":"","*":"Dynamic time warping"},{"ns":0,"exists":"","*":"Harmonic pitch class profiles"},{"ns":0,"exists":"","*":"Hidden Markov model"},{"ns":0,"exists":"","*":"International Standard Book Number"},{"ns":0,"exists":"","*":"International Standard Serial Number"},{"ns":0,"exists":"","*":"Music"},{"ns":0,"exists":"","*":"Music information retrieval"},{"ns":0,"exists":"","*":"Offline"},{"ns":0,"exists":"","*":"Pop music automation"},{"ns":0,"exists":"","*":"Robustness"},{"ns":0,"exists":"","*":"Score following"},{"ns":0,"exists":"","*":"Sheet music"},{"ns":0,"exists":"","*":"Synchronization"}],"templates":[{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Cite book"},{"ns":10,"exists":"","*":"Template:Cite journal"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"}],"images":["MusicAlignment_BeethovenFifth.png","MusicAlignment_Procedure.png"],"externallinks":["http://www.music-processing.de","//doi.org/10.1007/978-3-319-21945-5","https://link.springer.com/article/10.1007%2Fs00799-012-0087-y","//doi.org/10.1007/s00799-012-0087-y","https://www.audiolabs-erlangen.de/content/05-fau/professor/00-mueller/03-publications/2010_MuellerClausenKonzEwertFremerey_MusicSynchronization_ISR.pdf","//doi.org/10.1179/030801810X12723585301110","//doi.org/10.1109/TPAMI.2009.106","//www.worldcat.org/issn/0162-8828","http://recherche.ircam.fr/equipes/temps-reel/suivi/resources/orio.2002.nime.pdf","http://www.ece.rochester.edu/~zduan/resource/DuanPardo_ScoreFollowing_ICASSP11.pdf","//doi.org/10.1109/ICASSP.2011.5946374","http://articles.ircam.fr/textes/Montecchio11a/index.pdf","//doi.org/10.1109/ICASSP.2011.5946373","http://www.cs.cmu.edu/~rbd/papers/icmc84accomp.pdf","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.6559&rep=rep1&type=pdf","http://www.cs.cmu.edu/~rbd/papers/accompaniment-cacm-06.pdf","//doi.org/10.1145/1145287.1145311","//www.worldcat.org/issn/0001-0782"],"sections":[{"toclevel":1,"level":"2","line":"Basic procedure","number":"1","index":"1","fromtitle":"Music_alignment","byteoffset":2729,"anchor":"Basic_procedure"},{"toclevel":1,"level":"2","line":"Related tasks","number":"2","index":"2","fromtitle":"Music_alignment","byteoffset":4110,"anchor":"Related_tasks"},{"toclevel":1,"level":"2","line":"References","number":"3","index":"3","fromtitle":"Music_alignment","byteoffset":8749,"anchor":"References"}],"parsewarnings":[],"displaytitle":"Music alignment","iwlinks":[],"properties":[{"name":"wikibase_item","*":"Q23552485"}]}}