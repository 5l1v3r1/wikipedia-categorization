An adaptive system is a set of interacting or interdependent entities, real or abstract, forming an integrated whole that together are able to respond to environmental changes or changes in the interacting parts, in a way analogous to either continuous physiological homeostasis or evolutionary adaptation in biology. Feedback loops represent a key feature of adaptive systems, such as ecosystems and individual organisms; or in the human world, communities, organizations, and families. Artificial adaptive systems include robots with control systems that utilize negative feedback to maintain desired states. The law of adaptation can be stated informally as:  Every adaptive system converges to a state in which all kind of stimulation ceases.  Formally, the law can be defined as follows: Given a system                         S                 {\displaystyle S}    , we say that a physical event                         E                 {\displaystyle E}     is a stimulus for the system                         S                 {\displaystyle S}     if and only if the probability                         P         (         S         →                    S           ′                             |                  E         )                 {\displaystyle P(S\rightarrow S'|E)}     that the system suffers a change or be perturbed (in its elements or in its processes) when the event                         E                 {\displaystyle E}     occurs is strictly greater than the prior probability that                         S                 {\displaystyle S}     suffers a change independently of                         E                 {\displaystyle E}    : Let                         S                 {\displaystyle S}     be an arbitrary system subject to changes in time                         t                 {\displaystyle t}     and let                         E                 {\displaystyle E}     be an arbitrary event that is a stimulus for the system                         S                 {\displaystyle S}    : we say that                         S                 {\displaystyle S}     is an adaptive system if and only if when t tends to infinity                         (         t         →         ∞         )                 {\displaystyle (t\rightarrow \infty )}     the probability that the system                         S                 {\displaystyle S}     change its behavior                         (         S         →                    S           ′                  )                 {\displaystyle (S\rightarrow S')}     in a time step                                    t                        0                                     {\displaystyle t_{0}}     given the event                         E                 {\displaystyle E}     is equal to the probability that the system change its behavior independently of the occurrence of the event                         E                 {\displaystyle E}    . In mathematical terms: Thus, for each instant                         t                 {\displaystyle t}     will exist a temporal interval                         h                 {\displaystyle h}     such that: In an adaptive system, a parameter changes slowly and has no preferred value.  In a self-adjusting system though, the parameter value “depends on the history of the system dynamics”.  One of the most important qualities of self-adjusting systems is its “adaptation to the edge of chaos” or ability to avoid chaos.  Practically speaking, by heading to the edge of chaos without going further, a leader may act spontaneously yet without disaster.  A March/April 2009 Complexity article further explains the self-adjusting systems used and the realistic implications.  Physicists have shown that adaptation to the edge of chaos occurs in almost all systems with feedback.  Practopoiesis, a term due to its originator Danko Nikolić, is a reference to a kind of adaptive or self-adjusting system in which autopoiesis of an organism or a cell occurs through allopoietic interactions among its components.  The components are organized into a poietic hierarchy: one component creates another. The theory proposes that living systems exhibit a hierarchy of four such poietic operations in total: Practopoiesis challenges current neuroscience doctrine by asserting that mental operations primarily occur at the anapoietic level (iii) — i.e., that minds emerge from fast homeostatic (adaptive) mechanisms. This contrasts the widespread belief that thinking is synonymous with neural activity ('cell function' at level iv).  Each lower level contains knowledge that is more general than the higher level; for example, genes contain more general knowledge than anapoietic mechanisms, which in turn contain more general knowledge than cell functions. This hierarchy of knowledge enables the anapoietic level to directly store concepts, which are necessary for the emergence of mind. 