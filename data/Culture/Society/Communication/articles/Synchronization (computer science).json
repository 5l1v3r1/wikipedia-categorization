{"parse":{"title":"Synchronization (computer science)","pageid":4726017,"revid":848867513,"text":{"*":"<div class=\"mw-parser-output\"><table class=\"plainlinks metadata ambox ambox-content ambox-Refimprove\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><div style=\"width:52px\"><a href=\"/wiki/File:Question_book-new.svg\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png\" width=\"50\" height=\"39\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/75px-Question_book-new.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png 2x\" data-file-width=\"512\" data-file-height=\"399\" /></a></div></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">This article <b>needs additional citations for <a href=\"/wiki/Wikipedia:Verifiability\" title=\"Wikipedia:Verifiability\">verification</a></b>.<span class=\"hide-when-compact\"> Please help <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Synchronization_(computer_science)&amp;action=edit\">improve this article</a> by <a href=\"/wiki/Help:Introduction_to_referencing_with_Wiki_Markup/1\" title=\"Help:Introduction to referencing with Wiki Markup/1\">adding citations to reliable sources</a>. Unsourced material may be challenged and removed.</span>  <small><i>(November 2014)</i></small><small class=\"hide-when-compact\"><i> (<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>\n<p>In <a href=\"/wiki/Computer_science\" title=\"Computer science\">computer science</a>, <b>synchronization</b> refers to one of two distinct but related concepts: synchronization of <a href=\"/wiki/Process_(computer_science)\" class=\"mw-redirect\" title=\"Process (computer science)\">processes</a>, and synchronization of <a href=\"/wiki/Dataset\" class=\"mw-redirect\" title=\"Dataset\">Data</a>. <i>Process synchronization</i> refers to the idea that multiple processes are to join up or <a href=\"/wiki/Handshaking\" title=\"Handshaking\">handshake</a> at a certain point, in order to reach an agreement or commit to a certain sequence of action. <i><a href=\"/wiki/Data_synchronization\" title=\"Data synchronization\">Data synchronization</a></i> refers to the idea of keeping multiple copies of a dataset in coherence with one another, or to maintain <a href=\"/wiki/Data_integrity\" title=\"Data integrity\">data integrity</a>. Process synchronization primitives are commonly used to implement data synchronization.\n</p>\n<div id=\"toc\" class=\"toc\"><input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\" /><div class=\"toctitle\" lang=\"en\" dir=\"ltr\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#The_need_for_synchronization\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">The need for synchronization</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Thread_or_process_synchronization\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Thread or process synchronization</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#Minimizing_synchronization\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Minimizing synchronization</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-4\"><a href=\"#Classic_problems_of_synchronization\"><span class=\"tocnumber\">3.1</span> <span class=\"toctext\">Classic problems of synchronization</span></a></li>\n<li class=\"toclevel-2 tocsection-5\"><a href=\"#Hardware_synchronization\"><span class=\"tocnumber\">3.2</span> <span class=\"toctext\">Hardware synchronization</span></a></li>\n<li class=\"toclevel-2 tocsection-6\"><a href=\"#Synchronization_strategies_in_programming_languages\"><span class=\"tocnumber\">3.3</span> <span class=\"toctext\">Synchronization strategies in programming languages</span></a></li>\n<li class=\"toclevel-2 tocsection-7\"><a href=\"#Implementation_of_Synchronization\"><span class=\"tocnumber\">3.4</span> <span class=\"toctext\">Implementation of Synchronization</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-8\"><a href=\"#Spinlock\"><span class=\"tocnumber\">3.4.1</span> <span class=\"toctext\">Spinlock</span></a></li>\n<li class=\"toclevel-3 tocsection-9\"><a href=\"#Barriers\"><span class=\"tocnumber\">3.4.2</span> <span class=\"toctext\">Barriers</span></a></li>\n<li class=\"toclevel-3 tocsection-10\"><a href=\"#Semaphores\"><span class=\"tocnumber\">3.4.3</span> <span class=\"toctext\">Semaphores</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-2 tocsection-11\"><a href=\"#Mathematical_foundations\"><span class=\"tocnumber\">3.5</span> <span class=\"toctext\">Mathematical foundations</span></a></li>\n<li class=\"toclevel-2 tocsection-12\"><a href=\"#Synchronization_examples\"><span class=\"tocnumber\">3.6</span> <span class=\"toctext\">Synchronization examples</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-13\"><a href=\"#Synchronization_in_Windows\"><span class=\"tocnumber\">3.6.1</span> <span class=\"toctext\">Synchronization in Windows</span></a></li>\n<li class=\"toclevel-3 tocsection-14\"><a href=\"#Synchronization_in_Linux\"><span class=\"tocnumber\">3.6.2</span> <span class=\"toctext\">Synchronization in Linux</span></a></li>\n<li class=\"toclevel-3 tocsection-15\"><a href=\"#Synchronization_in_Solaris\"><span class=\"tocnumber\">3.6.3</span> <span class=\"toctext\">Synchronization in Solaris</span></a></li>\n<li class=\"toclevel-3 tocsection-16\"><a href=\"#Pthreads_synchronization\"><span class=\"tocnumber\">3.6.4</span> <span class=\"toctext\">Pthreads synchronization</span></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-17\"><a href=\"#Data_synchronization\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Data synchronization</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-18\"><a href=\"#Challenges_in_data_synchronization\"><span class=\"tocnumber\">4.1</span> <span class=\"toctext\">Challenges in data synchronization</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-19\"><a href=\"#Data_formats_complexity\"><span class=\"tocnumber\">4.1.1</span> <span class=\"toctext\">Data formats complexity</span></a></li>\n<li class=\"toclevel-3 tocsection-20\"><a href=\"#Real-timeliness\"><span class=\"tocnumber\">4.1.2</span> <span class=\"toctext\">Real-timeliness</span></a></li>\n<li class=\"toclevel-3 tocsection-21\"><a href=\"#Data_security\"><span class=\"tocnumber\">4.1.3</span> <span class=\"toctext\">Data security</span></a></li>\n<li class=\"toclevel-3 tocsection-22\"><a href=\"#Data_quality\"><span class=\"tocnumber\">4.1.4</span> <span class=\"toctext\">Data quality</span></a></li>\n<li class=\"toclevel-3 tocsection-23\"><a href=\"#Performance\"><span class=\"tocnumber\">4.1.5</span> <span class=\"toctext\">Performance</span></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-24\"><a href=\"#See_also\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-25\"><a href=\"#References\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-26\"><a href=\"#External_links\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class=\"mw-headline\" id=\"The_need_for_synchronization\">The need for synchronization</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=1\" title=\"Edit section: The need for synchronization\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>The need for synchronization does not arise merely in multi-processor systems but for any kind of concurrent processes; even in single processor systems. Mentioned below are some of the main needs for synchronization:\n</p><p><i><a href=\"/wiki/Fork-join_model\" class=\"mw-redirect\" title=\"Fork-join model\">Forks and Joins</a>:</i> When a job arrives at a fork point, it is split into N sub-jobs which are then serviced by n tasks. After being serviced, each sub-job waits until all other sub-jobs are done processing. Then, they are joined again and leave the system. Thus, in parallel programming, we require synchronization as all the parallel processes wait for several other processes to occur.\n</p><p><i><a href=\"/wiki/Producer%E2%80%93consumer_problem\" title=\"Producer\u2013consumer problem\">Producer-Consumer:</a></i> In a producer-consumer relationship, the consumer process is dependent on the producer process till the necessary data has been produced.\n</p><p><i>Exclusive use resources:</i> When multiple processes are dependent on a resource and they need to access it at the same time the operating system needs to ensure that only one processor accesses it at a given point in time.This reduces  concurrency.\n</p>\n<h2><span class=\"mw-headline\" id=\"Thread_or_process_synchronization\">Thread or process synchronization</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=2\" title=\"Edit section: Thread or process synchronization\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><a href=\"/wiki/File:Multiple_Processes_Accessing_the_shared_resource.png\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Multiple_Processes_Accessing_the_shared_resource.png/220px-Multiple_Processes_Accessing_the_shared_resource.png\" width=\"220\" height=\"128\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Multiple_Processes_Accessing_the_shared_resource.png/330px-Multiple_Processes_Accessing_the_shared_resource.png 1.5x, //upload.wikimedia.org/wikipedia/commons/a/a3/Multiple_Processes_Accessing_the_shared_resource.png 2x\" data-file-width=\"360\" data-file-height=\"210\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Multiple_Processes_Accessing_the_shared_resource.png\" class=\"internal\" title=\"Enlarge\"></a></div><b>Figure 1</b>: Three processes accessing a shared resource (<a href=\"/wiki/Critical_section\" title=\"Critical section\">critical section</a>) simultaneously.</div></div></div>\n<p>Thread synchronization is defined as a mechanism which ensures that two or more concurrent <a href=\"/wiki/Process_(computer_science)\" class=\"mw-redirect\" title=\"Process (computer science)\">processes</a> or <a href=\"/wiki/Thread_(computer_science)\" class=\"mw-redirect\" title=\"Thread (computer science)\">threads</a> do not simultaneously execute some particular program segment known as <a href=\"/wiki/Critical_section\" title=\"Critical section\">critical section</a>. Processes' access to critical section is controlled by using synchronization techniques. When one thread starts executing the <a href=\"/wiki/Critical_section\" title=\"Critical section\">critical section</a> (serialized segment of the program) the other thread should wait until the first thread finishes. If proper synchronization techniques<sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\">&#91;1&#93;</a></sup> are not applied, it may cause a <a href=\"/wiki/Race_condition#Software\" title=\"Race condition\">race condition</a> where the values of variables may be unpredictable and vary depending on the timings of <a href=\"/wiki/Context_switch\" title=\"Context switch\">context switches</a> of the processes or threads.\n</p><p>For example, suppose that there are three processes, namely 1, 2, and 3. All three of them are concurrently executing, and they need to share a common resource (critical section) as shown in Figure 1. Synchronization should be used here to avoid any conflicts for accessing this shared resource. Hence, when Process 1 and 2 both try to access that resource, it should be assigned to only one process at a time.  If it is assigned to Process 1, the other process (Process 2) needs to wait until Process 1 frees that resource (as shown in Figure 2).\n</p>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><a href=\"/wiki/File:Shared_Resource_access_in_synchronization_environment.png\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/50/Shared_Resource_access_in_synchronization_environment.png/220px-Shared_Resource_access_in_synchronization_environment.png\" width=\"220\" height=\"253\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/50/Shared_Resource_access_in_synchronization_environment.png/330px-Shared_Resource_access_in_synchronization_environment.png 1.5x, //upload.wikimedia.org/wikipedia/commons/5/50/Shared_Resource_access_in_synchronization_environment.png 2x\" data-file-width=\"350\" data-file-height=\"402\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Shared_Resource_access_in_synchronization_environment.png\" class=\"internal\" title=\"Enlarge\"></a></div><b>Figure 2</b>: A process accessing a shared resource if available, based on some synchronization technique.</div></div></div>\n<p>Another synchronization requirement which needs to be considered is the order in which particular processes or threads should be executed. For example, we cannot board a plane until we buy a ticket.  Similarly, we cannot check e-mails without validating our credentials (i.e., user name and password). In the same way, an ATM will not provide any service until we provide it with a correct PIN.\n</p><p>Other than mutual exclusion, synchronization also deals with the following:\n</p>\n<ul><li><a href=\"/wiki/Deadlock\" title=\"Deadlock\">deadlock</a>, which occurs when many processes are waiting for a shared resource (critical section) which is being held by some other process. In this case, the processes just keep waiting and execute no further;</li>\n<li><a href=\"/wiki/Resource_starvation\" class=\"mw-redirect\" title=\"Resource starvation\">starvation</a>, which occurs when a process is waiting to enter the critical section, but other processes monopolize the critical section, and the first process is forced to wait indefinitely;</li>\n<li><a href=\"/wiki/Priority_inversion\" title=\"Priority inversion\">priority inversion</a>, which occurs when a high-priority process is in the critical section, and it is interrupted by a medium-priority process. This violation of priority rules can happen under certain circumstances and may lead to serious consequences in real-time systems;</li>\n<li><a href=\"/wiki/Busy_waiting\" title=\"Busy waiting\">busy waiting</a>, which occurs when a process frequently polls to determine if it has access to a critical section. This frequent polling robs processing time from other processes.</li></ul>\n<h2><span class=\"mw-headline\" id=\"Minimizing_synchronization\">Minimizing synchronization</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=3\" title=\"Edit section: Minimizing synchronization\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>One of the challenges for exascale algorithm design is to minimize or reduce synchronization. \nSynchronization takes more time than computation, especially in distributed computing. Reducing synchronization drew attention from computer scientists for decades. Whereas it becomes an increasingly significant problem recently as the gap between the improvement of computing and latency increases. Experiments have shown that (global) communications due to synchronization on a distributed computers takes a dominated share in a sparse iterative solver.<sup id=\"cite_ref-2\" class=\"reference\"><a href=\"#cite_note-2\">&#91;2&#93;</a></sup> This problem is receiving increasing attention after the emergence of a new benchmark metric,the High Performance Conjugate Gradient(HPCG),<sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">&#91;3&#93;</a></sup> for ranking the top 500 supercomputers.\n</p>\n<h3><span class=\"mw-headline\" id=\"Classic_problems_of_synchronization\">Classic problems of synchronization</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=4\" title=\"Edit section: Classic problems of synchronization\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>The following are some classic problems of synchronization:\n</p>\n<ul><li><a href=\"/wiki/Producer%E2%80%93consumer_problem\" title=\"Producer\u2013consumer problem\">The Producer\u2013Consumer Problem</a> (also called The Bounded Buffer Problem);</li>\n<li><a href=\"/wiki/Readers%E2%80%93writers_problem\" title=\"Readers\u2013writers problem\">The Readers\u2013Writers Problem</a>;</li>\n<li><a href=\"/wiki/Dining_philosophers_problem\" title=\"Dining philosophers problem\">The Dining Philosophers Problem</a>.</li></ul>\n<p>These problems are used to test nearly every newly proposed synchronization scheme or primitive.\n</p>\n<h3><span class=\"mw-headline\" id=\"Hardware_synchronization\">Hardware synchronization</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=5\" title=\"Edit section: Hardware synchronization\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Many systems provide hardware support for <a href=\"/wiki/Critical_section\" title=\"Critical section\">critical section</a> code.\n</p><p>A single processor or <a href=\"/wiki/Uniprocessor_system\" title=\"Uniprocessor system\">uniprocessor system</a> could disable <a href=\"/wiki/Interrupt\" title=\"Interrupt\">interrupts</a> by executing currently running code without <a href=\"/wiki/Preemption_(computing)\" title=\"Preemption (computing)\">preemption</a>, which is very inefficient on <a href=\"/wiki/Multiprocessing\" title=\"Multiprocessing\">multiprocessor</a> systems.<sup id=\"cite_ref-Wiley2014_4-0\" class=\"reference\"><a href=\"#cite_note-Wiley2014-4\">&#91;4&#93;</a></sup>\n\"The key ability we require to implement synchronization in a multiprocessor is a set of hardware primitives with the ability to atomically read and modify a memory location. Without such a capability, the cost of building basic synchronization primitives will be too high and will increase as the processor count increases. There are a number of alternative formulations of the basic hardware primitives, all of which provide the ability to atomically read and modify a location, together with some way to tell if the read and write were performed atomically. These hardware primitives are the basic building blocks that are used to build a wide variety of user-level synchronization operations, including things such as <a href=\"/wiki/Lock_(computer_science)\" title=\"Lock (computer science)\">locks</a> and <a href=\"/wiki/Barrier_(computer_science)\" title=\"Barrier (computer science)\">barriers</a>. In general, architects do not expect users to employ the basic hardware primitives, but instead expect that the primitives will be used by system programmers to build a synchronization library, a process that is often complex and tricky.\"<sup id=\"cite_ref-Morgan2011_5-0\" class=\"reference\"><a href=\"#cite_note-Morgan2011-5\">&#91;5&#93;</a></sup> Many modern hardware provides special atomic hardware instructions by either <a href=\"/wiki/Test-and-set\" title=\"Test-and-set\">test-and-set</a> the memory word or <a href=\"/wiki/Compare-and-swap\" title=\"Compare-and-swap\">compare-and-swap</a> contents of two memory words.\n</p>\n<h3><span class=\"mw-headline\" id=\"Synchronization_strategies_in_programming_languages\">Synchronization strategies in programming languages</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=6\" title=\"Edit section: Synchronization strategies in programming languages\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>In <a href=\"/wiki/Java_(programming_language)\" title=\"Java (programming language)\">Java</a>, to prevent thread interference and memory consistency errors, blocks of code are wrapped into <b>synchronized</b> <i>(lock_object)</i> sections. This forces any thread to acquire the said lock object before it can execute the block. The lock is automatically released when the thread which acquired the lock, and is then executing the block, leaves the block or enters the waiting state within the block. Any variable updates, made by a thread in a synchronized block, become visible to other threads when they similarly acquire the lock and execute the block.\n</p><p>Java <i>synchronized</i> blocks, in addition to enabling mutual exclusion and memory consistency,  enable signaling\u2014i.e., sending events from threads which have acquired the lock and are executing the code block to those which are waiting for the lock within the block. This means that Java synchronized sections combine functionality of mutexes and events. Such primitive is known as <a href=\"/wiki/Monitor_(synchronization)\" title=\"Monitor (synchronization)\">synchronization monitor</a>.\n</p><p>Any object may be used as a lock/monitor in Java. The declaring object is a lock object when the whole method is marked with <i>synchronized</i>.\n</p><p>The <a href=\"/wiki/.NET_framework\" class=\"mw-redirect\" title=\".NET framework\">.NET framework</a> has synchronization primitives. \"Synchronization is designed to be cooperative, demanding that every thread or process follow the synchronization mechanism before accessing protected resources (critical section) for consistent results.\" In .NET, locking, signaling, lightweight synchronization types, spinwait and interlocked operations are some of mechanisms related to synchronization.<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;6&#93;</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Implementation_of_Synchronization\">Implementation of Synchronization</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=7\" title=\"Edit section: Implementation of Synchronization\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<h4><span class=\"mw-headline\" id=\"Spinlock\">Spinlock</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=8\" title=\"Edit section: Spinlock\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">Main article: <a href=\"/wiki/Spinlock\" title=\"Spinlock\">Spinlock</a></div>\n<p>Another effective way of implementing synchronization is by using spinlocks. Before accessing any shared resource or piece of code, every processor checks a flag. If the flag is reset, then the processor sets the flag and continues executing the thread. But, if the flag is set (locked), the threads would keep spinning in a loop and keep checking if the flag is set or not. But, spinlocks are effective only if the flag is reset for lower cycles otherwise it can lead to performance issues as it wastes many processor cycles waiting.<sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">&#91;7&#93;</a></sup>\n</p>\n<h4><span class=\"mw-headline\" id=\"Barriers\">Barriers</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=9\" title=\"Edit section: Barriers\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">Main article: <a href=\"/wiki/Barrier_(computer_science)\" title=\"Barrier (computer science)\">Barrier_(computer_science)</a></div>\n<p>Barriers are simple to implement and provide good responsiveness. They are based on the concept of implementing wait cycles to provide synchronization. Consider three threads running simultaneously, starting from barrier 1. After time t, thread1 reaches barrier 2 but it still has to wait for thread 2 and 3 to reach barrier2 as it does not have the correct data. Once all the threads reach barrier 2 they all start again. After time t, thread 1 reaches barrier3 but it will have to wait for threads 2 and 3 and the correct data again.\n</p><p>Thus, in barrier synchronization of multiple threads there will always be a few threads that will end up waiting for other threads as in the above example thread 1 keeps waiting for thread 2 and 3. This results in severe degradation of the process performance.<sup id=\"cite_ref-:0_8-0\" class=\"reference\"><a href=\"#cite_note-:0-8\">&#91;8&#93;</a></sup>\n</p><p>The barrier synchronization wait function for i<sup>th</sup> thread can be represented as:\n</p><p>(Wbarrier)i = f ((Tbarrier)i, (Rthread)i)\n</p><p>Where Wbarrier is the wait time for a thread, Tbarrier is the number of threads has arrived, and Rthread is the arrival rate of threads.<sup id=\"cite_ref-9\" class=\"reference\"><a href=\"#cite_note-9\">&#91;9&#93;</a></sup>\n</p><p>Experiments show that 34% of the total execution time is spent in waiting for other slower threads.<sup id=\"cite_ref-:0_8-1\" class=\"reference\"><a href=\"#cite_note-:0-8\">&#91;8&#93;</a></sup>\n</p>\n<h4><span class=\"mw-headline\" id=\"Semaphores\">Semaphores</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=10\" title=\"Edit section: Semaphores\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">Main article: <a href=\"/wiki/Semaphore_(programming)\" title=\"Semaphore (programming)\">Semaphore_(programming)</a></div>\n<p>Semaphores are signalling mechanisms which can allow one or more threads/processors to access a section. A Semaphore has a flag which has a certain fixed value associated with it and each time a thread wishes to access the section, it decrements the flag. Similarly, when the thread leaves the section, the flag is incremented. If the flag is zero, the thread cannot access the section and gets blocked if it chooses to wait.\n</p><p>Some semaphores would allow only one thread or process in the code section. Such Semaphores are called binary semaphore and are very similar to Mutex. Here, if the value of semaphore is 1, the thread is allowed to access and if the value is 0, the access is denied.<sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">&#91;10&#93;</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Mathematical_foundations\">Mathematical foundations</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=11\" title=\"Edit section: Mathematical foundations\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Synchronization was originally a process-based concept whereby a lock could be obtained on an object. Its primary usage was in databases. There are two types of (file) <a href=\"/wiki/File_locking\" title=\"File locking\">lock</a>; read-only and read\u2013write. Read-only locks may be obtained by many processes or threads. Readers\u2013writer locks are exclusive, as they may only be used by a single process/thread at a time.\n</p><p>Although locks were derived for file databases, data is also shared in memory between processes and threads. Sometimes more than one object (or file) is locked at a time. If they are not locked simultaneously they can overlap, causing a deadlock exception.\n</p><p><a href=\"/wiki/Java_(programming_language)\" title=\"Java (programming language)\">Java</a> and <a href=\"/wiki/Ada_(programming_language)\" title=\"Ada (programming language)\">Ada</a> only have exclusive locks because they are thread based and rely on the <a href=\"/wiki/Compare-and-swap\" title=\"Compare-and-swap\">compare-and-swap</a> processor instruction.\n</p><p>An abstract mathematical foundation for synchronization primitives is given by the <a href=\"/wiki/History_monoid\" title=\"History monoid\">history monoid</a>. There are also many higher-level theoretical devices, such as <a href=\"/wiki/Process_calculi\" class=\"mw-redirect\" title=\"Process calculi\">process calculi</a> and <a href=\"/wiki/Petri_net\" title=\"Petri net\">Petri nets</a>, which can be built on top of the history monoid.\n</p>\n<h3><span class=\"mw-headline\" id=\"Synchronization_examples\">Synchronization examples</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=12\" title=\"Edit section: Synchronization examples\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Following are some synchronization examples with respect to different platforms.<sup id=\"cite_ref-Wiley2012_11-0\" class=\"reference\"><a href=\"#cite_note-Wiley2012-11\">&#91;11&#93;</a></sup>\n</p>\n<h4><span class=\"mw-headline\" id=\"Synchronization_in_Windows\">Synchronization in Windows</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=13\" title=\"Edit section: Synchronization in Windows\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/Windows\" class=\"mw-redirect\" title=\"Windows\">Windows</a> provides:\n</p>\n<ul><li><a href=\"/wiki/Interrupt\" title=\"Interrupt\">interrupt masks</a>, which protect access to global resources (critical section) on uniprocessor systems;</li>\n<li><a href=\"/wiki/Spinlock\" title=\"Spinlock\">spinlocks</a>, which prevent, in multiprocessor systems, spinlocking-thread from being preempted;</li>\n<li><a href=\"/wiki/Dispatcher\" title=\"Dispatcher\">dispatchers</a>, which act like <a href=\"/wiki/Mutual_exclusion\" title=\"Mutual exclusion\">mutexes</a>, <a href=\"/wiki/Semaphore_(programming)\" title=\"Semaphore (programming)\">semaphores</a>, <a href=\"/wiki/Event_(computing)\" title=\"Event (computing)\">events</a>, and <a href=\"/wiki/Timer\" title=\"Timer\">timers</a>.</li></ul>\n<h4><span class=\"mw-headline\" id=\"Synchronization_in_Linux\">Synchronization in Linux</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=14\" title=\"Edit section: Synchronization in Linux\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/Linux\" title=\"Linux\">Linux</a> provides:\n</p>\n<ul><li><a href=\"/wiki/Semaphore_(programming)\" title=\"Semaphore (programming)\">semaphores</a>;</li>\n<li><a href=\"/wiki/Spinlock\" title=\"Spinlock\">spinlock</a>;</li>\n<li><a href=\"/wiki/Barrier_(computer_science)\" title=\"Barrier (computer science)\">barriers</a></li>\n<li><a href=\"/wiki/Mutual_exclusion\" title=\"Mutual exclusion\">mutex</a></li>\n<li><a href=\"/wiki/Readers%E2%80%93writer_lock\" title=\"Readers\u2013writer lock\">readers\u2013writer locks</a>, for the longer section of codes which are accessed very frequently but don't change very often.</li>\n<li><a href=\"/wiki/Read-copy-update\" title=\"Read-copy-update\">Read-copy-update</a> (RCU) <sup id=\"cite_ref-12\" class=\"reference\"><a href=\"#cite_note-12\">&#91;12&#93;</a></sup></li></ul>\n<p>Enabling and disabling of kernel preemption replaced spinlocks on uniprocessor systems. Prior to kernel version 2.6, <a href=\"/wiki/Linux\" title=\"Linux\">Linux</a> disabled interrupt to implement short critical sections. Since version 2.6 and later, Linux is fully preemptive.\n</p>\n<h4><span class=\"mw-headline\" id=\"Synchronization_in_Solaris\">Synchronization in Solaris</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=15\" title=\"Edit section: Synchronization in Solaris\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/Solaris_(operating_system)\" title=\"Solaris (operating system)\">Solaris</a> provides:\n</p>\n<ul><li><a href=\"/wiki/Semaphore_(programming)\" title=\"Semaphore (programming)\">semaphores</a>;</li>\n<li><a href=\"/wiki/Condition_variable\" class=\"mw-redirect\" title=\"Condition variable\">condition variables</a>;</li>\n<li><a href=\"/w/index.php?title=Adaptive_mutex&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"Adaptive mutex (page does not exist)\">adaptive mutexes</a>, binary semaphores that are implemented differently depending upon the conditions;</li>\n<li>readers\u2013writer locks:</li>\n<li><a href=\"/wiki/Turnstiles\" class=\"mw-redirect\" title=\"Turnstiles\">turnstiles</a>, queue of threads which are waiting on acquired lock.<sup id=\"cite_ref-13\" class=\"reference\"><a href=\"#cite_note-13\">&#91;13&#93;</a></sup></li></ul>\n<h4><span class=\"mw-headline\" id=\"Pthreads_synchronization\">Pthreads synchronization</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=16\" title=\"Edit section: Pthreads synchronization\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/Pthreads\" class=\"mw-redirect\" title=\"Pthreads\">Pthreads</a> is a platform-independent <a href=\"/wiki/API\" class=\"mw-redirect\" title=\"API\">API</a> that provides:\n</p>\n<ul><li>mutexes;</li>\n<li>condition variables;</li>\n<li>readers\u2013writer locks;</li>\n<li>spinlocks;</li>\n<li><a href=\"/wiki/Barrier_(computer_science)\" title=\"Barrier (computer science)\">barriers</a>.</li></ul>\n<h2><span class=\"mw-headline\" id=\"Data_synchronization\">Data synchronization</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=17\" title=\"Edit section: Data synchronization\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div role=\"note\" class=\"hatnote navigation-not-searchable\">Main article: <a href=\"/wiki/Data_synchronization\" title=\"Data synchronization\">Data synchronization</a></div>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:192px;\"><a href=\"/wiki/File:Data_Synchronization.png\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/d/dc/Data_Synchronization.png\" width=\"190\" height=\"255\" class=\"thumbimage\" data-file-width=\"190\" data-file-height=\"255\" /></a>  <div class=\"thumbcaption\"><div class=\"magnify\"><a href=\"/wiki/File:Data_Synchronization.png\" class=\"internal\" title=\"Enlarge\"></a></div><b>Figure 3: </b>Changes from both server and client(s) are synchronized.</div></div></div>\n<p>A distinctly different (but related) concept is that of <a href=\"/wiki/Data_synchronization\" title=\"Data synchronization\">data synchronization</a>. This refers to the need to keep multiple copies of a set of data coherent with one another or to maintain <a href=\"/wiki/Data_integrity\" title=\"Data integrity\">data integrity</a>, Figure 3. For example, database replication is used to keep multiple copies of data synchronized with database servers that store data in different locations.\n</p><p>Examples include:\n</p>\n<ul><li><a href=\"/wiki/File_synchronization\" title=\"File synchronization\">File synchronization</a>, such as syncing a hand-held MP3 player to a desktop computer;</li>\n<li><a href=\"/wiki/Cluster_file_system\" class=\"mw-redirect\" title=\"Cluster file system\">Cluster file systems</a>, which are <a href=\"/wiki/File_system\" title=\"File system\">file systems</a> that maintain data or indexes in a coherent fashion across a whole <a href=\"/wiki/Computing_cluster\" class=\"mw-redirect\" title=\"Computing cluster\">computing cluster</a>;</li>\n<li><a href=\"/wiki/Cache_coherency\" class=\"mw-redirect\" title=\"Cache coherency\">Cache coherency</a>, maintaining multiple copies of data in sync across multiple <a href=\"/wiki/Cache_(computing)\" title=\"Cache (computing)\">caches</a>;</li>\n<li><a href=\"/wiki/RAID\" title=\"RAID\">RAID</a>, where data is written in a redundant fashion across multiple disks, so that the loss of any one disk does not lead to a loss of data;</li>\n<li><a href=\"/wiki/Database_replication\" class=\"mw-redirect\" title=\"Database replication\">Database replication</a>, where copies of data on a <a href=\"/wiki/Database\" title=\"Database\">database</a> are kept in sync, despite possible large geographical separation;</li>\n<li><a href=\"/wiki/Journaling_file_system\" title=\"Journaling file system\">Journaling</a>, a technique used by many modern file systems to make sure that file metadata are updated on a disk in a coherent, consistent manner.</li></ul>\n<h3><span class=\"mw-headline\" id=\"Challenges_in_data_synchronization\">Challenges in data synchronization</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=18\" title=\"Edit section: Challenges in data synchronization\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Some of the challenges which user may face in data synchronization:\n</p>\n<ul><li>data formats complexity;</li>\n<li>real-timeliness;</li>\n<li>data security;</li>\n<li>data quality;</li>\n<li>performance.</li></ul>\n<h4><span class=\"mw-headline\" id=\"Data_formats_complexity\">Data formats complexity</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=19\" title=\"Edit section: Data formats complexity\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Data formats tend to grow more complex with time as the organization grows and evolves. This results not only in building simple interfaces between the two applications (source and target), but also in a need to transform the data while passing them to the target application. <a href=\"/wiki/Extract,_transform,_load\" title=\"Extract, transform, load\">ETL</a> (extraction transformation loading) tools can be helpful at this stage for managing data format complexities.\n</p>\n<h4><span class=\"mw-headline\" id=\"Real-timeliness\">Real-timeliness</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=20\" title=\"Edit section: Real-timeliness\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>In real-time systems, customers want to see the current status of their order in e-shop, the current status of a parcel delivery\u2014a real time parcel tracking\u2014, the current balance on their account, etc. This shows the need of a real-time system, which is being updated as well to enable smooth manufacturing process in real-time, e.g., ordering material when enterprise is running out stock, synchronizing customer orders with manufacturing process, etc. From real life, there exist so many examples where real-time processing gives successful and competitive advantage.\n</p>\n<h4><span class=\"mw-headline\" id=\"Data_security\">Data security</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=21\" title=\"Edit section: Data security\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>There are no fixed rules and policies to enforce data security. It may vary depending on the system which you are using. Even though the security is maintained correctly in the source system which captures the data, the security and information access privileges must be enforced on the target systems as well to prevent any potential misuse of the information. This is a serious issue and particularly when it comes for handling secret, confidential and personal information. So because of the sensitivity and confidentiality, data transfer and all in-between information must be encrypted.\n</p>\n<h4><span class=\"mw-headline\" id=\"Data_quality\">Data quality</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=22\" title=\"Edit section: Data quality\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Data quality is another serious constraint. For better management and to maintain good quality of data, the common practice is to store the data at one location and share with different people and different systems and/or applications from different locations. It helps in preventing inconsistencies in the data.\n</p>\n<h4><span class=\"mw-headline\" id=\"Performance\">Performance</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=23\" title=\"Edit section: Performance\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>There are five different phases involved in the data synchronization process:\n</p>\n<ul><li><a href=\"/wiki/Data_extraction\" title=\"Data extraction\">data extraction</a> from the source (or master, or main) system;</li>\n<li><a href=\"/wiki/Data_transfer\" class=\"mw-redirect\" title=\"Data transfer\">data transfer</a>;</li>\n<li><a href=\"/wiki/Data_transformation\" title=\"Data transformation\">data transformation</a>;</li>\n<li>data load to the target system.</li>\n<li>data updation</li></ul>\n<p>Each of these steps is critical. In case of large amounts of data, the synchronization process needs to be carefully planned and executed to avoid any negative impact on performance.\n</p>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=24\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a href=\"/wiki/Futures_and_promises\" title=\"Futures and promises\">Futures and promises</a>, synchronization mechanisms in pure functional paradigms</li></ul>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=25\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap mw-references-columns\"><ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation conference\">Gramoli, V. (2015). <a rel=\"nofollow\" class=\"external text\" href=\"http://sydney.edu.au/engineering/it/~gramoli/doc/pubs/gramoli-synchrobench.pdf\"><i>More than you ever wanted to know about synchronization: Synchrobench, measuring the impact of the synchronization on concurrent algorithms</i></a> <span style=\"font-size:85%;\">(PDF)</span>. Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming. ACM. pp.&#160;1\u201310.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=More+than+you+ever+wanted+to+know+about+synchronization%3A+Synchrobench%2C+measuring+the+impact+of+the+synchronization+on+concurrent+algorithms&amp;rft.pages=1-10&amp;rft.pub=ACM&amp;rft.date=2015&amp;rft.au=Gramoli%2C+V.&amp;rft_id=http%3A%2F%2Fsydney.edu.au%2Fengineering%2Fit%2F~gramoli%2Fdoc%2Fpubs%2Fgramoli-synchrobench.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-2\">^</a></b></span> <span class=\"reference-text\">\n<cite class=\"citation journal\">Shengxin, Zhu and Tongxiang Gu and Xingping Liu (2014). \"Minimizing synchronizations in sparse iterative solvers for distributed supercomputers\". <i>Computers &amp; Mathematics with Applications</i>. ELSEVIER. <b>67</b> (1): 199\u2013209. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1016/j.camwa.2013.11.008\">10.1016/j.camwa.2013.11.008</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computers+%26+Mathematics+with+Applications&amp;rft.atitle=Minimizing+synchronizations+in+sparse+iterative+solvers+for+distributed+supercomputers&amp;rft.volume=67&amp;rft.issue=1&amp;rft.pages=199-209&amp;rft.date=2014&amp;rft_id=info%3Adoi%2F10.1016%2Fj.camwa.2013.11.008&amp;rft.au=Shengxin%2C+Zhu+and+Tongxiang+Gu+and+Xingping+Liu&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\">\n{ {\n | url=<a rel=\"nofollow\" class=\"external free\" href=\"http://hpcg-benchmark.org/\">http://hpcg-benchmark.org/</a>\n}\n}</span>\n</li>\n<li id=\"cite_note-Wiley2014-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Wiley2014_4-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation book\">Silberschatz, Abraham; Gagne, Greg; Galvin, Peter Baer (July 11, 2008). \"Chapter 6: Process Synchronization\". <i>Operating System Concepts</i> (Eighth ed.). John Wiley &amp; Sons. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-0-470-12872-5\" title=\"Special:BookSources/978-0-470-12872-5\">978-0-470-12872-5</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Chapter+6%3A+Process+Synchronization&amp;rft.btitle=Operating+System+Concepts&amp;rft.edition=Eighth&amp;rft.pub=John+Wiley+%26+Sons.&amp;rft.date=2008-07-11&amp;rft.isbn=978-0-470-12872-5&amp;rft.aulast=Silberschatz&amp;rft.aufirst=Abraham&amp;rft.au=Gagne%2C+Greg&amp;rft.au=Galvin%2C+Peter+Baer&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-Morgan2011-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Morgan2011_5-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation book\">Hennessy, John L.; Patterson, David A. (September 30, 2011). \"Chapter 5: Thread-Level Parallelism\". <i>Computer Architecture: A Quantitative Approach</i> (Fifth ed.). Morgan Kaufmann. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-0-123-83872-8\" title=\"Special:BookSources/978-0-123-83872-8\">978-0-123-83872-8</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Chapter+5%3A+Thread-Level+Parallelism&amp;rft.btitle=Computer+Architecture%3A+A+Quantitative+Approach&amp;rft.edition=Fifth&amp;rft.pub=Morgan+Kaufmann&amp;rft.date=2011-09-30&amp;rft.isbn=978-0-123-83872-8&amp;rft.aulast=Hennessy&amp;rft.aufirst=John+L.&amp;rft.au=Patterson%2C+David+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a rel=\"nofollow\" class=\"external text\" href=\"http://msdn.microsoft.com/en-us/library/ms228964%28v=vs.110%29.aspx\">\"Synchronization Primitives in .NET framework\"</a>. <i>MSDN, The Microsoft Developer Network</i>. Microsoft<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">23 November</span> 2014</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MSDN%2C+The+Microsoft+Developer+Network&amp;rft.atitle=Synchronization+Primitives+in+.NET+framework&amp;rft_id=http%3A%2F%2Fmsdn.microsoft.com%2Fen-us%2Flibrary%2Fms228964%2528v%3Dvs.110%2529.aspx&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation book\">Massa, Anthony (2003). <i>Embedded Software Development with ECos</i>. Pearson Education Inc. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-_13-035473-2\" title=\"Special:BookSources/0- 13-035473-2\">0- 13-035473-2</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Embedded+Software+Development+with+ECos&amp;rft.pub=Pearson+Education+Inc&amp;rft.date=2003&amp;rft.isbn=0-13-035473-2&amp;rft.aulast=Massa&amp;rft.aufirst=Anthony&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-:0-8\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:0_8-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:0_8-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation journal\">Meng, Chen, Pan, Yao, Wu, Jinglei, Tianzhou, Ping, Jun. Minghui (2014). \"A speculative mechanism for barrier sychronization\". <i>2014 IEEE International Conference on High Performance Computing and Communications (HPCC), 2014 IEEE 6th International Symposium on Cyberspace Safety and Security (CSS) and 2014 IEEE 11th International Conference on Embedded Software and Systems (ICESS)</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=2014+IEEE+International+Conference+on+High+Performance+Computing+and+Communications+%28HPCC%29%2C+2014+IEEE+6th+International+Symposium+on+Cyberspace+Safety+and+Security+%28CSS%29+and+2014+IEEE+11th+International+Conference+on+Embedded+Software+and+Systems+%28ICESS%29&amp;rft.atitle=A+speculative+mechanism+for+barrier+sychronization&amp;rft.date=2014&amp;rft.aulast=Meng%2C+Chen%2C+Pan%2C+Yao%2C+Wu&amp;rft.aufirst=Jinglei%2C+Tianzhou%2C+Ping%2C+Jun.+Minghui&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span><span class=\"citation-comment\" style=\"display:none; color:#33aa33; margin-left:0.3em\">CS1 maint: Multiple names: authors list (<a href=\"/wiki/Category:CS1_maint:_Multiple_names:_authors_list\" title=\"Category:CS1 maint: Multiple names: authors list\">link</a>) </span></span>\n</li>\n<li id=\"cite_note-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-9\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">M. M., Rahman (2012). <a rel=\"nofollow\" class=\"external text\" href=\"http://ieeexplore.ieee.org.prox.lib.ncsu.edu/stamp/stamp.jsp?tp=&amp;arnumber=6317471&amp;isnumber=6317321\">\"Process synchronization in multiprocessor and multi-core processor\"</a>. <i>Informatics, Electronics &amp; Vision (ICIEV), 2012 International Conference</i>. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a rel=\"nofollow\" class=\"external text\" href=\"//doi.org/10.1109/ICIEV.2012.6317471\">10.1109/ICIEV.2012.6317471</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Informatics%2C+Electronics+%26+Vision+%28ICIEV%29%2C+2012+International+Conference&amp;rft.atitle=Process+synchronization+in+multiprocessor+and+multi-core+processor&amp;rft.date=2012&amp;rft_id=info%3Adoi%2F10.1109%2FICIEV.2012.6317471&amp;rft.aulast=M.+M.&amp;rft.aufirst=Rahman&amp;rft_id=http%3A%2F%2Fieeexplore.ieee.org.prox.lib.ncsu.edu%2Fstamp%2Fstamp.jsp%3Ftp%3D%26arnumber%3D6317471%26isnumber%3D6317321&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation book\">Li, Yao, Qing, Carolyn (2003). <i>Real-Time Concepts for Embedded Systems</i>. CMP Books. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/1578201241\" title=\"Special:BookSources/1578201241\">1578201241</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Real-Time+Concepts+for+Embedded+Systems&amp;rft.pub=CMP+Books&amp;rft.date=2003&amp;rft.isbn=1578201241&amp;rft.aulast=Li%2C+Yao&amp;rft.aufirst=Qing%2C+Carolyn&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-Wiley2012-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Wiley2012_11-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation book\">Silberschatz, Abraham; Gagne, Greg; Galvin, Peter Baer (December 7, 2012). \"Chapter 5: Process Synchronization\". <i>Operating System Concepts</i> (Ninth ed.). John Wiley &amp; Sons. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/978-1-118-06333-0\" title=\"Special:BookSources/978-1-118-06333-0\">978-1-118-06333-0</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Chapter+5%3A+Process+Synchronization&amp;rft.btitle=Operating+System+Concepts&amp;rft.edition=Ninth&amp;rft.pub=John+Wiley+%26+Sons.&amp;rft.date=2012-12-07&amp;rft.isbn=978-1-118-06333-0&amp;rft.aulast=Silberschatz&amp;rft.aufirst=Abraham&amp;rft.au=Gagne%2C+Greg&amp;rft.au=Galvin%2C+Peter+Baer&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a rel=\"nofollow\" class=\"external text\" href=\"https://lwn.net/Articles/262464/\">\"What is RCU, Fundamentally? &#91;LWN.net&#93;\"</a>. <i>lwn.net</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=lwn.net&amp;rft.atitle=What+is+RCU%2C+Fundamentally%3F+%5BLWN.net%5D&amp;rft_id=https%3A%2F%2Flwn.net%2FArticles%2F262464%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n<li id=\"cite_note-13\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-13\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\">Mauro, Jim. <a rel=\"nofollow\" class=\"external text\" href=\"http://sunsite.uakom.sk/sunworldonline/swol-08-1999/swol-08-insidesolaris.html\">\"Turnstiles and priority inheritance - SunWorld - August 1999\"</a>. <i>sunsite.uakom.sk</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=sunsite.uakom.sk&amp;rft.atitle=Turnstiles+and+priority+inheritance+-+SunWorld+-+August+1999&amp;rft.aulast=Mauro&amp;rft.aufirst=Jim&amp;rft_id=http%3A%2F%2Fsunsite.uakom.sk%2Fsunworldonline%2Fswol-08-1999%2Fswol-08-insidesolaris.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></span>\n</li>\n</ol></div></div>\n<ul><li><cite class=\"citation book\">Schneider, Fred B. (1997). <i>On concurrent programming</i>. Springer-Verlag New York, Inc. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>&#160;<a href=\"/wiki/Special:BookSources/0-387-94942-9\" title=\"Special:BookSources/0-387-94942-9\">0-387-94942-9</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=On+concurrent+programming&amp;rft.pub=Springer-Verlag+New+York%2C+Inc.&amp;rft.date=1997&amp;rft.isbn=0-387-94942-9&amp;rft.aulast=Schneider&amp;rft.aufirst=Fred+B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASynchronization+%28computer+science%29\" class=\"Z3988\"><span style=\"display:none;\">&#160;</span></span></li></ul>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=26\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20090209170415/http://ibm.com/developerworks/linux/library/l-linux-synchronization.html\">Anatomy of Linux synchronization methods</a> at IBM developerWorks</li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://greenteapress.com/semaphores/\"><i>The Little Book of Semaphores</i></a>, by Allen B. Downey</li></ul>\n<div role=\"navigation\" class=\"navbox\" aria-labelledby=\"Parallel_computing\" style=\"padding:3px\"><table class=\"nowraplinks hlist collapsible autocollapse navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\"><div class=\"plainlinks hlist navbar mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Parallel_computing\" title=\"Template:Parallel computing\"><abbr title=\"View this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Parallel_computing\" title=\"Template talk:Parallel computing\"><abbr title=\"Discuss this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Template:Parallel_computing&amp;action=edit\"><abbr title=\"Edit this template\" style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\">e</abbr></a></li></ul></div><div id=\"Parallel_computing\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Parallel_computing\" title=\"Parallel computing\">Parallel computing</a></div></th></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">General</th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Distributed_computing\" title=\"Distributed computing\">Distributed computing</a></li>\n<li><a href=\"/wiki/Parallel_computing\" title=\"Parallel computing\">Parallel computing</a></li>\n<li><a href=\"/wiki/Massively_parallel\" title=\"Massively parallel\">Massively parallel</a></li>\n<li><a href=\"/wiki/Cloud_computing\" title=\"Cloud computing\">Cloud computing</a></li>\n<li><a href=\"/wiki/Supercomputer\" title=\"Supercomputer\">High-performance computing</a></li>\n<li><a href=\"/wiki/Multiprocessing\" title=\"Multiprocessing\">Multiprocessing</a></li>\n<li><a href=\"/wiki/Manycore_processor\" title=\"Manycore processor\">Manycore processor</a></li>\n<li><a href=\"/wiki/General-purpose_computing_on_graphics_processing_units\" title=\"General-purpose computing on graphics processing units\">GPGPU</a></li>\n<li><a href=\"/wiki/Computer_network\" title=\"Computer network\">Computer network</a></li>\n<li><a href=\"/wiki/Systolic_array\" title=\"Systolic array\">Systolic array</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Levels</th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Bit-level_parallelism\" title=\"Bit-level parallelism\">Bit</a></li>\n<li><a href=\"/wiki/Instruction-level_parallelism\" title=\"Instruction-level parallelism\">Instruction</a></li>\n<li><a href=\"/wiki/Task_parallelism\" title=\"Task parallelism\">Thread</a></li>\n<li><a href=\"/wiki/Task_parallelism\" title=\"Task parallelism\">Task</a></li>\n<li><a href=\"/wiki/Data_parallelism\" title=\"Data parallelism\">Data</a></li>\n<li><a href=\"/wiki/Memory-level_parallelism\" title=\"Memory-level parallelism\">Memory</a></li>\n<li><a href=\"/wiki/Loop-level_parallelism\" title=\"Loop-level parallelism\">Loop</a></li>\n<li><a href=\"/wiki/Pipeline_(computing)\" title=\"Pipeline (computing)\">Pipeline</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Multithreading_(computer_architecture)\" title=\"Multithreading (computer architecture)\">Multithreading</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Temporal_multithreading\" title=\"Temporal multithreading\">Temporal</a></li>\n<li><a href=\"/wiki/Simultaneous_multithreading\" title=\"Simultaneous multithreading\">Simultaneous</a> (SMT)</li>\n<li><a href=\"/wiki/Speculative_multithreading\" title=\"Speculative multithreading\">Speculative</a> (SpMT)</li>\n<li><a href=\"/wiki/Preemption_(computing)\" title=\"Preemption (computing)\">Preemptive</a></li>\n<li><a href=\"/wiki/Computer_multitasking#Cooperative_multitasking\" title=\"Computer multitasking\">Cooperative</a></li>\n<li><a href=\"/wiki/Bulldozer_(microarchitecture)#Bulldozer_core\" title=\"Bulldozer (microarchitecture)\">Clustered Multi-Thread</a> (CMT)</li>\n<li><a href=\"/wiki/Hardware_scout\" title=\"Hardware scout\">Hardware scout</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Theory</th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Parallel_random-access_machine\" title=\"Parallel random-access machine\">PRAM model</a></li>\n<li><a href=\"/wiki/Analysis_of_parallel_algorithms\" title=\"Analysis of parallel algorithms\">Analysis of parallel algorithms</a></li>\n<li><a href=\"/wiki/Amdahl%27s_law\" title=\"Amdahl&#39;s law\">Amdahl's law</a></li>\n<li><a href=\"/wiki/Gustafson%27s_law\" title=\"Gustafson&#39;s law\">Gustafson's law</a></li>\n<li><a href=\"/wiki/Cost_efficiency\" title=\"Cost efficiency\">Cost efficiency</a></li>\n<li><a href=\"/wiki/Karp%E2%80%93Flatt_metric\" title=\"Karp\u2013Flatt metric\">Karp\u2013Flatt metric</a></li>\n<li><a href=\"/wiki/Parallel_slowdown\" title=\"Parallel slowdown\">Slowdown</a></li>\n<li><a href=\"/wiki/Speedup\" title=\"Speedup\">Speedup</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Elements</th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Process_(computing)\" title=\"Process (computing)\">Process</a></li>\n<li><a href=\"/wiki/Thread_(computing)\" title=\"Thread (computing)\">Thread</a></li>\n<li><a href=\"/wiki/Fiber_(computer_science)\" title=\"Fiber (computer science)\">Fiber</a></li>\n<li><a href=\"/wiki/Instruction_window\" title=\"Instruction window\">Instruction window</a></li>\n<li><a href=\"/wiki/Array_data_structure\" title=\"Array data structure\">Array data structure</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Coordination</th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Multiprocessing\" title=\"Multiprocessing\">Multiprocessing</a></li>\n<li><a href=\"/wiki/Memory_coherence\" title=\"Memory coherence\">Memory coherency</a></li>\n<li><a href=\"/wiki/Cache_coherence\" title=\"Cache coherence\">Cache coherency</a></li>\n<li><a href=\"/wiki/Cache_invalidation\" title=\"Cache invalidation\">Cache invalidation</a></li>\n<li><a href=\"/wiki/Barrier_(computer_science)\" title=\"Barrier (computer science)\">Barrier</a></li>\n<li><a class=\"mw-selflink selflink\">Synchronization</a></li>\n<li><a href=\"/wiki/Application_checkpointing\" title=\"Application checkpointing\">Application checkpointing</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Computer_programming\" title=\"Computer programming\">Programming</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Stream_processing\" title=\"Stream processing\">Stream processing</a></li>\n<li><a href=\"/wiki/Dataflow_programming\" title=\"Dataflow programming\">Dataflow programming</a></li>\n<li><a href=\"/wiki/Parallel_programming_model\" title=\"Parallel programming model\">Models</a>\n<ul><li><a href=\"/wiki/Implicit_parallelism\" title=\"Implicit parallelism\">Implicit parallelism</a></li>\n<li><a href=\"/wiki/Explicit_parallelism\" title=\"Explicit parallelism\">Explicit parallelism</a></li>\n<li><a href=\"/wiki/Concurrency_(computer_science)\" title=\"Concurrency (computer science)\">Concurrency</a></li></ul></li>\n<li><a href=\"/wiki/Non-blocking_algorithm\" title=\"Non-blocking algorithm\">Non-blocking algorithm</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Computer_hardware\" title=\"Computer hardware\">Hardware</a></th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Flynn%27s_taxonomy\" title=\"Flynn&#39;s taxonomy\">Flynn's taxonomy</a>\n<ul><li><a href=\"/wiki/SISD\" title=\"SISD\">SISD</a></li>\n<li><a href=\"/wiki/SIMD\" title=\"SIMD\">SIMD</a></li>\n<li><a href=\"/wiki/Single_instruction,_multiple_threads\" title=\"Single instruction, multiple threads\">SIMT</a></li>\n<li><a href=\"/wiki/MISD\" title=\"MISD\">MISD</a></li>\n<li><a href=\"/wiki/MIMD\" title=\"MIMD\">MIMD</a></li></ul></li>\n<li><a href=\"/wiki/Dataflow_architecture\" title=\"Dataflow architecture\">Dataflow architecture</a></li>\n<li><a href=\"/wiki/Instruction_pipelining\" title=\"Instruction pipelining\">Pipelined processor</a></li>\n<li><a href=\"/wiki/Superscalar_processor\" title=\"Superscalar processor\">Superscalar processor</a></li>\n<li><a href=\"/wiki/Vector_processor\" title=\"Vector processor\">Vector processor</a></li>\n<li><a href=\"/wiki/Multiprocessing\" title=\"Multiprocessing\">Multiprocessor</a>\n<ul><li><a href=\"/wiki/Symmetric_multiprocessing\" title=\"Symmetric multiprocessing\">symmetric</a></li>\n<li><a href=\"/wiki/Asymmetric_multiprocessing\" title=\"Asymmetric multiprocessing\">asymmetric</a></li></ul></li>\n<li><a href=\"/wiki/Semiconductor_memory\" title=\"Semiconductor memory\">Memory</a>\n<ul><li><a href=\"/wiki/Shared_memory\" title=\"Shared memory\">shared</a></li>\n<li><a href=\"/wiki/Distributed_memory\" title=\"Distributed memory\">distributed</a></li>\n<li><a href=\"/wiki/Distributed_shared_memory\" title=\"Distributed shared memory\">distributed shared</a></li>\n<li><a href=\"/wiki/Uniform_memory_access\" title=\"Uniform memory access\">UMA</a></li>\n<li><a href=\"/wiki/Non-uniform_memory_access\" title=\"Non-uniform memory access\">NUMA</a></li>\n<li><a href=\"/wiki/Cache-only_memory_architecture\" title=\"Cache-only memory architecture\">COMA</a></li></ul></li>\n<li><a href=\"/wiki/Massively_parallel\" title=\"Massively parallel\">Massively parallel computer</a></li>\n<li><a href=\"/wiki/Computer_cluster\" title=\"Computer cluster\">Computer cluster</a></li>\n<li><a href=\"/wiki/Grid_computing\" title=\"Grid computing\">Grid computer</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\"><a href=\"/wiki/Application_programming_interface\" title=\"Application programming interface\">APIs</a></th><td class=\"navbox-list navbox-odd\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Ateji_PX\" title=\"Ateji PX\">Ateji PX</a></li>\n<li><a href=\"/wiki/Boost_(C%2B%2B_libraries)#Multithreading_\u2013_Boost.Thread\" title=\"Boost (C++ libraries)\">Boost.Thread</a></li>\n<li><a href=\"/wiki/Chapel_(programming_language)\" title=\"Chapel (programming language)\">Chapel</a></li>\n<li><a href=\"/wiki/Charm%2B%2B\" title=\"Charm++\"> Charm++</a></li>\n<li><a href=\"/wiki/Cilk\" title=\"Cilk\">Cilk</a></li>\n<li><a href=\"/wiki/Coarray_Fortran\" title=\"Coarray Fortran\">Coarray Fortran</a></li>\n<li><a href=\"/wiki/CUDA\" title=\"CUDA\">CUDA</a></li>\n<li><a href=\"/wiki/Dryad_(programming)\" title=\"Dryad (programming)\">Dryad</a></li>\n<li><a href=\"/wiki/C%2B%2B_AMP\" title=\"C++ AMP\">C++ AMP</a></li>\n<li><a href=\"/wiki/Global_Arrays\" title=\"Global Arrays\">Global Arrays</a></li>\n<li><a href=\"/wiki/Message_Passing_Interface\" title=\"Message Passing Interface\">MPI</a></li>\n<li><a href=\"/wiki/OpenMP\" title=\"OpenMP\">OpenMP</a></li>\n<li><a href=\"/wiki/OpenCL\" title=\"OpenCL\">OpenCL</a></li>\n<li><a href=\"/wiki/OpenHMPP\" title=\"OpenHMPP\">OpenHMPP</a></li>\n<li><a href=\"/wiki/OpenACC\" title=\"OpenACC\">OpenACC</a></li>\n<li><a href=\"/wiki/Parallel_Extensions#Task_Parallel_Library\" title=\"Parallel Extensions\">TPL</a></li>\n<li><a href=\"/wiki/Parallel_Extensions#PLINQ\" title=\"Parallel Extensions\">PLINQ</a></li>\n<li><a href=\"/wiki/Parallel_Virtual_Machine\" title=\"Parallel Virtual Machine\">PVM</a></li>\n<li><a href=\"/wiki/POSIX_Threads\" title=\"POSIX Threads\">POSIX Threads</a></li>\n<li><a href=\"/wiki/RaftLib\" title=\"RaftLib\">RaftLib</a></li>\n<li><a href=\"/wiki/Unified_Parallel_C\" title=\"Unified Parallel C\">UPC</a></li>\n<li><a href=\"/wiki/Threading_Building_Blocks\" title=\"Threading Building Blocks\">TBB</a></li>\n<li><a href=\"/wiki/ZPL_(programming_language)\" title=\"ZPL (programming language)\">ZPL</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Problems</th><td class=\"navbox-list navbox-even\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Deadlock\" title=\"Deadlock\">Deadlock</a></li>\n<li><a href=\"/wiki/Deadlock#Livelock\" title=\"Deadlock\">Livelock</a></li>\n<li><a href=\"/wiki/Deterministic_algorithm\" title=\"Deterministic algorithm\">Deterministic algorithm</a></li>\n<li><a href=\"/wiki/Embarrassingly_parallel\" title=\"Embarrassingly parallel\">Embarrassingly parallel</a></li>\n<li><a href=\"/wiki/Parallel_slowdown\" title=\"Parallel slowdown\">Parallel slowdown</a></li>\n<li><a href=\"/wiki/Race_condition#Computing\" title=\"Race condition\">Race condition</a></li>\n<li><a href=\"/wiki/Software_lockout\" title=\"Software lockout\">Software lockout</a></li>\n<li><a href=\"/wiki/Scalability\" title=\"Scalability\">Scalability</a></li>\n<li><a href=\"/wiki/Starvation_(computer_science)\" title=\"Starvation (computer science)\">Starvation</a></li></ul>\n</div></td></tr><tr><td class=\"navbox-abovebelow\" colspan=\"2\"><div>\n<ul><li><img alt=\"Category\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png\" title=\"Category\" width=\"16\" height=\"14\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x\" data-file-width=\"36\" data-file-height=\"31\" />&#160;<a href=\"/wiki/Category:Parallel_computing\" title=\"Category:Parallel computing\">Category: parallel computing</a></li>\n<li><img alt=\"Commons page\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png\" title=\"Commons page\" width=\"12\" height=\"16\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x\" data-file-width=\"1024\" data-file-height=\"1376\" /> Media related to <a href=\"https://commons.wikimedia.org/wiki/Category:Parallel_computing\" class=\"extiw\" title=\"c:Category:Parallel computing\">Parallel computing</a> at Wikimedia Commons</li></ul>\n</div></td></tr></tbody></table></div>\n\n<!-- \nNewPP limit report\nParsed by mw2194\nCached time: 20180918005424\nCache expiry: 1900800\nDynamic content: false\nCPU time usage: 0.236 seconds\nReal time usage: 0.303 seconds\nPreprocessor visited node count: 924/1000000\nPreprocessor generated node count: 0/1500000\nPost\u2010expand include size: 49527/2097152 bytes\nTemplate argument size: 147/2097152 bytes\nHighest expansion depth: 7/40\nExpensive parser function count: 1/500\nUnstrip recursion depth: 0/20\nUnstrip post\u2010expand size: 14318/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.095/10.000 seconds\nLua memory usage: 4.08 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  202.622      1 -total\n 51.43%  104.218      1 Template:Reflist\n 23.52%   47.659      1 Template:Refimprove\n 15.12%   30.637      1 Template:Cite_conference\n 14.41%   29.195      1 Template:Ambox\n 13.74%   27.850      6 Template:Cite_book\n 12.13%   24.584      1 Template:Parallel_computing\n 10.38%   21.025      1 Template:Navbox\n  7.10%   14.380      3 Template:Cite_journal\n  6.14%   12.444      4 Template:Main_article\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:4726017-0!canonical and timestamp 20180918005424 and revision id 848867513\n -->\n</div>"},"langlinks":[{"lang":"ar","url":"https://ar.wikipedia.org/wiki/%D8%AA%D8%B2%D8%A7%D9%85%D9%86_(%D8%B9%D9%84%D9%85_%D8%A7%D9%84%D8%AD%D8%A7%D8%B3%D9%88%D8%A8)","langname":"Arabic","autonym":"\u0627\u0644\u0639\u0631\u0628\u064a\u0629","*":"\u062a\u0632\u0627\u0645\u0646 (\u0639\u0644\u0645 \u0627\u0644\u062d\u0627\u0633\u0648\u0628)"},{"lang":"cs","url":"https://cs.wikipedia.org/wiki/Synchronizace_(informatika)","langname":"Czech","autonym":"\u010de\u0161tina","*":"Synchronizace (informatika)"},{"lang":"de","url":"https://de.wikipedia.org/wiki/Prozesssynchronisation","langname":"German","autonym":"Deutsch","*":"Prozesssynchronisation"},{"lang":"fa","url":"https://fa.wikipedia.org/wiki/%D9%87%D9%85%DA%AF%D8%A7%D9%85%E2%80%8C%D8%B3%D8%A7%D8%B2%DB%8C_(%D8%B9%D9%84%D9%88%D9%85_%D8%B1%D8%A7%DB%8C%D8%A7%D9%86%D9%87)","langname":"Persian","autonym":"\u0641\u0627\u0631\u0633\u06cc","*":"\u0647\u0645\u06af\u0627\u0645\u200c\u0633\u0627\u0632\u06cc (\u0639\u0644\u0648\u0645 \u0631\u0627\u06cc\u0627\u0646\u0647)"},{"lang":"fr","url":"https://fr.wikipedia.org/wiki/Synchronisation_(multit%C3%A2ches)","langname":"French","autonym":"fran\u00e7ais","*":"Synchronisation (multit\u00e2ches)"},{"lang":"hr","url":"https://hr.wikipedia.org/wiki/Sinkronizacija_(ra%C4%8Dunalstvo)","langname":"Croatian","autonym":"hrvatski","*":"Sinkronizacija (ra\u010dunalstvo)"},{"lang":"it","url":"https://it.wikipedia.org/wiki/Sincronizzazione","langname":"Italian","autonym":"italiano","*":"Sincronizzazione"},{"lang":"he","url":"https://he.wikipedia.org/wiki/%D7%A1%D7%A0%D7%9B%D7%A8%D7%95%D7%9F_(%D7%9E%D7%93%D7%A2%D7%99_%D7%94%D7%9E%D7%97%D7%A9%D7%91)","langname":"Hebrew","autonym":"\u05e2\u05d1\u05e8\u05d9\u05ea","*":"\u05e1\u05e0\u05db\u05e8\u05d5\u05df (\u05de\u05d3\u05e2\u05d9 \u05d4\u05de\u05d7\u05e9\u05d1)"},{"lang":"ja","url":"https://ja.wikipedia.org/wiki/%E5%90%8C%E6%9C%9F_(%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%A6)","langname":"Japanese","autonym":"\u65e5\u672c\u8a9e","*":"\u540c\u671f (\u8a08\u7b97\u6a5f\u79d1\u5b66)"},{"lang":"no","url":"https://no.wikipedia.org/wiki/Synkronisering_(informatikk)","langname":"Norwegian","autonym":"norsk","*":"Synkronisering (informatikk)"},{"lang":"pt","url":"https://pt.wikipedia.org/wiki/Sincroniza%C3%A7%C3%A3o_(ci%C3%AAncia_da_computa%C3%A7%C3%A3o)","langname":"Portuguese","autonym":"portugu\u00eas","*":"Sincroniza\u00e7\u00e3o (ci\u00eancia da computa\u00e7\u00e3o)"},{"lang":"ru","url":"https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BD%D1%85%D1%80%D0%BE%D0%BD%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_(%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)","langname":"Russian","autonym":"\u0440\u0443\u0441\u0441\u043a\u0438\u0439","*":"\u0421\u0438\u043d\u0445\u0440\u043e\u043d\u0438\u0437\u0430\u0446\u0438\u044f (\u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0442\u0438\u043a\u0430)"},{"lang":"simple","url":"https://simple.wikipedia.org/wiki/Synchronization_(computer_science)","langname":"Simple English","autonym":"Simple English","*":"Synchronization (computer science)"},{"lang":"fi","url":"https://fi.wikipedia.org/wiki/Synkronointi_(ohjelmointi)","langname":"Finnish","autonym":"suomi","*":"Synkronointi (ohjelmointi)"},{"lang":"uk","url":"https://uk.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BD%D1%85%D1%80%D0%BE%D0%BD%D1%96%D0%B7%D0%B0%D1%86%D1%96%D1%8F_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%96%D0%B2","langname":"Ukrainian","autonym":"\u0443\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430","*":"\u0421\u0438\u043d\u0445\u0440\u043e\u043d\u0456\u0437\u0430\u0446\u0456\u044f \u043f\u0440\u043e\u0446\u0435\u0441\u0456\u0432"},{"lang":"zh","url":"https://zh.wikipedia.org/wiki/%E5%90%8C%E6%AD%A5_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6)","langname":"Chinese","autonym":"\u4e2d\u6587","*":"\u540c\u6b65 (\u8ba1\u7b97\u673a\u79d1\u5b66)"}],"categories":[{"sortkey":"","hidden":"","*":"CS1_maint:_Multiple_names:_authors_list"},{"sortkey":"","hidden":"","*":"Articles_needing_additional_references_from_November_2014"},{"sortkey":"","hidden":"","*":"All_articles_needing_additional_references"},{"sortkey":"","*":"Concurrency_(computer_science)"},{"sortkey":"","*":"Communication"},{"sortkey":"Computer science","*":"Synchronization"},{"sortkey":"","*":"Edsger_W._Dijkstra"}],"links":[{"ns":14,"exists":"","*":"Category:Articles needing additional references from November 2014"},{"ns":14,"exists":"","*":"Category:CS1 maint: Multiple names: authors list"},{"ns":14,"exists":"","*":"Category:Parallel computing"},{"ns":10,"exists":"","*":"Template:Parallel computing"},{"ns":0,"exists":"","*":".NET framework"},{"ns":0,"exists":"","*":"API"},{"ns":0,"exists":"","*":"Ada (programming language)"},{"ns":0,"exists":"","*":"Amdahl's law"},{"ns":0,"exists":"","*":"Analysis of parallel algorithms"},{"ns":0,"exists":"","*":"Application checkpointing"},{"ns":0,"exists":"","*":"Application programming interface"},{"ns":0,"exists":"","*":"Array data structure"},{"ns":0,"exists":"","*":"Asymmetric multiprocessing"},{"ns":0,"exists":"","*":"Ateji PX"},{"ns":0,"exists":"","*":"Barrier (computer science)"},{"ns":0,"exists":"","*":"Bit-level parallelism"},{"ns":0,"exists":"","*":"Boost (C++ libraries)"},{"ns":0,"exists":"","*":"Bulldozer (microarchitecture)"},{"ns":0,"exists":"","*":"Busy waiting"},{"ns":0,"exists":"","*":"C++ AMP"},{"ns":0,"exists":"","*":"CUDA"},{"ns":0,"exists":"","*":"Cache-only memory architecture"},{"ns":0,"exists":"","*":"Cache (computing)"},{"ns":0,"exists":"","*":"Cache coherence"},{"ns":0,"exists":"","*":"Cache coherency"},{"ns":0,"exists":"","*":"Cache invalidation"},{"ns":0,"exists":"","*":"Chapel (programming language)"},{"ns":0,"exists":"","*":"Charm++"},{"ns":0,"exists":"","*":"Cilk"},{"ns":0,"exists":"","*":"Cloud computing"},{"ns":0,"exists":"","*":"Cluster file system"},{"ns":0,"exists":"","*":"Coarray Fortran"},{"ns":0,"exists":"","*":"Compare-and-swap"},{"ns":0,"exists":"","*":"Computer cluster"},{"ns":0,"exists":"","*":"Computer hardware"},{"ns":0,"exists":"","*":"Computer multitasking"},{"ns":0,"exists":"","*":"Computer network"},{"ns":0,"exists":"","*":"Computer programming"},{"ns":0,"exists":"","*":"Computer science"},{"ns":0,"exists":"","*":"Computing cluster"},{"ns":0,"exists":"","*":"Concurrency (computer science)"},{"ns":0,"exists":"","*":"Condition variable"},{"ns":0,"exists":"","*":"Context switch"},{"ns":0,"exists":"","*":"Cost efficiency"},{"ns":0,"exists":"","*":"Critical section"},{"ns":0,"exists":"","*":"Data extraction"},{"ns":0,"exists":"","*":"Data integrity"},{"ns":0,"exists":"","*":"Data parallelism"},{"ns":0,"exists":"","*":"Data synchronization"},{"ns":0,"exists":"","*":"Data transfer"},{"ns":0,"exists":"","*":"Data transformation"},{"ns":0,"exists":"","*":"Database"},{"ns":0,"exists":"","*":"Database replication"},{"ns":0,"exists":"","*":"Dataflow architecture"},{"ns":0,"exists":"","*":"Dataflow programming"},{"ns":0,"exists":"","*":"Dataset"},{"ns":0,"exists":"","*":"Deadlock"},{"ns":0,"exists":"","*":"Deterministic algorithm"},{"ns":0,"exists":"","*":"Digital object identifier"},{"ns":0,"exists":"","*":"Dining philosophers problem"},{"ns":0,"exists":"","*":"Dispatcher"},{"ns":0,"exists":"","*":"Distributed computing"},{"ns":0,"exists":"","*":"Distributed memory"},{"ns":0,"exists":"","*":"Distributed shared memory"},{"ns":0,"exists":"","*":"Dryad (programming)"},{"ns":0,"exists":"","*":"Embarrassingly parallel"},{"ns":0,"exists":"","*":"Event (computing)"},{"ns":0,"exists":"","*":"Explicit parallelism"},{"ns":0,"exists":"","*":"Extract, transform, load"},{"ns":0,"exists":"","*":"Fiber (computer science)"},{"ns":0,"exists":"","*":"File locking"},{"ns":0,"exists":"","*":"File synchronization"},{"ns":0,"exists":"","*":"File system"},{"ns":0,"exists":"","*":"Flynn's taxonomy"},{"ns":0,"exists":"","*":"Fork-join model"},{"ns":0,"exists":"","*":"Futures and promises"},{"ns":0,"exists":"","*":"General-purpose computing on graphics processing units"},{"ns":0,"exists":"","*":"Global Arrays"},{"ns":0,"exists":"","*":"Grid computing"},{"ns":0,"exists":"","*":"Gustafson's law"},{"ns":0,"exists":"","*":"Handshaking"},{"ns":0,"exists":"","*":"Hardware scout"},{"ns":0,"exists":"","*":"History monoid"},{"ns":0,"exists":"","*":"Implicit parallelism"},{"ns":0,"exists":"","*":"Instruction-level parallelism"},{"ns":0,"exists":"","*":"Instruction pipelining"},{"ns":0,"exists":"","*":"Instruction window"},{"ns":0,"exists":"","*":"International Standard Book Number"},{"ns":0,"exists":"","*":"Interrupt"},{"ns":0,"exists":"","*":"Java (programming language)"},{"ns":0,"exists":"","*":"Journaling file system"},{"ns":0,"exists":"","*":"Karp\u2013Flatt metric"},{"ns":0,"exists":"","*":"Linux"},{"ns":0,"exists":"","*":"Lock (computer science)"},{"ns":0,"exists":"","*":"Loop-level parallelism"},{"ns":0,"exists":"","*":"MIMD"},{"ns":0,"exists":"","*":"MISD"},{"ns":0,"exists":"","*":"Manycore processor"},{"ns":0,"exists":"","*":"Massively parallel"},{"ns":0,"exists":"","*":"Memory-level parallelism"},{"ns":0,"exists":"","*":"Memory coherence"},{"ns":0,"exists":"","*":"Message Passing Interface"},{"ns":0,"exists":"","*":"Monitor (synchronization)"},{"ns":0,"exists":"","*":"Multiprocessing"},{"ns":0,"exists":"","*":"Multithreading (computer architecture)"},{"ns":0,"exists":"","*":"Mutual exclusion"},{"ns":0,"exists":"","*":"Non-blocking algorithm"},{"ns":0,"exists":"","*":"Non-uniform memory access"},{"ns":0,"exists":"","*":"OpenACC"},{"ns":0,"exists":"","*":"OpenCL"},{"ns":0,"exists":"","*":"OpenHMPP"},{"ns":0,"exists":"","*":"OpenMP"},{"ns":0,"exists":"","*":"POSIX Threads"},{"ns":0,"exists":"","*":"Parallel Extensions"},{"ns":0,"exists":"","*":"Parallel Virtual Machine"},{"ns":0,"exists":"","*":"Parallel computing"},{"ns":0,"exists":"","*":"Parallel programming model"},{"ns":0,"exists":"","*":"Parallel random-access machine"},{"ns":0,"exists":"","*":"Parallel slowdown"},{"ns":0,"exists":"","*":"Petri net"},{"ns":0,"exists":"","*":"Pipeline (computing)"},{"ns":0,"exists":"","*":"Preemption (computing)"},{"ns":0,"exists":"","*":"Priority inversion"},{"ns":0,"exists":"","*":"Process (computer science)"},{"ns":0,"exists":"","*":"Process (computing)"},{"ns":0,"exists":"","*":"Process calculi"},{"ns":0,"exists":"","*":"Producer\u2013consumer problem"},{"ns":0,"exists":"","*":"Pthreads"},{"ns":0,"exists":"","*":"RAID"},{"ns":0,"exists":"","*":"Race condition"},{"ns":0,"exists":"","*":"RaftLib"},{"ns":0,"exists":"","*":"Read-copy-update"},{"ns":0,"exists":"","*":"Readers\u2013writer lock"},{"ns":0,"exists":"","*":"Readers\u2013writers problem"},{"ns":0,"exists":"","*":"Resource starvation"},{"ns":0,"exists":"","*":"SIMD"},{"ns":0,"exists":"","*":"SISD"},{"ns":0,"exists":"","*":"Scalability"},{"ns":0,"exists":"","*":"Semaphore (programming)"},{"ns":0,"exists":"","*":"Semiconductor memory"},{"ns":0,"exists":"","*":"Shared memory"},{"ns":0,"exists":"","*":"Simultaneous multithreading"},{"ns":0,"exists":"","*":"Single instruction, multiple threads"},{"ns":0,"exists":"","*":"Software lockout"},{"ns":0,"exists":"","*":"Solaris (operating system)"},{"ns":0,"exists":"","*":"Speculative multithreading"},{"ns":0,"exists":"","*":"Speedup"},{"ns":0,"exists":"","*":"Spinlock"},{"ns":0,"exists":"","*":"Starvation (computer science)"},{"ns":0,"exists":"","*":"Stream processing"},{"ns":0,"exists":"","*":"Supercomputer"},{"ns":0,"exists":"","*":"Superscalar processor"},{"ns":0,"exists":"","*":"Symmetric multiprocessing"},{"ns":0,"exists":"","*":"Systolic array"},{"ns":0,"exists":"","*":"Task parallelism"},{"ns":0,"exists":"","*":"Temporal multithreading"},{"ns":0,"exists":"","*":"Test-and-set"},{"ns":0,"exists":"","*":"Thread (computer science)"},{"ns":0,"exists":"","*":"Thread (computing)"},{"ns":0,"exists":"","*":"Threading Building Blocks"},{"ns":0,"exists":"","*":"Timer"},{"ns":0,"exists":"","*":"Turnstiles"},{"ns":0,"exists":"","*":"Unified Parallel C"},{"ns":0,"exists":"","*":"Uniform memory access"},{"ns":0,"exists":"","*":"Uniprocessor system"},{"ns":0,"exists":"","*":"Vector processor"},{"ns":0,"exists":"","*":"Windows"},{"ns":0,"exists":"","*":"ZPL (programming language)"},{"ns":0,"*":"Adaptive mutex"},{"ns":4,"exists":"","*":"Wikipedia:Verifiability"},{"ns":11,"exists":"","*":"Template talk:Parallel computing"},{"ns":12,"exists":"","*":"Help:Introduction to referencing with Wiki Markup/1"},{"ns":12,"exists":"","*":"Help:Maintenance template removal"}],"templates":[{"ns":10,"exists":"","*":"Template:Refimprove"},{"ns":10,"exists":"","*":"Template:More citations needed"},{"ns":10,"exists":"","*":"Template:Ambox"},{"ns":10,"exists":"","*":"Template:Main article"},{"ns":10,"exists":"","*":"Template:Main"},{"ns":10,"exists":"","*":"Template:Reflist"},{"ns":10,"exists":"","*":"Template:Cite conference"},{"ns":10,"exists":"","*":"Template:Cite journal"},{"ns":10,"exists":"","*":"Template:Cite book"},{"ns":10,"exists":"","*":"Template:Cite web"},{"ns":10,"exists":"","*":"Template:Main other"},{"ns":10,"exists":"","*":"Template:Parallel computing"},{"ns":10,"exists":"","*":"Template:Navbox"},{"ns":10,"exists":"","*":"Template:Category-inline"},{"ns":10,"exists":"","*":"Template:Icon"},{"ns":828,"exists":"","*":"Module:Unsubst"},{"ns":828,"exists":"","*":"Module:Message box"},{"ns":828,"exists":"","*":"Module:No globals"},{"ns":828,"exists":"","*":"Module:Yesno"},{"ns":828,"exists":"","*":"Module:Arguments"},{"ns":828,"exists":"","*":"Module:Message box/configuration"},{"ns":828,"exists":"","*":"Module:Category handler"},{"ns":828,"exists":"","*":"Module:Category handler/data"},{"ns":828,"exists":"","*":"Module:Category handler/config"},{"ns":828,"exists":"","*":"Module:Category handler/shared"},{"ns":828,"exists":"","*":"Module:Category handler/blacklist"},{"ns":828,"exists":"","*":"Module:Namespace detect/data"},{"ns":828,"exists":"","*":"Module:Namespace detect/config"},{"ns":828,"exists":"","*":"Module:Main"},{"ns":828,"exists":"","*":"Module:Hatnote"},{"ns":828,"exists":"","*":"Module:Hatnote list"},{"ns":828,"exists":"","*":"Module:Citation/CS1"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Configuration"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Whitelist"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Utilities"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Date validation"},{"ns":828,"exists":"","*":"Module:Citation/CS1/Identifiers"},{"ns":828,"exists":"","*":"Module:Citation/CS1/COinS"},{"ns":828,"exists":"","*":"Module:Check for unknown parameters"},{"ns":828,"exists":"","*":"Module:Navbox"},{"ns":828,"exists":"","*":"Module:Navbar"},{"ns":828,"exists":"","*":"Module:Icon"},{"ns":828,"exists":"","*":"Module:Icon/data"}],"images":["Question_book-new.svg","Multiple_Processes_Accessing_the_shared_resource.png","Shared_Resource_access_in_synchronization_environment.png","Data_Synchronization.png","Folder_Hexagonal_Icon.svg","Commons-logo.svg"],"externallinks":["http://sydney.edu.au/engineering/it/~gramoli/doc/pubs/gramoli-synchrobench.pdf","//doi.org/10.1016/j.camwa.2013.11.008","http://msdn.microsoft.com/en-us/library/ms228964(v=vs.110).aspx","http://ieeexplore.ieee.org.prox.lib.ncsu.edu/stamp/stamp.jsp?tp=&arnumber=6317471&isnumber=6317321","//doi.org/10.1109/ICIEV.2012.6317471","https://lwn.net/Articles/262464/","http://sunsite.uakom.sk/sunworldonline/swol-08-1999/swol-08-insidesolaris.html","http://hpcg-benchmark.org/","https://web.archive.org/web/20090209170415/http://ibm.com/developerworks/linux/library/l-linux-synchronization.html","http://greenteapress.com/semaphores/"],"sections":[{"toclevel":1,"level":"2","line":"The need for synchronization","number":"1","index":"1","fromtitle":"Synchronization_(computer_science)","byteoffset":687,"anchor":"The_need_for_synchronization"},{"toclevel":1,"level":"2","line":"Thread or process synchronization","number":"2","index":"2","fromtitle":"Synchronization_(computer_science)","byteoffset":1794,"anchor":"Thread_or_process_synchronization"},{"toclevel":1,"level":"2","line":"Minimizing synchronization","number":"3","index":"3","fromtitle":"Synchronization_(computer_science)","byteoffset":5324,"anchor":"Minimizing_synchronization"},{"toclevel":2,"level":"3","line":"Classic problems of synchronization","number":"3.1","index":"4","fromtitle":"Synchronization_(computer_science)","byteoffset":6514,"anchor":"Classic_problems_of_synchronization"},{"toclevel":2,"level":"3","line":"Hardware synchronization","number":"3.2","index":"5","fromtitle":"Synchronization_(computer_science)","byteoffset":6945,"anchor":"Hardware_synchronization"},{"toclevel":2,"level":"3","line":"Synchronization strategies in programming languages","number":"3.3","index":"6","fromtitle":"Synchronization_(computer_science)","byteoffset":9061,"anchor":"Synchronization_strategies_in_programming_languages"},{"toclevel":2,"level":"3","line":"Implementation of Synchronization","number":"3.4","index":"7","fromtitle":"Synchronization_(computer_science)","byteoffset":10952,"anchor":"Implementation_of_Synchronization"},{"toclevel":3,"level":"4","line":"Spinlock","number":"3.4.1","index":"8","fromtitle":"Synchronization_(computer_science)","byteoffset":10995,"anchor":"Spinlock"},{"toclevel":3,"level":"4","line":"Barriers","number":"3.4.2","index":"9","fromtitle":"Synchronization_(computer_science)","byteoffset":11755,"anchor":"Barriers"},{"toclevel":3,"level":"4","line":"Semaphores","number":"3.4.3","index":"10","fromtitle":"Synchronization_(computer_science)","byteoffset":13886,"anchor":"Semaphores"},{"toclevel":2,"level":"3","line":"Mathematical foundations","number":"3.5","index":"11","fromtitle":"Synchronization_(computer_science)","byteoffset":14813,"anchor":"Mathematical_foundations"},{"toclevel":2,"level":"3","line":"Synchronization examples","number":"3.6","index":"12","fromtitle":"Synchronization_(computer_science)","byteoffset":15931,"anchor":"Synchronization_examples"},{"toclevel":3,"level":"4","line":"Synchronization in Windows","number":"3.6.1","index":"13","fromtitle":"Synchronization_(computer_science)","byteoffset":16337,"anchor":"Synchronization_in_Windows"},{"toclevel":3,"level":"4","line":"Synchronization in Linux","number":"3.6.2","index":"14","fromtitle":"Synchronization_(computer_science)","byteoffset":16763,"anchor":"Synchronization_in_Linux"},{"toclevel":3,"level":"4","line":"Synchronization in Solaris","number":"3.6.3","index":"15","fromtitle":"Synchronization_(computer_science)","byteoffset":17475,"anchor":"Synchronization_in_Solaris"},{"toclevel":3,"level":"4","line":"Pthreads synchronization","number":"3.6.4","index":"16","fromtitle":"Synchronization_(computer_science)","byteoffset":18055,"anchor":"Pthreads_synchronization"},{"toclevel":1,"level":"2","line":"Data synchronization","number":"4","index":"17","fromtitle":"Synchronization_(computer_science)","byteoffset":18265,"anchor":"Data_synchronization"},{"toclevel":2,"level":"3","line":"Challenges in data synchronization","number":"4.1","index":"18","fromtitle":"Synchronization_(computer_science)","byteoffset":19631,"anchor":"Challenges_in_data_synchronization"},{"toclevel":3,"level":"4","line":"Data formats complexity","number":"4.1.1","index":"19","fromtitle":"Synchronization_(computer_science)","byteoffset":19835,"anchor":"Data_formats_complexity"},{"toclevel":3,"level":"4","line":"Real-timeliness","number":"4.1.2","index":"20","fromtitle":"Synchronization_(computer_science)","byteoffset":20290,"anchor":"Real-timeliness"},{"toclevel":3,"level":"4","line":"Data security","number":"4.1.3","index":"21","fromtitle":"Synchronization_(computer_science)","byteoffset":20885,"anchor":"Data_security"},{"toclevel":3,"level":"4","line":"Data quality","number":"4.1.4","index":"22","fromtitle":"Synchronization_(computer_science)","byteoffset":21500,"anchor":"Data_quality"},{"toclevel":3,"level":"4","line":"Performance","number":"4.1.5","index":"23","fromtitle":"Synchronization_(computer_science)","byteoffset":21835,"anchor":"Performance"},{"toclevel":1,"level":"2","line":"See also","number":"5","index":"24","fromtitle":"Synchronization_(computer_science)","byteoffset":22285,"anchor":"See_also"},{"toclevel":1,"level":"2","line":"References","number":"6","index":"25","fromtitle":"Synchronization_(computer_science)","byteoffset":22383,"anchor":"References"},{"toclevel":1,"level":"2","line":"External links","number":"7","index":"26","fromtitle":"Synchronization_(computer_science)","byteoffset":22569,"anchor":"External_links"}],"parsewarnings":[],"displaytitle":"Synchronization (computer science)","iwlinks":[{"prefix":"c","url":"https://commons.wikimedia.org/wiki/Category:Parallel_computing","*":"c:Category:Parallel computing"}],"properties":[{"name":"wikibase_item","*":"Q650462"}]}}